{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.signal import butter, filtfilt, welch\nfrom scipy.stats import entropy\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\nimport math\n\n# Configuration\nclass Config:\n    base_path = '/kaggle/input/mtcaic3'\n    task = 'MI'\n    channels = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n    sample_rate = 250\n    mi_trial_length = 2250\n    batch_size = 32\n    lr = 0.0005  # Reduced learning rate\n    epochs = 200\n    patience = 20  # Increased patience\n    noise_std = 0.15  # Adjusted noise\n    max_shift = 25    # Increased time shift\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    checkpoint_path = '/kaggle/working/best_model.pth'\n    history_path = '/kaggle/working/training_history.csv'\n    max_grad_norm = 1.0  # Gradient clipping\n    dropout_rate = 0.5  # Increased dropout\n\nconfig = Config()\n\n# Bandpass Filter Setup\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\nmu_b, mu_a = butter_bandpass(8, 13, config.sample_rate)\nbeta_b, beta_a = butter_bandpass(13, 30, config.sample_rate)\n\n# Feature Extraction Functions\ndef compute_band_power(data, b, a):\n    filtered = filtfilt(b, a, data)\n    return np.mean(filtered ** 2)\n\ndef compute_spectral_entropy(data, fs=250):\n    f, psd = welch(data, fs=fs, nperseg=min(256, len(data)))\n    psd_norm = psd / psd.sum()\n    return entropy(psd_norm)\n\ndef hjorth_parameters(data):\n    first_deriv = np.diff(data)\n    second_deriv = np.diff(first_deriv)\n    \n    activity = np.var(data)\n    mobility = np.sqrt(np.var(first_deriv) / activity)\n    complexity = np.sqrt(np.var(second_deriv) / np.var(first_deriv)) / mobility\n    \n    return activity, mobility, complexity\n\ndef extract_features(eeg_data):\n    \"\"\"Extract enhanced features from 8-channel EEG data\"\"\"\n    features = []\n    n_channels = eeg_data.shape[0]\n    \n    # Band powers (Mu and Beta)\n    mu_powers = []\n    beta_powers = []\n    for i in range(n_channels):\n        channel_data = eeg_data[i]\n        mu_power = compute_band_power(channel_data, mu_b, mu_a)\n        beta_power = compute_band_power(channel_data, beta_b, beta_a)\n        mu_powers.append(mu_power)\n        beta_powers.append(beta_power)\n    \n    # Power differences (C3-C4)\n    c3_idx, c4_idx = config.channels.index('C3'), config.channels.index('C4')\n    mu_diff = mu_powers[c3_idx] - mu_powers[c4_idx]\n    beta_diff = beta_powers[c3_idx] - beta_powers[c4_idx]\n    \n    # Asymmetry indices\n    mu_asym = (mu_powers[c3_idx] - mu_powers[c4_idx]) / (mu_powers[c3_idx] + mu_powers[c4_idx] + 1e-10)\n    beta_asym = (beta_powers[c3_idx] - beta_powers[c4_idx]) / (beta_powers[c3_idx] + beta_powers[c4_idx] + 1e-10)\n    \n    # Band power ratios\n    mu_ratios = [mu / (mu + beta + 1e-10) for mu, beta in zip(mu_powers, beta_powers)]\n    \n    # Time-domain features\n    means = np.mean(eeg_data, axis=1)\n    variances = np.var(eeg_data, axis=1)\n    rms = np.sqrt(np.mean(eeg_data ** 2, axis=1))\n    \n    # Hjorth parameters\n    hjorth_features = []\n    for i in range(n_channels):\n        activity, mobility, complexity = hjorth_parameters(eeg_data[i])\n        hjorth_features.extend([activity, mobility, complexity])\n    \n    # Spectral entropy\n    spectral_entropies = [compute_spectral_entropy(eeg_data[i]) for i in range(n_channels)]\n    \n    # Assemble feature vector (84 features total)\n    features.extend(mu_powers)           # 8\n    features.extend(beta_powers)         # 8\n    features.extend([mu_diff, beta_diff, mu_asym, beta_asym])  # 4\n    features.extend(mu_ratios)           # 8\n    features.extend(means)               # 8\n    features.extend(variances)           # 8\n    features.extend(rms)                 # 8\n    features.extend(hjorth_features)     # 24\n    features.extend(spectral_entropies)  # 8\n    \n    return np.array(features)\n\n# Dataset Class with Fixed Feature Size Handling\nclass MIDataset(Dataset):\n    def __init__(self, df, base_path, eeg_scaler=None, feature_scaler=None, augment=False):\n        self.df = df\n        self.base_path = base_path\n        self.augment = augment\n        self.eeg_scaler = eeg_scaler\n        self.feature_scaler = feature_scaler\n        \n        # Store raw EEGs and labels\n        self.raw_eegs = []\n        self.labels = []\n        \n        for _, row in tqdm(df.iterrows(), total=len(df)):\n            eeg_data = self.load_eeg_data(row)\n            label = self.map_label(row['label'])\n            self.raw_eegs.append(eeg_data)\n            self.labels.append(label)\n            \n        # Initialize EEG scaler (per-channel normalization)\n        if eeg_scaler is None:\n            # Create array of shape (n_trials * time_points, channels)\n            all_eeg = np.vstack([eeg.T for eeg in self.raw_eegs])\n            self.eeg_scaler = StandardScaler()\n            self.eeg_scaler.fit(all_eeg)\n        else:\n            self.eeg_scaler = eeg_scaler\n            \n        # Precompute features for scaling\n        scaled_eegs = [self.eeg_scaler.transform(eeg.T).T for eeg in self.raw_eegs]\n        features_list = [extract_features(eeg) for eeg in scaled_eegs]\n        \n        # Initialize feature scaler\n        if feature_scaler is None:\n            self.feature_scaler = StandardScaler()\n            self.feature_scaler.fit(np.array(features_list))\n        else:\n            self.feature_scaler = feature_scaler\n            \n        # Save feature dimension for model initialization\n        self.feature_dim = len(features_list[0])\n    \n    def map_label(self, label_str):\n        # Only Left and Right classes for MI\n        mapping = {'Left': 0, 'Right': 1}\n        return mapping[label_str]\n    \n    def load_eeg_data(self, row):\n        # Determine dataset split\n        id_num = row['id']\n        if id_num <= 4800:\n            split = 'train'\n        elif id_num <= 4900:\n            split = 'validation'\n        else:\n            split = 'test'\n        \n        # Build file path\n        eeg_path = os.path.join(\n            self.base_path, \n            row['task'], \n            split,\n            row['subject_id'],\n            str(row['trial_session']),\n            'EEGdata.csv'\n        )\n        \n        # Load and extract trial data\n        full_data = pd.read_csv(eeg_path)\n        start_idx = (row['trial'] - 1) * config.mi_trial_length\n        end_idx = start_idx + config.mi_trial_length\n        trial_data = full_data.iloc[start_idx:end_idx][config.channels].values.T\n        return trial_data.astype(np.float32)\n    \n    def __len__(self):\n        return len(self.raw_eegs)\n    \n    def __getitem__(self, idx):\n        eeg = self.raw_eegs[idx].copy()\n        label = self.labels[idx]\n        \n        # Data augmentation\n        if self.augment:\n            # Time shifting\n            shift = np.random.randint(-config.max_shift, config.max_shift + 1)\n            if shift != 0:\n                eeg = np.roll(eeg, shift, axis=1)\n            \n            # Gaussian noise\n            noise = np.random.normal(0, config.noise_std, eeg.shape)\n            eeg += noise\n            \n            # Random frequency filtering\n            if np.random.rand() > 0.5:\n                cutoff = np.random.uniform(5, 20)\n                b, a = butter_bandpass(cutoff, min(cutoff+15, 40), config.sample_rate, order=3)\n                for i in range(eeg.shape[0]):\n                    eeg[i] = filtfilt(b, a, eeg[i])\n            \n            # Random amplitude scaling\n            if np.random.rand() > 0.7:\n                scale = np.random.uniform(0.8, 1.2)\n                eeg *= scale\n        \n        # Apply EEG scaling\n        eeg_scaled = self.eeg_scaler.transform(eeg.T).T\n        \n        # Extract and scale features\n        features = extract_features(eeg_scaled)\n        features_scaled = self.feature_scaler.transform(features.reshape(1, -1)).flatten()\n        \n        return (\n            torch.tensor(eeg_scaled, dtype=torch.float32),\n            torch.tensor(features_scaled, dtype=torch.float32),\n            torch.tensor(label, dtype=torch.long)\n        )\n\n# Enhanced Hybrid Model Architecture with ShallowConvNet\nclass ShallowConvNet(nn.Module):\n    def __init__(self, num_channels, time_length):\n        super().__init__()\n        self.conv1 = nn.Conv1d(num_channels, 40, kernel_size=25, padding=12)\n        self.conv2 = nn.Conv1d(40, 40, kernel_size=1)\n        self.pool = nn.AvgPool1d(kernel_size=75, stride=15)\n        self.dropout = nn.Dropout(config.dropout_rate)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = torch.square(x)  # Square activation\n        x = self.pool(x)\n        x = torch.log(torch.clamp(x, min=1e-6))  # Safe log\n        x = self.dropout(x)\n        return x\n\nclass HybridModel(nn.Module):\n    def __init__(self, num_channels, time_length, num_features, num_classes):\n        super().__init__()\n        \n        # CNN Branch (ShallowConvNet style)\n        self.cnn = ShallowConvNet(num_channels, time_length)\n        \n        # Calculate CNN output size\n        with torch.no_grad():\n            dummy = torch.randn(1, num_channels, time_length)\n            cnn_out = self.cnn(dummy)\n            cnn_out_size = cnn_out.view(1, -1).shape[1]\n        \n        # CNN classifier\n        self.cnn_classifier = nn.Sequential(\n            nn.Linear(cnn_out_size, 128),\n            nn.ELU(),\n            nn.Dropout(config.dropout_rate),\n            nn.Linear(128, 64)\n        )\n        \n        # MLP Branch for engineered features\n        self.mlp = nn.Sequential(\n            nn.Linear(num_features, 128),\n            nn.ELU(),\n            nn.Dropout(config.dropout_rate),\n            nn.Linear(128, 64)\n        )\n        \n        # Combined Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(64 + 64, 128),\n            nn.ELU(),\n            nn.Dropout(config.dropout_rate),\n            nn.Linear(128, num_classes)\n        )\n    \n    def forward(self, eeg, features):\n        # CNN processing\n        cnn_out = self.cnn(eeg)\n        cnn_out = cnn_out.view(cnn_out.size(0), -1)\n        cnn_out = self.cnn_classifier(cnn_out)\n        \n        # MLP processing\n        mlp_out = self.mlp(features)\n        \n        # Combine and classify\n        combined = torch.cat((cnn_out, mlp_out), dim=1)\n        return self.classifier(combined)\n\n# Enhanced Training Function with Focal Loss\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = (1 - pt) ** self.gamma * ce_loss\n        \n        if self.alpha is not None:\n            focal_loss = self.alpha[targets] * focal_loss\n            \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        return focal_loss\n\ndef train_model():\n    # Load and prepare data\n    train_df = pd.read_csv(os.path.join(config.base_path, 'train.csv'))\n    val_df = pd.read_csv(os.path.join(config.base_path, 'validation.csv'))\n    \n    # Filter for MI task\n    train_df = train_df[train_df['task'] == config.task]\n    val_df = val_df[val_df['task'] == config.task]\n    \n    # Create datasets\n    train_dataset = MIDataset(train_df, config.base_path, augment=True)\n    val_dataset = MIDataset(\n        val_df, config.base_path,\n        eeg_scaler=train_dataset.eeg_scaler,\n        feature_scaler=train_dataset.feature_scaler\n    )\n    \n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2\n    )\n    \n    # Only 2 classes for MI: Left and Right\n    num_classes = 2\n    \n    # Initialize model with correct feature dimension\n    model = HybridModel(\n        num_channels=len(config.channels),\n        time_length=config.mi_trial_length,\n        num_features=train_dataset.feature_dim,\n        num_classes=num_classes\n    ).to(config.device)\n    \n    # Print model summary\n    print(f\"Model initialized with:\")\n    print(f\"- CNN input: {len(config.channels)} channels × {config.mi_trial_length} timepoints\")\n    print(f\"- MLP input: {train_dataset.feature_dim} features\")\n    print(f\"- Output classes: {num_classes}\")\n    print(f\"- Total parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n    \n    # Class weighting for imbalance\n    label_counts = np.bincount(train_dataset.labels)\n    class_weights = 1. / (label_counts + 1e-6)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(config.device)\n    \n    # Use Focal Loss to handle class imbalance\n    criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n    \n    # Optimizer with weight decay\n    optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4)\n    \n    # Learning rate scheduler with longer patience\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=10, verbose=True\n    )\n    \n    # Training state\n    best_f1 = 0.0\n    epochs_no_improve = 0\n    history = []\n    \n    # Training loop\n    for epoch in range(config.epochs):\n        # Training phase\n        model.train()\n        train_loss, train_correct, train_total = 0, 0, 0\n        all_preds, all_labels = [], []\n        \n        for eeg, features, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n            eeg, features, labels = (\n                eeg.to(config.device),\n                features.to(config.device),\n                labels.to(config.device)\n            )\n            \n            # Forward pass\n            outputs = model(eeg, features)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass with gradient clipping\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n            optimizer.step()\n            \n            # Track metrics\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n        \n        # Calculate training metrics\n        train_loss /= len(train_loader)\n        train_acc = train_correct / train_total\n        train_f1 = f1_score(all_labels, all_preds, average='binary')  # Binary for 2 classes\n        \n        # Validation phase\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        all_preds, all_labels = [], []\n        \n        with torch.no_grad():\n            for eeg, features, labels in val_loader:\n                eeg, features, labels = (\n                    eeg.to(config.device),\n                    features.to(config.device),\n                    labels.to(config.device)\n                )\n                \n                outputs = model(eeg, features)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n                all_preds.extend(predicted.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n        \n        # Calculate validation metrics\n        val_loss /= len(val_loader)\n        val_acc = val_correct / val_total\n        val_f1 = f1_score(all_labels, all_preds, average='binary')  # Binary for 2 classes\n        \n        # Update learning rate\n        scheduler.step(val_f1)\n        \n        # Record history\n        history.append({\n            'epoch': epoch + 1,\n            'train_loss': train_loss,\n            'train_acc': train_acc,\n            'train_f1': train_f1,\n            'val_loss': val_loss,\n            'val_acc': val_acc,\n            'val_f1': val_f1,\n            'lr': optimizer.param_groups[0]['lr']\n        })\n        \n        # Print metrics\n        print(f\"Epoch {epoch+1}/{config.epochs}: \"\n              f\"Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} | \"\n              f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f} | \"\n              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n        \n        # Early stopping and checkpointing\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            epochs_no_improve = 0\n            torch.save({\n                'epoch': epoch + 1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_f1': val_f1,\n                'history': history\n            }, config.checkpoint_path)\n            print(f\"Checkpoint saved with F1: {val_f1:.4f}\")\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= config.patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    \n    # Save training history\n    history_df = pd.DataFrame(history)\n    history_df.to_csv(config.history_path, index=False)\n    return history_df\n\n# Run training\nif __name__ == \"__main__\":\n    history = train_model()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:14:45.405705Z","iopub.execute_input":"2025-06-17T18:14:45.406331Z","iopub.status.idle":"2025-06-17T18:26:47.918218Z","shell.execute_reply.started":"2025-06-17T18:14:45.406306Z","shell.execute_reply":"2025-06-17T18:26:47.917386Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2400/2400 [03:34<00:00, 11.18it/s]\n100%|██████████| 50/50 [00:03<00:00, 14.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model initialized with:\n- CNN input: 8 channels × 2250 timepoints\n- MLP input: 84 features\n- Output classes: 2\n- Total parameters: 0.80M\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nEpoch 1: 100%|██████████| 75/75 [00:16<00:00,  4.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200: Train Loss: 0.0003, Train F1: 0.5169 | Val Loss: 0.0001, Val F1: 0.2308 | LR: 0.000500\nCheckpoint saved with F1: 0.2308\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 75/75 [00:14<00:00,  5.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/200: Train Loss: 0.0002, Train F1: 0.5175 | Val Loss: 0.0001, Val F1: 0.5714 | LR: 0.000500\nCheckpoint saved with F1: 0.5714\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 75/75 [00:14<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/200: Train Loss: 0.0002, Train F1: 0.5195 | Val Loss: 0.0001, Val F1: 0.5424 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 75/75 [00:15<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/200: Train Loss: 0.0002, Train F1: 0.4907 | Val Loss: 0.0001, Val F1: 0.2222 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 75/75 [00:15<00:00,  4.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/200: Train Loss: 0.0001, Train F1: 0.5196 | Val Loss: 0.0001, Val F1: 0.3889 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 75/75 [00:15<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/200: Train Loss: 0.0001, Train F1: 0.5176 | Val Loss: 0.0001, Val F1: 0.3636 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 75/75 [00:14<00:00,  5.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/200: Train Loss: 0.0001, Train F1: 0.5104 | Val Loss: 0.0001, Val F1: 0.5283 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 75/75 [00:14<00:00,  5.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/200: Train Loss: 0.0001, Train F1: 0.5034 | Val Loss: 0.0001, Val F1: 0.5714 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 75/75 [00:14<00:00,  5.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/200: Train Loss: 0.0001, Train F1: 0.5338 | Val Loss: 0.0001, Val F1: 0.5263 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 75/75 [00:14<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/200: Train Loss: 0.0001, Train F1: 0.5210 | Val Loss: 0.0001, Val F1: 0.1538 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 75/75 [00:14<00:00,  5.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/200: Train Loss: 0.0001, Train F1: 0.5065 | Val Loss: 0.0001, Val F1: 0.6000 | LR: 0.000500\nCheckpoint saved with F1: 0.6000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 75/75 [00:14<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/200: Train Loss: 0.0001, Train F1: 0.5123 | Val Loss: 0.0001, Val F1: 0.0870 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 75/75 [00:14<00:00,  5.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/200: Train Loss: 0.0001, Train F1: 0.5339 | Val Loss: 0.0001, Val F1: 0.3030 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 75/75 [00:14<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/200: Train Loss: 0.0001, Train F1: 0.5029 | Val Loss: 0.0001, Val F1: 0.5000 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 75/75 [00:15<00:00,  4.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/200: Train Loss: 0.0001, Train F1: 0.5204 | Val Loss: 0.0001, Val F1: 0.4898 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 75/75 [00:14<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/200: Train Loss: 0.0001, Train F1: 0.4911 | Val Loss: 0.0001, Val F1: 0.5667 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 75/75 [00:15<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/200: Train Loss: 0.0001, Train F1: 0.5368 | Val Loss: 0.0001, Val F1: 0.3913 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 75/75 [00:14<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/200: Train Loss: 0.0001, Train F1: 0.5066 | Val Loss: 0.0001, Val F1: 0.5357 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 75/75 [00:15<00:00,  4.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/200: Train Loss: 0.0001, Train F1: 0.5402 | Val Loss: 0.0001, Val F1: 0.4615 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 75/75 [00:14<00:00,  5.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/200: Train Loss: 0.0001, Train F1: 0.5178 | Val Loss: 0.0001, Val F1: 0.5902 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 75/75 [00:14<00:00,  5.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/200: Train Loss: 0.0001, Train F1: 0.5206 | Val Loss: 0.0001, Val F1: 0.5091 | LR: 0.000500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|██████████| 75/75 [00:14<00:00,  5.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/200: Train Loss: 0.0001, Train F1: 0.5531 | Val Loss: 0.0001, Val F1: 0.4898 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|██████████| 75/75 [00:15<00:00,  4.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/200: Train Loss: 0.0001, Train F1: 0.5202 | Val Loss: 0.0001, Val F1: 0.4783 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|██████████| 75/75 [00:14<00:00,  5.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/200: Train Loss: 0.0001, Train F1: 0.5434 | Val Loss: 0.0001, Val F1: 0.4898 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 75/75 [00:14<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/200: Train Loss: 0.0001, Train F1: 0.5067 | Val Loss: 0.0001, Val F1: 0.5098 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|██████████| 75/75 [00:14<00:00,  5.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/200: Train Loss: 0.0001, Train F1: 0.5176 | Val Loss: 0.0001, Val F1: 0.5098 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|██████████| 75/75 [00:14<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/200: Train Loss: 0.0001, Train F1: 0.5027 | Val Loss: 0.0001, Val F1: 0.5098 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28: 100%|██████████| 75/75 [00:15<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/200: Train Loss: 0.0001, Train F1: 0.5087 | Val Loss: 0.0001, Val F1: 0.5385 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29: 100%|██████████| 75/75 [00:14<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/200: Train Loss: 0.0001, Train F1: 0.5495 | Val Loss: 0.0001, Val F1: 0.4878 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30: 100%|██████████| 75/75 [00:15<00:00,  4.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/200: Train Loss: 0.0001, Train F1: 0.5420 | Val Loss: 0.0001, Val F1: 0.4889 | LR: 0.000250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|██████████| 75/75 [00:14<00:00,  5.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/200: Train Loss: 0.0001, Train F1: 0.4994 | Val Loss: 0.0001, Val F1: 0.5098 | LR: 0.000250\nEarly stopping at epoch 31\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}