{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12287666,"sourceType":"datasetVersion","datasetId":7744011}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, classification_report\nfrom mne.decoding import CSP\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import (\n    EarlyStopping,\n    ModelCheckpoint,\n    CSVLogger,\n    LearningRateScheduler,\n)\n\n# --- 1) Config ---\ndata_dir = '/kaggle/input/preprocessed/mtc-aic3_dataset_preprocessed'  # Root of preprocessed dataset\noutput_dir = './models'\nos.makedirs(output_dir, exist_ok=True)\n\n# --- 2) Data Loading Function ---\ndef load_dataset(csv_name, split):\n    \"\"\"Load EEG data and labels from CSV files\"\"\"\n    # Read metadata CSV\n    df = pd.read_csv(os.path.join(data_dir, csv_name))\n    mi_df = df[df['task'] == 'MI']  # Filter for MI tasks\n    \n    X, y = [], []\n    session_cache = {}  # Cache session data to avoid repeated reads\n    \n    # Known EEG channels in the dataset\n    eeg_channels = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n    \n    for _, row in mi_df.iterrows():\n        # Construct EEG data path\n        eeg_path = os.path.join(\n            data_dir, 'MI', split,\n            row['subject_id'], str(row['trial_session']), 'EEGdata.csv'\n        )\n        \n        # Cache session data\n        if eeg_path not in session_cache:\n            try:\n                session_data = pd.read_csv(eeg_path)\n                \n                # Verify and select only EEG channels\n                available_cols = session_data.columns.tolist()\n                keep_cols = [col for col in available_cols if col in eeg_channels or col == 'Time']\n                session_data = session_data[keep_cols]\n                \n                # Drop Time column if exists\n                if 'Time' in session_data.columns:\n                    session_data = session_data.drop(columns=['Time'])\n                \n                # Verify we have exactly 8 channels\n                if len(session_data.columns) != 8:\n                    raise ValueError(f\"Expected 8 channels, found {len(session_data.columns)} in {eeg_path}\")\n                \n                # Reshape to (trials, time, channels)\n                n_trials = 10\n                n_samples = 375\n                total_samples = n_trials * n_samples\n                \n                # Verify data size\n                if len(session_data) != total_samples:\n                    raise ValueError(f\"Unexpected data size in {eeg_path}: \"\n                                    f\"Expected {total_samples} rows, got {len(session_data)}\")\n                \n                # Reshape and store in cache\n                session_cache[eeg_path] = session_data.values.reshape(n_trials, n_samples, len(eeg_channels))\n            except Exception as e:\n                print(f\"Error loading {eeg_path}: {str(e)}\")\n                raise\n        \n        # Extract trial (375 samples, 8 channels)\n        trial_idx = row['trial'] - 1\n        trial_data = session_cache[eeg_path][trial_idx]\n        X.append(trial_data)\n        y.append(row['label'])\n    \n    return np.array(X), np.array(y)\n\n# --- 3) Data Cleaning Function ---\ndef clean_data(X):\n    \"\"\"Remove NaNs, Infs, and handle extreme values\"\"\"\n    print(\"Cleaning data...\")\n    nan_count = np.isnan(X).sum()\n    inf_count = np.isinf(X).sum()\n    \n    if nan_count > 0 or inf_count > 0:\n        print(f\"Cleaning: Found {nan_count} NaNs and {inf_count} Infs\")\n    \n    # Replace NaNs and Infs with channel mean\n    for i in range(X.shape[0]):  # For each trial\n        for j in range(X.shape[2]):  # For each channel\n            channel_data = X[i, :, j]\n            \n            # Find and replace NaNs/Infs\n            mask = np.isnan(channel_data) | np.isinf(channel_data)\n            if np.any(mask):\n                mean_val = np.nanmean(channel_data[~mask])\n                if np.isnan(mean_val) or np.isinf(mean_val):\n                    mean_val = 0.0  # Fallback if mean is still problematic\n                channel_data[mask] = mean_val\n                X[i, :, j] = channel_data\n            \n            # Clip extreme values (±1000μV)\n            np.clip(channel_data, -1000, 1000, out=channel_data)\n    \n    # Verify cleaning results\n    post_nan = np.isnan(X).sum()\n    post_inf = np.isinf(X).sum()\n    \n    if post_nan > 0 or post_inf > 0:\n        print(f\"Warning: Still found {post_nan} NaNs and {post_inf} Infs after cleaning\")\n    else:\n        print(\"Data cleaning successful - no NaNs or Infs remaining\")\n    \n    return X\n\n# --- 4) Data Inspection ---\ndef inspect_data(X, y, name):\n    \"\"\"Print data statistics for quality control\"\"\"\n    print(f\"\\n=== {name} Data Inspection ===\")\n    print(f\"Shape: {X.shape} (trials × samples × channels)\")\n    print(f\"Labels: {np.unique(y, return_counts=True)}\")\n    \n    # Channel statistics\n    channel_names = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n    for i, ch in enumerate(channel_names):\n        chan_data = X[:, :, i]\n        print(f\"{ch}: Min={np.min(chan_data):.2f}μV, \"\n              f\"Max={np.max(chan_data):.2f}μV, \"\n              f\"Mean={np.mean(chan_data):.2f}μV, \"\n              f\"NaNs={np.isnan(chan_data).sum()}, \"\n              f\"Infs={np.isinf(chan_data).sum()}\")\n\n# --- 5) Load and clean data ---\nprint(\"Loading training data...\")\nX_train, y_train = load_dataset('train.csv', 'train')\nprint(\"Loading validation data...\")\nX_val, y_val = load_dataset('validation.csv', 'validation')\n\n# Data inspection\ninspect_data(X_train, y_train, \"Training\")\ninspect_data(X_val, y_val, \"Validation\")\n\n# Clean data\nX_train = clean_data(X_train)\nX_val = clean_data(X_val)\n\n# Binarize labels\ny_train_bin = (y_train == 'Right').astype(int)\ny_val_bin = (y_val == 'Right').astype(int)\n\n# --- 6) CSP (4 components) ---\nprint(\"Applying CSP...\")\nX_train_csp = X_train.transpose(0, 2, 1)  # Convert to (n, 8, 375) for CSP\n\n# Add small noise to prevent singular matrix issues\nX_train_csp += np.random.normal(0, 1e-10, X_train_csp.shape)\n\ncsp = CSP(n_components=4, log=False, norm_trace=False)\ncsp.fit(X_train_csp, y_train_bin)\nW = csp.filters_[:4]\n\ndef apply_csp(X):\n    \"\"\"Apply CSP filters to EEG data\"\"\"\n    X_csp = X.transpose(0, 2, 1)  # Convert to (n, 8, 375)\n    return np.stack([W.dot(ep) for ep in X_csp], axis=0)\n\nprint(\"Transforming training data with CSP...\")\nXtr = apply_csp(X_train).astype('float32')  # (n, 4, 375)\nXtr = Xtr.transpose(0, 2, 1)               # (n, 375, 4) for models\nprint(\"Transforming validation data with CSP...\")\nXvl = apply_csp(X_val).astype('float32')    # (n, 4, 375)\nXvl = Xvl.transpose(0, 2, 1)               # (n, 375, 4)\n\n# --- 7) For Model3 only: add channel axis → (n, T, F=4, 1) ---\nXtr_spec = Xtr[..., np.newaxis]\nXvl_spec = Xvl[..., np.newaxis]\n\n# --- 8) One‑hot labels ---\nytr_oh = keras.utils.to_categorical(y_train_bin, 2)\nyvl_oh = keras.utils.to_categorical(y_val_bin, 2)\n\n# --- 9) Data‑augmentation gens ---\ndef aug_gen(X, y, seed=0, batch_size=32):\n    n = X.shape[0]\n    rng = np.random.RandomState(seed)\n    while True:\n        idx = rng.randint(0, n, batch_size)\n        bx, by = X[idx].copy(), y[idx]\n        # Add Gaussian noise and random scaling\n        bx += rng.normal(0, 0.5, bx.shape)  # Increased noise magnitude\n        bx *= rng.uniform(0.9, 1.1, bx.shape)  # Random scaling\n        yield bx, by\n\ntrain_gen_1d = aug_gen(Xtr, ytr_oh, seed=0, batch_size=64)\ntrain_gen_2d = aug_gen(Xtr_spec, ytr_oh, seed=1, batch_size=64)\n\nsteps_1d = len(Xtr) // 64\nsteps_2d = len(Xtr_spec) // 64\n\n# --- 10) LR schedule ---\ndef cosine_lr(epoch, lr_max=1e-4, epochs=200):  # Lower max LR\n    return lr_max * (1 + np.cos(np.pi * epoch / epochs)) / 2\n\n# --- 11) F1Score metric ---\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        preds = tf.argmax(y_pred, axis=1)\n        labels = tf.argmax(y_true, axis=1)\n        preds = tf.cast(preds, tf.int32)\n        labels = tf.cast(labels, tf.int32)\n\n        tp = tf.reduce_sum(\n            tf.cast(tf.logical_and(preds == 1, labels == 1), tf.float32)\n        )\n        fp = tf.reduce_sum(\n            tf.cast(tf.logical_and(preds == 1, labels == 0), tf.float32)\n        )\n        fn = tf.reduce_sum(\n            tf.cast(tf.logical_and(preds == 0, labels == 1), tf.float32)\n        )\n\n        self.tp.assign_add(tp)\n        self.fp.assign_add(fp)\n        self.fn.assign_add(fn)\n\n    def result(self):\n        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.assign(0.0)\n        self.fp.assign(0.0)\n        self.fn.assign(0.0)\n\n# --- 12) Callbacks factory ---\ndef get_callbacks(name):\n    return [\n        EarlyStopping(\"val_f1_score\", mode=\"max\", patience=20, restore_best_weights=True),\n        ModelCheckpoint(\n            os.path.join(output_dir, f\"best_{name}.h5\"),\n            \"val_f1_score\", mode=\"max\", save_best_only=True\n        ),\n        CSVLogger(os.path.join(output_dir, f\"log_{name}.csv\")),\n        LearningRateScheduler(cosine_lr)\n    ]\n\n# --- 13) Model builders ---\ndef build_modelA(input_shape):\n    m = keras.Sequential([\n        layers.Input(input_shape),\n        layers.Conv1D(32, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(64, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(128,5,activation=\"relu\",padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling1D(),\n        layers.Dense(64, activation=\"relu\", \n                     kernel_regularizer=regularizers.l2(1e-4)),\n        layers.Dropout(0.7),\n        layers.Dense(2, activation=\"softmax\"),\n    ])\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_modelB(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for f in [16,32,64,128,256]:\n        x = layers.Conv1D(f,3,activation=\"relu\",padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.MaxPool1D(2)(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\",\n                         kernel_regularizer=regularizers.l2(1e-4))(x)\n        x = layers.Dropout(0.5)(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model1(input_shape):\n    inp = layers.Input(input_shape+(1,))\n    x = layers.Concatenate()([inp, inp, inp])\n    x = layers.Resizing(32,32)(x)\n    base = keras.applications.ResNet50(\n        include_top=False, weights=\"imagenet\",\n        input_shape=(32,32,3), pooling=\"avg\"\n    )\n    base.trainable = False\n    x = base(x)\n    x = layers.Reshape((1, x.shape[-1]))(x)\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.MultiHeadAttention(num_heads=4,key_dim=32)(x,x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model2(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(32,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model3(input_shape):\n    inp = layers.Input(input_shape)  # (T, F, 1)\n    x = inp\n    for _ in range(5):\n        x = layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model4(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.LSTM(128)(x)\n    for _ in range(4):\n        x = layers.Dense(64, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model5(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for _ in range(3):\n        x = layers.Dense(64, activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model6(input_shape):\n    C3, C4 = 0,2\n    eeg_in = layers.Input(input_shape)\n    c3 = layers.Lambda(lambda x: x[:,:,C3:C3+1])(eeg_in)\n    c4 = layers.Lambda(lambda x: x[:,:,C4:C4+1])(eeg_in)\n    def branch():\n        return models.Sequential([\n            layers.Conv1D(16,250,activation=\"relu\",padding=\"same\"),\n            layers.MaxPool1D(3),\n            layers.Conv1D(32,50,activation=\"relu\",padding=\"same\"),\n            layers.GlobalAveragePooling1D()\n        ])\n    b3, b4 = branch()(c3), branch()(c4)\n    x = layers.Concatenate()([b3,b4])\n    for _ in range(4):\n        x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2,activation=\"softmax\")(x)\n    m = models.Model(eeg_in,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\n# --- 14) Train & eval loop ---\nbuilders = {\n    'modelA': build_modelA,\n    'modelB': build_modelB,\n    'model1': build_model1,\n    'model2': build_model2,\n    'model3': build_model3,\n    'model4': build_model4,\n    'model5': build_model5,\n    'model6': build_model6,\n}\n\nresults = {}\nshape_1d = Xtr.shape[1:]      # (375, 4)\nshape_2d = Xtr_spec.shape[1:] # (375, 4, 1)\n\nprint(\"\\n=== Starting Model Training ===\")\nfor name, build_fn in builders.items():\n    print(f\"\\n>>> Training {name}\")\n    if name == 'model3':\n        model = build_fn(shape_2d)\n        gen   = train_gen_2d\n        steps = steps_2d\n        val_x = Xvl_spec\n    else:\n        model = build_fn(shape_1d)\n        gen   = train_gen_1d\n        steps = steps_1d\n        val_x = Xvl\n\n    # Add model summary\n    model.summary()\n    \n    # Train with error handling\n    try:\n        history = model.fit(\n            gen,\n            steps_per_epoch=steps,\n            validation_data=(val_x, yvl_oh),\n            epochs=100,  # Reduced epochs for faster iteration\n            callbacks=get_callbacks(name),\n            verbose=2\n        )\n\n        # Evaluate best model\n        preds = np.argmax(model.predict(val_x), axis=1)\n        f1 = f1_score(y_val_bin, preds)\n        print(f\"{name} → val F1 = {f1:.4f}\")\n        print(classification_report(y_val_bin, preds, target_names=['Left','Right']))\n        results[name] = (f1, model)\n    except Exception as e:\n        print(f\"Error training {name}: {str(e)}\")\n        results[name] = (0.0, None)\n\n# --- 15) Save best model ---\n# Filter out failed models\nsuccessful_results = {k: v for k, v in results.items() if v[0] > 0}\nif successful_results:\n    best_name, (best_f1, best_model) = max(successful_results.items(), key=lambda kv: kv[1][0])\n    print(f\"\\n=== Final best: {best_name} (F1={best_f1:.4f}) ===\")\n    best_model.save(os.path.join(output_dir, 'best_final.h5'))\nelse:\n    print(\"\\n!!! No models trained successfully !!!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-27T02:56:29.578482Z","iopub.execute_input":"2025-06-27T02:56:29.579298Z","iopub.status.idle":"2025-06-27T03:20:35.152605Z","shell.execute_reply.started":"2025-06-27T02:56:29.579268Z","shell.execute_reply":"2025-06-27T03:20:35.151682Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nLoading validation data...\n\n=== Training Data Inspection ===\nShape: (2400, 375, 8) (trials × samples × channels)\nLabels: (array(['Left', 'Right'], dtype='<U5'), array([1187, 1213]))\nFZ: Min=225946.38μV, Max=456689.25μV, Mean=298502.13μV, NaNs=0, Infs=0\nC3: Min=223116.38μV, Max=456487.47μV, Mean=301820.80μV, NaNs=0, Infs=0\nCZ: Min=nanμV, Max=nanμV, Mean=nanμV, NaNs=30375, Infs=0\nC4: Min=nanμV, Max=nanμV, Mean=nanμV, NaNs=42375, Infs=0\nPZ: Min=nanμV, Max=nanμV, Mean=nanμV, NaNs=111000, Infs=0\nPO7: Min=178733.77μV, Max=353583.69μV, Mean=288641.41μV, NaNs=0, Infs=0\nOZ: Min=222399.95μV, Max=382140.81μV, Mean=285756.78μV, NaNs=0, Infs=0\nPO8: Min=166140.80μV, Max=358059.41μV, Mean=286186.18μV, NaNs=0, Infs=0\n\n=== Validation Data Inspection ===\nShape: (50, 375, 8) (trials × samples × channels)\nLabels: (array(['Left', 'Right'], dtype='<U5'), array([28, 22]))\nFZ: Min=247211.28μV, Max=325971.16μV, Mean=294708.74μV, NaNs=0, Infs=0\nC3: Min=263503.75μV, Max=350721.59μV, Mean=312971.08μV, NaNs=0, Infs=0\nCZ: Min=nanμV, Max=nanμV, Mean=nanμV, NaNs=3375, Infs=0\nC4: Min=283821.31μV, Max=372027.81μV, Mean=328166.26μV, NaNs=0, Infs=0\nPZ: Min=nanμV, Max=nanμV, Mean=nanμV, NaNs=3750, Infs=0\nPO7: Min=225116.41μV, Max=316227.50μV, Mean=278059.72μV, NaNs=0, Infs=0\nOZ: Min=272238.53μV, Max=437243.16μV, Mean=313413.75μV, NaNs=0, Infs=0\nPO8: Min=258356.77μV, Max=316655.22μV, Mean=288896.72μV, NaNs=0, Infs=0\nCleaning data...\nCleaning: Found 183750 NaNs and 0 Infs\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/537930018.py:101: RuntimeWarning: Mean of empty slice\n  mean_val = np.nanmean(channel_data[~mask])\n","output_type":"stream"},{"name":"stdout","text":"Data cleaning successful - no NaNs or Infs remaining\nCleaning data...\nCleaning: Found 7125 NaNs and 0 Infs\nData cleaning successful - no NaNs or Infs remaining\nApplying CSP...\nComputing rank from data with rank=None\n    Using tolerance 4.7e+03 (2.2e-16 eps * 8 dim * 2.6e+18  max singular value)\n    Estimated rank (data): 8\n    data: rank 8 computed from 8 data channels with 0 projectors\nReducing data rank from 8 -> 8\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\nTransforming training data with CSP...\nTransforming validation data with CSP...\n\n=== Starting Model Training ===\n\n>>> Training modelA\n","output_type":"stream"},{"name":"stderr","text":"2025-06-27 02:56:36.421763: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m672\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m10,304\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m41,088\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,346\u001b[0m (239.63 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,346</span> (239.63 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,898\u001b[0m (237.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,898</span> (237.88 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 8s - 212ms/step - accuracy: 0.5351 - f1_score: 0.6141 - loss: 0.7966 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7000 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 2s - 57ms/step - accuracy: 0.5084 - f1_score: 0.5557 - loss: 0.7450 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7009 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 2s - 56ms/step - accuracy: 0.4975 - f1_score: 0.4958 - loss: 0.7194 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7200 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 2s - 57ms/step - accuracy: 0.5084 - f1_score: 0.5138 - loss: 0.7250 - val_accuracy: 0.4200 - val_f1_score: 0.5397 - val_loss: 0.7519 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 2s - 56ms/step - accuracy: 0.5139 - f1_score: 0.5485 - loss: 0.7118 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7325 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 2s - 56ms/step - accuracy: 0.4996 - f1_score: 0.5482 - loss: 0.7109 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7002 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 2s - 56ms/step - accuracy: 0.4983 - f1_score: 0.5221 - loss: 0.7050 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7037 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 2s - 56ms/step - accuracy: 0.5025 - f1_score: 0.5184 - loss: 0.7063 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7357 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 2s - 57ms/step - accuracy: 0.5101 - f1_score: 0.4727 - loss: 0.7067 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7789 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 2s - 56ms/step - accuracy: 0.5025 - f1_score: 0.4797 - loss: 0.7043 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6990 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 3s - 71ms/step - accuracy: 0.4861 - f1_score: 0.4430 - loss: 0.7034 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7276 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 2s - 58ms/step - accuracy: 0.5097 - f1_score: 0.3775 - loss: 0.7004 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7180 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 2s - 56ms/step - accuracy: 0.4924 - f1_score: 0.3713 - loss: 0.7022 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7023 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 2s - 56ms/step - accuracy: 0.4835 - f1_score: 0.4894 - loss: 0.7013 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7981 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 2s - 56ms/step - accuracy: 0.4979 - f1_score: 0.5737 - loss: 0.6989 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.9737 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 2s - 56ms/step - accuracy: 0.5186 - f1_score: 0.5949 - loss: 0.6967 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 1.2737 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 2s - 56ms/step - accuracy: 0.5287 - f1_score: 0.6287 - loss: 0.6965 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 1.2296 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 2s - 56ms/step - accuracy: 0.4996 - f1_score: 0.6169 - loss: 0.7024 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8375 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 2s - 56ms/step - accuracy: 0.5232 - f1_score: 0.5656 - loss: 0.6985 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7259 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 2s - 56ms/step - accuracy: 0.4949 - f1_score: 0.5689 - loss: 0.7013 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8836 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 2s - 55ms/step - accuracy: 0.5122 - f1_score: 0.6032 - loss: 0.6996 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7361 - learning_rate: 8.3736e-04\nEpoch 22/100\n37/37 - 2s - 56ms/step - accuracy: 0.5215 - f1_score: 0.6070 - loss: 0.6975 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7756 - learning_rate: 8.1479e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\nmodelA → val F1 = 0.6197\n              precision    recall  f1-score   support\n\n        Left       1.00      0.04      0.07        28\n       Right       0.45      1.00      0.62        22\n\n    accuracy                           0.46        50\n   macro avg       0.72      0.52      0.34        50\nweighted avg       0.76      0.46      0.31        50\n\n\n>>> Training modelB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m208\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │              \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m1,568\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │           \u001b[38;5;34m6,208\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m98,560\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2816\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m360,576\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2816</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">360,576</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m504,210\u001b[0m (1.92 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">504,210</span> (1.92 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m503,218\u001b[0m (1.92 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">503,218</span> (1.92 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m992\u001b[0m (3.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> (3.88 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 12s - 315ms/step - accuracy: 0.4941 - f1_score: 0.4975 - loss: 1.1127 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7999 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 2s - 56ms/step - accuracy: 0.5152 - f1_score: 0.5426 - loss: 0.8248 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8512 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 2s - 56ms/step - accuracy: 0.5046 - f1_score: 0.4794 - loss: 0.7679 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8917 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 2s - 56ms/step - accuracy: 0.4958 - f1_score: 0.4048 - loss: 0.7514 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8248 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 2s - 56ms/step - accuracy: 0.5013 - f1_score: 0.3735 - loss: 0.7411 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8774 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 2s - 57ms/step - accuracy: 0.5072 - f1_score: 0.4539 - loss: 0.7368 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8226 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 2s - 56ms/step - accuracy: 0.4966 - f1_score: 0.3598 - loss: 0.7362 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8062 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 2s - 56ms/step - accuracy: 0.4941 - f1_score: 0.3773 - loss: 0.7345 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8183 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 2s - 56ms/step - accuracy: 0.5000 - f1_score: 0.6027 - loss: 0.7344 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8403 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 2s - 56ms/step - accuracy: 0.4932 - f1_score: 0.5851 - loss: 0.7335 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7824 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 2s - 58ms/step - accuracy: 0.5008 - f1_score: 0.4387 - loss: 0.7302 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7611 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 2s - 56ms/step - accuracy: 0.4970 - f1_score: 0.6186 - loss: 0.7343 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7613 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 2s - 56ms/step - accuracy: 0.4932 - f1_score: 0.6106 - loss: 0.7324 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7665 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 2s - 56ms/step - accuracy: 0.5135 - f1_score: 0.6303 - loss: 0.7315 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7659 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 3s - 68ms/step - accuracy: 0.5236 - f1_score: 0.6755 - loss: 0.7301 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7707 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 2s - 62ms/step - accuracy: 0.4932 - f1_score: 0.6462 - loss: 0.7306 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7688 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 2s - 56ms/step - accuracy: 0.5203 - f1_score: 0.6756 - loss: 0.7335 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7638 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 2s - 56ms/step - accuracy: 0.4958 - f1_score: 0.6529 - loss: 0.7297 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7597 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 2s - 56ms/step - accuracy: 0.5228 - f1_score: 0.6698 - loss: 0.7297 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7540 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 2s - 57ms/step - accuracy: 0.5097 - f1_score: 0.6647 - loss: 0.7296 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7537 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 2s - 57ms/step - accuracy: 0.5004 - f1_score: 0.6636 - loss: 0.7295 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7486 - learning_rate: 8.3736e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step\nmodelB → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                           │                        │                │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                           │                        │                │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ resizing (\u001b[38;5;33mResizing\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m23,587,712\u001b[0m │ resizing[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m393,280\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m12,352\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m12,352\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m12,352\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m12,352\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m12,352\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m12,352\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m33,216\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m130\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                           │                        │                │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                           │                        │                │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ resizing[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">393,280</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,216</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,092,610\u001b[0m (91.91 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,092,610</span> (91.91 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m504,898\u001b[0m (1.93 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">504,898</span> (1.93 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 28s - 744ms/step - accuracy: 0.5004 - f1_score: 0.6297 - loss: 0.6934 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6961 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 6s - 150ms/step - accuracy: 0.4865 - f1_score: 0.5575 - loss: 0.6932 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6913 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 5s - 148ms/step - accuracy: 0.4878 - f1_score: 0.4840 - loss: 0.6968 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6907 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 5s - 147ms/step - accuracy: 0.4941 - f1_score: 0.5737 - loss: 0.6915 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7153 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 6s - 165ms/step - accuracy: 0.5220 - f1_score: 0.6367 - loss: 0.6912 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6997 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 5s - 148ms/step - accuracy: 0.5190 - f1_score: 0.6833 - loss: 0.6921 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6991 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 5s - 147ms/step - accuracy: 0.5135 - f1_score: 0.6786 - loss: 0.6914 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7024 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 5s - 148ms/step - accuracy: 0.4975 - f1_score: 0.6188 - loss: 0.6920 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6927 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 5s - 148ms/step - accuracy: 0.5101 - f1_score: 0.0397 - loss: 0.6932 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6896 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 5s - 148ms/step - accuracy: 0.5131 - f1_score: 0.0510 - loss: 0.6924 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6901 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 6s - 167ms/step - accuracy: 0.4928 - f1_score: 0.5244 - loss: 0.6907 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7000 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 5s - 148ms/step - accuracy: 0.5055 - f1_score: 0.0378 - loss: 0.6924 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6937 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 6s - 149ms/step - accuracy: 0.4920 - f1_score: 0.5417 - loss: 0.6931 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6969 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 5s - 147ms/step - accuracy: 0.5245 - f1_score: 0.6881 - loss: 0.6915 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6997 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 5s - 148ms/step - accuracy: 0.5080 - f1_score: 0.6738 - loss: 0.6908 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7140 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 5s - 147ms/step - accuracy: 0.4920 - f1_score: 0.6324 - loss: 0.6906 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6957 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 6s - 166ms/step - accuracy: 0.5118 - f1_score: 0.6568 - loss: 0.6880 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7212 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 5s - 147ms/step - accuracy: 0.5051 - f1_score: 0.6712 - loss: 0.6914 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7059 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 5s - 147ms/step - accuracy: 0.5076 - f1_score: 0.6734 - loss: 0.6921 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7143 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 5s - 148ms/step - accuracy: 0.5059 - f1_score: 0.6719 - loss: 0.6881 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7374 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 5s - 147ms/step - accuracy: 0.5068 - f1_score: 0.6726 - loss: 0.6938 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6932 - learning_rate: 8.3736e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step\nmodel1 → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m416\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m3,104\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m3,104\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,866\u001b[0m (34.63 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,866</span> (34.63 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,866\u001b[0m (34.63 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,866</span> (34.63 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 4s - 113ms/step - accuracy: 0.5089 - f1_score: 0.4123 - loss: 0.6953 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6995 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 1s - 28ms/step - accuracy: 0.5165 - f1_score: 0.6222 - loss: 0.6921 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7342 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 1s - 29ms/step - accuracy: 0.4996 - f1_score: 0.4942 - loss: 0.6939 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7107 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 1s - 27ms/step - accuracy: 0.5127 - f1_score: 0.6148 - loss: 0.6926 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7088 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 1s - 27ms/step - accuracy: 0.5122 - f1_score: 0.2073 - loss: 0.6920 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7230 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 1s - 27ms/step - accuracy: 0.4954 - f1_score: 0.5084 - loss: 0.6917 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6921 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 1s - 27ms/step - accuracy: 0.4903 - f1_score: 0.4271 - loss: 0.6907 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6926 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 1s - 27ms/step - accuracy: 0.5101 - f1_score: 0.6510 - loss: 0.6929 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6991 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 1s - 27ms/step - accuracy: 0.5042 - f1_score: 0.4504 - loss: 0.6912 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6979 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 1s - 28ms/step - accuracy: 0.4932 - f1_score: 0.5787 - loss: 0.6953 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6986 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 1s - 27ms/step - accuracy: 0.5270 - f1_score: 0.6815 - loss: 0.6916 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7026 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 1s - 29ms/step - accuracy: 0.4975 - f1_score: 0.5660 - loss: 0.6897 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7309 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 1s - 27ms/step - accuracy: 0.4970 - f1_score: 0.5799 - loss: 0.6919 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7013 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 1s - 27ms/step - accuracy: 0.5232 - f1_score: 0.1848 - loss: 0.6909 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6911 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 1s - 27ms/step - accuracy: 0.5135 - f1_score: 0.4961 - loss: 0.6892 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.8085 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 1s - 27ms/step - accuracy: 0.5017 - f1_score: 0.4838 - loss: 0.6887 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7486 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 1s - 27ms/step - accuracy: 0.4861 - f1_score: 0.5731 - loss: 0.6907 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7408 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 1s - 27ms/step - accuracy: 0.5021 - f1_score: 0.6037 - loss: 0.6929 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7028 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 1s - 27ms/step - accuracy: 0.5186 - f1_score: 0.5017 - loss: 0.6935 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7016 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 1s - 27ms/step - accuracy: 0.5076 - f1_score: 0.6674 - loss: 0.6906 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7201 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 1s - 27ms/step - accuracy: 0.4903 - f1_score: 0.5298 - loss: 0.6911 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7011 - learning_rate: 8.3736e-04\nEpoch 22/100\n37/37 - 1s - 28ms/step - accuracy: 0.4962 - f1_score: 0.5101 - loss: 0.6900 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7076 - learning_rate: 8.1479e-04\nEpoch 23/100\n37/37 - 1s - 27ms/step - accuracy: 0.5148 - f1_score: 0.6711 - loss: 0.6915 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7019 - learning_rate: 7.9071e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\nmodel2 → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m6,144,128\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144,128</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,191,842\u001b[0m (23.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,191,842</span> (23.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,191,842\u001b[0m (23.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,191,842</span> (23.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 21s - 562ms/step - accuracy: 0.4992 - f1_score: 0.6094 - loss: 0.6946 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7430 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 15s - 407ms/step - accuracy: 0.4992 - f1_score: 0.6023 - loss: 0.6914 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6918 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 16s - 434ms/step - accuracy: 0.5051 - f1_score: 0.6111 - loss: 0.6936 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6960 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 15s - 413ms/step - accuracy: 0.5274 - f1_score: 0.6870 - loss: 0.6886 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6961 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 16s - 428ms/step - accuracy: 0.5080 - f1_score: 0.6686 - loss: 0.6925 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6958 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 15s - 407ms/step - accuracy: 0.5101 - f1_score: 0.6712 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6958 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 16s - 430ms/step - accuracy: 0.5097 - f1_score: 0.6688 - loss: 0.6928 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6954 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 15s - 412ms/step - accuracy: 0.5139 - f1_score: 0.6751 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6951 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 16s - 426ms/step - accuracy: 0.4962 - f1_score: 0.6046 - loss: 0.6923 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6922 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 15s - 407ms/step - accuracy: 0.4941 - f1_score: 0.4898 - loss: 0.6917 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6936 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 16s - 426ms/step - accuracy: 0.4954 - f1_score: 0.5956 - loss: 0.6927 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6941 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 15s - 407ms/step - accuracy: 0.4932 - f1_score: 0.6321 - loss: 0.6923 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6939 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 16s - 419ms/step - accuracy: 0.5038 - f1_score: 0.6549 - loss: 0.6931 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6919 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 16s - 423ms/step - accuracy: 0.5008 - f1_score: 0.5461 - loss: 0.6910 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8289 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 15s - 414ms/step - accuracy: 0.5068 - f1_score: 0.6684 - loss: 0.6939 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6944 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 16s - 437ms/step - accuracy: 0.5169 - f1_score: 0.6774 - loss: 0.6915 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6957 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 15s - 416ms/step - accuracy: 0.5025 - f1_score: 0.6263 - loss: 0.6901 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7114 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 16s - 430ms/step - accuracy: 0.4911 - f1_score: 0.5843 - loss: 0.6914 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6925 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 15s - 414ms/step - accuracy: 0.4924 - f1_score: 0.5858 - loss: 0.6908 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7197 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 16s - 431ms/step - accuracy: 0.5097 - f1_score: 0.6736 - loss: 0.6904 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7101 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 15s - 412ms/step - accuracy: 0.5131 - f1_score: 0.6738 - loss: 0.6904 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6945 - learning_rate: 8.3736e-04\nEpoch 22/100\n37/37 - 16s - 430ms/step - accuracy: 0.5084 - f1_score: 0.6686 - loss: 0.6911 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6957 - learning_rate: 8.1479e-04\nEpoch 23/100\n37/37 - 15s - 414ms/step - accuracy: 0.5266 - f1_score: 0.6852 - loss: 0.6908 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7050 - learning_rate: 7.9071e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790ms/step\nmodel3 → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model4\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m832\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m98,816\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m145,218\u001b[0m (567.26 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145,218</span> (567.26 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m145,218\u001b[0m (567.26 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145,218</span> (567.26 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 25s - 673ms/step - accuracy: 0.4992 - f1_score: 0.5873 - loss: 0.6929 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6952 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 18s - 491ms/step - accuracy: 0.5207 - f1_score: 0.6443 - loss: 0.6921 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7043 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 18s - 491ms/step - accuracy: 0.4924 - f1_score: 0.5223 - loss: 0.6929 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6965 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 18s - 492ms/step - accuracy: 0.5139 - f1_score: 0.6641 - loss: 0.6922 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6954 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 18s - 479ms/step - accuracy: 0.5072 - f1_score: 0.4231 - loss: 0.6907 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6928 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 19s - 502ms/step - accuracy: 0.4916 - f1_score: 0.3377 - loss: 0.6919 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6999 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 18s - 482ms/step - accuracy: 0.5106 - f1_score: 0.6695 - loss: 0.6874 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7169 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 19s - 504ms/step - accuracy: 0.4970 - f1_score: 0.6109 - loss: 0.6902 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7381 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 18s - 484ms/step - accuracy: 0.5013 - f1_score: 0.6663 - loss: 0.6921 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7102 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 18s - 491ms/step - accuracy: 0.5165 - f1_score: 0.6785 - loss: 0.6875 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7417 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 18s - 481ms/step - accuracy: 0.5122 - f1_score: 0.6742 - loss: 0.6915 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7121 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 18s - 495ms/step - accuracy: 0.4983 - f1_score: 0.6175 - loss: 0.6851 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7964 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 18s - 495ms/step - accuracy: 0.5042 - f1_score: 0.4457 - loss: 0.6872 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7209 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 19s - 500ms/step - accuracy: 0.4992 - f1_score: 0.6619 - loss: 0.6912 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7045 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 19s - 505ms/step - accuracy: 0.5144 - f1_score: 0.6768 - loss: 0.6910 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7045 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 18s - 478ms/step - accuracy: 0.5063 - f1_score: 0.6723 - loss: 0.6895 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7139 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 18s - 492ms/step - accuracy: 0.5034 - f1_score: 0.6695 - loss: 0.6938 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6951 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 18s - 480ms/step - accuracy: 0.4894 - f1_score: 0.5457 - loss: 0.6916 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6975 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 19s - 501ms/step - accuracy: 0.5144 - f1_score: 0.0650 - loss: 0.6895 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7181 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 18s - 481ms/step - accuracy: 0.5148 - f1_score: 0.4557 - loss: 0.6913 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7047 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 19s - 502ms/step - accuracy: 0.5063 - f1_score: 0.6505 - loss: 0.6929 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6948 - learning_rate: 8.3736e-04\nEpoch 22/100\n37/37 - 18s - 486ms/step - accuracy: 0.5042 - f1_score: 0.6609 - loss: 0.6917 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6998 - learning_rate: 8.1479e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step\nmodel4 → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m832\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m1,536,064\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536,064</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,619,458\u001b[0m (6.18 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,619,458</span> (6.18 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,619,458\u001b[0m (6.18 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,619,458</span> (6.18 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 14s - 367ms/step - accuracy: 0.4958 - f1_score: 0.4958 - loss: 0.7598 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.9445 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 7s - 191ms/step - accuracy: 0.5220 - f1_score: 0.5207 - loss: 0.7243 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7147 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 7s - 193ms/step - accuracy: 0.5055 - f1_score: 0.5040 - loss: 0.7088 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7055 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 8s - 206ms/step - accuracy: 0.5004 - f1_score: 0.5486 - loss: 0.7044 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6828 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 7s - 188ms/step - accuracy: 0.5013 - f1_score: 0.5278 - loss: 0.7148 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7974 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 7s - 176ms/step - accuracy: 0.5072 - f1_score: 0.4989 - loss: 0.7132 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7114 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 7s - 176ms/step - accuracy: 0.5131 - f1_score: 0.5149 - loss: 0.6950 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7690 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 7s - 189ms/step - accuracy: 0.4878 - f1_score: 0.5035 - loss: 0.7063 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7060 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 7s - 196ms/step - accuracy: 0.4911 - f1_score: 0.5542 - loss: 0.7044 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7048 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 7s - 180ms/step - accuracy: 0.5118 - f1_score: 0.6079 - loss: 0.6977 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6962 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 7s - 179ms/step - accuracy: 0.5177 - f1_score: 0.4906 - loss: 0.6937 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7295 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 7s - 185ms/step - accuracy: 0.5008 - f1_score: 0.4676 - loss: 0.6982 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7079 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 7s - 187ms/step - accuracy: 0.4996 - f1_score: 0.4814 - loss: 0.6951 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8658 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 8s - 208ms/step - accuracy: 0.4941 - f1_score: 0.5346 - loss: 0.6996 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7552 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 7s - 192ms/step - accuracy: 0.4970 - f1_score: 0.5702 - loss: 0.6973 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7021 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 7s - 181ms/step - accuracy: 0.4992 - f1_score: 0.5725 - loss: 0.6969 - val_accuracy: 0.4200 - val_f1_score: 0.5397 - val_loss: 0.6969 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 7s - 190ms/step - accuracy: 0.5059 - f1_score: 0.5034 - loss: 0.6962 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7186 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 7s - 188ms/step - accuracy: 0.5186 - f1_score: 0.4790 - loss: 0.6980 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6821 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 8s - 209ms/step - accuracy: 0.5139 - f1_score: 0.3037 - loss: 0.6921 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6879 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 7s - 190ms/step - accuracy: 0.5135 - f1_score: 0.6108 - loss: 0.6940 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6862 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 7s - 189ms/step - accuracy: 0.5190 - f1_score: 0.4516 - loss: 0.6942 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6838 - learning_rate: 8.3736e-04\nEpoch 22/100\n37/37 - 7s - 190ms/step - accuracy: 0.5101 - f1_score: 0.4082 - loss: 0.6946 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6908 - learning_rate: 8.1479e-04\nEpoch 23/100\n37/37 - 8s - 205ms/step - accuracy: 0.4992 - f1_score: 0.5075 - loss: 0.6930 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7725 - learning_rate: 7.9071e-04\nEpoch 24/100\n37/37 - 7s - 182ms/step - accuracy: 0.4992 - f1_score: 0.4580 - loss: 0.7019 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.8639 - learning_rate: 7.6518e-04\nEpoch 25/100\n37/37 - 7s - 187ms/step - accuracy: 0.5063 - f1_score: 0.5973 - loss: 0.6954 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7106 - learning_rate: 7.3832e-04\nEpoch 26/100\n37/37 - 7s - 189ms/step - accuracy: 0.5025 - f1_score: 0.5524 - loss: 0.7004 - val_accuracy: 0.4400 - val_f1_score: 0.5484 - val_loss: 0.7029 - learning_rate: 7.1022e-04\nEpoch 27/100\n37/37 - 7s - 186ms/step - accuracy: 0.4861 - f1_score: 0.5237 - loss: 0.7024 - val_accuracy: 0.5400 - val_f1_score: 0.0000e+00 - val_loss: 0.7037 - learning_rate: 6.8101e-04\nEpoch 28/100\n37/37 - 8s - 205ms/step - accuracy: 0.5144 - f1_score: 0.4461 - loss: 0.6968 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6860 - learning_rate: 6.5084e-04\nEpoch 29/100\n37/37 - 7s - 187ms/step - accuracy: 0.5084 - f1_score: 0.4983 - loss: 0.6959 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7021 - learning_rate: 6.1987e-04\nEpoch 30/100\n37/37 - 7s - 177ms/step - accuracy: 0.5182 - f1_score: 0.5527 - loss: 0.6928 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7131 - learning_rate: 5.8827e-04\nEpoch 31/100\n37/37 - 7s - 188ms/step - accuracy: 0.5063 - f1_score: 0.5818 - loss: 0.6943 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6920 - learning_rate: 5.5621e-04\nEpoch 32/100\n37/37 - 7s - 190ms/step - accuracy: 0.4966 - f1_score: 0.4440 - loss: 0.6932 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6891 - learning_rate: 5.2388e-04\nEpoch 33/100\n37/37 - 8s - 212ms/step - accuracy: 0.5089 - f1_score: 0.6085 - loss: 0.6927 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7427 - learning_rate: 4.9148e-04\nEpoch 34/100\n37/37 - 7s - 189ms/step - accuracy: 0.5072 - f1_score: 0.5618 - loss: 0.6954 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6966 - learning_rate: 4.5920e-04\nEpoch 35/100\n37/37 - 7s - 189ms/step - accuracy: 0.4924 - f1_score: 0.3460 - loss: 0.6944 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6903 - learning_rate: 4.2723e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step\nmodel5 → val F1 = 0.6197\n              precision    recall  f1-score   support\n\n        Left       1.00      0.04      0.07        28\n       Right       0.45      1.00      0.62        22\n\n    accuracy                           0.46        50\n   macro avg       0.72      0.52      0.34        50\nweighted avg       0.76      0.46      0.31        50\n\n\n>>> Training model6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_9\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m29,648\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m29,648\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_25 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_27 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m130\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">29,648</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">29,648</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,066\u001b[0m (297.13 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,066</span> (297.13 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,066\u001b[0m (297.13 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,066</span> (297.13 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n37/37 - 11s - 293ms/step - accuracy: 0.5169 - f1_score: 0.6266 - loss: 0.6939 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6922 - learning_rate: 0.0010\nEpoch 2/100\n37/37 - 6s - 169ms/step - accuracy: 0.5013 - f1_score: 0.5568 - loss: 0.6960 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6948 - learning_rate: 9.9994e-04\nEpoch 3/100\n37/37 - 5s - 142ms/step - accuracy: 0.5063 - f1_score: 0.6723 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6945 - learning_rate: 9.9969e-04\nEpoch 4/100\n37/37 - 5s - 147ms/step - accuracy: 0.4932 - f1_score: 0.2849 - loss: 0.6935 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6929 - learning_rate: 9.9914e-04\nEpoch 5/100\n37/37 - 5s - 146ms/step - accuracy: 0.4873 - f1_score: 0.3749 - loss: 0.6933 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6923 - learning_rate: 9.9815e-04\nEpoch 6/100\n37/37 - 5s - 136ms/step - accuracy: 0.4772 - f1_score: 0.2320 - loss: 0.6934 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6926 - learning_rate: 9.9661e-04\nEpoch 7/100\n37/37 - 5s - 148ms/step - accuracy: 0.4962 - f1_score: 0.6275 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6940 - learning_rate: 9.9440e-04\nEpoch 8/100\n37/37 - 6s - 166ms/step - accuracy: 0.5135 - f1_score: 0.6786 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6957 - learning_rate: 9.9140e-04\nEpoch 9/100\n37/37 - 6s - 150ms/step - accuracy: 0.5055 - f1_score: 0.6715 - loss: 0.6935 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6942 - learning_rate: 9.8749e-04\nEpoch 10/100\n37/37 - 5s - 145ms/step - accuracy: 0.5127 - f1_score: 0.6778 - loss: 0.6931 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6968 - learning_rate: 9.8256e-04\nEpoch 11/100\n37/37 - 5s - 145ms/step - accuracy: 0.4949 - f1_score: 0.6489 - loss: 0.6935 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6939 - learning_rate: 9.7652e-04\nEpoch 12/100\n37/37 - 5s - 147ms/step - accuracy: 0.5291 - f1_score: 0.6921 - loss: 0.6924 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6993 - learning_rate: 9.6924e-04\nEpoch 13/100\n37/37 - 5s - 147ms/step - accuracy: 0.5127 - f1_score: 0.6778 - loss: 0.6934 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6973 - learning_rate: 9.6066e-04\nEpoch 14/100\n37/37 - 6s - 166ms/step - accuracy: 0.5110 - f1_score: 0.6764 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6965 - learning_rate: 9.5068e-04\nEpoch 15/100\n37/37 - 5s - 145ms/step - accuracy: 0.5211 - f1_score: 0.6852 - loss: 0.6926 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6973 - learning_rate: 9.3923e-04\nEpoch 16/100\n37/37 - 5s - 144ms/step - accuracy: 0.4911 - f1_score: 0.6587 - loss: 0.6938 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6936 - learning_rate: 9.2626e-04\nEpoch 17/100\n37/37 - 5s - 143ms/step - accuracy: 0.5152 - f1_score: 0.6800 - loss: 0.6931 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6947 - learning_rate: 9.1171e-04\nEpoch 18/100\n37/37 - 5s - 142ms/step - accuracy: 0.4970 - f1_score: 0.6640 - loss: 0.6935 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6935 - learning_rate: 8.9555e-04\nEpoch 19/100\n37/37 - 5s - 143ms/step - accuracy: 0.4916 - f1_score: 0.6542 - loss: 0.6932 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6933 - learning_rate: 8.7777e-04\nEpoch 20/100\n37/37 - 6s - 165ms/step - accuracy: 0.5148 - f1_score: 0.6797 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6957 - learning_rate: 8.5837e-04\nEpoch 21/100\n37/37 - 5s - 139ms/step - accuracy: 0.5165 - f1_score: 0.6811 - loss: 0.6927 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6963 - learning_rate: 8.3736e-04\nEpoch 22/100\n37/37 - 5s - 147ms/step - accuracy: 0.5165 - f1_score: 0.6811 - loss: 0.6927 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6971 - learning_rate: 8.1479e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\nmodel6 → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n=== Final best: modelA (F1=0.6197) ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}