{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom scipy import interpolate\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score, f1_score\nfrom tensorflow.keras.layers import (\n    Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n    Dense, Activation, Flatten, Input, Multiply, Add, \n    Concatenate, BatchNormalization, Reshape, Dropout\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers, metrics, losses, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nimport random\n\n# ============================== Data Loading & Preprocessing ==============================\nclass BCICompetitionData:\n    def __init__(self, base_path, task='MI'):\n        self.base_path = base_path\n        self.task = task\n        self.samples_per_trial_original = 2250\n        self.downsample_length = 1050\n        self.channels = ['C3', 'CZ', 'C4']\n        \n    def load_data(self, df):\n        data_list = []\n        label_list = []\n        for idx, row in df.iterrows():\n            trial_data = self.load_trial_data(row)\n            eeg_data = trial_data[self.channels].values\n            \n            # Downsample and normalize\n            eeg_data_down = self.interpolate_data(eeg_data, self.samples_per_trial_original, self.downsample_length)\n            eeg_data_down = (eeg_data_down - eeg_data_down.mean(axis=0)) / (eeg_data_down.std(axis=0) + 1e-8)\n            \n            data_list.append(eeg_data_down)\n            if 'label' in row:\n                label_list.append(0 if row['label'] == 'Left' else 1)\n                \n        data_array = np.array(data_list)\n        label_array = np.array(label_list)\n        \n        # One-hot encode labels\n        if len(label_array) > 0:\n            onehot_encoder = OneHotEncoder(sparse=False)\n            label_array = onehot_encoder.fit_transform(label_array.reshape(-1, 1))\n        return data_array, label_array\n    \n    def interpolate_data(self, data, orig, prolong, kind='linear'):\n        new_data = []\n        x_orig = np.linspace(0, prolong, orig)\n        x_new = np.linspace(0, prolong, prolong)\n        for i in range(data.shape[1]):\n            f = interpolate.interp1d(x_orig, data[:, i], kind=kind)\n            new_data.append(f(x_new))\n        return np.array(new_data).T\n    \n    def load_trial_data(self, row):\n        id_num = row['id']\n        dataset = 'train' if id_num <= 4800 else 'validation' if id_num <= 4900 else 'test'\n        \n        eeg_path = os.path.join(\n            self.base_path, \n            row['task'], \n            dataset, \n            row['subject_id'], \n            str(row['trial_session']), \n            'EEGdata.csv'\n        )\n        eeg_data = pd.read_csv(eeg_path)\n        \n        # Extract trial data\n        trial_num = int(row['trial'])\n        start_idx = (trial_num - 1) * 2250\n        return eeg_data.iloc[start_idx:start_idx + 2250]\n    \n    def data_augmentation(self, data, label, windows_long, interval):\n        new_data, new_labels = [], []\n        for i in range(len(data)):\n            trial = data[i]\n            num_windows = (trial.shape[0] - windows_long) // interval + 1\n            for j in range(num_windows):\n                start = j * interval\n                window = trial[start:start + windows_long]\n                new_data.append(window)\n                new_labels.append(label[i])\n        return np.array(new_data), np.array(new_labels)\n    \n    def gauss_data_augmentation(self, data, label, sigma, m=2):\n        if m == 1:\n            return data, label\n        new_data = [data]\n        new_labels = [label]\n        for _ in range(1, m):\n            noisy_data = data + np.random.normal(0, sigma, data.shape)\n            new_data.append(noisy_data)\n            new_labels.append(label)\n        return np.vstack(new_data), np.vstack(new_labels)\n\n# ============================== Model Architecture ==============================\nclass MMCNN_model:\n    def __init__(self, channels=3, samples=1000):\n        self.channels = channels\n        self.samples = samples\n        self.activation = 'elu'\n        self.learning_rate = 0.0001\n        self.dropout = 0.8\n        self.inception_filters = [16, 16, 16, 16]\n        self.inception_kernel_length = [\n            [5, 10, 15, 10],\n            [40, 45, 50, 100],\n            [60, 65, 70, 100],\n            [80, 85, 90, 100],\n            [160, 180, 200, 180],\n        ]\n        self.inception_stride = [2, 4, 4, 4, 16]\n        self.first_maxpooling_size = 4\n        self.first_maxpooling_stride = 4\n        self.res_block_filters = [16, 16, 16]\n        self.res_block_kernel_stride = [8, 7, 7, 7, 6]\n        self.se_block_kernel_stride = 16\n        self.se_ratio = 8\n        self.second_maxpooling_size = [4, 3, 3, 3, 2]\n        self.second_maxpooling_stride = [4, 3, 3, 3, 2]\n        self.model = self.build_model()\n        \n        adam = optimizers.Adam(learning_rate=self.learning_rate) \n        self.model.compile(\n            loss=losses.binary_crossentropy,\n            optimizer=adam,\n            metrics=['mae', metrics.binary_accuracy]\n        )\n    \n    def build_model(self):\n        input_tensor = Input(shape=(self.samples, self.channels))\n        output_conns = []\n        \n        # EIN-a (Branch 0)\n        x = self.inception_block(input_tensor, self.inception_filters, self.inception_kernel_length[0], self.inception_stride[0], self.activation)\n        x = MaxPooling1D(pool_size=self.first_maxpooling_size, strides=self.first_maxpooling_stride, padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(self.dropout)(x)\n        x = self.conv_block(x, self.res_block_filters, self.res_block_kernel_stride[0], activation=self.activation)\n        x = self.squeeze_excitation_layer(x, self.se_block_kernel_stride, self.activation, ratio=self.se_ratio)\n        x = MaxPooling1D(pool_size=self.second_maxpooling_size[0], strides=self.second_maxpooling_stride[0], padding='same')(x)\n        x = Flatten()(x)\n        output_conns.append(x)\n        \n        # EIN-b (Branch 1)\n        y1 = self.inception_block(input_tensor, self.inception_filters, self.inception_kernel_length[1], self.inception_stride[1], self.activation)\n        y1 = MaxPooling1D(pool_size=self.first_maxpooling_size, strides=self.first_maxpooling_stride, padding='same')(y1)\n        y1 = BatchNormalization()(y1)\n        y1 = Dropout(self.dropout)(y1)\n        y1 = self.conv_block(y1, self.res_block_filters, self.res_block_kernel_stride[1], activation=self.activation)\n        y1 = self.squeeze_excitation_layer(y1, self.se_block_kernel_stride, self.activation, ratio=self.se_ratio)\n        y1 = MaxPooling1D(pool_size=self.second_maxpooling_size[1], strides=self.second_maxpooling_stride[1], padding='same')(y1)\n        y1 = Flatten()(y1)\n        output_conns.append(y1)\n        \n        # EIN-c (Branch 2)\n        y2 = self.inception_block(input_tensor, self.inception_filters, self.inception_kernel_length[2], self.inception_stride[2], self.activation)\n        y2 = MaxPooling1D(pool_size=self.first_maxpooling_size, strides=self.first_maxpooling_stride, padding='same')(y2)\n        y2 = BatchNormalization()(y2)\n        y2 = Dropout(self.dropout)(y2)\n        y2 = self.conv_block(y2, self.res_block_filters, self.res_block_kernel_stride[2], activation=self.activation)\n        y2 = self.squeeze_excitation_layer(y2, self.se_block_kernel_stride, self.activation, ratio=self.se_ratio)\n        y2 = MaxPooling1D(pool_size=self.second_maxpooling_size[2], strides=self.second_maxpooling_stride[2], padding='same')(y2)\n        y2 = Flatten()(y2)\n        output_conns.append(y2)\n        \n        # EIN-d (Branch 3)\n        y3 = self.inception_block(input_tensor, self.inception_filters, self.inception_kernel_length[3], self.inception_stride[3], self.activation)\n        y3 = MaxPooling1D(pool_size=self.first_maxpooling_size, strides=self.first_maxpooling_stride, padding='same')(y3)\n        y3 = BatchNormalization()(y3)\n        y3 = Dropout(self.dropout)(y3)\n        y3 = self.conv_block(y3, self.res_block_filters, self.res_block_kernel_stride[3], activation=self.activation)\n        y3 = self.squeeze_excitation_layer(y3, self.se_block_kernel_stride, self.activation, ratio=self.se_ratio)\n        y3 = MaxPooling1D(pool_size=self.second_maxpooling_size[3], strides=self.second_maxpooling_stride[3], padding='same')(y3)\n        y3 = Flatten()(y3)\n        output_conns.append(y3)\n        \n        # EIN-e (Branch 4)\n        z = self.inception_block(input_tensor, self.inception_filters, self.inception_kernel_length[4], self.inception_stride[4], self.activation)\n        z = MaxPooling1D(pool_size=self.first_maxpooling_size, strides=self.first_maxpooling_stride, padding='same')(z)\n        z = BatchNormalization()(z)\n        z = Dropout(self.dropout)(z)\n        z = self.conv_block(z, self.res_block_filters, self.res_block_kernel_stride[4], activation=self.activation)\n        z = self.squeeze_excitation_layer(z, self.se_block_kernel_stride, self.activation, ratio=self.se_ratio)\n        z = MaxPooling1D(pool_size=self.second_maxpooling_size[4], strides=self.second_maxpooling_stride[4], padding='same')(z)\n        z = Flatten()(z)\n        output_conns.append(z)\n        \n        # Combine all branches\n        output_conns = Concatenate(axis=-1)(output_conns)\n        output_conns = Dropout(self.dropout)(output_conns)\n        output_tensor = Dense(2, activation='sigmoid')(output_conns)\n        return Model(input_tensor, output_tensor)\n\n    def squeeze_excitation_layer(self, x, out_dim, activation, ratio=8):\n        squeeze = GlobalAveragePooling1D()(x)\n\n        excitation = Dense(units=out_dim//ratio)(squeeze)\n        excitation = Activation(activation)(excitation)\n        excitation = Dense(units=out_dim, activation='sigmoid')(excitation)\n        excitation = Reshape((1, out_dim))(excitation)\n\n        scale = Multiply()([x, excitation])\n        return scale\n        \n    '''\n    res_block\n    '''\n    def conv_block(self, x, nb_filter, length, activation):\n        k1, k2, k3 = nb_filter\n\n        out = Conv1D(k1, length, strides=1, padding='same', \n                    kernel_regularizer=regularizers.l2(0.002))(x)\n        out = BatchNormalization()(out)\n        out = Activation(activation)(out)\n\n        out = Conv1D(k2, length, strides=1, padding='same', \n                    kernel_regularizer=regularizers.l2(0.002))(out)\n        out = BatchNormalization()(out)\n        out = Activation(activation)(out)\n\n        out = Conv1D(k3, length, strides=1, padding='same', \n                    kernel_regularizer=regularizers.l2(0.002))(out)\n        out = BatchNormalization()(out)\n\n        x = Conv1D(k3, 1, strides=1, padding='same')(x)\n        x = BatchNormalization()(x)\n\n        out = Add()([out, x])\n        out = Activation(activation)(out)\n        out = tf.keras.layers.Dropout(self.dropout)(out)\n        return out\n    \n    '''\n    inception_block \n    '''\n    def inception_block(self, x, ince_filter, ince_length, stride, activation):\n        k1, k2, k3, k4 = ince_filter\n        l1, l2, l3, l4 = ince_length\n        inception = []\n\n        x1 = Conv1D(k1, l1, strides=stride, padding='same', \n                   kernel_regularizer=regularizers.l2(0.01))(x)\n        x1 = BatchNormalization()(x1)\n        x1 = Activation(activation)(x1)\n        inception.append(x1)\n\n        x2 = Conv1D(k2, l2, strides=stride, padding='same', \n                   kernel_regularizer=regularizers.l2(0.01))(x)\n        x2 = BatchNormalization()(x2)\n        x2 = Activation(activation)(x2)\n        inception.append(x2)\n\n        x3 = Conv1D(k3, l3, strides=stride, padding='same', \n                   kernel_regularizer=regularizers.l2(0.01))(x)\n        x3 = BatchNormalization()(x3)\n        x3 = Activation(activation)(x3)\n        inception.append(x3)\n\n        x4 = MaxPooling1D(pool_size=l4, strides=stride, padding='same')(x)\n        x4 = Conv1D(k4, 1, strides=1, padding='same')(x4)\n        x4 = BatchNormalization()(x4)\n        x4 = Activation(activation)(x4)\n        inception.append(x4)\n        \n        v1 = Concatenate(axis=-1)(inception)\n        return v1\n    \n    # ... [Helper methods: inception_block, conv_block, squeeze_excitation_layer] ...\n\n# ============================== Evaluation Metrics ==============================\nclass Evaluations:\n    def __init__(self, history, y_pred, y_true, loss_score, error, validation_score):\n        self.history = history\n        self.y_pred = y_pred\n        self.y_true = y_true\n        self.loss_score = loss_score\n        self.error = error\n        self.validation_score = validation_score\n        self.matrix, self.kappa = self.matrix_and_kappa()\n        self.f1 = self.compute_f1_score()\n    \n    def matrix_and_kappa(self):\n        y_pred_labels = np.argmax(self.y_pred, axis=1)\n        y_true_labels = np.argmax(self.y_true, axis=1)\n        C2 = confusion_matrix(y_true_labels, y_pred_labels)\n        kappa_value = cohen_kappa_score(y_true_labels, y_pred_labels)\n        return C2, kappa_value\n    \n    def compute_f1_score(self):\n        y_pred_labels = np.argmax(self.y_pred, axis=1)\n        y_true_labels = np.argmax(self.y_true, axis=1)\n        return f1_score(y_true_labels, y_pred_labels, average='weighted')\n\n# ============================== Main Training Pipeline ==============================\ndef main():\n    # Configuration\n    base_path = '/kaggle/input/mtcaic3'\n    task = 'MI'\n    \n    # Load metadata\n    train_df = pd.read_csv(f'{base_path}/train.csv')\n    val_df = pd.read_csv(f'{base_path}/validation.csv')\n    test_df = pd.read_csv(f'{base_path}/test.csv')\n    \n    # Filter for MI task\n    train_df = train_df[train_df['task'] == task]\n    val_df = val_df[val_df['task'] == task]\n    \n    # Initialize data loader\n    data_loader = BCICompetitionData(base_path, task)\n    \n    # Load and preprocess data\n    train_data, train_labels = data_loader.load_data(train_df)\n    val_data, val_labels = data_loader.load_data(val_df)\n    \n    # Data augmentation parameters\n    window_long = 1000\n    window_val_interval = 10\n    window_test_interval = 50\n    \n    # Augment training data\n    train_data_aug, train_labels_aug = data_loader.data_augmentation(\n        train_data, train_labels, window_long, window_val_interval\n    )\n    train_data_aug, train_labels_aug = data_loader.gauss_data_augmentation(\n        train_data_aug, train_labels_aug, 0.005, m=2\n    )\n    \n    # Augment validation data\n    val_data_aug, val_labels_aug = data_loader.data_augmentation(\n        val_data, val_labels, window_long, window_test_interval\n    )\n    \n    # Initialize and train model\n    model = MMCNN_model(channels=3, samples=1000).model\n    \n    checkpoint = ModelCheckpoint(\n        'best_model.h5',\n        monitor='val_loss',\n        save_best_only=True,\n        mode='min',\n        verbose=1\n    )\n    early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n    \n    history = model.fit(\n        train_data_aug, train_labels_aug,\n        validation_data=(val_data_aug, val_labels_aug),\n        epochs=100,\n        batch_size=128,\n        callbacks=[checkpoint, early_stop],\n        verbose=1\n    )\n    \n    # Evaluate on validation set\n    val_loss, val_mae, val_acc = model.evaluate(val_data_aug, val_labels_aug, verbose=0)\n    y_pred = model.predict(val_data_aug)\n    eval_results = Evaluations(history, y_pred, val_labels_aug, val_loss, val_mae, val_acc)\n    \n    print(f\"Validation Accuracy: {val_acc:.4f}\")\n    print(f\"F1 Score: {eval_results.f1:.4f}\")\n    print(f\"Cohen's Kappa: {eval_results.kappa:.4f}\")\n    \n    # Generate test predictions\n    test_data, _ = data_loader.load_data(test_df)\n    test_data_aug, _ = data_loader.data_augmentation(\n        test_data, np.zeros((len(test_data), 2)), window_long, window_test_interval\n    )\n    test_probs = model.predict(test_data_aug)\n    \n    # Aggregate predictions per trial\n    final_preds = []\n    window_size = test_data_aug.shape[0] // len(test_data)\n    for i in range(len(test_data)):\n        trial_probs = test_probs[i * window_size : (i + 1) * window_size]\n        avg_probs = np.mean(trial_probs, axis=0)\n        final_preds.append('Left' if np.argmax(avg_probs) == 0 else 'Right')\n    \n    # Create submission file\n    submission_df = pd.read_csv(f'{base_path}/sample_submission.csv')\n    test_df_full = pd.read_csv(f'{base_path}/test.csv')\n    \n    # Fill predictions only for MI trials\n    mi_mask = test_df_full['task'] == 'MI'\n    submission_df.loc[mi_mask, 'label'] = final_preds\n    submission_df.to_csv('submission.csv', index=False)\n    print(\"Submission file created!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:53:55.247009Z","iopub.execute_input":"2025-06-23T08:53:55.247286Z","execution_failed":"2025-06-23T09:55:23.262Z"}},"outputs":[{"name":"stderr","text":"2025-06-23 08:53:58.410655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750668838.653627      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750668838.723599      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n2025-06-23 08:58:15.292463: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - binary_accuracy: 0.5029 - loss: 3.7177 - mae: 0.4976\nEpoch 1: val_loss improved from inf to 2.00972, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 447ms/step - binary_accuracy: 0.5029 - loss: 3.7172 - mae: 0.4976 - val_binary_accuracy: 0.5300 - val_loss: 2.0097 - val_mae: 0.4959\nEpoch 2/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - binary_accuracy: 0.5010 - loss: 3.3092 - mae: 0.4988\nEpoch 2: val_loss improved from 2.00972 to 1.97475, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 411ms/step - binary_accuracy: 0.5010 - loss: 3.3087 - mae: 0.4988 - val_binary_accuracy: 0.5250 - val_loss: 1.9747 - val_mae: 0.4952\nEpoch 3/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - binary_accuracy: 0.5034 - loss: 3.0104 - mae: 0.4960\nEpoch 3: val_loss improved from 1.97475 to 1.94346, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 402ms/step - binary_accuracy: 0.5034 - loss: 3.0101 - mae: 0.4960 - val_binary_accuracy: 0.4950 - val_loss: 1.9435 - val_mae: 0.4960\nEpoch 4/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - binary_accuracy: 0.5000 - loss: 2.7239 - mae: 0.4992\nEpoch 4: val_loss improved from 1.94346 to 1.90921, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 406ms/step - binary_accuracy: 0.5001 - loss: 2.7237 - mae: 0.4992 - val_binary_accuracy: 0.5150 - val_loss: 1.9092 - val_mae: 0.4970\nEpoch 5/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - binary_accuracy: 0.5042 - loss: 2.5064 - mae: 0.4969\nEpoch 5: val_loss improved from 1.90921 to 1.87418, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 407ms/step - binary_accuracy: 0.5042 - loss: 2.5062 - mae: 0.4969 - val_binary_accuracy: 0.5100 - val_loss: 1.8742 - val_mae: 0.4980\nEpoch 6/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - binary_accuracy: 0.5009 - loss: 2.3345 - mae: 0.4988\nEpoch 6: val_loss improved from 1.87418 to 1.83284, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 407ms/step - binary_accuracy: 0.5009 - loss: 2.3343 - mae: 0.4988 - val_binary_accuracy: 0.4950 - val_loss: 1.8328 - val_mae: 0.4976\nEpoch 7/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - binary_accuracy: 0.5056 - loss: 2.1702 - mae: 0.4954\nEpoch 7: val_loss improved from 1.83284 to 1.79400, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 407ms/step - binary_accuracy: 0.5056 - loss: 2.1701 - mae: 0.4954 - val_binary_accuracy: 0.5000 - val_loss: 1.7940 - val_mae: 0.4985\nEpoch 8/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - binary_accuracy: 0.5049 - loss: 2.0374 - mae: 0.4972\nEpoch 8: val_loss improved from 1.79400 to 1.75255, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 408ms/step - binary_accuracy: 0.5049 - loss: 2.0373 - mae: 0.4972 - val_binary_accuracy: 0.5000 - val_loss: 1.7525 - val_mae: 0.4991\nEpoch 9/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - binary_accuracy: 0.5103 - loss: 1.9200 - mae: 0.4950\nEpoch 9: val_loss improved from 1.75255 to 1.71044, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 407ms/step - binary_accuracy: 0.5103 - loss: 1.9199 - mae: 0.4950 - val_binary_accuracy: 0.4900 - val_loss: 1.7104 - val_mae: 0.4998\nEpoch 10/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - binary_accuracy: 0.5101 - loss: 1.8283 - mae: 0.4957\nEpoch 10: val_loss improved from 1.71044 to 1.66393, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 422ms/step - binary_accuracy: 0.5101 - loss: 1.8282 - mae: 0.4957 - val_binary_accuracy: 0.4850 - val_loss: 1.6639 - val_mae: 0.4997\nEpoch 11/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - binary_accuracy: 0.5113 - loss: 1.7457 - mae: 0.4952\nEpoch 11: val_loss improved from 1.66393 to 1.61644, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 418ms/step - binary_accuracy: 0.5113 - loss: 1.7456 - mae: 0.4952 - val_binary_accuracy: 0.4850 - val_loss: 1.6164 - val_mae: 0.4997\nEpoch 12/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - binary_accuracy: 0.5155 - loss: 1.6666 - mae: 0.4944\nEpoch 12: val_loss improved from 1.61644 to 1.56873, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 421ms/step - binary_accuracy: 0.5155 - loss: 1.6666 - mae: 0.4944 - val_binary_accuracy: 0.5250 - val_loss: 1.5687 - val_mae: 0.5002\nEpoch 13/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - binary_accuracy: 0.5113 - loss: 1.6000 - mae: 0.4951\nEpoch 13: val_loss improved from 1.56873 to 1.52171, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 416ms/step - binary_accuracy: 0.5113 - loss: 1.5999 - mae: 0.4951 - val_binary_accuracy: 0.5200 - val_loss: 1.5217 - val_mae: 0.5014\nEpoch 14/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - binary_accuracy: 0.5138 - loss: 1.5350 - mae: 0.4951\nEpoch 14: val_loss improved from 1.52171 to 1.46876, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 423ms/step - binary_accuracy: 0.5138 - loss: 1.5349 - mae: 0.4951 - val_binary_accuracy: 0.5450 - val_loss: 1.4688 - val_mae: 0.5004\nEpoch 15/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - binary_accuracy: 0.5166 - loss: 1.4747 - mae: 0.4949\nEpoch 15: val_loss improved from 1.46876 to 1.41847, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 421ms/step - binary_accuracy: 0.5166 - loss: 1.4746 - mae: 0.4949 - val_binary_accuracy: 0.5550 - val_loss: 1.4185 - val_mae: 0.5007\nEpoch 16/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - binary_accuracy: 0.5228 - loss: 1.4151 - mae: 0.4942\nEpoch 16: val_loss improved from 1.41847 to 1.36743, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 422ms/step - binary_accuracy: 0.5228 - loss: 1.4150 - mae: 0.4942 - val_binary_accuracy: 0.5350 - val_loss: 1.3674 - val_mae: 0.5007\nEpoch 17/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - binary_accuracy: 0.5265 - loss: 1.3576 - mae: 0.4935\nEpoch 17: val_loss improved from 1.36743 to 1.31254, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 418ms/step - binary_accuracy: 0.5265 - loss: 1.3576 - mae: 0.4935 - val_binary_accuracy: 0.5500 - val_loss: 1.3125 - val_mae: 0.4989\nEpoch 18/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - binary_accuracy: 0.5274 - loss: 1.3058 - mae: 0.4941\nEpoch 18: val_loss improved from 1.31254 to 1.26084, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 423ms/step - binary_accuracy: 0.5274 - loss: 1.3058 - mae: 0.4941 - val_binary_accuracy: 0.5450 - val_loss: 1.2608 - val_mae: 0.4984\nEpoch 19/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - binary_accuracy: 0.5278 - loss: 1.2523 - mae: 0.4940\nEpoch 19: val_loss improved from 1.26084 to 1.21252, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 429ms/step - binary_accuracy: 0.5278 - loss: 1.2523 - mae: 0.4940 - val_binary_accuracy: 0.5400 - val_loss: 1.2125 - val_mae: 0.4985\nEpoch 20/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - binary_accuracy: 0.5334 - loss: 1.2003 - mae: 0.4929\nEpoch 20: val_loss improved from 1.21252 to 1.16633, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 435ms/step - binary_accuracy: 0.5335 - loss: 1.2003 - mae: 0.4929 - val_binary_accuracy: 0.5750 - val_loss: 1.1663 - val_mae: 0.4990\nEpoch 21/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - binary_accuracy: 0.5328 - loss: 1.1532 - mae: 0.4930\nEpoch 21: val_loss improved from 1.16633 to 1.11881, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 426ms/step - binary_accuracy: 0.5328 - loss: 1.1531 - mae: 0.4930 - val_binary_accuracy: 0.5550 - val_loss: 1.1188 - val_mae: 0.4985\nEpoch 22/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - binary_accuracy: 0.5428 - loss: 1.1042 - mae: 0.4917\nEpoch 22: val_loss improved from 1.11881 to 1.07509, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 424ms/step - binary_accuracy: 0.5428 - loss: 1.1042 - mae: 0.4917 - val_binary_accuracy: 0.5600 - val_loss: 1.0751 - val_mae: 0.4983\nEpoch 23/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - binary_accuracy: 0.5404 - loss: 1.0617 - mae: 0.4918\nEpoch 23: val_loss improved from 1.07509 to 1.03945, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 424ms/step - binary_accuracy: 0.5404 - loss: 1.0617 - mae: 0.4918 - val_binary_accuracy: 0.4950 - val_loss: 1.0394 - val_mae: 0.5002\nEpoch 24/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - binary_accuracy: 0.5413 - loss: 1.0222 - mae: 0.4919\nEpoch 24: val_loss improved from 1.03945 to 0.99353, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 423ms/step - binary_accuracy: 0.5413 - loss: 1.0222 - mae: 0.4919 - val_binary_accuracy: 0.5600 - val_loss: 0.9935 - val_mae: 0.4965\nEpoch 25/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - binary_accuracy: 0.5462 - loss: 0.9833 - mae: 0.4905\nEpoch 25: val_loss improved from 0.99353 to 0.96188, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 422ms/step - binary_accuracy: 0.5462 - loss: 0.9832 - mae: 0.4905 - val_binary_accuracy: 0.5600 - val_loss: 0.9619 - val_mae: 0.4981\nEpoch 26/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - binary_accuracy: 0.5436 - loss: 0.9499 - mae: 0.4911\nEpoch 26: val_loss improved from 0.96188 to 0.92855, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 421ms/step - binary_accuracy: 0.5436 - loss: 0.9499 - mae: 0.4911 - val_binary_accuracy: 0.5500 - val_loss: 0.9286 - val_mae: 0.4974\nEpoch 27/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - binary_accuracy: 0.5398 - loss: 0.9199 - mae: 0.4917\nEpoch 27: val_loss improved from 0.92855 to 0.90360, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 421ms/step - binary_accuracy: 0.5398 - loss: 0.9199 - mae: 0.4917 - val_binary_accuracy: 0.5700 - val_loss: 0.9036 - val_mae: 0.4976\nEpoch 28/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - binary_accuracy: 0.5472 - loss: 0.8916 - mae: 0.4906\nEpoch 28: val_loss improved from 0.90360 to 0.87747, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 423ms/step - binary_accuracy: 0.5472 - loss: 0.8915 - mae: 0.4906 - val_binary_accuracy: 0.5600 - val_loss: 0.8775 - val_mae: 0.4972\nEpoch 29/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - binary_accuracy: 0.5490 - loss: 0.8666 - mae: 0.4901\nEpoch 29: val_loss improved from 0.87747 to 0.85340, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 421ms/step - binary_accuracy: 0.5490 - loss: 0.8665 - mae: 0.4901 - val_binary_accuracy: 0.5600 - val_loss: 0.8534 - val_mae: 0.4963\nEpoch 30/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - binary_accuracy: 0.5470 - loss: 0.8457 - mae: 0.4900\nEpoch 30: val_loss improved from 0.85340 to 0.83244, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 422ms/step - binary_accuracy: 0.5470 - loss: 0.8457 - mae: 0.4900 - val_binary_accuracy: 0.5550 - val_loss: 0.8324 - val_mae: 0.4955\nEpoch 31/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - binary_accuracy: 0.5670 - loss: 0.8207 - mae: 0.4860\nEpoch 31: val_loss improved from 0.83244 to 0.81108, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 421ms/step - binary_accuracy: 0.5669 - loss: 0.8207 - mae: 0.4860 - val_binary_accuracy: 0.5000 - val_loss: 0.8111 - val_mae: 0.4933\nEpoch 32/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - binary_accuracy: 0.5483 - loss: 0.8100 - mae: 0.4897\nEpoch 32: val_loss improved from 0.81108 to 0.80560, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 418ms/step - binary_accuracy: 0.5483 - loss: 0.8100 - mae: 0.4897 - val_binary_accuracy: 0.5600 - val_loss: 0.8056 - val_mae: 0.4968\nEpoch 33/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - binary_accuracy: 0.5581 - loss: 0.7926 - mae: 0.4866\nEpoch 33: val_loss improved from 0.80560 to 0.79081, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 422ms/step - binary_accuracy: 0.5581 - loss: 0.7926 - mae: 0.4866 - val_binary_accuracy: 0.5600 - val_loss: 0.7908 - val_mae: 0.4956\nEpoch 34/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - binary_accuracy: 0.5548 - loss: 0.7831 - mae: 0.4877\nEpoch 34: val_loss did not improve from 0.79081\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 415ms/step - binary_accuracy: 0.5548 - loss: 0.7830 - mae: 0.4877 - val_binary_accuracy: 0.5400 - val_loss: 0.7925 - val_mae: 0.5001\nEpoch 35/100\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - binary_accuracy: 0.5584 - loss: 0.7690 - mae: 0.4851\nEpoch 35: val_loss improved from 0.79081 to 0.77963, saving model to best_model.h5\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 424ms/step - binary_accuracy: 0.5583 - loss: 0.7690 - mae: 0.4851 - val_binary_accuracy: 0.4800 - val_loss: 0.7796 - val_mae: 0.4986\nEpoch 36/100\n\u001b[1m163/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 420ms/step - binary_accuracy: 0.5594 - loss: 0.7632 - mae: 0.4858","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}