{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12247473,"sourceType":"datasetVersion","datasetId":7717010}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport mne\nfrom scipy.interpolate import CloughTocher2DInterpolator\nfrom scipy.fft import fft\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, Input, GlobalAveragePooling2D, Dense, Dropout\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\n\n# Constants\nFS = 250  # Sampling frequency (Hz)\nN_FFT = 256  # FFT length\nWIN_SIZE = int(0.3 * FS)  # 0.3s window (75 samples)\nN_WINDOWS = 10  # Number of time windows\nBANDS = [(8, 13), (13, 21), (21, 30)]  # Frequency bands (Hz)\nIMG_SIZE = 64  # Image dimensions\n# Standard electrode positions (Cz at origin)\nELECTRODE_POS = {'C3': (-1, 0), 'Cz': (0, 0), 'C4': (1, 0)}\n\ndef load_data(subject, session):\n    \"\"\"Load EEG data and events for a subject with proper scaling and timing\"\"\"\n    filename = f'B{subject:02d}{session}.gdf'\n    filepath = os.path.join('/kaggle/input/bci-competition-2008-graz-data-set-b/BCICIV_2b_gdf', filename)\n    if not os.path.exists(filepath):\n        print(f\"[ERROR] File not found: {filepath}\")\n        return np.array([]), np.array([])\n    \n    try:\n        # Load with scaling to microvolts (uV)\n        raw = mne.io.read_raw_gdf(filepath, preload=True, verbose='ERROR')\n        raw.apply_function(lambda x: x * 1e6)  # Convert to microvolts\n        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n        \n        print(f\"\\n-- Session {session} --\")\n        print(f\"[SUCCESS] Loading file: {filepath}\")\n        print(f\"Found {len(events)} events. Event IDs: {event_ids}\")\n        \n        trials, labels = [], []\n        for event in events:\n            if event[2] in [event_ids.get('769', -1), event_ids.get('770', -1)]:\n                # Start immediately at cue onset (paper uses 3s from cue start)\n                start = event[0]\n                end = start + int(3 * FS)  # 3 seconds of data\n                \n                if end > raw.n_times:\n                    print(f\"Event {event} out of bounds: {end} > {raw.n_times}\")\n                    continue\n                    \n                # Get only C3, Cz, C4 channels (first 3)\n                trial = raw.get_data()[:3, start:end]\n                \n                # Log trial stats\n                print(f\"Event {event}: Label={'left' if event[2]==event_ids['769'] else 'right'}, \"\n                      f\"Start={start}, End={end}, Shape={trial.shape}, \"\n                      f\"Mean={np.mean(trial):.2f}uV, Std={np.std(trial):.2f}uV\")\n                \n                trials.append(trial)\n                labels.append(0 if event[2] == event_ids.get('769', -1) else 1)\n                \n        print(f\"Extracted {len(trials)} trials from session\")\n        return np.array(trials), np.array(labels)\n    \n    except Exception as e:\n        print(f\"[ERROR] Processing {filepath}: {str(e)}\")\n        return np.array([]), np.array([])\n\ndef compute_band_power(data, band):\n    \"\"\"Compute band power using spectral energy (FFT magnitudes)\"\"\"\n    band_powers = []\n    for window in np.array_split(data, N_WINDOWS, axis=1):\n        # Compute FFT\n        spec = fft(window, n=N_FFT, axis=1)\n        freqs = np.fft.fftfreq(N_FFT, 1/FS)\n        \n        # Find frequency indices in band\n        band_idx = np.where((freqs >= band[0]) & (freqs <= band[1]))[0]\n        if len(band_idx) == 0:\n            print(f\"No frequencies found in band {band}!\")\n            band_powers.append(np.zeros(data.shape[0]))\n            continue\n        \n        # Compute power spectral density (|X(f)|^2)\n        power_spectrum = np.abs(spec[:, band_idx]) ** 2\n        \n        # Sum power in frequency band\n        power = np.sum(power_spectrum, axis=1)\n        band_powers.append(power)\n    \n    # Average power across windows\n    return np.mean(band_powers, axis=0)\n\ndef create_tpct_image(trial_data):\n    \"\"\"Create TPCT image with proper scaling and interpolation\"\"\"\n    print(f\"\\nCreating TPCT image for trial\")\n    print(f\"Trial data shape: {trial_data.shape} (channels x samples)\")\n    print(f\"Data stats: Min={np.min(trial_data):.2f}uV, Max={np.max(trial_data):.2f}uV, \"\n          f\"Mean={np.mean(trial_data):.2f}uV\")\n    \n    features = []\n    for band_idx, band in enumerate(BANDS):\n        print(f\"\\nProcessing band {band_idx+1}: {band[0]}-{band[1]}Hz\")\n        band_power = compute_band_power(trial_data, band)\n        print(f\"Band power: C3={band_power[0]:.4f}, Cz={band_power[1]:.4f}, C4={band_power[2]:.4f}\")\n        features.append(band_power)\n    \n    features = np.array(features).T  # Shape: (3 electrodes, 3 bands)\n    print(f\"\\nFeature matrix:\\n{features}\")\n\n    # Apply logarithmic scaling to handle microvolts\n    features = np.log10(features + 1e-12)  # Add small constant to avoid log(0)\n    print(f\"Log-scaled features:\\n{features}\")\n\n    # Create positions for interpolation\n    positions, values = [], []\n    for i, (electrode, pos) in enumerate(ELECTRODE_POS.items()):\n        # Single position per electrode (no artificial shifts)\n        positions.append(pos)\n        values.append(features[i, 0])  # Band 1\n        positions.append(pos)\n        values.append(features[i, 1])  # Band 2\n        positions.append(pos)\n        values.append(features[i, 2])  # Band 3\n\n    # Create interpolation grid\n    x_grid = np.linspace(-1.2, 1.2, IMG_SIZE)\n    y_grid = np.linspace(-1.2, 1.2, IMG_SIZE)\n    xx, yy = np.meshgrid(x_grid, y_grid)\n    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n    \n    # Interpolate each band separately\n    image = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n    for band_idx in range(3):\n        band_values = [values[i] for i in range(band_idx, len(values), 3)]\n        try:\n            interpolator = CloughTocher2DInterpolator(\n                np.array(positions)[0::3],  # Original positions only\n                band_values\n            )\n            band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n            band_image = np.nan_to_num(band_image, nan=0)\n            \n            # Normalize band\n            band_min, band_max = band_image.min(), band_image.max()\n            if band_max - band_min > 1e-8:\n                band_image = (band_image - band_min) / (band_max - band_min)\n                \n            image[..., band_idx] = band_image\n            print(f\"Band {band_idx+1} image: Min={band_min:.4f}, Max={band_max:.4f}\")\n        except Exception as e:\n            print(f\"Interpolation error for band {band_idx}: {str(e)}\")\n            image[..., band_idx] = np.zeros((IMG_SIZE, IMG_SIZE))\n    \n    print(f\"Image shape: {image.shape}, Range: {np.min(image):.4f}-{np.max(image):.4f}\")\n    return image\n\ndef build_mvgg(input_shape=(64, 64, 3), num_classes=2):\n    \"\"\"Build modified VGG network per paper specifications\"\"\"\n    inputs = Input(shape=input_shape)\n    \n    # Simplified architecture based on paper\n    x = Conv2D(32, (5, 5), activation='relu', padding='same')(inputs)\n    x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n    x = Conv2D(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n    \n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(128, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(256, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(inputs, outputs)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\ndef main():\n    all_images, all_labels = [], []\n    \n    print(\"Processing all subjects and sessions...\")\n    for subject in range(1, 10):\n        print(f\"\\n{'='*50}\")\n        print(f\"Processing Subject {subject}\")\n        print(f\"{'='*50}\")\n        \n        sessions = ['01T', '02T', '03T', '04E', '05E']\n        for session in sessions:\n            trials, labels = load_data(subject, session)\n            if len(trials) == 0:\n                print(f\"Skipping subject {subject} session {session}\")\n                continue\n                \n            print(f\"\\nProcessing {len(trials)} trials for subject {subject} session {session}...\")\n            for i, trial in enumerate(trials):\n                print(f\"\\nTrial {i+1}/{len(trials)}\")\n                image = create_tpct_image(trial)\n                all_images.append(image)\n            all_labels.extend(labels)\n    \n    X = np.array(all_images)\n    y = np.array(all_labels)\n    print(f\"\\nTotal dataset size: {X.shape[0]} samples\")\n    \n    if len(X) == 0:\n        print(\"No data found - exiting\")\n        return\n    \n    # 5-fold cross-validation (per paper)\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    accuracies, kappas = [], []\n    \n    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n        print(f\"\\n{'='*50}\")\n        print(f\"Training fold {fold+1}/5\")\n        print(f\"{'='*50}\")\n        \n        model = build_mvgg()\n        history = model.fit(X[train_idx], y[train_idx], \n                            epochs=30,\n                            batch_size=32,\n                            validation_split=0.2,\n                            verbose=1)\n        \n        y_pred = model.predict(X[test_idx]).argmax(axis=1)\n        acc = accuracy_score(y[test_idx], y_pred)\n        kappa = cohen_kappa_score(y[test_idx], y_pred)\n        \n        accuracies.append(acc)\n        kappas.append(kappa)\n        print(f'Fold {fold+1} Accuracy: {acc:.4f}, Kappa: {kappa:.4f}')\n    \n    print(f'\\nFinal Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}')\n    print(f'Final Kappa: {np.mean(kappas):.4f} ± {np.std(kappas):.4f}')\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport mne\nfrom scipy.interpolate import CloughTocher2DInterpolator, LinearNDInterpolator, NearestNDInterpolator\nfrom scipy.fft import fft, ifft\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\n\n# ======================== CONSTANTS ========================\nFS = 250  # Sampling frequency (Hz)\nN_FFT = 256  # FFT length\nN_WINDOWS = 10  # Number of time windows\nBANDS = [(8, 13), (13, 21), (21, 30)]  # Frequency bands (Hz)\nIMG_SIZE = 64  # Image dimensions\nDELTA = 0.05  # Increased shift value for better separation\n\nELECTRODE_POS = {\n    'C3': [\n        (-1 - DELTA, -DELTA),  # Band 1: left and down\n        (-1, 0),               # Band 2: center\n        (-1 + DELTA, DELTA)    # Band 3: right and up\n    ],\n    'Cz': [\n        (0 - DELTA, DELTA),    # Band 1: left and up\n        (0, 0),                # Band 2: center\n        (0 + DELTA, -DELTA)    # Band 3: right and down\n    ],\n    'C4': [\n        (1 - DELTA, -DELTA),   # Band 1: left and down\n        (1, 0),                # Band 2: center\n        (1 + DELTA, DELTA)     # Band 3: right and up\n    ]\n}\n\n# ======================== DATA LOADING ========================\ndef load_data(subject, session):\n    \"\"\"Load EEG data and events with proper scaling and timing\"\"\"\n    filename = f'B{subject:02d}{session}.gdf'\n    filepath = os.path.join('/kaggle/input/bci-competition-2008-graz-data-set-b/BCICIV_2b_gdf', filename)\n    \n    if not os.path.exists(filepath):\n        print(f\"[ERROR] File not found: {filepath}\")\n        return np.array([]), np.array([])\n    \n    try:\n        print(f\"\\n=== Loading subject {subject}, session {session} ===\")\n        \n        # Load and scale to microvolts\n        raw = mne.io.read_raw_gdf(filepath, preload=True, verbose='ERROR')\n        raw.apply_function(lambda x: x * 1e6)\n        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n        \n        print(f\"Found {len(events)} events\")\n        \n        trials, labels = [], []\n        valid_events = 0\n        \n        for event in events:\n            if event[2] in [event_ids.get('769', -1), event_ids.get('770', -1)]:\n                start = event[0]\n                end = start + int(3 * FS)  # 3 seconds of data\n                \n                if end > raw.n_times:\n                    print(f\"  - Event at {start} exceeds data length ({raw.n_times}), skipping\")\n                    continue\n                    \n                # Get only C3, Cz, C4 channels\n                trial = raw.get_data()[:3, start:end]\n                trials.append(trial)\n                \n                label = 0 if event[2] == event_ids.get('769', -1) else 1\n                labels.append(label)\n                valid_events += 1\n                \n                # Print detailed info for first event\n                if valid_events == 1:\n                    print(f\"\\nFirst trial details:\")\n                    print(f\"  Shape: {trial.shape} (channels x samples)\")\n                    print(f\"  Min: {np.min(trial):.2f}μV, Max: {np.max(trial):.2f}μV\")\n                    print(f\"  Mean: {np.mean(trial):.2f}μV, Std: {np.std(trial):.2f}μV\")\n                    print(f\"  Variance: {np.var(trial):.2f}μV²\")\n                    print(f\"  Channel means: C3={np.mean(trial[0]):.2f}μV, Cz={np.mean(trial[1]):.2f}μV, C4={np.mean(trial[2]):.2f}μV\")\n                \n        print(f\"\\nExtracted {valid_events} valid trials\")\n        print(f\"Label distribution: Left={labels.count(0)}, Right={labels.count(1)}\")\n        return np.array(trials), np.array(labels)\n    \n    except Exception as e:\n        print(f\"[ERROR] Processing file: {str(e)}\")\n        return np.array([]), np.array([])\n\n# ======================== TPCT FEATURE EXTRACTION ========================\ndef compute_band_features(trial_data, band, verbose=False):\n    \"\"\"Compute band features using paper's method (FFT → sub-band → IFFT → power)\"\"\"\n    window_size = trial_data.shape[1] // N_WINDOWS\n    band_powers = []\n    \n    if verbose:\n        print(f\"\\nComputing features for band {band[0]}-{band[1]}Hz\")\n        print(f\"  Trial shape: {trial_data.shape}\")\n        print(f\"  Window size: {window_size} samples\")\n    \n    for win_idx in range(N_WINDOWS):\n        start = win_idx * window_size\n        end = start + window_size\n        window = trial_data[:, start:end]\n        \n        # FFT with zero-padding\n        spec = fft(window, n=N_FFT, axis=1)\n        freqs = np.fft.fftfreq(N_FFT, 1/FS)\n        \n        # Extract sub-band frequencies\n        band_idx = np.where((freqs >= band[0]) & (freqs <= band[1]))[0]\n        if len(band_idx) == 0:\n            band_powers.append(np.zeros(trial_data.shape[0]))\n            continue\n            \n        sub_band_spec = spec[:, band_idx]\n        \n        # IFFT → Time-domain signal\n        time_domain = ifft(sub_band_spec, axis=1)\n        \n        # Compute power (Eq 10)\n        power = np.mean(np.abs(time_domain)**2, axis=1)\n        band_powers.append(power)\n        \n        if verbose and win_idx == 0:\n            print(f\"  Window 1 power: C3={power[0]:.2f}, Cz={power[1]:.2f}, C4={power[2]:.2f}\")\n    \n    # Average power across windows (Eq 11)\n    avg_power = np.mean(band_powers, axis=0)\n    \n    if verbose:\n        print(f\"\\nBand {band[0]}-{band[1]}Hz average power:\")\n        print(f\"  C3: {avg_power[0]:.2f} (Min: {np.min([p[0] for p in band_powers]):.2f}, Max: {np.max([p[0] for p in band_powers]):.2f})\")\n        print(f\"  Cz: {avg_power[1]:.2f} (Min: {np.min([p[1] for p in band_powers]):.2f}, Max: {np.max([p[1] for p in band_powers]):.2f})\")\n        print(f\"  C4: {avg_power[2]:.2f} (Min: {np.min([p[2] for p in band_powers]):.2f}, Max: {np.max([p[2] for p in band_powers]):.2f})\")\n    \n    return avg_power\n\ndef create_tpct_image(trial_data, verbose=False):\n    \"\"\"Create TPCT image with robust interpolation\"\"\"\n    if verbose:\n        print(\"\\n\" + \"=\"*60)\n        print(\"Creating TPCT Image\")\n        print(\"=\"*60)\n        print(f\"Input trial shape: {trial_data.shape}\")\n        print(f\"Min: {np.min(trial_data):.2f}μV, Max: {np.max(trial_data):.2f}μV\")\n        print(f\"Mean: {np.mean(trial_data):.2f}μV, Std: {np.std(trial_data):.2f}μV\")\n        print(f\"Variance: {np.var(trial_data):.2f}μV²\")\n    \n    features = []\n    for band in BANDS:\n        band_features = compute_band_features(trial_data, band, verbose=verbose)\n        features.append(band_features)\n    \n    features = np.array(features).T  # Shape: (3 electrodes, 3 bands)\n    \n    if verbose:\n        print(\"\\nRaw features (electrode x band):\")\n        print(features)\n    \n    # Apply logarithmic scaling\n    features = np.log10(features + 1e-12)\n    \n    if verbose:\n        print(\"\\nLog-scaled features:\")\n        print(features)\n        print(f\"Feature stats - Min: {np.min(features):.4f}, Max: {np.max(features):.4f}\")\n        print(f\"Mean: {np.mean(features):.4f}, Std: {np.std(features):.4f}\")\n        print(f\"Variance: {np.var(features):.4f}\")\n\n    positions, values = [], []\n    for elec_idx, electrode in enumerate(['C3', 'Cz', 'C4']):\n        for band_idx in range(3):\n            pos = ELECTRODE_POS[electrode][band_idx]\n            positions.append(pos)\n            values.append(features[elec_idx, band_idx])\n    \n    if verbose:\n        print(\"\\nElectrode positions and values:\")\n        for i, (pos, val) in enumerate(zip(positions, values)):\n            elec = ['C3', 'Cz', 'C4'][i // 3]\n            band = ['μ (8-13Hz)', 'β1 (13-21Hz)', 'β2 (21-30Hz)'][i % 3]\n            print(f\"  {elec} {band}: Position={pos}, Value={val:.4f}\")\n    \n    # Create grid with expanded boundaries\n    x_grid = np.linspace(-1.5, 1.5, IMG_SIZE)\n    y_grid = np.linspace(-0.5, 0.5, IMG_SIZE)\n    xx, yy = np.meshgrid(x_grid, y_grid)\n    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n    \n    image = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n    \n    for band_idx in range(3):\n        band_values = values[band_idx::3]\n        band_positions = positions[band_idx::3]\n        \n        # FIX: Increased jitter magnitude to prevent collinear points\n        jitter = np.random.normal(0, 0.001, (len(band_positions), 2))  # Increased from 1e-5 to 0.001\n        band_positions_jittered = np.array(band_positions) + jitter\n        \n        try:\n            interpolator = CloughTocher2DInterpolator(band_positions_jittered, band_values)\n            band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n            method = \"Clough-Tocher\"\n        except:\n            try:\n                # FIX: First fallback to linear interpolation\n                interpolator = LinearNDInterpolator(band_positions_jittered, band_values)\n                band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n                method = \"Linear\"\n            except:\n                # FIX: Final fallback to nearest neighbor interpolation\n                interpolator = NearestNDInterpolator(band_positions_jittered, band_values)\n                band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n                method = \"Nearest\"\n        \n        band_image = np.nan_to_num(band_image, nan=0)\n        \n        # Normalize band\n        band_min, band_max = band_image.min(), band_image.max()\n        if band_max - band_min > 1e-8:\n            band_image = (band_image - band_min) / (band_max - band_min)\n        else:\n            # Handle constant band case\n            band_image = np.zeros_like(band_image)\n            \n        image[..., band_idx] = band_image\n        \n        if verbose:\n            band_name = ['μ (8-13Hz)', 'β1 (13-21Hz)', 'β2 (21-30Hz)'][band_idx]\n            print(f\"\\n{band_name} band image ({method}):\")\n            print(f\"  Raw: Min={np.min(band_image):.4f}, Max={np.max(band_image):.4f}, Mean={np.mean(band_image):.4f}\")\n            print(f\"  Normalized: Min={np.min(image[..., band_idx]):.4f}, Max={np.max(image[..., band_idx]):.4f}\")\n            print(f\"  Jitter magnitude: {np.max(np.abs(jitter)):.4f}\")\n    \n    if verbose:\n        print(\"\\nFinal TPCT image:\")\n        print(f\"  Shape: {image.shape}\")\n        print(f\"  Min: {np.min(image):.4f}, Max: {np.max(image):.4f}\")\n        print(f\"  Mean: {np.mean(image):.4f}, Std: {np.std(image):.4f}\")\n        print(f\"  Variance: {np.var(image):.6f}\")\n        print(\"=\"*60)\n    \n    return image\n\n# ======================== PAPER'S MVGG ARCHITECTURE ========================\ndef build_mvgg(input_shape=(64, 64, 3)):\n    \"\"\"Build exact mVGG architecture from paper (Table I)\"\"\"\n    print(\"\\nBuilding mVGG model architecture\")\n    \n    inputs = Input(shape=input_shape)\n    x = inputs\n    \n    # Section 1: 6x [Conv3x3-64]\n    for i in range(6):\n        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (2, 2), strides=2, activation='relu', padding='same')(x)  # Downsample\n    \n    # Section 2: 5x [Conv2x2-128]\n    for i in range(5):\n        x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(128, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 3: 5x [Conv2x2-256]\n    for i in range(5):\n        x = Conv2D(256, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(256, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 4: 5x [Conv2x2-512]\n    for i in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 5: 5x [Conv2x2-512]\n    for i in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Classification head\n    x = GlobalAveragePooling2D()(x)\n    outputs = Dense(2, activation='softmax')(x)\n    \n    model = Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(\"Model summary:\")\n    model.summary()\n    print(f\"Total parameters: {model.count_params()}\")\n    return model\n\n# ======================== MAIN EXECUTION ========================\ndef main():\n    # Load all data\n    all_images, all_labels = [], []\n    total_trials = 0\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STARTING DATA PROCESSING\")\n    print(\"=\"*80)\n    \n    for subject in range(1, 10):  # Subjects 1-9\n        sessions = ['01T', '02T', '03T']\n        print(f\"\\nProcessing subject {subject}/9\")\n        \n        subject_trials = 0\n        for session_idx, session in enumerate(sessions):\n            print(f\"\\n  Session {session_idx+1}/3: {session}\")\n            \n            trials, labels = load_data(subject, session)\n            if len(trials) == 0:\n                print(\"  -> Skipped (no trials)\")\n                continue\n                \n            print(f\"  -> Processing {len(trials)} trials\")\n            \n            for trial_idx, trial in enumerate(trials):\n                # Only show details for first trial of first session\n                verbose = (subject == 1 and session == '01T' and trial_idx == 0)\n                \n                if verbose:\n                    print(f\"\\n    Processing trial {trial_idx+1}/{len(trials)} (VERBOSE OUTPUT)\")\n                    image = create_tpct_image(trial, verbose=True)\n                else:\n                    if trial_idx == 0:\n                        print(f\"    Processing {len(trials)} trials...\")\n                    image = create_tpct_image(trial, verbose=False)\n                \n                all_images.append(image)\n                subject_trials += 1\n            \n            all_labels.extend(labels)\n            total_trials += len(trials)\n        \n        print(f\"\\n  Subject {subject} summary: {subject_trials} trials processed\")\n    \n    X = np.array(all_images)\n    y = np.array(all_labels)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"DATASET SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Total trials: {X.shape[0]}\")\n    print(f\"Image shape: {X.shape[1:]} (height x width x channels)\")\n    print(f\"Class distribution: Left={np.sum(y==0)}, Right={np.sum(y==1)}\")\n    print(f\"Data stats - Min: {np.min(X):.4f}, Max: {np.max(X):.4f}\")\n    print(f\"Mean: {np.mean(X):.4f}, Std: {np.std(X):.4f}\")\n    print(f\"Variance: {np.var(X):.6f}\")\n    \n    # 10-fold cross-validation as in paper\n    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    accuracies, kappas = [], []\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STARTING 10-FOLD CROSS VALIDATION\")\n    print(\"=\"*80)\n    \n    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n        print(f\"\\nFold {fold+1}/10\")\n        print(f\"  Train samples: {len(train_idx)} ({len(train_idx)/len(X)*100:.1f}%)\")\n        print(f\"  Test samples: {len(test_idx)} ({len(test_idx)/len(X)*100:.1f}%)\")\n        print(f\"  Train class distribution: Left={np.sum(y[train_idx]==0)}, Right={np.sum(y[train_idx]==1)}\")\n        print(f\"  Test class distribution: Left={np.sum(y[test_idx]==0)}, Right={np.sum(y[test_idx]==1)}\")\n        \n        model = build_mvgg()\n        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n        \n        print(\"\\n  Training model...\")\n        history = model.fit(\n            X[train_idx], y[train_idx],\n            validation_split=0.1,\n            epochs=100,\n            batch_size=32,\n            callbacks=[early_stop],\n            verbose=1\n        )\n        \n        print(\"\\n  Evaluating model...\")\n        y_pred = model.predict(X[test_idx], verbose=0).argmax(axis=1)\n        acc = accuracy_score(y[test_idx], y_pred)\n        kappa = cohen_kappa_score(y[test_idx], y_pred)\n        \n        accuracies.append(acc)\n        kappas.append(kappa)\n        print(f\"\\n  Fold {fold+1} results:\")\n        print(f\"    Accuracy: {acc:.4f}\")\n        print(f\"    Kappa:    {kappa:.4f}\")\n        print(f\"    Error:    {1-acc:.4f}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"FINAL RESULTS\")\n    print(\"=\"*80)\n    print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n    print(f\"Mean Kappa:    {np.mean(kappas):.4f} ± {np.std(kappas):.4f}\")\n    print(f\"Min Accuracy:  {np.min(accuracies):.4f}, Max Accuracy: {np.max(accuracies):.4f}\")\n    print(f\"Min Kappa:     {np.min(kappas):.4f}, Max Kappa:    {np.max(kappas):.4f}\")\n\nif __name__ == \"__main__\":\n    # Configure GPU memory growth\n    physical_devices = tf.config.list_physical_devices('GPU')\n    if physical_devices:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    \n    # Set random seeds for reproducibility\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:29:25.561283Z","iopub.execute_input":"2025-06-22T20:29:25.561845Z","iopub.status.idle":"2025-06-22T20:29:39.123872Z","shell.execute_reply.started":"2025-06-22T20:29:25.561817Z","shell.execute_reply":"2025-06-22T20:29:39.122899Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nSTARTING DATA PROCESSING\n================================================================================\n\nProcessing subject 1/9\n\n  Session 1/3: 01T\n\n=== Loading subject 1, session 01T ===\nFound 271 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -9.88μV, Max: 10.97μV\n  Mean: -0.01μV, Std: 3.02μV\n  Variance: 9.10μV²\n  Channel means: C3=0.09μV, Cz=-0.16μV, C4=0.05μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n\n    Processing trial 1/120 (VERBOSE OUTPUT)\n\n============================================================\nCreating TPCT Image\n============================================================\nInput trial shape: (3, 750)\nMin: -9.88μV, Max: 10.97μV\nMean: -0.01μV, Std: 3.02μV\nVariance: 9.10μV²\n\nComputing features for band 8-13Hz\n  Trial shape: (3, 750)\n  Window size: 75 samples\n  Window 1 power: C3=892.15, Cz=566.63, C4=1059.41\n\nBand 8-13Hz average power:\n  C3: 1035.13 (Min: 26.89, Max: 4275.71)\n  Cz: 948.81 (Min: 55.81, Max: 3476.82)\n  C4: 528.74 (Min: 78.32, Max: 1059.41)\n\nComputing features for band 13-21Hz\n  Trial shape: (3, 750)\n  Window size: 75 samples\n  Window 1 power: C3=179.98, Cz=65.21, C4=138.37\n\nBand 13-21Hz average power:\n  C3: 175.24 (Min: 43.01, Max: 506.36)\n  Cz: 202.21 (Min: 52.51, Max: 724.61)\n  C4: 300.91 (Min: 69.47, Max: 864.58)\n\nComputing features for band 21-30Hz\n  Trial shape: (3, 750)\n  Window size: 75 samples\n  Window 1 power: C3=211.18, Cz=176.40, C4=99.63\n\nBand 21-30Hz average power:\n  C3: 121.15 (Min: 31.55, Max: 357.84)\n  Cz: 73.30 (Min: 18.33, Max: 176.40)\n  C4: 118.13 (Min: 25.77, Max: 259.49)\n\nRaw features (electrode x band):\n[[1035.13063523  175.23762409  121.14874331]\n [ 948.81241084  202.2137417    73.29946343]\n [ 528.7401903   300.90876922  118.13073528]]\n\nLog-scaled features:\n[[3.01499516 2.24362736 2.08331891]\n [2.97718036 2.30581067 1.8651008 ]\n [2.72324232 2.47843484 2.07236291]]\nFeature stats - Min: 1.8651, Max: 3.0150\nMean: 2.4182, Std: 0.3867\nVariance: 0.1496\n\nElectrode positions and values:\n  C3 μ (8-13Hz): Position=(-1.05, -0.05), Value=3.0150\n  C3 β1 (13-21Hz): Position=(-1, 0), Value=2.2436\n  C3 β2 (21-30Hz): Position=(-0.95, 0.05), Value=2.0833\n  Cz μ (8-13Hz): Position=(-0.05, 0.05), Value=2.9772\n  Cz β1 (13-21Hz): Position=(0, 0), Value=2.3058\n  Cz β2 (21-30Hz): Position=(0.05, -0.05), Value=1.8651\n  C4 μ (8-13Hz): Position=(0.95, -0.05), Value=2.7232\n  C4 β1 (13-21Hz): Position=(1, 0), Value=2.4784\n  C4 β2 (21-30Hz): Position=(1.05, 0.05), Value=2.0724\n\nμ (8-13Hz) band image (Clough-Tocher):\n  Raw: Min=0.0000, Max=1.0000, Mean=0.0300\n  Normalized: Min=0.0000, Max=1.0000\n  Jitter magnitude: 0.0015\n\nβ1 (13-21Hz) band image (Clough-Tocher):\n  Raw: Min=0.0000, Max=0.0000, Mean=0.0000\n  Normalized: Min=0.0000, Max=0.0000\n  Jitter magnitude: 0.0016\n\nβ2 (21-30Hz) band image (Clough-Tocher):\n  Raw: Min=0.0000, Max=1.0000, Mean=0.0303\n  Normalized: Min=0.0000, Max=1.0000\n  Jitter magnitude: 0.0019\n\nFinal TPCT image:\n  Shape: (64, 64, 3)\n  Min: 0.0000, Max: 1.0000\n  Mean: 0.0201, Std: 0.1381\n  Variance: 0.019076\n============================================================\n\n  Session 2/3: 02T\n\n=== Loading subject 1, session 02T ===\nFound 268 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -16.35μV, Max: 15.08μV\n  Mean: -0.41μV, Std: 4.29μV\n  Variance: 18.37μV²\n  Channel means: C3=0.06μV, Cz=-0.73μV, C4=-0.56μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n\n  Session 3/3: 03T\n\n=== Loading subject 1, session 03T ===\nFound 527 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -9.38μV, Max: 9.35μV\n  Mean: -0.03μV, Std: 2.98μV\n  Variance: 8.88μV²\n  Channel means: C3=0.11μV, Cz=0.05μV, C4=-0.23μV\n\nExtracted 160 valid trials\nLabel distribution: Left=80, Right=80\n  -> Processing 160 trials\n    Processing 160 trials...\n\n  Subject 1 summary: 400 trials processed\n\nProcessing subject 2/9\n\n  Session 1/3: 01T\n\n=== Loading subject 2, session 01T ===\nFound 275 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -9.07μV, Max: 11.55μV\n  Mean: 0.49μV, Std: 3.07μV\n  Variance: 9.45μV²\n  Channel means: C3=0.58μV, Cz=0.05μV, C4=0.84μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n\n  Session 2/3: 02T\n\n=== Loading subject 2, session 02T ===\nFound 273 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -11.11μV, Max: 7.92μV\n  Mean: -0.56μV, Std: 2.59μV\n  Variance: 6.69μV²\n  Channel means: C3=-0.37μV, Cz=-1.35μV, C4=0.02μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n\n  Session 3/3: 03T\n\n=== Loading subject 2, session 03T ===\nFound 520 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -13.68μV, Max: 11.23μV\n  Mean: 0.66μV, Std: 3.65μV\n  Variance: 13.30μV²\n  Channel means: C3=0.76μV, Cz=0.53μV, C4=0.68μV\n\nExtracted 160 valid trials\nLabel distribution: Left=80, Right=80\n  -> Processing 160 trials\n    Processing 160 trials...\n\n  Subject 2 summary: 400 trials processed\n\nProcessing subject 3/9\n\n  Session 1/3: 01T\n\n=== Loading subject 3, session 01T ===\nFound 283 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -22.38μV, Max: 16.82μV\n  Mean: -0.27μV, Std: 4.58μV\n  Variance: 20.97μV²\n  Channel means: C3=-0.37μV, Cz=-0.15μV, C4=-0.28μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n\n  Session 2/3: 02T\n\n=== Loading subject 3, session 02T ===\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_452/2521566109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_452/2521566109.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n  Session {session_idx+1}/3: {session}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  -> Skipped (no trials)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_452/2521566109.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(subject, session)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Load and scale to microvolts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents_from_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36mread_raw_gdf\u001b[0;34m(input_fname, eog, misc, stim_channel, exclude, include, preload, verbose)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"gdf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Only GDF files are supported, got {ext}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m     return RawGDF(\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0minput_fname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0meog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-323>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, preload, include, verbose)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, preload, include, verbose)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Raw attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mlast_samps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0medf_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nsamples\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mpreload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-303>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# If we have True or a string, actually do the preloading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_from_disk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_argvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_preload_data\u001b[0;34m(self, preload)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;34mf\"Reading 0 ... {len(t) - 1}  =  {0.0:9.3f} ... {t[-1]:9.3f} secs...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         )\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nchan\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-305>\u001b[0m in \u001b[0;36m_read_segment\u001b[0;34m(self, start, stop, sel, data_buffer, verbose)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_read_segment\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;31m# reindex back to original file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0morig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_picks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneed_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             _ReadSegmentFileProtector(self)._read_segment_file(\n\u001b[0m\u001b[1;32m    478\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_sl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0morig_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/base.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[0;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_segment_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2701\u001b[0;31m         return self.__raw.__class__._read_segment_file(\n\u001b[0m\u001b[1;32m   2702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[0;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_segment_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Read a chunk of raw data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         return _read_segment_file(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[0;34m(data, idx, fi, start, stop, raw_extras, filenames, cals, mult)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;31m# We could read this one EDF block at a time, which would be this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0mch_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mblock_start_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_lims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_blk_read_lims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0;31m# But to speed it up, we really need to read multiple blocks at once,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# Otherwise we can end up with e.g. 18,181 chunks for a 20 MB file!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mne/_fiff/utils.py\u001b[0m in \u001b[0;36m_blk_read_lims\u001b[0;34m(start, stop, buf_len)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mr_eidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0md_lims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md_sidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_eidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mr_lims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr_sidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_eidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mblock_start_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_lims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_lims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport numpy as np\nimport mne\nfrom scipy.interpolate import CloughTocher2DInterpolator, NearestNDInterpolator, RBFInterpolator\nfrom scipy.fft import fft, ifft\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\n\n# ======================== CONSTANTS ========================\nFS = 250  # Sampling frequency (Hz)\nN_FFT = 256  # FFT length\nN_WINDOWS = 10  # Number of time windows\nBANDS = [(8, 13), (13, 21), (21, 30)]  # Frequency bands (Hz)\nIMG_SIZE = 64  # Image dimensions\nDELTA = 0.05  # Shift value for electrode positioning\n\nELECTRODE_POS = {\n    'C3': [\n        (-1 - DELTA, -DELTA),  # Band 1: left and down\n        (-1, 0),               # Band 2: center\n        (-1 + DELTA, DELTA)    # Band 3: right and up\n    ],\n    'Cz': [\n        (0 - DELTA, DELTA),    # Band 1: left and up\n        (0, 0),                # Band 2: center\n        (0 + DELTA, -DELTA)    # Band 3: right and down\n    ],\n    'C4': [\n        (1 - DELTA, -DELTA),   # Band 1: left and down\n        (1, 0),                # Band 2: center\n        (1 + DELTA, DELTA)     # Band 3: right and up\n    ]\n}\n\n# ======================== DATA LOADING ========================\ndef load_data(subject, session):\n    \"\"\"Load EEG data and events with proper scaling and timing\"\"\"\n    filename = f'B{subject:02d}{session}.gdf'\n    filepath = os.path.join('/kaggle/input/bci-competition-2008-graz-data-set-b/BCICIV_2b_gdf', filename)\n    \n    if not os.path.exists(filepath):\n        print(f\"[ERROR] File not found: {filepath}\")\n        return np.array([]), np.array([])\n    \n    try:\n        # Load and scale to microvolts\n        raw = mne.io.read_raw_gdf(filepath, preload=True, verbose='ERROR')\n        raw.apply_function(lambda x: x * 1e6)\n        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n        \n        trials, labels = [], []\n        \n        for event in events:\n            if event[2] in [event_ids.get('769', -1), event_ids.get('770', -1)]:\n                start = event[0]\n                end = start + int(3 * FS)  # 3 seconds of data\n                \n                if end > raw.n_times:\n                    continue\n                    \n                # Get only C3, Cz, C4 channels\n                trial = raw.get_data()[:3, start:end]\n                trials.append(trial)\n                \n                label = 0 if event[2] == event_ids.get('769', -1) else 1\n                labels.append(label)\n                \n        return np.array(trials), np.array(labels)\n    \n    except Exception as e:\n        print(f\"[ERROR] Processing file: {str(e)}\")\n        return np.array([]), np.array([])\n\n# ======================== TPCT FEATURE EXTRACTION ========================\ndef compute_band_features(trial_data, band):\n    \"\"\"Compute band features using paper's method (FFT → sub-band → IFFT → power)\"\"\"\n    window_size = trial_data.shape[1] // N_WINDOWS\n    band_powers = []\n    \n    for win_idx in range(N_WINDOWS):\n        start = win_idx * window_size\n        end = start + window_size\n        window = trial_data[:, start:end]\n        \n        # FFT with zero-padding\n        spec = fft(window, n=N_FFT, axis=1)\n        freqs = np.fft.fftfreq(N_FFT, 1/FS)\n        \n        # Extract sub-band frequencies\n        band_idx = np.where((freqs >= band[0]) & (freqs <= band[1]))[0]\n        if len(band_idx) == 0:\n            band_powers.append(np.zeros(trial_data.shape[0]))\n            continue\n            \n        sub_band_spec = spec[:, band_idx]\n        \n        # IFFT → Time-domain signal\n        time_domain = ifft(sub_band_spec, axis=1)\n        \n        # Compute power\n        power = np.mean(np.abs(time_domain)**2, axis=1)\n        band_powers.append(power)\n    \n    # Average power across windows\n    return np.mean(band_powers, axis=0)\n\ndef create_tpct_image(trial_data):\n    \"\"\"Create TPCT image with robust interpolation\"\"\"\n    features = []\n    for band in BANDS:\n        band_features = compute_band_features(trial_data, band)\n        features.append(band_features)\n    \n    features = np.array(features).T  # Shape: (3 electrodes, 3 bands)\n    \n    # Apply logarithmic scaling\n    features = np.log10(features + 1e-6)\n\n    positions, values = [], []\n    for elec_idx, electrode in enumerate(['C3', 'Cz', 'C4']):\n        for band_idx in range(3):\n            pos = ELECTRODE_POS[electrode][band_idx]\n            positions.append(pos)\n            values.append(features[elec_idx, band_idx])\n    \n    # Create grid\n    x_grid = np.linspace(-1.5, 1.5, IMG_SIZE)\n    y_grid = np.linspace(-0.5, 0.5, IMG_SIZE)\n    xx, yy = np.meshgrid(x_grid, y_grid)\n    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n    \n    image = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n    \n    for band_idx in range(3):\n        band_values = values[band_idx::3]\n        band_positions = positions[band_idx::3]\n        \n        # Add jitter to prevent collinear points\n        jitter = np.random.uniform(-0.1, 0.1, (len(band_positions), 2))\n        band_positions_jittered = np.array(band_positions) + jitter\n        \n        # Enhanced interpolation with fallbacks\n        try:\n            interpolator = CloughTocher2DInterpolator(band_positions_jittered, band_values)\n            band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n        except:\n            try:\n                interpolator = RBFInterpolator(band_positions_jittered, band_values)\n                band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n            except:\n                interpolator = NearestNDInterpolator(band_positions_jittered, band_values)\n                band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n        \n        # Handle NaNs\n        band_image = np.nan_to_num(band_image, nan=np.mean(band_values))\n        \n        # Normalize band\n        band_min = np.min(band_image)\n        band_max = np.max(band_image)\n        if band_max - band_min > 1e-4:\n            band_image = (band_image - band_min) / (band_max - band_min)\n        else:\n            band_mean = np.mean(band_image)\n            band_std = np.std(band_image)\n            if band_std > 1e-6:\n                band_image = 1 / (1 + np.exp(-(band_image - band_mean) / band_std))\n        \n        image[..., band_idx] = band_image\n    \n    return image\n\n# ======================== PAPER'S MVGG ARCHITECTURE ========================\ndef build_mvgg(input_shape=(64, 64, 3)):\n    \"\"\"Build mVGG architecture from paper\"\"\"\n    inputs = Input(shape=input_shape)\n    x = inputs\n    \n    # Section 1: 6x [Conv3x3-64]\n    for _ in range(6):\n        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 2: 5x [Conv2x2-128]\n    for _ in range(5):\n        x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(128, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 3: 5x [Conv2x2-256]\n    for _ in range(5):\n        x = Conv2D(256, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(256, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 4: 5x [Conv2x2-512]\n    for _ in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 5: 5x [Conv2x2-512]\n    for _ in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Classification head\n    x = GlobalAveragePooling2D()(x)\n    outputs = Dense(2, activation='softmax')(x)\n    \n    model = Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# ======================== MAIN EXECUTION ========================\ndef main():\n    # Load all data\n    all_images, all_labels = [], []\n    total_trials = 0\n    \n    print(\"Starting data processing for 9 subjects...\")\n    \n    for subject in range(1, 10):\n        sessions = ['01T', '02T', '03T']\n        print(f\"\\nProcessing subject {subject}/9\")\n        \n        subject_trials = 0\n        for session in sessions:\n            trials, labels = load_data(subject, session)\n            if len(trials) == 0:\n                continue\n                \n            print(f\"  Session {session}: {len(trials)} trials\")\n            \n            for trial in trials:\n                image = create_tpct_image(trial)\n                all_images.append(image)\n                subject_trials += 1\n            \n            all_labels.extend(labels)\n            total_trials += len(trials)\n        \n        print(f\"  Subject {subject} completed: {subject_trials} trials\")\n    \n    X = np.array(all_images)\n    y = np.array(all_labels)\n    \n    print(\"\\nDataset summary:\")\n    print(f\"Total trials: {X.shape[0]}\")\n    print(f\"Class distribution: Left={np.sum(y==0)}, Right={np.sum(y==1)}\")\n    \n    # 10-fold cross-validation\n    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    accuracies, kappas = [], []\n    \n    print(\"\\nStarting 10-fold cross-validation with mVGG model\")\n    \n    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n        print(f\"\\nFold {fold+1}/10\")\n        print(f\"  Training samples: {len(train_idx)}, Test samples: {len(test_idx)}\")\n        print(f\"  Class ratio: {np.sum(y[train_idx]==0)}L/{np.sum(y[train_idx]==1)}R train, \"\n              f\"{np.sum(y[test_idx]==0)}L/{np.sum(y[test_idx]==1)}R test\")\n        \n        model = build_mvgg()\n        early_stop = EarlyStopping(monitor='val_loss', patience=5, \n                                  restore_best_weights=True, verbose=1)\n        \n        print(\"  Training model...\")\n        history = model.fit(\n            X[train_idx], y[train_idx],\n            validation_split=0.1,\n            epochs=100,\n            batch_size=32,\n            callbacks=[early_stop],\n            verbose=1\n        )\n        \n        # Evaluate model\n        y_pred = model.predict(X[test_idx], verbose=0).argmax(axis=1)\n        acc = accuracy_score(y[test_idx], y_pred)\n        kappa = cohen_kappa_score(y[test_idx], y_pred)\n        \n        accuracies.append(acc)\n        kappas.append(kappa)\n        print(f\"  Fold results - Accuracy: {acc:.4f}, Kappa: {kappa:.4f}\")\n    \n    print(\"\\nFinal results:\")\n    print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n    print(f\"Mean Kappa:    {np.mean(kappas):.4f} ± {np.std(kappas):.4f}\")\n\nif __name__ == \"__main__\":\n    # Configure GPU\n    physical_devices = tf.config.list_physical_devices('GPU')\n    if physical_devices:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    \n    # Set random seeds\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:06:50.467141Z","iopub.execute_input":"2025-06-22T21:06:50.467433Z","iopub.status.idle":"2025-06-22T21:06:51.986619Z","shell.execute_reply.started":"2025-06-22T21:06:50.467411Z","shell.execute_reply":"2025-06-22T21:06:51.985718Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mQhullError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_452/1556305734.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_452/1556305734.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_tpct_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_452/1556305734.py\u001b[0m in \u001b[0;36mcreate_tpct_image\u001b[0;34m(trial_data)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mch_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Positions for this channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0minterpolator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloughTocher2DInterpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mch_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_interpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate._interpnd.CloughTocher2DInterpolator.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_interpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate._interpnd.NDInterpolatorBase.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_interpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate._interpnd.CloughTocher2DInterpolator._calculate_triangulation\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_qhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial._qhull.Delaunay.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_qhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial._qhull._Qhull.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;31mQhullError\u001b[0m: QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)\n\nWhile executing:  | qhull d Qt Qc Q12 Qbb Qz\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 104642130  delaunay  Qtriangulate  Qcoplanar-keep  Q12-allow-wide\n  Qbbound-last  Qz-infinity-point  _pre-merge  _zero-centrum  Qinterior-keep\n  Pgood  _max-width  2  Error-roundoff 1.4e-15  _one-merge 9.7e-15\n  Visible-distance 2.8e-15  U-max-coplanar 2.8e-15  Width-outside 5.5e-15\n  _wide-facet 1.7e-14  _maxoutside 1.1e-14\n\nThe input to qhull appears to be less than 3 dimensional, or a\ncomputation has overflowed.\n\nQhull could not construct a clearly convex simplex from points:\n- p3(v4):     0     0     1\n- p1(v3):     0     0     0\n- p2(v2):     1     0  0.91\n- p0(v1):    -1     0  0.91\n\nThe center point is coplanar with a facet, or a vertex is coplanar\nwith a neighboring facet.  The maximum round off error for\ncomputing distances is 1.4e-15.  The center point, facets and distances\nto the center point are as follows:\n\ncenter point        0        0   0.7045\n\nfacet p1 p2 p0 distance=    0\nfacet p3 p2 p0 distance=    0\nfacet p3 p1 p0 distance=    0\nfacet p3 p1 p2 distance=    0\n\nThese points either have a maximum or minimum x-coordinate, or\nthey maximize the determinant for k coordinates.  Trial points\nare first selected from points that maximize a coordinate.\n\nThe min and max coordinates for each dimension are:\n  0:        -1         1  difference=    2\n  1:         0         0  difference=    0\n  2:         0         1  difference=    1\n\nIf the input should be full dimensional, you have several options that\nmay determine an initial simplex:\n  - use 'QJ'  to joggle the input and make it full dimensional\n  - use 'QbB' to scale the points to the unit cube\n  - use 'QR0' to randomly rotate the input for different maximum points\n  - use 'Qs'  to search all points for the initial simplex\n  - use 'En'  to specify a maximum roundoff error less than 1.4e-15.\n  - trace execution with 'T3' to see the determinant for each point.\n\nIf the input is lower dimensional:\n  - use 'QJ' to joggle the input and make it full dimensional\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\n    pick the coordinate with the least range.  The hull will have the\n    correct topology.\n  - determine the flat containing the points, rotate the points\n    into a coordinate plane, and delete the other coordinates.\n  - add one or more points to make the input full dimensional.\n"],"ename":"QhullError","evalue":"QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)\n\nWhile executing:  | qhull d Qt Qc Q12 Qbb Qz\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 104642130  delaunay  Qtriangulate  Qcoplanar-keep  Q12-allow-wide\n  Qbbound-last  Qz-infinity-point  _pre-merge  _zero-centrum  Qinterior-keep\n  Pgood  _max-width  2  Error-roundoff 1.4e-15  _one-merge 9.7e-15\n  Visible-distance 2.8e-15  U-max-coplanar 2.8e-15  Width-outside 5.5e-15\n  _wide-facet 1.7e-14  _maxoutside 1.1e-14\n\nThe input to qhull appears to be less than 3 dimensional, or a\ncomputation has overflowed.\n\nQhull could not construct a clearly convex simplex from points:\n- p3(v4):     0     0     1\n- p1(v3):     0     0     0\n- p2(v2):     1     0  0.91\n- p0(v1):    -1     0  0.91\n\nThe center point is coplanar with a facet, or a vertex is coplanar\nwith a neighboring facet.  The maximum round off error for\ncomputing distances is 1.4e-15.  The center point, facets and distances\nto the center point are as follows:\n\ncenter point        0        0   0.7045\n\nfacet p1 p2 p0 distance=    0\nfacet p3 p2 p0 distance=    0\nfacet p3 p1 p0 distance=    0\nfacet p3 p1 p2 distance=    0\n\nThese points either have a maximum or minimum x-coordinate, or\nthey maximize the determinant for k coordinates.  Trial points\nare first selected from points that maximize a coordinate.\n\nThe min and max coordinates for each dimension are:\n  0:        -1         1  difference=    2\n  1:         0         0  difference=    0\n  2:         0         1  difference=    1\n\nIf the input should be full dimensional, you have several options that\nmay determine an initial simplex:\n  - use 'QJ'  to joggle the input and make it full dimensional\n  - use 'QbB' to scale the points to the unit cube\n  - use 'QR0' to randomly rotate the input for different maximum points\n  - use 'Qs'  to search all points for the initial simplex\n  - use 'En'  to specify a maximum roundoff error less than 1.4e-15.\n  - trace execution with 'T3' to see the determinant for each point.\n\nIf the input is lower dimensional:\n  - use 'QJ' to joggle the input and make it full dimensional\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\n    pick the coordinate with the least range.  The hull will have the\n    correct topology.\n  - determine the flat containing the points, rotate the points\n    into a coordinate plane, and delete the other coordinates.\n  - add one or more points to make the input full dimensional.\n","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"import os\nimport numpy as np\nimport mne\nfrom scipy.interpolate import CloughTocher2DInterpolator\nfrom scipy.fft import fft, ifft\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nimport matplotlib.pyplot as plt\n\n# ======================== PAPER-CORRECTED CONSTANTS ========================\nFS = 250\nN_FFT = 256\nN_WINDOWS = 10\nBANDS = [(8, 13), (13, 21), (21, 30)]  # μ, lower β, upper β\nIMG_SIZE = 64\nDELTA = 0.05  # Position shift\nVERTICAL_OFFSET = 0.01  # Small vertical offset to break collinearity\n\n# Corrected positions with vertical offset for band 1\nELECTRODE_POS = {\n    'C3': [\n        (-1, VERTICAL_OFFSET),      # Band 1 (center) - shifted UP\n        (-1 - DELTA, -DELTA),      # Band 2\n        (-1 + DELTA, DELTA)        # Band 3\n    ],\n    'Cz': [\n        (0, 0),                    # Band 1 (center) - unchanged\n        (0 - DELTA, DELTA),        # Band 2\n        (0 + DELTA, -DELTA)        # Band 3\n    ],\n    'C4': [\n        (1, -VERTICAL_OFFSET),     # Band 1 (center) - shifted DOWN\n        (1 - DELTA, -DELTA),       # Band 2\n        (1 + DELTA, DELTA)         # Band 3\n    ]\n}\n\n# ======================== DATA LOADING ========================\ndef load_data(subject, session):\n    filename = f'B{subject:02d}{session}.gdf'\n    filepath = os.path.join('/kaggle/input/bci-competition-2008-graz-data-set-b/BCICIV_2b_gdf', filename)\n    \n    try:\n        raw = mne.io.read_raw_gdf(filepath, preload=True, verbose='ERROR')\n        raw.apply_function(lambda x: x * 1e6)  # μV conversion\n        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n        \n        trials, labels = [], []\n        for event in events:\n            if event[2] in [event_ids.get('769', -1), event_ids.get('770', -1)]:\n                start = event[0]\n                end = start + int(3 * FS)  # 3s trial\n                if end > raw.n_times: continue\n                trials.append(raw.get_data()[:3, start:end])  # C3, Cz, C4\n                labels.append(0 if event[2] == event_ids.get('769', -1) else 1)\n                \n        return np.array(trials), np.array(labels)\n    except Exception as e:\n        print(f\"Error loading {filepath}: {str(e)}\")\n        return np.array([]), np.array([])\n\n# ======================== PAPER-ACCURATE TPCT ========================\ndef compute_band_features(trial_data, band):\n    \"\"\"Paper-corrected feature calculation (Eq. 2-11)\"\"\"\n    n_samples = trial_data.shape[1]\n    window_size = n_samples // N_WINDOWS\n    band_powers = np.zeros((N_WINDOWS, trial_data.shape[0]))\n    \n    for win_idx in range(N_WINDOWS):\n        start = win_idx * window_size\n        end = start + window_size\n        window = trial_data[:, start:end]\n        \n        # FFT with zero-padding\n        spec = fft(window, n=N_FFT, axis=1)\n        freqs = np.fft.fftfreq(N_FFT, 1/FS)\n        \n        # Extract sub-band\n        band_mask = (freqs >= band[0]) & (freqs <= band[1])\n        sub_band_spec = spec[:, band_mask]\n        \n        # IFFT → Time-domain (Eq. 8)\n        time_domain = np.real(ifft(sub_band_spec, axis=1))\n        \n        # Average power (Eq. 10)\n        band_powers[win_idx] = np.mean(np.abs(time_domain), axis=1)\n    \n    # Average across windows (Eq. 11)\n    return np.mean(band_powers, axis=0)\n\ndef create_tpct_image(trial_data):\n    \"\"\"Paper-accurate TPCT image generation\"\"\"\n    features = []\n    for band in BANDS:\n        band_features = compute_band_features(trial_data, band)\n        features.append(band_features)\n    \n    features = np.array(features).T  # (electrodes, bands)\n    features = np.log10(features + 1e-12)  # Log scaling\n    \n    # Prepare interpolation points\n    positions, values = [], []\n    for elec_idx, electrode in enumerate(['C3', 'Cz', 'C4']):\n        for band_idx in range(3):\n            positions.append(ELECTRODE_POS[electrode][band_idx])\n            values.append(features[elec_idx, band_idx])\n    \n    # Create grid\n    x_grid = np.linspace(-1.5, 1.5, IMG_SIZE)\n    y_grid = np.linspace(-0.5, 0.5, IMG_SIZE)\n    xx, yy = np.meshgrid(x_grid, y_grid)\n    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n    \n    # Paper-corrected interpolation\n    image = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n    for ch in range(3):\n        ch_values = values[ch::3]  # Values for this channel\n        ch_positions = positions[ch::3]  # Positions for this channel\n        \n        interpolator = CloughTocher2DInterpolator(np.array(ch_positions), ch_values)\n        ch_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n        \n        # Handle NaNs\n        ch_image = np.nan_to_num(ch_image, nan=np.mean(ch_values))\n        image[..., ch] = ch_image\n    \n    # Normalize per channel\n    for ch in range(3):\n        channel = image[..., ch]\n        channel = (channel - np.min(channel)) / (np.max(channel) - np.min(channel) + 1e-8)\n        image[..., ch] = channel\n    \n    return image\n\n# ======================== PAPER-ACCURATE MVGG ========================\ndef build_mvgg(input_shape=(64, 64, 3)):\n    \"\"\"Paper-accurate mVGG implementation (Table I)\"\"\"\n    inputs = Input(shape=input_shape)\n    x = inputs\n    \n    # Section 1: 6x [Conv3x3-64]\n    for _ in range(6):\n        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (2, 2), strides=2, activation='relu', padding='same')(x)  # Downsample\n    \n    # Section 2: 5x [Conv2x2-128]\n    for _ in range(5):\n        x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(128, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 3: 5x [Conv2x2-256]\n    for _ in range(5):\n        x = Conv2D(256, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(256, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 4: 5x [Conv2x2-512]\n    for _ in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 5: 5x [Conv2x2-512]\n    for _ in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Paper-corrected classification head (Section III-C.2.d)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    x = Flatten()(x)\n    outputs = Dense(2, activation='softmax')(x)\n    \n    model = Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ======================== VALIDATION UTILITIES ========================\ndef visualize_sample(X, y, num=5):\n    \"\"\"Visualize samples to verify feature generation\"\"\"\n    plt.figure(figsize=(15, 6))\n    for i in range(num):\n        plt.subplot(2, num, i+1)\n        plt.imshow(X[y==0][i])\n        plt.title(f\"Left Hand (Sample {i})\")\n        plt.axis('off')\n        \n        plt.subplot(2, num, num+i+1)\n        plt.imshow(X[y==1][i])\n        plt.title(f\"Right Hand (Sample {i})\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# ======================== MAIN EXECUTION ========================\ndef main():\n    # Load data\n    all_images, all_labels = [], []\n    \n    for subject in range(1, 10):  # 9 subjects\n        for session in ['01T', '02T', '03T']:  # Training sessions\n            trials, labels = load_data(subject, session)\n            for trial in trials:\n                all_images.append(create_tpct_image(trial))\n            all_labels.extend(labels)\n    \n    X = np.array(all_images)\n    y = np.array(all_labels)\n    \n    # Verify dataset\n    print(f\"Dataset shape: {X.shape}, Labels: {y.shape}\")\n    print(f\"Class distribution: {np.sum(y==0)} Left, {np.sum(y==1)} Right\")\n    visualize_sample(X, y)  # Critical validation\n    \n    # 10-fold CV\n    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    accuracies, kappas = [], []\n    \n    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n        print(f\"\\nFold {fold+1}/10\")\n        model = build_mvgg()\n        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n        \n        # Train with validation split\n        history = model.fit(\n            X[train_idx], y[train_idx],\n            validation_split=0.1,\n            epochs=100,\n            batch_size=32,\n            callbacks=[early_stop],\n            verbose=1\n        )\n        \n        # Evaluate\n        y_pred = model.predict(X[test_idx]).argmax(axis=1)\n        acc = accuracy_score(y[test_idx], y_pred)\n        kappa = cohen_kappa_score(y[test_idx], y_pred)\n        \n        accuracies.append(acc)\n        kappas.append(kappa)\n        print(f\"Fold {fold+1} - Accuracy: {acc:.4f}, Kappa: {kappa:.4f}\")\n    \n    # Final results\n    print(\"\\nFinal Results:\")\n    print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n    print(f\"Mean Kappa: {np.mean(kappas):.4f} ± {np.std(kappas):.4f}\")\n\nif __name__ == \"__main__\":\n    # Configure GPU\n    physical_devices = tf.config.list_physical_devices('GPU')\n    if physical_devices:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    \n    # Set seeds for reproducibility\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:12:31.220551Z","iopub.execute_input":"2025-06-22T21:12:31.220880Z","iopub.status.idle":"2025-06-22T21:12:32.705777Z","shell.execute_reply.started":"2025-06-22T21:12:31.220858Z","shell.execute_reply":"2025-06-22T21:12:32.704697Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mQhullError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_452/3564473848.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_452/3564473848.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_tpct_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_452/3564473848.py\u001b[0m in \u001b[0;36mcreate_tpct_image\u001b[0;34m(trial_data)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mch_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Positions for this channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0minterpolator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloughTocher2DInterpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mch_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_interpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate._interpnd.CloughTocher2DInterpolator.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_interpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate._interpnd.NDInterpolatorBase.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_interpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate._interpnd.CloughTocher2DInterpolator._calculate_triangulation\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_qhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial._qhull.Delaunay.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_qhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial._qhull._Qhull.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;31mQhullError\u001b[0m: QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)\n\nWhile executing:  | qhull d Qt Qc Q12 Qbb Qz\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 110373317  delaunay  Qtriangulate  Qcoplanar-keep  Q12-allow-wide\n  Qbbound-last  Qz-infinity-point  _pre-merge  _zero-centrum  Qinterior-keep\n  Pgood  _max-width  2  Error-roundoff 1.4e-15  _one-merge 9.7e-15\n  Visible-distance 2.8e-15  U-max-coplanar 2.8e-15  Width-outside 5.5e-15\n  _wide-facet 1.7e-14  _maxoutside 1.1e-14\n\nThe input to qhull appears to be less than 3 dimensional, or a\ncomputation has overflowed.\n\nQhull could not construct a clearly convex simplex from points:\n- p3(v4):     0     0     1\n- p1(v3):     0     0     0\n- p2(v2):     1 -0.01  0.91\n- p0(v1):    -1  0.01  0.91\n\nThe center point is coplanar with a facet, or a vertex is coplanar\nwith a neighboring facet.  The maximum round off error for\ncomputing distances is 1.4e-15.  The center point, facets and distances\nto the center point are as follows:\n\ncenter point        0        0   0.7045\n\nfacet p1 p2 p0 distance=    0\nfacet p3 p2 p0 distance=    0\nfacet p3 p1 p0 distance=    0\nfacet p3 p1 p2 distance=    0\n\nThese points either have a maximum or minimum x-coordinate, or\nthey maximize the determinant for k coordinates.  Trial points\nare first selected from points that maximize a coordinate.\n\nThe min and max coordinates for each dimension are:\n  0:        -1         1  difference=    2\n  1:     -0.01      0.01  difference= 0.02\n  2:         0         1  difference=    1\n\nIf the input should be full dimensional, you have several options that\nmay determine an initial simplex:\n  - use 'QJ'  to joggle the input and make it full dimensional\n  - use 'QbB' to scale the points to the unit cube\n  - use 'QR0' to randomly rotate the input for different maximum points\n  - use 'Qs'  to search all points for the initial simplex\n  - use 'En'  to specify a maximum roundoff error less than 1.4e-15.\n  - trace execution with 'T3' to see the determinant for each point.\n\nIf the input is lower dimensional:\n  - use 'QJ' to joggle the input and make it full dimensional\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\n    pick the coordinate with the least range.  The hull will have the\n    correct topology.\n  - determine the flat containing the points, rotate the points\n    into a coordinate plane, and delete the other coordinates.\n  - add one or more points to make the input full dimensional.\n"],"ename":"QhullError","evalue":"QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)\n\nWhile executing:  | qhull d Qt Qc Q12 Qbb Qz\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 110373317  delaunay  Qtriangulate  Qcoplanar-keep  Q12-allow-wide\n  Qbbound-last  Qz-infinity-point  _pre-merge  _zero-centrum  Qinterior-keep\n  Pgood  _max-width  2  Error-roundoff 1.4e-15  _one-merge 9.7e-15\n  Visible-distance 2.8e-15  U-max-coplanar 2.8e-15  Width-outside 5.5e-15\n  _wide-facet 1.7e-14  _maxoutside 1.1e-14\n\nThe input to qhull appears to be less than 3 dimensional, or a\ncomputation has overflowed.\n\nQhull could not construct a clearly convex simplex from points:\n- p3(v4):     0     0     1\n- p1(v3):     0     0     0\n- p2(v2):     1 -0.01  0.91\n- p0(v1):    -1  0.01  0.91\n\nThe center point is coplanar with a facet, or a vertex is coplanar\nwith a neighboring facet.  The maximum round off error for\ncomputing distances is 1.4e-15.  The center point, facets and distances\nto the center point are as follows:\n\ncenter point        0        0   0.7045\n\nfacet p1 p2 p0 distance=    0\nfacet p3 p2 p0 distance=    0\nfacet p3 p1 p0 distance=    0\nfacet p3 p1 p2 distance=    0\n\nThese points either have a maximum or minimum x-coordinate, or\nthey maximize the determinant for k coordinates.  Trial points\nare first selected from points that maximize a coordinate.\n\nThe min and max coordinates for each dimension are:\n  0:        -1         1  difference=    2\n  1:     -0.01      0.01  difference= 0.02\n  2:         0         1  difference=    1\n\nIf the input should be full dimensional, you have several options that\nmay determine an initial simplex:\n  - use 'QJ'  to joggle the input and make it full dimensional\n  - use 'QbB' to scale the points to the unit cube\n  - use 'QR0' to randomly rotate the input for different maximum points\n  - use 'Qs'  to search all points for the initial simplex\n  - use 'En'  to specify a maximum roundoff error less than 1.4e-15.\n  - trace execution with 'T3' to see the determinant for each point.\n\nIf the input is lower dimensional:\n  - use 'QJ' to joggle the input and make it full dimensional\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\n    pick the coordinate with the least range.  The hull will have the\n    correct topology.\n  - determine the flat containing the points, rotate the points\n    into a coordinate plane, and delete the other coordinates.\n  - add one or more points to make the input full dimensional.\n","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"import os\nimport numpy as np\nimport mne\nfrom scipy.interpolate import Rbf, CloughTocher2DInterpolator, LinearNDInterpolator, NearestNDInterpolator\nfrom scipy.fft import fft, ifft\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\n\n# ======================== CONSTANTS ========================\nFS = 250  # Sampling frequency (Hz)\nN_FFT = 256  # FFT length\nN_WINDOWS = 10  # Number of time windows\nBANDS = [(8, 13), (13, 21), (21, 30)]  # Frequency bands (Hz)\nIMG_SIZE = 64  # Image dimensions\nDELTA = 0.05  # Increased shift value for better separation\n\nELECTRODE_POS = {\n    'C3': [\n        (-1 - DELTA, -DELTA),  # Band 1: left and down\n        (-1, 0),               # Band 2: center\n        (-1 + DELTA, DELTA)    # Band 3: right and up\n    ],\n    'Cz': [\n        (0 - DELTA, DELTA),    # Band 1: left and up\n        (0, 0),                # Band 2: center\n        (0 + DELTA, -DELTA)    # Band 3: right and down\n    ],\n    'C4': [\n        (1 - DELTA, -DELTA),   # Band 1: left and down\n        (1, 0),                # Band 2: center\n        (1 + DELTA, DELTA)     # Band 3: right and up\n    ]\n}\n\n# ======================== DATA LOADING ========================\ndef load_data(subject, session):\n    \"\"\"Load EEG data and events with proper scaling and timing\"\"\"\n    filename = f'B{subject:02d}{session}.gdf'\n    filepath = os.path.join('/kaggle/input/bci-competition-2008-graz-data-set-b/BCICIV_2b_gdf', filename)\n    \n    if not os.path.exists(filepath):\n        print(f\"[ERROR] File not found: {filepath}\")\n        return np.array([]), np.array([])\n    \n    try:\n        print(f\"\\n=== Loading subject {subject}, session {session} ===\")\n        \n        # Load and scale to microvolts\n        raw = mne.io.read_raw_gdf(filepath, preload=True, verbose='ERROR')\n        raw.apply_function(lambda x: x * 1e6)\n        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n        \n        print(f\"Found {len(events)} events\")\n        \n        trials, labels = [], []\n        valid_events = 0\n        \n        for event in events:\n            if event[2] in [event_ids.get('769', -1), event_ids.get('770', -1)]:\n                start = event[0]\n                end = start + int(3 * FS)  # 3 seconds of data\n                \n                if end > raw.n_times:\n                    print(f\"  - Event at {start} exceeds data length ({raw.n_times}), skipping\")\n                    continue\n                    \n                # Get only C3, Cz, C4 channels\n                trial = raw.get_data()[:3, start:end]\n                trials.append(trial)\n                \n                label = 0 if event[2] == event_ids.get('769', -1) else 1\n                labels.append(label)\n                valid_events += 1\n                \n                # Print detailed info for first event\n                if valid_events == 1:\n                    print(f\"\\nFirst trial details:\")\n                    print(f\"  Shape: {trial.shape} (channels x samples)\")\n                    print(f\"  Min: {np.min(trial):.2f}μV, Max: {np.max(trial):.2f}μV\")\n                    print(f\"  Mean: {np.mean(trial):.2f}μV, Std: {np.std(trial):.2f}μV\")\n                    print(f\"  Variance: {np.var(trial):.2f}μV²\")\n                    print(f\"  Channel means: C3={np.mean(trial[0]):.2f}μV, Cz={np.mean(trial[1]):.2f}μV, C4={np.mean(trial[2]):.2f}μV\")\n                \n        print(f\"\\nExtracted {valid_events} valid trials\")\n        print(f\"Label distribution: Left={labels.count(0)}, Right={labels.count(1)}\")\n        return np.array(trials), np.array(labels)\n    \n    except Exception as e:\n        print(f\"[ERROR] Processing file: {str(e)}\")\n        return np.array([]), np.array([])\n\n# ======================== TPCT FEATURE EXTRACTION ========================\ndef compute_band_features(trial_data, band, verbose=False):\n    \"\"\"Compute band features using paper's method (FFT → sub-band → IFFT → power)\"\"\"\n    window_size = trial_data.shape[1] // N_WINDOWS\n    band_powers = []\n    \n    if verbose:\n        print(f\"\\nComputing features for band {band[0]}-{band[1]}Hz\")\n        print(f\"  Trial shape: {trial_data.shape}\")\n        print(f\"  Window size: {window_size} samples\")\n    \n    for win_idx in range(N_WINDOWS):\n        start = win_idx * window_size\n        end = start + window_size\n        window = trial_data[:, start:end]\n        \n        # FFT with zero-padding\n        spec = fft(window, n=N_FFT, axis=1)\n        freqs = np.fft.fftfreq(N_FFT, 1/FS)\n        \n        # Extract sub-band frequencies\n        band_idx = np.where((freqs >= band[0]) & (freqs <= band[1]))[0]\n        if len(band_idx) == 0:\n            band_powers.append(np.zeros(trial_data.shape[0]))\n            continue\n            \n        sub_band_spec = spec[:, band_idx]\n        \n        # IFFT → Time-domain signal\n        time_domain = ifft(sub_band_spec, axis=1)\n        \n        # Compute power (Eq 10)\n        power = np.mean(np.abs(time_domain)**2, axis=1)\n        band_powers.append(power)\n        \n        if verbose and win_idx == 0:\n            print(f\"  Window 1 power: C3={power[0]:.2f}, Cz={power[1]:.2f}, C4={power[2]:.2f}\")\n    \n    # Average power across windows (Eq 11)\n    avg_power = np.mean(band_powers, axis=0)\n    \n    if verbose:\n        print(f\"\\nBand {band[0]}-{band[1]}Hz average power:\")\n        print(f\"  C3: {avg_power[0]:.2f} (Min: {np.min([p[0] for p in band_powers]):.2f}, Max: {np.max([p[0] for p in band_powers]):.2f})\")\n        print(f\"  Cz: {avg_power[1]:.2f} (Min: {np.min([p[1] for p in band_powers]):.2f}, Max: {np.max([p[1] for p in band_powers]):.2f})\")\n        print(f\"  C4: {avg_power[2]:.2f} (Min: {np.min([p[2] for p in band_powers]):.2f}, Max: {np.max([p[2] for p in band_powers]):.2f})\")\n    \n    return avg_power\n\ndef create_tpct_image(trial_data, verbose=False):\n    \"\"\"Create TPCT image with robust interpolation\"\"\"\n    if verbose:\n        print(\"\\n\" + \"=\"*60)\n        print(\"Creating TPCT Image\")\n        print(\"=\"*60)\n        print(f\"Input trial shape: {trial_data.shape}\")\n        print(f\"Min: {np.min(trial_data):.2f}μV, Max: {np.max(trial_data):.2f}μV\")\n        print(f\"Mean: {np.mean(trial_data):.2f}μV, Std: {np.std(trial_data):.2f}μV\")\n        print(f\"Variance: {np.var(trial_data):.2f}μV²\")\n    \n    features = []\n    for band in BANDS:\n        band_features = compute_band_features(trial_data, band, verbose=verbose)\n        features.append(band_features)\n    \n    features = np.array(features).T  # Shape: (3 electrodes, 3 bands)\n    \n    if verbose:\n        print(\"\\nRaw features (electrode x band):\")\n        print(features)\n    \n    # Apply logarithmic scaling\n    features = np.log10(features + 1e-12)\n    \n    if verbose:\n        print(\"\\nLog-scaled features:\")\n        print(features)\n        print(f\"Feature stats - Min: {np.min(features):.4f}, Max: {np.max(features):.4f}\")\n        print(f\"Mean: {np.mean(features):.4f}, Std: {np.std(features):.4f}\")\n        print(f\"Variance: {np.var(features):.4f}\")\n\n    positions, values = [], []\n    for elec_idx, electrode in enumerate(['C3', 'Cz', 'C4']):\n        for band_idx in range(3):\n            pos = ELECTRODE_POS[electrode][band_idx]\n            positions.append(pos)\n            values.append(features[elec_idx, band_idx])\n    \n    if verbose:\n        print(\"\\nElectrode positions and values:\")\n        for i, (pos, val) in enumerate(zip(positions, values)):\n            elec = ['C3', 'Cz', 'C4'][i // 3]\n            band = ['μ (8-13Hz)', 'β1 (13-21Hz)', 'β2 (21-30Hz)'][i % 3]\n            print(f\"  {elec} {band}: Position={pos}, Value={val:.4f}\")\n    \n    # Create grid with expanded boundaries\n    x_grid = np.linspace(-1.5, 1.5, IMG_SIZE)\n    y_grid = np.linspace(-0.5, 0.5, IMG_SIZE)\n    xx, yy = np.meshgrid(x_grid, y_grid)\n    grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n    \n    image = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n    \n    # ====== FIXED INTERPOLATION ======\n    for band_idx in range(3):\n        band_values = values[band_idx::3]\n        band_positions = positions[band_idx::3]\n        \n        # Add unique y-offsets to break collinearity\n        band_name = ['μ (8-13Hz)', 'β1 (13-21Hz)', 'β2 (21-30Hz)'][band_idx]\n        y_offsets = {\n            'β1 (13-21Hz)': [-0.01, 0.01, 0.0],  # Break collinearity for β1 band\n            'default': [0, 0, 0]\n        }\n        offsets = y_offsets.get(band_name, y_offsets['default'])\n        \n        band_positions_shifted = []\n        for i, (x, y) in enumerate(band_positions):\n            band_positions_shifted.append((x, y + offsets[i]))\n        \n        # Convert to numpy arrays\n        points = np.array(band_positions_shifted)\n        values_arr = np.array(band_values)\n        \n        # Use RBF interpolation with fallback\n        try:\n            # Create RBF interpolator\n            rbf = Rbf(points[:, 0], points[:, 1], values_arr, function='thin_plate')\n            band_image = rbf(xx, yy)\n            method = \"RBF (thin_plate)\"\n        except Exception as e:\n            if verbose:\n                print(f\"RBF failed: {str(e)}\")\n            # Fallback to nearest neighbor\n            interpolator = NearestNDInterpolator(points, values_arr)\n            band_image = interpolator(grid_points).reshape(IMG_SIZE, IMG_SIZE)\n            method = \"Nearest (fallback)\"\n        \n        # Robust normalization\n        band_range = np.max(band_image) - np.min(band_image)\n        if band_range < 1e-8:  # Handle near-constant case\n            band_image = np.zeros_like(band_image)\n        else:\n            band_image = (band_image - np.min(band_image)) / band_range\n        \n        image[..., band_idx] = band_image\n        \n        if verbose:\n            print(f\"\\n{band_name} band image ({method}):\")\n            print(f\"  Raw: Min={np.min(band_image):.4f}, Max={np.max(band_image):.4f}\")\n            print(f\"  Normalized: Min={np.min(image[..., band_idx]):.4f}, Max={np.max(image[..., band_idx]):.4f}\")\n            print(f\"  Offsets applied: {offsets}\")\n    # ====== END FIX ======\n    \n    if verbose:\n        print(\"\\nFinal TPCT image:\")\n        print(f\"  Shape: {image.shape}\")\n        print(f\"  Min: {np.min(image):.4f}, Max: {np.max(image):.4f}\")\n        print(f\"  Mean: {np.mean(image):.4f}, Std: {np.std(image):.4f}\")\n        print(f\"  Variance: {np.var(image):.6f}\")\n        print(\"=\"*60)\n    \n    return image\n\n# ======================== PAPER'S MVGG ARCHITECTURE ========================\ndef build_mvgg(input_shape=(64, 64, 3)):\n    \"\"\"Build exact mVGG architecture from paper (Table I)\"\"\"\n    print(\"\\nBuilding mVGG model architecture\")\n    \n    inputs = Input(shape=input_shape)\n    x = inputs\n    \n    # Section 1: 6x [Conv3x3-64]\n    for i in range(6):\n        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (2, 2), strides=2, activation='relu', padding='same')(x)  # Downsample\n    \n    # Section 2: 5x [Conv2x2-128]\n    for i in range(5):\n        x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(128, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 3: 5x [Conv2x2-256]\n    for i in range(5):\n        x = Conv2D(256, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(256, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 4: 5x [Conv2x2-512]\n    for i in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Section 5: 5x [Conv2x2-512]\n    for i in range(5):\n        x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n    x = Conv2D(512, (2, 2), strides=2, activation='relu', padding='same')(x)\n    \n    # Classification head\n    x = GlobalAveragePooling2D()(x)\n    outputs = Dense(2, activation='softmax')(x)\n    \n    model = Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(\"Model summary:\")\n    model.summary()\n    print(f\"Total parameters: {model.count_params()}\")\n    return model\n\n# ======================== MAIN EXECUTION ========================\ndef main():\n    # Load all data\n    all_images, all_labels = [], []\n    total_trials = 0\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STARTING DATA PROCESSING\")\n    print(\"=\"*80)\n    \n    for subject in range(1, 10):  # Subjects 1-9\n        sessions = ['01T', '02T', '03T']\n        print(f\"\\nProcessing subject {subject}/9\")\n        \n        subject_trials = 0\n        for session_idx, session in enumerate(sessions):\n            print(f\"\\n  Session {session_idx+1}/3: {session}\")\n            \n            trials, labels = load_data(subject, session)\n            if len(trials) == 0:\n                print(\"  -> Skipped (no trials)\")\n                continue\n                \n            print(f\"  -> Processing {len(trials)} trials\")\n            \n            for trial_idx, trial in enumerate(trials):\n                # Only show details for first trial of first session\n                verbose = (subject == 1 and session == '01T' and trial_idx == 0)\n                \n                if verbose:\n                    print(f\"\\n    Processing trial {trial_idx+1}/{len(trials)} (VERBOSE OUTPUT)\")\n                    image = create_tpct_image(trial, verbose=True)\n                else:\n                    if trial_idx == 0:\n                        print(f\"    Processing {len(trials)} trials...\")\n                    image = create_tpct_image(trial, verbose=False)\n                \n                all_images.append(image)\n                subject_trials += 1\n            \n            all_labels.extend(labels)\n            total_trials += len(trials)\n        \n        print(f\"\\n  Subject {subject} summary: {subject_trials} trials processed\")\n    \n    X = np.array(all_images)\n    y = np.array(all_labels)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"DATASET SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Total trials: {X.shape[0]}\")\n    print(f\"Image shape: {X.shape[1:]} (height x width x channels)\")\n    print(f\"Class distribution: Left={np.sum(y==0)}, Right={np.sum(y==1)}\")\n    print(f\"Data stats - Min: {np.min(X):.4f}, Max: {np.max(X):.4f}\")\n    print(f\"Mean: {np.mean(X):.4f}, Std: {np.std(X):.4f}\")\n    print(f\"Variance: {np.var(X):.6f}\")\n    \n    # 10-fold cross-validation as in paper\n    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    accuracies, kappas = [], []\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STARTING 10-FOLD CROSS VALIDATION\")\n    print(\"=\"*80)\n    \n    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n        print(f\"\\nFold {fold+1}/10\")\n        print(f\"  Train samples: {len(train_idx)} ({len(train_idx)/len(X)*100:.1f}%)\")\n        print(f\"  Test samples: {len(test_idx)} ({len(test_idx)/len(X)*100:.1f}%)\")\n        print(f\"  Train class distribution: Left={np.sum(y[train_idx]==0)}, Right={np.sum(y[train_idx]==1)}\")\n        print(f\"  Test class distribution: Left={np.sum(y[test_idx]==0)}, Right={np.sum(y[test_idx]==1)}\")\n        \n        model = build_mvgg()\n        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n        \n        print(\"\\n  Training model...\")\n        history = model.fit(\n            X[train_idx], y[train_idx],\n            validation_split=0.1,\n            epochs=100,\n            batch_size=32,\n            callbacks=[early_stop],\n            verbose=1\n        )\n        \n        print(\"\\n  Evaluating model...\")\n        y_pred = model.predict(X[test_idx], verbose=0).argmax(axis=1)\n        acc = accuracy_score(y[test_idx], y_pred)\n        kappa = cohen_kappa_score(y[test_idx], y_pred)\n        \n        accuracies.append(acc)\n        kappas.append(kappa)\n        print(f\"\\n  Fold {fold+1} results:\")\n        print(f\"    Accuracy: {acc:.4f}\")\n        print(f\"    Kappa:    {kappa:.4f}\")\n        print(f\"    Error:    {1-acc:.4f}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"FINAL RESULTS\")\n    print(\"=\"*80)\n    print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n    print(f\"Mean Kappa:    {np.mean(kappas):.4f} ± {np.std(kappas):.4f}\")\n    print(f\"Min Accuracy:  {np.min(accuracies):.4f}, Max Accuracy: {np.max(accuracies):.4f}\")\n    print(f\"Min Kappa:     {np.min(kappas):.4f}, Max Kappa:    {np.max(kappas):.4f}\")\n\nif __name__ == \"__main__\":\n    # Configure GPU memory growth\n    physical_devices = tf.config.list_physical_devices('GPU')\n    if physical_devices:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    \n    # Set random seeds for reproducibility\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:52:24.202849Z","iopub.execute_input":"2025-06-22T20:52:24.203158Z","iopub.status.idle":"2025-06-22T20:52:33.759629Z","shell.execute_reply.started":"2025-06-22T20:52:24.203137Z","shell.execute_reply":"2025-06-22T20:52:33.758599Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nSTARTING DATA PROCESSING\n================================================================================\n\nProcessing subject 1/9\n\n  Session 1/3: 01T\n\n=== Loading subject 1, session 01T ===\nFound 271 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -9.88μV, Max: 10.97μV\n  Mean: -0.01μV, Std: 3.02μV\n  Variance: 9.10μV²\n  Channel means: C3=0.09μV, Cz=-0.16μV, C4=0.05μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n\n    Processing trial 1/120 (VERBOSE OUTPUT)\n\n============================================================\nCreating TPCT Image\n============================================================\nInput trial shape: (3, 750)\nMin: -9.88μV, Max: 10.97μV\nMean: -0.01μV, Std: 3.02μV\nVariance: 9.10μV²\n\nComputing features for band 8-13Hz\n  Trial shape: (3, 750)\n  Window size: 75 samples\n  Window 1 power: C3=892.15, Cz=566.63, C4=1059.41\n\nBand 8-13Hz average power:\n  C3: 1035.13 (Min: 26.89, Max: 4275.71)\n  Cz: 948.81 (Min: 55.81, Max: 3476.82)\n  C4: 528.74 (Min: 78.32, Max: 1059.41)\n\nComputing features for band 13-21Hz\n  Trial shape: (3, 750)\n  Window size: 75 samples\n  Window 1 power: C3=179.98, Cz=65.21, C4=138.37\n\nBand 13-21Hz average power:\n  C3: 175.24 (Min: 43.01, Max: 506.36)\n  Cz: 202.21 (Min: 52.51, Max: 724.61)\n  C4: 300.91 (Min: 69.47, Max: 864.58)\n\nComputing features for band 21-30Hz\n  Trial shape: (3, 750)\n  Window size: 75 samples\n  Window 1 power: C3=211.18, Cz=176.40, C4=99.63\n\nBand 21-30Hz average power:\n  C3: 121.15 (Min: 31.55, Max: 357.84)\n  Cz: 73.30 (Min: 18.33, Max: 176.40)\n  C4: 118.13 (Min: 25.77, Max: 259.49)\n\nRaw features (electrode x band):\n[[1035.13063523  175.23762409  121.14874331]\n [ 948.81241084  202.2137417    73.29946343]\n [ 528.7401903   300.90876922  118.13073528]]\n\nLog-scaled features:\n[[3.01499516 2.24362736 2.08331891]\n [2.97718036 2.30581067 1.8651008 ]\n [2.72324232 2.47843484 2.07236291]]\nFeature stats - Min: 1.8651, Max: 3.0150\nMean: 2.4182, Std: 0.3867\nVariance: 0.1496\n\nElectrode positions and values:\n  C3 μ (8-13Hz): Position=(-1.05, -0.05), Value=3.0150\n  C3 β1 (13-21Hz): Position=(-1, 0), Value=2.2436\n  C3 β2 (21-30Hz): Position=(-0.95, 0.05), Value=2.0833\n  Cz μ (8-13Hz): Position=(-0.05, 0.05), Value=2.9772\n  Cz β1 (13-21Hz): Position=(0, 0), Value=2.3058\n  Cz β2 (21-30Hz): Position=(0.05, -0.05), Value=1.8651\n  C4 μ (8-13Hz): Position=(0.95, -0.05), Value=2.7232\n  C4 β1 (13-21Hz): Position=(1, 0), Value=2.4784\n  C4 β2 (21-30Hz): Position=(1.05, 0.05), Value=2.0724\n\nμ (8-13Hz) band image (RBF (thin_plate)):\n  Raw: Min=0.0000, Max=1.0000\n  Normalized: Min=0.0000, Max=1.0000\n  Offsets applied: [0, 0, 0]\n\nβ1 (13-21Hz) band image (RBF (thin_plate)):\n  Raw: Min=0.0000, Max=1.0000\n  Normalized: Min=0.0000, Max=1.0000\n  Offsets applied: [-0.01, 0.01, 0.0]\n\nβ2 (21-30Hz) band image (RBF (thin_plate)):\n  Raw: Min=0.0000, Max=1.0000\n  Normalized: Min=0.0000, Max=1.0000\n  Offsets applied: [0, 0, 0]\n\nFinal TPCT image:\n  Shape: (64, 64, 3)\n  Min: 0.0000, Max: 1.0000\n  Mean: 0.8165, Std: 0.2343\n  Variance: 0.054877\n============================================================\n\n  Session 2/3: 02T\n\n=== Loading subject 1, session 02T ===\nFound 268 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -16.35μV, Max: 15.08μV\n  Mean: -0.41μV, Std: 4.29μV\n  Variance: 18.37μV²\n  Channel means: C3=0.06μV, Cz=-0.73μV, C4=-0.56μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n\n  Session 3/3: 03T\n\n=== Loading subject 1, session 03T ===\nFound 527 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -9.38μV, Max: 9.35μV\n  Mean: -0.03μV, Std: 2.98μV\n  Variance: 8.88μV²\n  Channel means: C3=0.11μV, Cz=0.05μV, C4=-0.23μV\n\nExtracted 160 valid trials\nLabel distribution: Left=80, Right=80\n  -> Processing 160 trials\n    Processing 160 trials...\n\n  Subject 1 summary: 400 trials processed\n\nProcessing subject 2/9\n\n  Session 1/3: 01T\n\n=== Loading subject 2, session 01T ===\nFound 275 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -9.07μV, Max: 11.55μV\n  Mean: 0.49μV, Std: 3.07μV\n  Variance: 9.45μV²\n  Channel means: C3=0.58μV, Cz=0.05μV, C4=0.84μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n\n  Session 2/3: 02T\n\n=== Loading subject 2, session 02T ===\nFound 273 events\n\nFirst trial details:\n  Shape: (3, 750) (channels x samples)\n  Min: -11.11μV, Max: 7.92μV\n  Mean: -0.56μV, Std: 2.59μV\n  Variance: 6.69μV²\n  Channel means: C3=-0.37μV, Cz=-1.35μV, C4=0.02μV\n\nExtracted 120 valid trials\nLabel distribution: Left=60, Right=60\n  -> Processing 120 trials\n    Processing 120 trials...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_452/1360244912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_452/1360244912.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtrial_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"    Processing {len(trials)} trials...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tpct_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_452/1360244912.py\u001b[0m in \u001b[0;36mcreate_tpct_image\u001b[0;34m(trial_data, verbose)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBANDS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mband_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_band_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_452/1360244912.py\u001b[0m in \u001b[0;36mcompute_band_features\u001b[0;34m(trial_data, band, verbose)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# FFT with zero-padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_FFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_FFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_backend.py\u001b[0m in \u001b[0;36m__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_basic_backend.py\u001b[0m in \u001b[0;36mfft\u001b[0;34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     77\u001b[0m def fft(x, n=None, axis=-1, norm=None,\n\u001b[1;32m     78\u001b[0m         overwrite_x=False, workers=None, *, plan=None):\n\u001b[0;32m---> 79\u001b[0;31m     return _execute_1D('fft', _pocketfft.fft, x, n=n, axis=axis, norm=norm,\n\u001b[0m\u001b[1;32m     80\u001b[0m                        overwrite_x=overwrite_x, workers=workers, plan=plan)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_basic_backend.py\u001b[0m in \u001b[0;36m_execute_1D\u001b[0;34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         return pocketfft_func(x, n=n, axis=axis, norm=norm,\n\u001b[0m\u001b[1;32m     33\u001b[0m                               overwrite_x=overwrite_x, workers=workers, plan=plan)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_pocketfft/basic.py\u001b[0m in \u001b[0;36mc2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fix_shape_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moverwrite_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_x\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcopied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_pocketfft/helper.py\u001b[0m in \u001b[0;36m_fix_shape_1d\u001b[0;34m(x, n, axis)\u001b[0m\n\u001b[1;32m    147\u001b[0m             f\"invalid number of data points ({n}) specified\")\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_fix_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_pocketfft/helper.py\u001b[0m in \u001b[0;36m_fix_shape\u001b[0;34m(x, shape, axes)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}