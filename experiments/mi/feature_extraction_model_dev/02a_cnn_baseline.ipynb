{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import signal\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation, \n                                    DepthwiseConv2D, AveragePooling2D, Dropout, \n                                    SeparableConv2D, Flatten, Dense, SpatialDropout2D)\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical\nfrom tqdm import tqdm\nimport gc\n\n# =============================================\n# 1. Configuration and Data Loading\n# =============================================\n# Set paths and parameters\nBASE_PATH = '/kaggle/input/mtcaic3'\nTRAIN_CSV = os.path.join(BASE_PATH, 'train.csv')\nEEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\nSAMPLING_RATE = 250  # Hz\nMI_DURATION = 9  # seconds\nMI_SAMPLES = SAMPLING_RATE * MI_DURATION\nCROPPED_SAMPLES = 2240  # Divisible by 32 for EEGNet\n\n# Load training data and filter for MI\ntrain_df = pd.read_csv(TRAIN_CSV)\nmi_df = train_df[train_df['task'] == 'MI'].copy()\nmi_df['label'] = mi_df['label'].map({'Left': 0, 'Right': 1})\n\n# =============================================\n# 2. Improved Preprocessing Functions\n# =============================================\ndef butter_bandpass(lowcut, highcut, fs, order=4):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = signal.butter(order, [low, high], btype='band')\n    return b, a\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = signal.filtfilt(b, a, data, axis=0)\n    return y\n\ndef notch_filter(data, f0, fs, Q=30):\n    w0 = f0 / (fs/2)\n    b, a = signal.iirnotch(w0, Q)\n    y = signal.filtfilt(b, a, data, axis=0)\n    return y\n\ndef load_mi_trial(subject_id, session, trial_num):\n    eeg_path = f\"{BASE_PATH}/MI/train/{subject_id}/{session}/EEGdata.csv\"\n    full_data = pd.read_csv(eeg_path)\n    start_idx = (trial_num - 1) * MI_SAMPLES\n    end_idx = start_idx + MI_SAMPLES\n    return full_data.iloc[start_idx:end_idx].copy()\n\n# =============================================\n# 3. Enhanced EEGNet Model Architecture\n# =============================================\ndef EEGNet_v2(nb_classes, Chans=8, Samples=2240, \n              dropoutRate=0.5, kernLength=128, F1=16, \n              D=2, F2=32):\n    \n    input_shape = (Chans, Samples, 1)\n    input1 = Input(shape=input_shape)\n\n    # Block 1 - Temporal convolution with larger kernel\n    block1 = Conv2D(F1, (1, kernLength), padding='same',\n                   use_bias=False)(input1)\n    block1 = BatchNormalization()(block1)\n    block1 = Activation('elu')(block1)\n    \n    # Spatial filtering with spatial dropout\n    block1 = DepthwiseConv2D((Chans, 1), depth_multiplier=D,\n                            depthwise_constraint=max_norm(1.),\n                            use_bias=False)(block1)\n    block1 = BatchNormalization()(block1)\n    block1 = Activation('elu')(block1)\n    block1 = AveragePooling2D((1, 4))(block1)\n    block1 = SpatialDropout2D(dropoutRate)(block1)  # Better for spatial data\n\n    # Block 2 - Temporal feature extraction\n    block2 = SeparableConv2D(F2, (1, 32),  # Increased kernel size\n                            padding='same', use_bias=False)(block1)\n    block2 = BatchNormalization()(block2)\n    block2 = Activation('elu')(block2)\n    block2 = AveragePooling2D((1, 8))(block2)\n    block2 = Dropout(dropoutRate)(block2)\n    \n    # Additional convolutional block\n    block3 = SeparableConv2D(F2*2, (1, 16), \n                            padding='same', use_bias=False)(block2)\n    block3 = BatchNormalization()(block3)\n    block3 = Activation('elu')(block3)\n    block3 = AveragePooling2D((1, 4))(block3)\n    block3 = Dropout(dropoutRate)(block3)\n\n    # Output\n    flatten = Flatten(name='flatten')(block3)\n    dense = Dense(32, activation='elu', name='dense1')(flatten)  # Additional dense layer\n    dense = Dropout(0.3)(dense)\n    output = Dense(nb_classes, name='output', \n                 kernel_constraint=max_norm(0.25))(dense)\n    softmax = Activation('softmax', name='softmax')(output)\n    \n    return Model(inputs=input1, outputs=softmax)\n\n# =============================================\n# 4. Data Preparation Pipeline with improved filtering\n# =============================================\n# Preload and preprocess trials\nX = []\ny = []\n\nprint(\"Loading and preprocessing trials...\")\nfor _, row in tqdm(mi_df.iterrows(), total=len(mi_df)):\n    try:\n        data = load_mi_trial(row['subject_id'], row['trial_session'], row['trial'])\n        data = data[EEG_CHANNELS][:CROPPED_SAMPLES]  # Crop to 2240 samples\n        \n        # Apply preprocessing per channel\n        processed_data = []\n        for channel in EEG_CHANNELS:\n            # Denoising pipeline with improved filtering\n            ch_data = data[channel].values\n            ch_data = notch_filter(ch_data, f0=50.0, fs=SAMPLING_RATE)\n            ch_data = notch_filter(ch_data, f0=60.0, fs=SAMPLING_RATE)  # Additional notch\n            ch_data = butter_bandpass_filter(ch_data, lowcut=8.0, highcut=30.0,  # Focus on mu/beta bands\n                                            fs=SAMPLING_RATE, order=6)  # Higher order filter\n            \n            # Robust scaling with outlier clipping\n            median = np.median(ch_data)\n            iqr = np.percentile(ch_data, 75) - np.percentile(ch_data, 25)\n            ch_data = (ch_data - median) / iqr\n            # Clip outliers to ±5 IQRs\n            ch_data = np.clip(ch_data, -5, 5)\n            processed_data.append(ch_data)\n        \n        X.append(np.array(processed_data))  # Shape: (8, 2240)\n        y.append(row['label'])\n    except Exception as e:\n        print(f\"Error processing trial {row['trial']}: {str(e)}\")\n\nX = np.array(X, dtype=np.float32)  # Convert to float32\ny = np.array(y)\n\n# Reshape for EEGNet: (n_trials, channels, time, 1)\nX = X[..., np.newaxis]\n\n# Convert labels to one-hot encoding\ny = to_categorical(y, num_classes=2)\n\n# Train-validation split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"Data shapes - X_train: {X_train.shape}, X_val: {X_val.shape}\")\nprint(f\"Data types - X_train: {X_train.dtype}, X_val: {X_val.dtype}\")\n\n# Clean memory\ndel X, y\ngc.collect()\n\n# =============================================\n# 5. Fixed Data Augmentation (without time warping)\n# =============================================\ndef augment_trial(trial, label):\n    \"\"\"Apply random augmentations to EEG trial using TF ops\"\"\"\n    # Gaussian noise - 40% probability\n    if tf.random.uniform(()) > 0.6:\n        noise = tf.random.normal(tf.shape(trial), mean=0.0, stddev=0.03, dtype=tf.float32)\n        trial = trial + noise\n    \n    # Channel dropout - 30% probability to apply\n    if tf.random.uniform(()) > 0.7:\n        # Create a random mask for channels (corrected shape)\n        # Shape should be (num_channels, 1, 1) for broadcasting\n        channel_mask = tf.random.uniform((tf.shape(trial)[0], 1, 1), dtype=tf.float32) > 0.15\n        trial = trial * tf.cast(channel_mask, tf.float32)\n    \n    # Random scaling - 30% probability\n    if tf.random.uniform(()) > 0.7:\n        scale = tf.random.normal([], mean=1.0, stddev=0.15, dtype=tf.float32)\n        trial = trial * scale\n        \n    # Ensure consistent shape\n    trial = tf.ensure_shape(trial, (8, 2240, 1))\n        \n    return trial, label\n\n# Create TensorFlow Dataset with augmentation\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_dataset = train_dataset.shuffle(buffer_size=2048)  # Larger buffer\ntrain_dataset = train_dataset.map(\n    lambda x, y: augment_trial(x, y),\n    num_parallel_calls=tf.data.AUTOTUNE\n)\ntrain_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)  # Original batch size\n\n# Validation dataset\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\nval_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n\n# =============================================\n# 6. Model Training with Enhanced Setup\n# =============================================\n# Build enhanced EEGNet model\nmodel = EEGNet_v2(nb_classes=2, Chans=8, Samples=CROPPED_SAMPLES,\n                  dropoutRate=0.5, kernLength=128, F1=16, D=2, F2=32)\n\n# Use class weights to address imbalance in predictions\nclass_weights = {0: 2.5, 1: 0.8}  # Penalize misclassification of Left more\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Lower learning rate\n              metrics=['accuracy'])\n\nmodel.summary()\n\n# Enhanced callbacks\ncallbacks = [\n    CSVLogger('training_log.csv', append=False),\n    ModelCheckpoint('best_model.keras', save_best_only=True,  # Fixed saving format\n                   monitor='val_loss', mode='min'),\n    EarlyStopping(monitor='val_loss', patience=20, \n                  restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                      patience=8, min_lr=1e-6, verbose=1)\n]\n\n# Custom callback for F1 score\nclass F1Callback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        val_pred = self.model.predict(X_val, verbose=0, batch_size=32)\n        val_pred = np.argmax(val_pred, axis=1)\n        val_true = np.argmax(y_val, axis=1)\n        f1 = f1_score(val_true, val_pred, average='macro')\n        logs['val_f1'] = f1\n        print(f\" - val_f1: {f1:.4f}\")\n\ncallbacks.append(F1Callback())\n\n# Train model\nprint(\"Starting training...\")\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=100,\n    callbacks=callbacks,\n    verbose=1,\n    class_weight=class_weights  # Apply class weights\n)\n\n# =============================================\n# 7. Enhanced Evaluation and Visualization\n# =============================================\n# Load best model\nmodel = tf.keras.models.load_model('best_model.keras')\n\n# Generate predictions\ny_pred = model.predict(X_val, verbose=0, batch_size=32)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_val, axis=1)\n\n# Classification report\nclass_names = ['Left', 'Right']\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred_classes, target_names=class_names, digits=4))\n\n# Enhanced Confusion Matrix\ncm = confusion_matrix(y_true, y_pred_classes)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names,\n            cbar=True, annot_kws={\"size\": 16})\n\n# Add percentages\ntotal = np.sum(cm)\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        plt.text(j+0.5, i+0.5, f\"{cm[i, j]}\\n({cm[i, j]/total:.1%})\",\n                 ha='center', va='center', color='red', fontsize=12)\n\nplt.xlabel('Predicted', fontsize=14)\nplt.ylabel('True', fontsize=14)\nplt.title('Confusion Matrix', fontsize=16)\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Plot training history\nhistory_df = pd.read_csv('training_log.csv')\nplt.figure(figsize=(15, 12))\n\n# Loss plot\nplt.subplot(2, 2, 1)\nplt.plot(history_df['loss'], label='Training Loss')\nplt.plot(history_df['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss', fontsize=14)\nplt.xlabel('Epoch', fontsize=12)\nplt.ylabel('Loss', fontsize=12)\nplt.legend()\nplt.grid(alpha=0.3)\n\n# Accuracy plot\nplt.subplot(2, 2, 2)\nplt.plot(history_df['accuracy'], label='Training Accuracy')\nplt.plot(history_df['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy', fontsize=14)\nplt.xlabel('Epoch', fontsize=12)\nplt.ylabel('Accuracy', fontsize=12)\nplt.legend()\nplt.grid(alpha=0.3)\n\n# F1 Score plot\nplt.subplot(2, 2, 3)\nif 'val_f1' in history_df.columns:\n    plt.plot(history_df['val_f1'], label='Validation F1', color='green')\n    plt.title('Validation F1 Score', fontsize=14)\n    plt.xlabel('Epoch', fontsize=12)\n    plt.ylabel('F1 Score', fontsize=12)\n    plt.legend()\n    plt.grid(alpha=0.3)\n\n# Combined metrics\nplt.subplot(2, 2, 4)\nif 'val_f1' in history_df.columns:\n    plt.plot(history_df['val_accuracy'], label='Accuracy')\n    plt.plot(history_df['val_f1'], label='F1 Score')\n    plt.title('Validation Metrics Comparison', fontsize=14)\n    plt.xlabel('Epoch', fontsize=12)\n    plt.ylabel('Score', fontsize=12)\n    plt.legend()\n    plt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_history.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Save final metrics\nfinal_val_f1 = f1_score(y_true, y_pred_classes, average='macro')\nfinal_val_acc = history_df['val_accuracy'].iloc[-1]\n\nprint(\"\\n================ Final Metrics ================\")\nprint(f\"Validation Accuracy: {final_val_acc:.4f}\")\nprint(f\"Validation F1 Score: {final_val_f1:.4f}\")\nprint(\"==============================================\")\n\n# Additional Performance Visualization\n# Plot sample predictions\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.bar(class_names, [np.sum(y_true == 0), np.sum(y_true == 1)], color=['blue', 'orange'])\nplt.title('True Class Distribution')\nplt.ylabel('Count')\n\nplt.subplot(1, 2, 2)\nplt.bar(class_names, [np.sum(y_pred_classes == 0), np.sum(y_pred_classes == 1)], color=['blue', 'orange'])\nplt.title('Predicted Class Distribution')\nplt.savefig('class_distributions.png', dpi=300)\nplt.show()\n\n# Plot learning curves\nfig, ax1 = plt.subplots(figsize=(10, 6))\n\ncolor = 'tab:red'\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss', color=color)\nax1.plot(history_df['loss'], color=color, label='Train Loss')\nax1.plot(history_df['val_loss'], color='tab:orange', label='Val Loss')\nax1.tick_params(axis='y', labelcolor=color)\nax1.legend(loc='upper left')\n\nax2 = ax1.twinx()\ncolor = 'tab:blue'\nax2.set_ylabel('Accuracy', color=color)\nax2.plot(history_df['accuracy'], color=color, label='Train Acc')\nax2.plot(history_df['val_accuracy'], color='tab:green', label='Val Acc')\nax2.tick_params(axis='y', labelcolor=color)\nax2.legend(loc='upper right')\n\nplt.title('Training History')\nplt.savefig('learning_curves.png', dpi=300)\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T05:07:39.163551Z","iopub.execute_input":"2025-06-18T05:07:39.163954Z"}},"outputs":[{"name":"stdout","text":"Loading and preprocessing trials...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2400/2400 [03:55<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Data shapes - X_train: (1920, 8, 2240, 1), X_val: (480, 8, 2240, 1)\nData types - X_train: float32, X_val: float32\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │              \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_13 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ depthwise_conv2d_5 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_14 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2240\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ average_pooling2d_9                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m560\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ spatial_dropout2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m560\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_5 (\u001b[38;5;33mSeparableConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m560\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m2,048\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m560\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_15 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m560\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ average_pooling2d_10                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_6 (\u001b[38;5;33mSeparableConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m2,560\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_16 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ average_pooling2d_11                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1088\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense1 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m34,848\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ softmax (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ depthwise_conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ average_pooling2d_9                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ spatial_dropout2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ average_pooling2d_10                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ average_pooling2d_11                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1088</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,848</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,402\u001b[0m (165.63 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,402</span> (165.63 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,114\u001b[0m (164.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,114</span> (164.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Starting training...\nEpoch 1/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.4918 - loss: 1.0359 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 607ms/step - accuracy: 0.4918 - loss: 1.0350 - val_accuracy: 0.4938 - val_loss: 0.6970 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 2/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.4841 - loss: 0.9390 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 628ms/step - accuracy: 0.4843 - loss: 0.9389 - val_accuracy: 0.4938 - val_loss: 0.7024 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 3/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.4843 - loss: 0.9344 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 596ms/step - accuracy: 0.4844 - loss: 0.9345 - val_accuracy: 0.4938 - val_loss: 0.7096 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 4/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - accuracy: 0.4942 - loss: 0.9336 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 628ms/step - accuracy: 0.4942 - loss: 0.9336 - val_accuracy: 0.4938 - val_loss: 0.7177 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 5/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.4902 - loss: 0.9181 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 594ms/step - accuracy: 0.4903 - loss: 0.9181 - val_accuracy: 0.4938 - val_loss: 0.7359 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 6/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.4983 - loss: 0.9236 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 607ms/step - accuracy: 0.4982 - loss: 0.9236 - val_accuracy: 0.4938 - val_loss: 0.7487 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 7/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.5025 - loss: 0.9338 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 606ms/step - accuracy: 0.5024 - loss: 0.9337 - val_accuracy: 0.4938 - val_loss: 0.7657 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 8/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.5104 - loss: 0.9090 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 585ms/step - accuracy: 0.5102 - loss: 0.9091 - val_accuracy: 0.4938 - val_loss: 0.7711 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 9/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.4928 - loss: 0.9253\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 587ms/step - accuracy: 0.4928 - loss: 0.9252 - val_accuracy: 0.4938 - val_loss: 0.7860 - learning_rate: 5.0000e-04 - val_f1: 0.3305\nEpoch 10/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.5000 - loss: 0.9164 - val_f1: 0.3305\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 586ms/step - accuracy: 0.4999 - loss: 0.9164 - val_accuracy: 0.4938 - val_loss: 0.7947 - learning_rate: 2.5000e-04 - val_f1: 0.3305\nEpoch 11/100\n\u001b[1m 9/60\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 512ms/step - accuracy: 0.4654 - loss: 0.9242","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}