{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom scipy.signal import butter, filtfilt, iirnotch\n\n# Configuration\nBASE_PATH = '/kaggle/input/mtcaic3'\nOUTPUT_DIR = './preprocessed'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Filter design\ndef design_filters(fs=250.0):\n    # Bandpass 1-40 Hz\n    bp_b, bp_a = butter(4, [1/(fs/2), 40/(fs/2)], btype='band')\n    # Notch at 50 Hz\n    notch_b, notch_a = iirnotch(50/(fs/2), Q=30)\n    return bp_b, bp_a, notch_b, notch_a\n\n# Preprocessing steps for one trial\ndef preprocess_trial(df):\n    eeg_cols = ['FZ','C3','CZ','C4','PZ','PO7','OZ','PO8']\n    motion_cols = ['AccX','AccY','AccZ','Gyro1','Gyro2','Gyro3']\n    val_col = 'Validation'\n\n    # 1) Motion artifact detection\n    motion_mag = np.sqrt((df[motion_cols]**2).sum(axis=1))\n    mot_thresh = np.percentile(motion_mag, 95)\n    bad_mask = motion_mag > mot_thresh\n\n    # 2) Mask EEG\n    data = df[eeg_cols].copy().values\n    data[bad_mask, :] = np.nan\n    data[df[val_col] == 0, :] = np.nan\n\n    # 3) Interpolation\n    for ch in range(data.shape[1]):\n        col = data[:, ch]\n        nans = np.isnan(col)\n        if nans.all():\n            continue\n        idx = np.arange(len(col))\n        data[nans, ch] = np.interp(idx[nans], idx[~nans], col[~nans])\n\n    # 4) Filtering\n    bp_b, bp_a, notch_b, notch_a = design_filters()\n    for ch in range(data.shape[1]):\n        data[:, ch] = filtfilt(bp_b, bp_a, data[:, ch])\n        data[:, ch] = filtfilt(notch_b, notch_a, data[:, ch])\n\n    # 5) Baseline correction (first 0.5s)\n    bs = int(0.5 * 250)\n    baseline = data[:bs].mean(axis=0)\n    data -= baseline\n    return data\n\n# Load index DataFrame\ndef load_index(fname, label_col=True):\n    df = pd.read_csv(os.path.join(BASE_PATH, fname))\n    cols = ['id','subject_id','task','trial_session','trial'] + (['label'] if label_col else [])\n    return df[cols]\n\n# Process a split, grouping by task\ndef process_split(df, has_label=True):\n    data_dict = {'MI': {'X': [], 'y': []}, 'SSVEP': {'X': [], 'y': []}}\n    for _, row in df.iterrows():\n        # Identify folder\n        idx = row['id']\n        split = 'train' if idx <= 4800 else 'validation' if idx <= 4900 else 'test'\n        # Load EEGdata\n        path = os.path.join(BASE_PATH, row['task'], split, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n        df_eeg = pd.read_csv(path)\n        # Extract correct segment\n        n_samp = 2250 if row['task']=='MI' else 1750\n        start = (row['trial']-1)*n_samp\n        seg = df_eeg.iloc[int(start):int(start+n_samp)].reset_index(drop=True)\n        proc = preprocess_trial(seg)\n        data_dict[row['task']]['X'].append(proc.T)\n        if has_label:\n            data_dict[row['task']]['y'].append(row['label'])\n    # Stack\n    for t in data_dict:\n        X = np.stack(data_dict[t]['X'])\n        y = np.array(data_dict[t]['y']) if has_label else None\n        data_dict[t]['X'] = X\n        data_dict[t]['y'] = y\n    return data_dict\n\n# Execute processing and save\nfor fname, label_col in [('train.csv', True), ('validation.csv', True), ('test.csv', False)]:\n    df_idx = load_index(fname, label_col)\n    results = process_split(df_idx, label_col)\n    for task, d in results.items():\n        out_file = f\"{os.path.splitext(fname)[0]}_{task}.npz\"\n        path = os.path.join(OUTPUT_DIR, out_file)\n        if label_col:\n            np.savez_compressed(path, X=d['X'], y=d['y'])\n        else:\n            np.savez_compressed(path, X=d['X'])\n        print(f\"Saved {out_file}: X={d['X'].shape}\" + (f\", y={d['y'].shape}\" if d['y'] is not None else ''))\nprint('Preprocessing complete.')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-27T06:27:50.337074Z","iopub.execute_input":"2025-06-27T06:27:50.337316Z","iopub.status.idle":"2025-06-27T06:34:50.843053Z","shell.execute_reply.started":"2025-06-27T06:27:50.337297Z","shell.execute_reply":"2025-06-27T06:34:50.842264Z"}},"outputs":[{"name":"stdout","text":"Saved train_MI.npz: X=(2400, 8, 2250), y=(2400,)\nSaved train_SSVEP.npz: X=(2400, 8, 1750), y=(2400,)\nSaved validation_MI.npz: X=(50, 8, 2250), y=(50,)\nSaved validation_SSVEP.npz: X=(50, 8, 1750), y=(50,)\nSaved test_MI.npz: X=(50, 8, 2250)\nSaved test_SSVEP.npz: X=(50, 8, 1750)\nPreprocessing complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score, classification_report\nfrom mne.decoding import CSP\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n\n# --- 0) Config ---\ndata_dir = './preprocessed'\noutput_dir = './cv_models'\nos.makedirs(output_dir, exist_ok=True)\n\neeg_indices = [1, 2, 3, 4]  # C3, CZ, C4, PZ\nn_folds = 5\nbatch_size = 64\n\n# --- 1) Load & prepare data ---\ntrain_npz = np.load(os.path.join(data_dir, 'train_MI.npz'))\nval_npz = np.load(os.path.join(data_dir, 'validation_MI.npz'))\n\n# Combine train and validation for CV\nX_all = np.concatenate([train_npz['X'], val_npz['X']], axis=0)\ny_all = np.concatenate([train_npz['y'], val_npz['y']], axis=0)\n\n# Filter for EEG channels and transpose\nX_all_raw = X_all[:, eeg_indices, :].transpose(0, 2, 1).astype('float32')  # (n, T, 4)\ny_all_bin = (y_all == 'Right').astype(int)  # Binarize labels\n\n# --- 2) Model Builders (unchanged) ---\ndef build_modelA(input_shape):\n    m = keras.Sequential([\n        layers.Input(input_shape),\n        layers.Conv1D(32, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(64, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(128, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling1D(),\n        layers.Dense(64, activation=\"relu\", \n                     kernel_regularizer=regularizers.l2(1e-4)),\n        layers.Dropout(0.7),\n        layers.Dense(2, activation=\"softmax\"),\n    ])\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", MacroF1Score()])\n    return m\n\ndef build_modelB(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for f in [16, 32, 64, 128, 256]:\n        x = layers.Conv1D(f, 3, activation=\"relu\", padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.MaxPool1D(2)(x)\n    x = layers.Flatten()(x)\n    for u in [128, 64, 32]:\n        x = layers.Dense(u, activation=\"relu\",\n                         kernel_regularizer=regularizers.l2(1e-4))(x)\n        x = layers.Dropout(0.5)(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", MacroF1Score()])\n    return m\n\ndef build_model5(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(7):\n        x = layers.Conv1D(64, 3, activation=\"elu\", padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for _ in range(3):\n        x = layers.Dense(64, activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", MacroF1Score()])\n    return m\n\ndef build_model6(input_shape):\n    C3, C4 = 0, 2\n    eeg_in = layers.Input(input_shape)\n    c3 = layers.Lambda(lambda x: x[:, :, C3:C3+1])(eeg_in)\n    c4 = layers.Lambda(lambda x: x[:, :, C4:C4+1])(eeg_in)\n    def branch():\n        return models.Sequential([\n            layers.Conv1D(16, 250, activation=\"relu\", padding=\"same\"),\n            layers.MaxPool1D(3),\n            layers.Conv1D(32, 50, activation=\"relu\", padding=\"same\"),\n            layers.GlobalAveragePooling1D()\n        ])\n    b3, b4 = branch()(c3), branch()(c4)\n    x = layers.Concatenate()([b3, b4])\n    for _ in range(4):\n        x = layers.Dense(64, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(eeg_in, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", MacroF1Score()])\n    return m\n\n# --- 3) Macro F1 Score Metric ---\nclass MacroF1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.classes = 2\n        self.tp = [self.add_weight(name=f\"tp_{i}\", initializer=\"zeros\") for i in range(self.classes)]\n        self.fp = [self.add_weight(name=f\"fp_{i}\", initializer=\"zeros\") for i in range(self.classes)]\n        self.fn = [self.add_weight(name=f\"fn_{i}\", initializer=\"zeros\") for i in range(self.classes)]\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.argmax(y_true, axis=1)\n        y_pred = tf.argmax(y_pred, axis=1)\n        \n        for i in range(self.classes):\n            true_pos = tf.logical_and(tf.equal(y_true, i), tf.equal(y_pred, i))\n            false_pos = tf.logical_and(tf.not_equal(y_true, i), tf.equal(y_pred, i))\n            false_neg = tf.logical_and(tf.equal(y_true, i), tf.not_equal(y_pred, i))\n            \n            self.tp[i].assign_add(tf.reduce_sum(tf.cast(true_pos, tf.float32)))\n            self.fp[i].assign_add(tf.reduce_sum(tf.cast(false_pos, tf.float32)))\n            self.fn[i].assign_add(tf.reduce_sum(tf.cast(false_neg, tf.float32)))\n\n    def result(self):\n        f1_scores = []\n        eps = tf.keras.backend.epsilon()\n        for i in range(self.classes):\n            precision = self.tp[i] / (self.tp[i] + self.fp[i] + eps)\n            recall = self.tp[i] / (self.tp[i] + self.fn[i] + eps)\n            f1 = 2 * precision * recall / (precision + recall + eps)\n            f1_scores.append(f1)\n        return tf.reduce_mean(f1_scores)\n\n    def reset_states(self):\n        for i in range(self.classes):\n            self.tp[i].assign(0.0)\n            self.fp[i].assign(0.0)\n            self.fn[i].assign(0.0)\n\n# --- 4) Cosine LR Schedule ---\ndef cosine_lr(epoch, lr_max=5e-5, epochs=200):\n    return lr_max * (1 + np.cos(np.pi * epoch / epochs)) / 2\n\n# --- 5) Callbacks ---\ndef get_callbacks(name):\n    return [\n        EarlyStopping(monitor=\"val_f1_score\", mode=\"max\", patience=20, restore_best_weights=True),\n        ModelCheckpoint(os.path.join(output_dir, f\"best_{name}.h5\"),\n                        monitor=\"val_f1_score\", mode=\"max\", save_best_only=True),\n        CSVLogger(os.path.join(output_dir, f\"log_{name}.csv\")),\n        LearningRateScheduler(cosine_lr)\n    ]\n\n# --- 6) Data Augmentation Generator ---\ndef aug_gen(X, y, seed=0, batch_size=32):\n    n = X.shape[0]\n    rng = np.random.RandomState(seed)\n    while True:\n        idx = rng.randint(0, n, batch_size)\n        bx, by = X[idx].copy(), y[idx]\n        bx += rng.normal(0, 0.005, bx.shape)\n        yield bx, by\n\n# --- 7) Apply CSP ---\ndef apply_csp(W, X):  # X: (n, T, C)\n    return np.stack([W.dot(ep.T) for ep in X], axis=0).astype('float32')\n\n# --- 8) Cross-Validation ---\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\nmodels_to_run = {\n    'oldA': build_modelA,\n    'oldB': build_modelB,\n    'model5': build_model5,\n    'model6': build_model6\n}\n\n# Store results\nresults = {name: [] for name in models_to_run}\n\nfor fold_idx, (train_idx, test_idx) in enumerate(kf.split(X_all_raw)):\n    print(f\"\\n=== Fold {fold_idx+1}/{n_folds} ===\")\n    \n    # Split data\n    X_train_raw, X_test_raw = X_all_raw[train_idx], X_all_raw[test_idx]\n    y_train_bin, y_test_bin = y_all_bin[train_idx], y_all_bin[test_idx]\n    y_train_oh = keras.utils.to_categorical(y_train_bin, 2)\n    y_test_oh = keras.utils.to_categorical(y_test_bin, 2)\n    \n    # Prepare CSP for model5 (using training data only)\n    if 'model5' in models_to_run:\n        csp = CSP(n_components=4, log=False, norm_trace=False)\n        X_train_csp_input = X_train_raw.transpose(0, 2, 1).astype('float64')\n        csp.fit(X_train_csp_input, y_train_bin)\n        W = csp.filters_[:4]\n        \n        X_train_csp = apply_csp(W, X_train_raw).transpose(0, 2, 1)\n        X_test_csp = apply_csp(W, X_test_raw).transpose(0, 2, 1)\n    \n    # Train each model\n    for name, builder in models_to_run.items():\n        print(f\"\\nTraining {name} (Fold {fold_idx+1})\")\n        \n        # Select data\n        if name == 'model5':\n            X_train, X_test = X_train_csp, X_test_csp\n        else:\n            X_train, X_test = X_train_raw, X_test_raw\n        \n        # Create data generators\n        train_gen = aug_gen(X_train, y_train_oh, seed=fold_idx, batch_size=batch_size)\n        steps_per_epoch = len(X_train) // batch_size\n        \n        # Build and train model\n        model = builder(X_train.shape[1:])\n        model.fit(\n            train_gen,\n            steps_per_epoch=steps_per_epoch,\n            epochs=200,\n            validation_data=(X_test, y_test_oh),\n            callbacks=get_callbacks(f\"{name}_fold{fold_idx}\"),\n            verbose=2\n        )\n        \n        # Evaluate with macro F1\n        preds = np.argmax(model.predict(X_test), axis=1)\n        f1 = f1_score(y_test_bin, preds, average='macro')  # Macro F1\n        results[name].append(f1)\n        print(f\"{name} (Fold {fold_idx+1}) Macro F1: {f1:.4f}\")\n        print(classification_report(y_test_bin, preds, target_names=[\"Left\", \"Right\"]))\n\n# --- 9) Print CV Results ---\nprint(\"\\n=== Cross-Validation Results ===\")\nfor name, f1_scores in results.items():\n    mean_f1 = np.mean(f1_scores)\n    std_f1 = np.std(f1_scores)\n    print(f\"{name}:\")\n    print(f\"  Macro F1 Scores: {[f'{s:.4f}' for s in f1_scores]}\")\n    print(f\"  Mean Macro F1: {mean_f1:.4f} ± {std_f1:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T06:59:55.396314Z","iopub.execute_input":"2025-06-27T06:59:55.397355Z","iopub.status.idle":"2025-06-27T07:13:51.522335Z","shell.execute_reply.started":"2025-06-27T06:59:55.397331Z","shell.execute_reply":"2025-06-27T07:13:51.521723Z"}},"outputs":[{"name":"stdout","text":"\n=== Fold 1/5 ===\nComputing rank from data with rank=None\n    Using tolerance 3e+03 (2.2e-16 eps * 4 dim * 3.4e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\nTraining oldA (Fold 1)\nEpoch 1/200\n30/30 - 9s - 305ms/step - accuracy: 0.4995 - f1_score: 0.4977 - loss: 0.8474 - val_accuracy: 0.5000 - val_f1_score: 0.4250 - val_loss: 0.8936 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 30ms/step - accuracy: 0.4969 - f1_score: 0.4944 - loss: 0.7884 - val_accuracy: 0.5020 - val_f1_score: 0.5015 - val_loss: 0.7223 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 28ms/step - accuracy: 0.4740 - f1_score: 0.4739 - loss: 0.7497 - val_accuracy: 0.4837 - val_f1_score: 0.4413 - val_loss: 0.7275 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 28ms/step - accuracy: 0.5063 - f1_score: 0.5062 - loss: 0.7301 - val_accuracy: 0.4898 - val_f1_score: 0.4617 - val_loss: 0.7097 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 28ms/step - accuracy: 0.5385 - f1_score: 0.5327 - loss: 0.7147 - val_accuracy: 0.5041 - val_f1_score: 0.4887 - val_loss: 0.7133 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 28ms/step - accuracy: 0.5125 - f1_score: 0.5076 - loss: 0.7083 - val_accuracy: 0.5000 - val_f1_score: 0.4475 - val_loss: 0.7116 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 28ms/step - accuracy: 0.5380 - f1_score: 0.5375 - loss: 0.7073 - val_accuracy: 0.4878 - val_f1_score: 0.4650 - val_loss: 0.7047 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 28ms/step - accuracy: 0.5146 - f1_score: 0.5138 - loss: 0.7102 - val_accuracy: 0.4918 - val_f1_score: 0.4385 - val_loss: 0.7088 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 29ms/step - accuracy: 0.5063 - f1_score: 0.4994 - loss: 0.7057 - val_accuracy: 0.5082 - val_f1_score: 0.4863 - val_loss: 0.7041 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 30ms/step - accuracy: 0.5000 - f1_score: 0.4983 - loss: 0.7070 - val_accuracy: 0.5082 - val_f1_score: 0.5069 - val_loss: 0.7033 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 28ms/step - accuracy: 0.5255 - f1_score: 0.5232 - loss: 0.7006 - val_accuracy: 0.4898 - val_f1_score: 0.4815 - val_loss: 0.7043 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 28ms/step - accuracy: 0.5245 - f1_score: 0.5239 - loss: 0.6981 - val_accuracy: 0.4980 - val_f1_score: 0.4842 - val_loss: 0.7027 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 28ms/step - accuracy: 0.5323 - f1_score: 0.5322 - loss: 0.6963 - val_accuracy: 0.5000 - val_f1_score: 0.4709 - val_loss: 0.7022 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 28ms/step - accuracy: 0.5276 - f1_score: 0.5259 - loss: 0.7016 - val_accuracy: 0.5245 - val_f1_score: 0.4891 - val_loss: 0.6999 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 28ms/step - accuracy: 0.5260 - f1_score: 0.5241 - loss: 0.6990 - val_accuracy: 0.4939 - val_f1_score: 0.4228 - val_loss: 0.7070 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 28ms/step - accuracy: 0.5479 - f1_score: 0.5342 - loss: 0.6988 - val_accuracy: 0.4898 - val_f1_score: 0.4181 - val_loss: 0.7068 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 28ms/step - accuracy: 0.5229 - f1_score: 0.5185 - loss: 0.7006 - val_accuracy: 0.5041 - val_f1_score: 0.4407 - val_loss: 0.7023 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 28ms/step - accuracy: 0.5349 - f1_score: 0.5349 - loss: 0.6997 - val_accuracy: 0.5102 - val_f1_score: 0.4889 - val_loss: 0.7016 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 30ms/step - accuracy: 0.5365 - f1_score: 0.5348 - loss: 0.7014 - val_accuracy: 0.5184 - val_f1_score: 0.5155 - val_loss: 0.7036 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 28ms/step - accuracy: 0.5542 - f1_score: 0.5524 - loss: 0.6951 - val_accuracy: 0.5245 - val_f1_score: 0.5104 - val_loss: 0.7021 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 30ms/step - accuracy: 0.5380 - f1_score: 0.5380 - loss: 0.6949 - val_accuracy: 0.5367 - val_f1_score: 0.5363 - val_loss: 0.7037 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 28ms/step - accuracy: 0.5380 - f1_score: 0.5369 - loss: 0.6965 - val_accuracy: 0.5143 - val_f1_score: 0.5103 - val_loss: 0.6995 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 28ms/step - accuracy: 0.5260 - f1_score: 0.5249 - loss: 0.6995 - val_accuracy: 0.5184 - val_f1_score: 0.5000 - val_loss: 0.7003 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 28ms/step - accuracy: 0.5224 - f1_score: 0.5221 - loss: 0.6953 - val_accuracy: 0.5347 - val_f1_score: 0.5290 - val_loss: 0.6960 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 28ms/step - accuracy: 0.5437 - f1_score: 0.5381 - loss: 0.6967 - val_accuracy: 0.5265 - val_f1_score: 0.4984 - val_loss: 0.7098 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 28ms/step - accuracy: 0.5469 - f1_score: 0.5406 - loss: 0.6944 - val_accuracy: 0.5224 - val_f1_score: 0.5026 - val_loss: 0.7031 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 28ms/step - accuracy: 0.5266 - f1_score: 0.5265 - loss: 0.6956 - val_accuracy: 0.5061 - val_f1_score: 0.5005 - val_loss: 0.7022 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 28ms/step - accuracy: 0.5370 - f1_score: 0.5253 - loss: 0.6952 - val_accuracy: 0.5163 - val_f1_score: 0.4685 - val_loss: 0.7005 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 28ms/step - accuracy: 0.5484 - f1_score: 0.5455 - loss: 0.6927 - val_accuracy: 0.5143 - val_f1_score: 0.5064 - val_loss: 0.7055 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 28ms/step - accuracy: 0.5453 - f1_score: 0.5453 - loss: 0.6903 - val_accuracy: 0.4980 - val_f1_score: 0.4869 - val_loss: 0.7106 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 28ms/step - accuracy: 0.5276 - f1_score: 0.5272 - loss: 0.6951 - val_accuracy: 0.5204 - val_f1_score: 0.5118 - val_loss: 0.7044 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 28ms/step - accuracy: 0.5380 - f1_score: 0.5356 - loss: 0.6940 - val_accuracy: 0.5184 - val_f1_score: 0.5071 - val_loss: 0.7033 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 28ms/step - accuracy: 0.5307 - f1_score: 0.5289 - loss: 0.6901 - val_accuracy: 0.5041 - val_f1_score: 0.5036 - val_loss: 0.7062 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 28ms/step - accuracy: 0.5479 - f1_score: 0.5467 - loss: 0.6893 - val_accuracy: 0.5327 - val_f1_score: 0.5312 - val_loss: 0.6987 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 28ms/step - accuracy: 0.5526 - f1_score: 0.5520 - loss: 0.6894 - val_accuracy: 0.5041 - val_f1_score: 0.4839 - val_loss: 0.7033 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 28ms/step - accuracy: 0.5453 - f1_score: 0.5310 - loss: 0.6899 - val_accuracy: 0.4959 - val_f1_score: 0.4717 - val_loss: 0.7060 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 28ms/step - accuracy: 0.5427 - f1_score: 0.5402 - loss: 0.6924 - val_accuracy: 0.5245 - val_f1_score: 0.5175 - val_loss: 0.7055 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 28ms/step - accuracy: 0.5516 - f1_score: 0.5491 - loss: 0.6864 - val_accuracy: 0.5061 - val_f1_score: 0.4904 - val_loss: 0.7065 - learning_rate: 3.3498e-04\nEpoch 39/200\n30/30 - 1s - 28ms/step - accuracy: 0.5745 - f1_score: 0.5719 - loss: 0.6803 - val_accuracy: 0.5102 - val_f1_score: 0.4871 - val_loss: 0.7102 - learning_rate: 3.0602e-04\nEpoch 40/200\n30/30 - 1s - 28ms/step - accuracy: 0.5464 - f1_score: 0.5454 - loss: 0.6867 - val_accuracy: 0.5020 - val_f1_score: 0.4984 - val_loss: 0.7116 - learning_rate: 2.7820e-04\nEpoch 41/200\n30/30 - 1s - 28ms/step - accuracy: 0.5641 - f1_score: 0.5639 - loss: 0.6862 - val_accuracy: 0.5224 - val_f1_score: 0.5209 - val_loss: 0.7073 - learning_rate: 2.5163e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\noldA (Fold 1) Macro F1: 0.5363\n              precision    recall  f1-score   support\n\n        Left       0.52      0.58      0.55       238\n       Right       0.56      0.49      0.52       252\n\n    accuracy                           0.54       490\n   macro avg       0.54      0.54      0.54       490\nweighted avg       0.54      0.54      0.54       490\n\n\nTraining oldB (Fold 1)\nEpoch 1/200\n30/30 - 14s - 477ms/step - accuracy: 0.4990 - f1_score: 0.4988 - loss: 2.9678 - val_accuracy: 0.4980 - val_f1_score: 0.4875 - val_loss: 0.9470 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 33ms/step - accuracy: 0.4839 - f1_score: 0.4824 - loss: 2.1231 - val_accuracy: 0.5286 - val_f1_score: 0.4187 - val_loss: 0.7707 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 32ms/step - accuracy: 0.5047 - f1_score: 0.5046 - loss: 1.7494 - val_accuracy: 0.5020 - val_f1_score: 0.3926 - val_loss: 0.7696 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 33ms/step - accuracy: 0.4906 - f1_score: 0.4905 - loss: 1.3059 - val_accuracy: 0.5184 - val_f1_score: 0.3995 - val_loss: 0.7705 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 38ms/step - accuracy: 0.5219 - f1_score: 0.5219 - loss: 1.0107 - val_accuracy: 0.5082 - val_f1_score: 0.4906 - val_loss: 0.7574 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 33ms/step - accuracy: 0.4969 - f1_score: 0.4967 - loss: 1.0255 - val_accuracy: 0.5143 - val_f1_score: 0.4711 - val_loss: 0.7483 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 32ms/step - accuracy: 0.4953 - f1_score: 0.4945 - loss: 0.9445 - val_accuracy: 0.5388 - val_f1_score: 0.4740 - val_loss: 0.7464 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 32ms/step - accuracy: 0.5083 - f1_score: 0.5068 - loss: 0.8710 - val_accuracy: 0.5000 - val_f1_score: 0.4805 - val_loss: 0.7482 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 32ms/step - accuracy: 0.4870 - f1_score: 0.4866 - loss: 0.8701 - val_accuracy: 0.4898 - val_f1_score: 0.4272 - val_loss: 0.7478 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 32ms/step - accuracy: 0.5026 - f1_score: 0.5011 - loss: 0.8105 - val_accuracy: 0.5041 - val_f1_score: 0.4353 - val_loss: 0.7460 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 33ms/step - accuracy: 0.5120 - f1_score: 0.5082 - loss: 0.7961 - val_accuracy: 0.4980 - val_f1_score: 0.4397 - val_loss: 0.7469 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 32ms/step - accuracy: 0.4969 - f1_score: 0.4964 - loss: 0.7999 - val_accuracy: 0.4980 - val_f1_score: 0.4881 - val_loss: 0.7481 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 32ms/step - accuracy: 0.5188 - f1_score: 0.5121 - loss: 0.7731 - val_accuracy: 0.5122 - val_f1_score: 0.3566 - val_loss: 0.7465 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 33ms/step - accuracy: 0.5104 - f1_score: 0.5005 - loss: 0.7839 - val_accuracy: 0.5122 - val_f1_score: 0.3697 - val_loss: 0.7459 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 37ms/step - accuracy: 0.5016 - f1_score: 0.4926 - loss: 0.7739 - val_accuracy: 0.5531 - val_f1_score: 0.4927 - val_loss: 0.7465 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 32ms/step - accuracy: 0.5125 - f1_score: 0.4908 - loss: 0.7776 - val_accuracy: 0.5286 - val_f1_score: 0.3748 - val_loss: 0.7456 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 32ms/step - accuracy: 0.5109 - f1_score: 0.4978 - loss: 0.7771 - val_accuracy: 0.5184 - val_f1_score: 0.3525 - val_loss: 0.7459 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 37ms/step - accuracy: 0.4969 - f1_score: 0.4942 - loss: 0.7735 - val_accuracy: 0.5265 - val_f1_score: 0.5264 - val_loss: 0.7469 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 32ms/step - accuracy: 0.5229 - f1_score: 0.5227 - loss: 0.7583 - val_accuracy: 0.5082 - val_f1_score: 0.4929 - val_loss: 0.7464 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 32ms/step - accuracy: 0.5115 - f1_score: 0.5040 - loss: 0.7570 - val_accuracy: 0.5020 - val_f1_score: 0.4244 - val_loss: 0.7459 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 34ms/step - accuracy: 0.5156 - f1_score: 0.5082 - loss: 0.7652 - val_accuracy: 0.5388 - val_f1_score: 0.4925 - val_loss: 0.7456 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 33ms/step - accuracy: 0.5005 - f1_score: 0.4938 - loss: 0.7593 - val_accuracy: 0.5041 - val_f1_score: 0.4473 - val_loss: 0.7457 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 32ms/step - accuracy: 0.5005 - f1_score: 0.4918 - loss: 0.7634 - val_accuracy: 0.5000 - val_f1_score: 0.4845 - val_loss: 0.7462 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 32ms/step - accuracy: 0.5000 - f1_score: 0.4992 - loss: 0.7597 - val_accuracy: 0.4980 - val_f1_score: 0.4862 - val_loss: 0.7466 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 32ms/step - accuracy: 0.5026 - f1_score: 0.4975 - loss: 0.7535 - val_accuracy: 0.5122 - val_f1_score: 0.3424 - val_loss: 0.7451 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 32ms/step - accuracy: 0.5000 - f1_score: 0.4890 - loss: 0.7554 - val_accuracy: 0.5143 - val_f1_score: 0.4957 - val_loss: 0.7459 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 33ms/step - accuracy: 0.5177 - f1_score: 0.5078 - loss: 0.7463 - val_accuracy: 0.5163 - val_f1_score: 0.3479 - val_loss: 0.7448 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 33ms/step - accuracy: 0.5182 - f1_score: 0.4851 - loss: 0.7543 - val_accuracy: 0.5143 - val_f1_score: 0.3396 - val_loss: 0.7446 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 33ms/step - accuracy: 0.4990 - f1_score: 0.4859 - loss: 0.7510 - val_accuracy: 0.5122 - val_f1_score: 0.4848 - val_loss: 0.7453 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 32ms/step - accuracy: 0.4943 - f1_score: 0.4864 - loss: 0.7490 - val_accuracy: 0.5082 - val_f1_score: 0.4486 - val_loss: 0.7449 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 33ms/step - accuracy: 0.5208 - f1_score: 0.5075 - loss: 0.7504 - val_accuracy: 0.5041 - val_f1_score: 0.4335 - val_loss: 0.7448 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 32ms/step - accuracy: 0.5224 - f1_score: 0.5182 - loss: 0.7465 - val_accuracy: 0.5122 - val_f1_score: 0.5108 - val_loss: 0.7451 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 32ms/step - accuracy: 0.5302 - f1_score: 0.5256 - loss: 0.7446 - val_accuracy: 0.5122 - val_f1_score: 0.4878 - val_loss: 0.7447 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 32ms/step - accuracy: 0.5104 - f1_score: 0.5050 - loss: 0.7487 - val_accuracy: 0.5163 - val_f1_score: 0.4892 - val_loss: 0.7445 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 32ms/step - accuracy: 0.5307 - f1_score: 0.5133 - loss: 0.7452 - val_accuracy: 0.5224 - val_f1_score: 0.4073 - val_loss: 0.7443 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 32ms/step - accuracy: 0.4948 - f1_score: 0.4668 - loss: 0.7474 - val_accuracy: 0.5082 - val_f1_score: 0.4156 - val_loss: 0.7441 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 32ms/step - accuracy: 0.5073 - f1_score: 0.4963 - loss: 0.7453 - val_accuracy: 0.5143 - val_f1_score: 0.5143 - val_loss: 0.7442 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 32ms/step - accuracy: 0.5151 - f1_score: 0.5151 - loss: 0.7467 - val_accuracy: 0.5245 - val_f1_score: 0.4902 - val_loss: 0.7444 - learning_rate: 3.3498e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\noldB (Fold 1) Macro F1: 0.5264\n              precision    recall  f1-score   support\n\n        Left       0.51      0.56      0.53       238\n       Right       0.54      0.50      0.52       252\n\n    accuracy                           0.53       490\n   macro avg       0.53      0.53      0.53       490\nweighted avg       0.53      0.53      0.53       490\n\n\nTraining model5 (Fold 1)\nEpoch 1/200\n30/30 - 8s - 270ms/step - accuracy: 0.5063 - f1_score: 0.5049 - loss: 1.0854 - val_accuracy: 0.4980 - val_f1_score: 0.4922 - val_loss: 0.9742 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 25ms/step - accuracy: 0.5328 - f1_score: 0.5300 - loss: 0.7682 - val_accuracy: 0.4878 - val_f1_score: 0.4429 - val_loss: 0.7526 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 24ms/step - accuracy: 0.5115 - f1_score: 0.5109 - loss: 0.7975 - val_accuracy: 0.4918 - val_f1_score: 0.4052 - val_loss: 0.8743 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 24ms/step - accuracy: 0.5349 - f1_score: 0.5349 - loss: 0.7463 - val_accuracy: 0.4857 - val_f1_score: 0.4356 - val_loss: 0.8479 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 24ms/step - accuracy: 0.5286 - f1_score: 0.5264 - loss: 0.7355 - val_accuracy: 0.4714 - val_f1_score: 0.4580 - val_loss: 0.7535 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 24ms/step - accuracy: 0.5234 - f1_score: 0.5194 - loss: 0.7271 - val_accuracy: 0.5122 - val_f1_score: 0.4428 - val_loss: 0.7669 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 24ms/step - accuracy: 0.5214 - f1_score: 0.5119 - loss: 0.7068 - val_accuracy: 0.4959 - val_f1_score: 0.3701 - val_loss: 0.7253 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 40ms/step - accuracy: 0.5234 - f1_score: 0.5213 - loss: 0.7126 - val_accuracy: 0.5143 - val_f1_score: 0.5023 - val_loss: 0.7143 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 42ms/step - accuracy: 0.5328 - f1_score: 0.5180 - loss: 0.6940 - val_accuracy: 0.5143 - val_f1_score: 0.5047 - val_loss: 0.7212 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 24ms/step - accuracy: 0.6297 - f1_score: 0.6296 - loss: 0.6367 - val_accuracy: 0.4776 - val_f1_score: 0.4152 - val_loss: 0.8006 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 24ms/step - accuracy: 0.7349 - f1_score: 0.7346 - loss: 0.5227 - val_accuracy: 0.4776 - val_f1_score: 0.4744 - val_loss: 0.9990 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 24ms/step - accuracy: 0.7563 - f1_score: 0.7554 - loss: 0.4739 - val_accuracy: 0.4776 - val_f1_score: 0.4765 - val_loss: 1.0591 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 24ms/step - accuracy: 0.8219 - f1_score: 0.8213 - loss: 0.3962 - val_accuracy: 0.5000 - val_f1_score: 0.4999 - val_loss: 1.2294 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 24ms/step - accuracy: 0.8802 - f1_score: 0.8801 - loss: 0.2696 - val_accuracy: 0.4612 - val_f1_score: 0.4564 - val_loss: 1.5446 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 24ms/step - accuracy: 0.9036 - f1_score: 0.9036 - loss: 0.2297 - val_accuracy: 0.4918 - val_f1_score: 0.4917 - val_loss: 1.5632 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 24ms/step - accuracy: 0.9177 - f1_score: 0.9176 - loss: 0.1951 - val_accuracy: 0.4694 - val_f1_score: 0.4688 - val_loss: 1.8014 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 24ms/step - accuracy: 0.9615 - f1_score: 0.9614 - loss: 0.0963 - val_accuracy: 0.4776 - val_f1_score: 0.4767 - val_loss: 2.2337 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 24ms/step - accuracy: 0.9693 - f1_score: 0.9693 - loss: 0.0896 - val_accuracy: 0.4694 - val_f1_score: 0.4681 - val_loss: 2.5159 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 24ms/step - accuracy: 0.9745 - f1_score: 0.9745 - loss: 0.0727 - val_accuracy: 0.4694 - val_f1_score: 0.4647 - val_loss: 2.6054 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 24ms/step - accuracy: 0.9818 - f1_score: 0.9818 - loss: 0.0562 - val_accuracy: 0.4898 - val_f1_score: 0.4867 - val_loss: 2.7111 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 24ms/step - accuracy: 0.9859 - f1_score: 0.9859 - loss: 0.0403 - val_accuracy: 0.4694 - val_f1_score: 0.4694 - val_loss: 3.1685 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 24ms/step - accuracy: 0.9885 - f1_score: 0.9885 - loss: 0.0268 - val_accuracy: 0.4612 - val_f1_score: 0.4599 - val_loss: 3.1946 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 24ms/step - accuracy: 0.9964 - f1_score: 0.9964 - loss: 0.0138 - val_accuracy: 0.4755 - val_f1_score: 0.4714 - val_loss: 3.3255 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 24ms/step - accuracy: 0.9979 - f1_score: 0.9979 - loss: 0.0086 - val_accuracy: 0.4755 - val_f1_score: 0.4749 - val_loss: 3.5544 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 24ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0046 - val_accuracy: 0.4673 - val_f1_score: 0.4670 - val_loss: 3.7372 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 24ms/step - accuracy: 0.9990 - f1_score: 0.9990 - loss: 0.0062 - val_accuracy: 0.4755 - val_f1_score: 0.4754 - val_loss: 3.8396 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - val_accuracy: 0.4755 - val_f1_score: 0.4755 - val_loss: 3.9550 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 24ms/step - accuracy: 0.9990 - f1_score: 0.9990 - loss: 0.0027 - val_accuracy: 0.4776 - val_f1_score: 0.4753 - val_loss: 3.9427 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 24ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0025 - val_accuracy: 0.4857 - val_f1_score: 0.4853 - val_loss: 4.0753 - learning_rate: 6.1987e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\nmodel5 (Fold 1) Macro F1: 0.5047\n              precision    recall  f1-score   support\n\n        Left       0.50      0.67      0.57       238\n       Right       0.54      0.37      0.44       252\n\n    accuracy                           0.51       490\n   macro avg       0.52      0.52      0.50       490\nweighted avg       0.52      0.51      0.50       490\n\n\nTraining model6 (Fold 1)\nEpoch 1/200\n30/30 - 9s - 286ms/step - accuracy: 0.5094 - f1_score: 0.5072 - loss: 3.7194 - val_accuracy: 0.4857 - val_f1_score: 0.4095 - val_loss: 2.4759 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 41ms/step - accuracy: 0.4927 - f1_score: 0.4918 - loss: 1.9055 - val_accuracy: 0.5041 - val_f1_score: 0.5009 - val_loss: 1.0684 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 39ms/step - accuracy: 0.5078 - f1_score: 0.5078 - loss: 1.1170 - val_accuracy: 0.5224 - val_f1_score: 0.4605 - val_loss: 1.0419 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 39ms/step - accuracy: 0.5010 - f1_score: 0.5006 - loss: 0.8041 - val_accuracy: 0.4857 - val_f1_score: 0.4737 - val_loss: 0.8190 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 41ms/step - accuracy: 0.5161 - f1_score: 0.5062 - loss: 0.8540 - val_accuracy: 0.5367 - val_f1_score: 0.5056 - val_loss: 0.8385 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 39ms/step - accuracy: 0.5052 - f1_score: 0.5051 - loss: 0.7286 - val_accuracy: 0.4959 - val_f1_score: 0.4779 - val_loss: 0.7640 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 39ms/step - accuracy: 0.4969 - f1_score: 0.4783 - loss: 0.7315 - val_accuracy: 0.4980 - val_f1_score: 0.4397 - val_loss: 0.7002 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 40ms/step - accuracy: 0.4911 - f1_score: 0.4752 - loss: 0.7070 - val_accuracy: 0.5184 - val_f1_score: 0.5120 - val_loss: 0.7029 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 39ms/step - accuracy: 0.5052 - f1_score: 0.4308 - loss: 0.6961 - val_accuracy: 0.4857 - val_f1_score: 0.3673 - val_loss: 0.6959 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 39ms/step - accuracy: 0.5042 - f1_score: 0.4349 - loss: 0.6933 - val_accuracy: 0.4837 - val_f1_score: 0.4311 - val_loss: 0.6956 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 40ms/step - accuracy: 0.5312 - f1_score: 0.5205 - loss: 0.6920 - val_accuracy: 0.4837 - val_f1_score: 0.4837 - val_loss: 0.6956 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 39ms/step - accuracy: 0.5083 - f1_score: 0.5074 - loss: 0.6932 - val_accuracy: 0.4755 - val_f1_score: 0.3768 - val_loss: 0.6945 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 39ms/step - accuracy: 0.4984 - f1_score: 0.4726 - loss: 0.6921 - val_accuracy: 0.5041 - val_f1_score: 0.4987 - val_loss: 0.6975 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 39ms/step - accuracy: 0.5292 - f1_score: 0.5244 - loss: 0.6923 - val_accuracy: 0.4918 - val_f1_score: 0.4844 - val_loss: 0.6941 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 39ms/step - accuracy: 0.5135 - f1_score: 0.4817 - loss: 0.6942 - val_accuracy: 0.5020 - val_f1_score: 0.3763 - val_loss: 0.6961 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 39ms/step - accuracy: 0.5167 - f1_score: 0.4487 - loss: 0.6926 - val_accuracy: 0.5041 - val_f1_score: 0.3493 - val_loss: 0.6961 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 39ms/step - accuracy: 0.5146 - f1_score: 0.3779 - loss: 0.6908 - val_accuracy: 0.5163 - val_f1_score: 0.3653 - val_loss: 0.6968 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 39ms/step - accuracy: 0.4984 - f1_score: 0.4968 - loss: 0.6923 - val_accuracy: 0.4918 - val_f1_score: 0.4052 - val_loss: 0.6946 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 39ms/step - accuracy: 0.5312 - f1_score: 0.4540 - loss: 0.6905 - val_accuracy: 0.4837 - val_f1_score: 0.4042 - val_loss: 0.6945 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 39ms/step - accuracy: 0.5302 - f1_score: 0.4841 - loss: 0.6899 - val_accuracy: 0.5163 - val_f1_score: 0.5082 - val_loss: 0.6930 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 39ms/step - accuracy: 0.5292 - f1_score: 0.5192 - loss: 0.6870 - val_accuracy: 0.5020 - val_f1_score: 0.4618 - val_loss: 0.6986 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.5155 - loss: 0.6952 - val_accuracy: 0.4918 - val_f1_score: 0.4879 - val_loss: 0.6948 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 39ms/step - accuracy: 0.5000 - f1_score: 0.4944 - loss: 0.6959 - val_accuracy: 0.4878 - val_f1_score: 0.4401 - val_loss: 0.6967 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 39ms/step - accuracy: 0.5083 - f1_score: 0.4885 - loss: 0.6971 - val_accuracy: 0.5102 - val_f1_score: 0.5069 - val_loss: 0.6938 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 39ms/step - accuracy: 0.5391 - f1_score: 0.5235 - loss: 0.6892 - val_accuracy: 0.4714 - val_f1_score: 0.4307 - val_loss: 0.6977 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 39ms/step - accuracy: 0.5109 - f1_score: 0.4791 - loss: 0.6892 - val_accuracy: 0.4755 - val_f1_score: 0.4741 - val_loss: 0.7047 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 39ms/step - accuracy: 0.5344 - f1_score: 0.5336 - loss: 0.6915 - val_accuracy: 0.4980 - val_f1_score: 0.4624 - val_loss: 0.7002 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 40ms/step - accuracy: 0.5464 - f1_score: 0.4784 - loss: 0.6858 - val_accuracy: 0.5000 - val_f1_score: 0.4190 - val_loss: 0.6994 - learning_rate: 6.5084e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\nmodel6 (Fold 1) Macro F1: 0.5120\n              precision    recall  f1-score   support\n\n        Left       0.51      0.42      0.46       238\n       Right       0.53      0.62      0.57       252\n\n    accuracy                           0.52       490\n   macro avg       0.52      0.52      0.51       490\nweighted avg       0.52      0.52      0.51       490\n\n\n=== Fold 2/5 ===\nComputing rank from data with rank=None\n    Using tolerance 3e+03 (2.2e-16 eps * 4 dim * 3.4e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\nTraining oldA (Fold 2)\nEpoch 1/200\n30/30 - 8s - 274ms/step - accuracy: 0.4932 - f1_score: 0.4932 - loss: 0.9300 - val_accuracy: 0.5306 - val_f1_score: 0.5230 - val_loss: 0.7725 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 28ms/step - accuracy: 0.5266 - f1_score: 0.5265 - loss: 0.7992 - val_accuracy: 0.4735 - val_f1_score: 0.4033 - val_loss: 0.7511 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 28ms/step - accuracy: 0.5115 - f1_score: 0.5110 - loss: 0.7439 - val_accuracy: 0.4367 - val_f1_score: 0.3714 - val_loss: 0.7667 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 28ms/step - accuracy: 0.5130 - f1_score: 0.5123 - loss: 0.7388 - val_accuracy: 0.5122 - val_f1_score: 0.4828 - val_loss: 0.7253 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 28ms/step - accuracy: 0.5146 - f1_score: 0.5121 - loss: 0.7366 - val_accuracy: 0.4980 - val_f1_score: 0.4346 - val_loss: 0.7037 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.5182 - loss: 0.7146 - val_accuracy: 0.4796 - val_f1_score: 0.4217 - val_loss: 0.7205 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 28ms/step - accuracy: 0.5276 - f1_score: 0.5271 - loss: 0.7055 - val_accuracy: 0.4776 - val_f1_score: 0.4548 - val_loss: 0.7086 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 28ms/step - accuracy: 0.5229 - f1_score: 0.5220 - loss: 0.7119 - val_accuracy: 0.4776 - val_f1_score: 0.4539 - val_loss: 0.7210 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 28ms/step - accuracy: 0.5172 - f1_score: 0.5164 - loss: 0.7110 - val_accuracy: 0.4755 - val_f1_score: 0.4661 - val_loss: 0.7042 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 28ms/step - accuracy: 0.5417 - f1_score: 0.5396 - loss: 0.7064 - val_accuracy: 0.5041 - val_f1_score: 0.4520 - val_loss: 0.7062 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.5181 - loss: 0.7018 - val_accuracy: 0.4633 - val_f1_score: 0.4404 - val_loss: 0.7083 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 28ms/step - accuracy: 0.5188 - f1_score: 0.5160 - loss: 0.7056 - val_accuracy: 0.4694 - val_f1_score: 0.4687 - val_loss: 0.7081 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 28ms/step - accuracy: 0.5297 - f1_score: 0.5172 - loss: 0.7035 - val_accuracy: 0.4857 - val_f1_score: 0.4455 - val_loss: 0.7071 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 28ms/step - accuracy: 0.5078 - f1_score: 0.5047 - loss: 0.7035 - val_accuracy: 0.4612 - val_f1_score: 0.4231 - val_loss: 0.7077 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 28ms/step - accuracy: 0.5417 - f1_score: 0.5397 - loss: 0.6940 - val_accuracy: 0.4551 - val_f1_score: 0.4347 - val_loss: 0.7083 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 28ms/step - accuracy: 0.5219 - f1_score: 0.5211 - loss: 0.7037 - val_accuracy: 0.4571 - val_f1_score: 0.4569 - val_loss: 0.7074 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 28ms/step - accuracy: 0.5401 - f1_score: 0.5393 - loss: 0.6960 - val_accuracy: 0.4694 - val_f1_score: 0.4658 - val_loss: 0.7105 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 28ms/step - accuracy: 0.5385 - f1_score: 0.5344 - loss: 0.6980 - val_accuracy: 0.4571 - val_f1_score: 0.4423 - val_loss: 0.7078 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 28ms/step - accuracy: 0.5365 - f1_score: 0.5282 - loss: 0.6980 - val_accuracy: 0.4980 - val_f1_score: 0.4828 - val_loss: 0.7090 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 28ms/step - accuracy: 0.5417 - f1_score: 0.5357 - loss: 0.6990 - val_accuracy: 0.4673 - val_f1_score: 0.4665 - val_loss: 0.7076 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 28ms/step - accuracy: 0.5453 - f1_score: 0.5423 - loss: 0.6973 - val_accuracy: 0.4816 - val_f1_score: 0.4726 - val_loss: 0.7062 - learning_rate: 8.3736e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\noldA (Fold 2) Macro F1: 0.5230\n              precision    recall  f1-score   support\n\n        Left       0.53      0.64      0.58       251\n       Right       0.52      0.41      0.46       239\n\n    accuracy                           0.53       490\n   macro avg       0.53      0.53      0.52       490\nweighted avg       0.53      0.53      0.52       490\n\n\nTraining oldB (Fold 2)\nEpoch 1/200\n30/30 - 14s - 476ms/step - accuracy: 0.5036 - f1_score: 0.5031 - loss: 4.0891 - val_accuracy: 0.5000 - val_f1_score: 0.4549 - val_loss: 1.1825 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 37ms/step - accuracy: 0.4958 - f1_score: 0.4954 - loss: 2.8243 - val_accuracy: 0.4633 - val_f1_score: 0.4632 - val_loss: 1.6711 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 38ms/step - accuracy: 0.4833 - f1_score: 0.4833 - loss: 2.3642 - val_accuracy: 0.5429 - val_f1_score: 0.5238 - val_loss: 0.7596 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 32ms/step - accuracy: 0.4974 - f1_score: 0.4966 - loss: 1.5862 - val_accuracy: 0.4571 - val_f1_score: 0.4465 - val_loss: 0.7790 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 32ms/step - accuracy: 0.4958 - f1_score: 0.4950 - loss: 1.3516 - val_accuracy: 0.4898 - val_f1_score: 0.4889 - val_loss: 0.7653 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 32ms/step - accuracy: 0.5000 - f1_score: 0.5000 - loss: 1.2485 - val_accuracy: 0.5102 - val_f1_score: 0.5046 - val_loss: 0.7525 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 32ms/step - accuracy: 0.5130 - f1_score: 0.5129 - loss: 1.1188 - val_accuracy: 0.5020 - val_f1_score: 0.4714 - val_loss: 0.7466 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 32ms/step - accuracy: 0.5104 - f1_score: 0.5102 - loss: 0.9783 - val_accuracy: 0.4857 - val_f1_score: 0.4115 - val_loss: 0.7530 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 32ms/step - accuracy: 0.5109 - f1_score: 0.5098 - loss: 0.8623 - val_accuracy: 0.4735 - val_f1_score: 0.4089 - val_loss: 0.7537 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 32ms/step - accuracy: 0.5250 - f1_score: 0.5236 - loss: 0.8746 - val_accuracy: 0.4531 - val_f1_score: 0.3741 - val_loss: 0.7518 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 32ms/step - accuracy: 0.4974 - f1_score: 0.4965 - loss: 0.8465 - val_accuracy: 0.5245 - val_f1_score: 0.4393 - val_loss: 0.7477 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 32ms/step - accuracy: 0.4927 - f1_score: 0.4923 - loss: 0.8266 - val_accuracy: 0.5429 - val_f1_score: 0.4786 - val_loss: 0.7463 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 32ms/step - accuracy: 0.5042 - f1_score: 0.5037 - loss: 0.8418 - val_accuracy: 0.5449 - val_f1_score: 0.4766 - val_loss: 0.7447 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 32ms/step - accuracy: 0.5125 - f1_score: 0.5125 - loss: 0.7873 - val_accuracy: 0.5449 - val_f1_score: 0.4985 - val_loss: 0.7452 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 32ms/step - accuracy: 0.5198 - f1_score: 0.5179 - loss: 0.7895 - val_accuracy: 0.5041 - val_f1_score: 0.4061 - val_loss: 0.7483 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 32ms/step - accuracy: 0.5276 - f1_score: 0.5260 - loss: 0.7838 - val_accuracy: 0.5163 - val_f1_score: 0.4208 - val_loss: 0.7469 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 32ms/step - accuracy: 0.5021 - f1_score: 0.4995 - loss: 0.7814 - val_accuracy: 0.5102 - val_f1_score: 0.4377 - val_loss: 0.7464 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 32ms/step - accuracy: 0.5182 - f1_score: 0.5115 - loss: 0.7762 - val_accuracy: 0.5061 - val_f1_score: 0.4026 - val_loss: 0.7468 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 32ms/step - accuracy: 0.5115 - f1_score: 0.5085 - loss: 0.7660 - val_accuracy: 0.5102 - val_f1_score: 0.4811 - val_loss: 0.7478 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 32ms/step - accuracy: 0.5130 - f1_score: 0.5085 - loss: 0.7735 - val_accuracy: 0.4837 - val_f1_score: 0.4212 - val_loss: 0.7470 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 32ms/step - accuracy: 0.5099 - f1_score: 0.5031 - loss: 0.7657 - val_accuracy: 0.5000 - val_f1_score: 0.4805 - val_loss: 0.7496 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 32ms/step - accuracy: 0.5109 - f1_score: 0.5052 - loss: 0.7637 - val_accuracy: 0.4878 - val_f1_score: 0.4568 - val_loss: 0.7494 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 32ms/step - accuracy: 0.5000 - f1_score: 0.4925 - loss: 0.7734 - val_accuracy: 0.5163 - val_f1_score: 0.4437 - val_loss: 0.7472 - learning_rate: 7.9071e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\noldB (Fold 2) Macro F1: 0.5238\n              precision    recall  f1-score   support\n\n        Left       0.54      0.73      0.62       251\n       Right       0.55      0.35      0.43       239\n\n    accuracy                           0.54       490\n   macro avg       0.54      0.54      0.52       490\nweighted avg       0.54      0.54      0.53       490\n\n\nTraining model5 (Fold 2)\nEpoch 1/200\n30/30 - 9s - 287ms/step - accuracy: 0.5104 - f1_score: 0.5104 - loss: 1.2713 - val_accuracy: 0.4939 - val_f1_score: 0.4814 - val_loss: 0.8971 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 42ms/step - accuracy: 0.5089 - f1_score: 0.5087 - loss: 0.8221 - val_accuracy: 0.5184 - val_f1_score: 0.5160 - val_loss: 0.7369 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 25ms/step - accuracy: 0.4974 - f1_score: 0.4970 - loss: 0.7664 - val_accuracy: 0.4796 - val_f1_score: 0.4618 - val_loss: 0.7422 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 24ms/step - accuracy: 0.5245 - f1_score: 0.5239 - loss: 0.7189 - val_accuracy: 0.5061 - val_f1_score: 0.4074 - val_loss: 0.7325 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 24ms/step - accuracy: 0.5339 - f1_score: 0.5251 - loss: 0.7058 - val_accuracy: 0.4796 - val_f1_score: 0.4408 - val_loss: 0.7237 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 41ms/step - accuracy: 0.5490 - f1_score: 0.5487 - loss: 0.7053 - val_accuracy: 0.5531 - val_f1_score: 0.5460 - val_loss: 0.7257 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 25ms/step - accuracy: 0.6104 - f1_score: 0.6104 - loss: 0.6848 - val_accuracy: 0.5184 - val_f1_score: 0.5065 - val_loss: 0.7160 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 24ms/step - accuracy: 0.6458 - f1_score: 0.6432 - loss: 0.6543 - val_accuracy: 0.4980 - val_f1_score: 0.4881 - val_loss: 0.7651 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 24ms/step - accuracy: 0.6849 - f1_score: 0.6842 - loss: 0.6062 - val_accuracy: 0.4776 - val_f1_score: 0.4442 - val_loss: 0.9012 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 24ms/step - accuracy: 0.7589 - f1_score: 0.7578 - loss: 0.4875 - val_accuracy: 0.5082 - val_f1_score: 0.5082 - val_loss: 0.9850 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 24ms/step - accuracy: 0.8089 - f1_score: 0.8088 - loss: 0.3944 - val_accuracy: 0.5122 - val_f1_score: 0.5081 - val_loss: 1.2804 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 24ms/step - accuracy: 0.8266 - f1_score: 0.8258 - loss: 0.3870 - val_accuracy: 0.5286 - val_f1_score: 0.5269 - val_loss: 1.2298 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 24ms/step - accuracy: 0.8995 - f1_score: 0.8992 - loss: 0.2535 - val_accuracy: 0.5163 - val_f1_score: 0.5154 - val_loss: 1.6037 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 24ms/step - accuracy: 0.9172 - f1_score: 0.9171 - loss: 0.2150 - val_accuracy: 0.5265 - val_f1_score: 0.5264 - val_loss: 1.6440 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 24ms/step - accuracy: 0.9370 - f1_score: 0.9369 - loss: 0.1627 - val_accuracy: 0.5102 - val_f1_score: 0.5006 - val_loss: 2.0665 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 25ms/step - accuracy: 0.9536 - f1_score: 0.9536 - loss: 0.1256 - val_accuracy: 0.5429 - val_f1_score: 0.5414 - val_loss: 2.3088 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 24ms/step - accuracy: 0.9547 - f1_score: 0.9547 - loss: 0.1232 - val_accuracy: 0.5204 - val_f1_score: 0.5192 - val_loss: 2.2234 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 24ms/step - accuracy: 0.9667 - f1_score: 0.9666 - loss: 0.0824 - val_accuracy: 0.5265 - val_f1_score: 0.5265 - val_loss: 2.5859 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 24ms/step - accuracy: 0.9760 - f1_score: 0.9760 - loss: 0.0675 - val_accuracy: 0.5082 - val_f1_score: 0.5076 - val_loss: 2.7505 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 25ms/step - accuracy: 0.9875 - f1_score: 0.9875 - loss: 0.0557 - val_accuracy: 0.5429 - val_f1_score: 0.5426 - val_loss: 2.6132 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 24ms/step - accuracy: 0.9880 - f1_score: 0.9880 - loss: 0.0382 - val_accuracy: 0.5163 - val_f1_score: 0.5154 - val_loss: 3.2034 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 24ms/step - accuracy: 0.9958 - f1_score: 0.9958 - loss: 0.0149 - val_accuracy: 0.5122 - val_f1_score: 0.5122 - val_loss: 3.4324 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 24ms/step - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0119 - val_accuracy: 0.5041 - val_f1_score: 0.5041 - val_loss: 3.5961 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 24ms/step - accuracy: 0.9948 - f1_score: 0.9948 - loss: 0.0138 - val_accuracy: 0.5041 - val_f1_score: 0.5028 - val_loss: 3.6423 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 24ms/step - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0156 - val_accuracy: 0.5184 - val_f1_score: 0.5172 - val_loss: 3.6001 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 24ms/step - accuracy: 0.9953 - f1_score: 0.9953 - loss: 0.0118 - val_accuracy: 0.5265 - val_f1_score: 0.5252 - val_loss: 3.7004 - learning_rate: 7.1022e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\nmodel5 (Fold 2) Macro F1: 0.5460\n              precision    recall  f1-score   support\n\n        Left       0.59      0.42      0.49       251\n       Right       0.53      0.69      0.60       239\n\n    accuracy                           0.55       490\n   macro avg       0.56      0.56      0.55       490\nweighted avg       0.56      0.55      0.54       490\n\n\nTraining model6 (Fold 2)\nEpoch 1/200\n30/30 - 7s - 243ms/step - accuracy: 0.4969 - f1_score: 0.4966 - loss: 4.1247 - val_accuracy: 0.5000 - val_f1_score: 0.3862 - val_loss: 3.9757 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 41ms/step - accuracy: 0.5089 - f1_score: 0.5087 - loss: 1.5545 - val_accuracy: 0.5265 - val_f1_score: 0.5161 - val_loss: 1.2642 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 39ms/step - accuracy: 0.4932 - f1_score: 0.4929 - loss: 1.2619 - val_accuracy: 0.4735 - val_f1_score: 0.4675 - val_loss: 1.3742 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 39ms/step - accuracy: 0.5135 - f1_score: 0.5132 - loss: 0.9014 - val_accuracy: 0.5306 - val_f1_score: 0.4889 - val_loss: 0.8046 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 40ms/step - accuracy: 0.5057 - f1_score: 0.5045 - loss: 0.8534 - val_accuracy: 0.4714 - val_f1_score: 0.4642 - val_loss: 1.0600 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 39ms/step - accuracy: 0.4911 - f1_score: 0.4873 - loss: 0.8915 - val_accuracy: 0.5204 - val_f1_score: 0.4954 - val_loss: 0.8743 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 39ms/step - accuracy: 0.4932 - f1_score: 0.4932 - loss: 0.7725 - val_accuracy: 0.4796 - val_f1_score: 0.4657 - val_loss: 0.8314 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 39ms/step - accuracy: 0.5000 - f1_score: 0.4995 - loss: 0.7487 - val_accuracy: 0.5082 - val_f1_score: 0.4418 - val_loss: 0.7215 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 41ms/step - accuracy: 0.5229 - f1_score: 0.5209 - loss: 0.7271 - val_accuracy: 0.5490 - val_f1_score: 0.5458 - val_loss: 0.7681 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 41ms/step - accuracy: 0.5104 - f1_score: 0.5102 - loss: 0.7609 - val_accuracy: 0.5673 - val_f1_score: 0.5653 - val_loss: 0.7136 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 39ms/step - accuracy: 0.5182 - f1_score: 0.5168 - loss: 0.7734 - val_accuracy: 0.4857 - val_f1_score: 0.3829 - val_loss: 0.9847 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 39ms/step - accuracy: 0.5063 - f1_score: 0.5061 - loss: 0.8342 - val_accuracy: 0.4490 - val_f1_score: 0.4427 - val_loss: 0.8998 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 39ms/step - accuracy: 0.5063 - f1_score: 0.5008 - loss: 0.7672 - val_accuracy: 0.4694 - val_f1_score: 0.4563 - val_loss: 0.7438 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 39ms/step - accuracy: 0.4927 - f1_score: 0.4862 - loss: 0.7465 - val_accuracy: 0.5061 - val_f1_score: 0.4291 - val_loss: 0.7145 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 39ms/step - accuracy: 0.5297 - f1_score: 0.5255 - loss: 0.7023 - val_accuracy: 0.5061 - val_f1_score: 0.5059 - val_loss: 0.7297 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 39ms/step - accuracy: 0.5208 - f1_score: 0.5124 - loss: 0.7099 - val_accuracy: 0.5102 - val_f1_score: 0.4923 - val_loss: 0.6924 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 39ms/step - accuracy: 0.4974 - f1_score: 0.4962 - loss: 0.7146 - val_accuracy: 0.4857 - val_f1_score: 0.4856 - val_loss: 0.7112 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 39ms/step - accuracy: 0.5240 - f1_score: 0.5196 - loss: 0.6995 - val_accuracy: 0.4796 - val_f1_score: 0.3931 - val_loss: 0.7022 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 39ms/step - accuracy: 0.4953 - f1_score: 0.4864 - loss: 0.7158 - val_accuracy: 0.4816 - val_f1_score: 0.3876 - val_loss: 0.7083 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 39ms/step - accuracy: 0.5328 - f1_score: 0.5276 - loss: 0.7103 - val_accuracy: 0.4694 - val_f1_score: 0.4177 - val_loss: 0.7489 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 39ms/step - accuracy: 0.4969 - f1_score: 0.4660 - loss: 0.7034 - val_accuracy: 0.5306 - val_f1_score: 0.5235 - val_loss: 0.7080 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 39ms/step - accuracy: 0.5005 - f1_score: 0.4886 - loss: 0.6965 - val_accuracy: 0.4735 - val_f1_score: 0.3657 - val_loss: 0.7054 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 39ms/step - accuracy: 0.5177 - f1_score: 0.4628 - loss: 0.6945 - val_accuracy: 0.4653 - val_f1_score: 0.3584 - val_loss: 0.7024 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 39ms/step - accuracy: 0.5016 - f1_score: 0.4914 - loss: 0.6994 - val_accuracy: 0.4816 - val_f1_score: 0.3780 - val_loss: 0.7027 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 39ms/step - accuracy: 0.5198 - f1_score: 0.4177 - loss: 0.6925 - val_accuracy: 0.4633 - val_f1_score: 0.3439 - val_loss: 0.7175 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 39ms/step - accuracy: 0.5063 - f1_score: 0.4981 - loss: 0.6936 - val_accuracy: 0.4633 - val_f1_score: 0.4497 - val_loss: 0.7012 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 39ms/step - accuracy: 0.5068 - f1_score: 0.5040 - loss: 0.7010 - val_accuracy: 0.4551 - val_f1_score: 0.4390 - val_loss: 0.7048 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 39ms/step - accuracy: 0.5146 - f1_score: 0.4991 - loss: 0.6925 - val_accuracy: 0.4796 - val_f1_score: 0.3665 - val_loss: 0.7084 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 39ms/step - accuracy: 0.5005 - f1_score: 0.4665 - loss: 0.6939 - val_accuracy: 0.4551 - val_f1_score: 0.4159 - val_loss: 0.7038 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 39ms/step - accuracy: 0.5089 - f1_score: 0.5060 - loss: 0.6986 - val_accuracy: 0.4388 - val_f1_score: 0.3956 - val_loss: 0.7126 - learning_rate: 5.8827e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\nmodel6 (Fold 2) Macro F1: 0.5653\n              precision    recall  f1-score   support\n\n        Left       0.57      0.62      0.60       251\n       Right       0.56      0.51      0.54       239\n\n    accuracy                           0.57       490\n   macro avg       0.57      0.57      0.57       490\nweighted avg       0.57      0.57      0.57       490\n\n\n=== Fold 3/5 ===\nComputing rank from data with rank=None\n    Using tolerance 3.1e+03 (2.2e-16 eps * 4 dim * 3.5e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\nTraining oldA (Fold 3)\nEpoch 1/200\n30/30 - 9s - 303ms/step - accuracy: 0.4911 - f1_score: 0.4901 - loss: 0.8821 - val_accuracy: 0.4959 - val_f1_score: 0.4446 - val_loss: 0.7357 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 29ms/step - accuracy: 0.5005 - f1_score: 0.5005 - loss: 0.8095 - val_accuracy: 0.4755 - val_f1_score: 0.3744 - val_loss: 0.7110 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 30ms/step - accuracy: 0.5125 - f1_score: 0.5115 - loss: 0.7344 - val_accuracy: 0.5224 - val_f1_score: 0.5152 - val_loss: 0.7177 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 28ms/step - accuracy: 0.5344 - f1_score: 0.5342 - loss: 0.7250 - val_accuracy: 0.4694 - val_f1_score: 0.3581 - val_loss: 0.7280 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 28ms/step - accuracy: 0.5089 - f1_score: 0.5038 - loss: 0.7253 - val_accuracy: 0.4776 - val_f1_score: 0.3804 - val_loss: 0.7157 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 28ms/step - accuracy: 0.5271 - f1_score: 0.5247 - loss: 0.7185 - val_accuracy: 0.4980 - val_f1_score: 0.4804 - val_loss: 0.7127 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 28ms/step - accuracy: 0.5135 - f1_score: 0.5133 - loss: 0.7158 - val_accuracy: 0.5245 - val_f1_score: 0.4968 - val_loss: 0.6997 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 28ms/step - accuracy: 0.5089 - f1_score: 0.5046 - loss: 0.7074 - val_accuracy: 0.4857 - val_f1_score: 0.4855 - val_loss: 0.7098 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 28ms/step - accuracy: 0.5224 - f1_score: 0.5166 - loss: 0.7085 - val_accuracy: 0.4959 - val_f1_score: 0.4571 - val_loss: 0.7090 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 28ms/step - accuracy: 0.5328 - f1_score: 0.5315 - loss: 0.7014 - val_accuracy: 0.4939 - val_f1_score: 0.4839 - val_loss: 0.7142 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 28ms/step - accuracy: 0.5276 - f1_score: 0.5245 - loss: 0.7025 - val_accuracy: 0.4755 - val_f1_score: 0.4532 - val_loss: 0.7237 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 28ms/step - accuracy: 0.5354 - f1_score: 0.5321 - loss: 0.7054 - val_accuracy: 0.5082 - val_f1_score: 0.4854 - val_loss: 0.7070 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 28ms/step - accuracy: 0.5047 - f1_score: 0.5047 - loss: 0.7052 - val_accuracy: 0.4694 - val_f1_score: 0.4043 - val_loss: 0.7149 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 28ms/step - accuracy: 0.5250 - f1_score: 0.5244 - loss: 0.7001 - val_accuracy: 0.5000 - val_f1_score: 0.4750 - val_loss: 0.7097 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 28ms/step - accuracy: 0.5219 - f1_score: 0.5216 - loss: 0.7015 - val_accuracy: 0.5082 - val_f1_score: 0.4638 - val_loss: 0.7053 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 28ms/step - accuracy: 0.5203 - f1_score: 0.5201 - loss: 0.6990 - val_accuracy: 0.4878 - val_f1_score: 0.4862 - val_loss: 0.7111 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 28ms/step - accuracy: 0.5339 - f1_score: 0.5334 - loss: 0.6992 - val_accuracy: 0.4939 - val_f1_score: 0.4886 - val_loss: 0.7169 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 29ms/step - accuracy: 0.5172 - f1_score: 0.5172 - loss: 0.7031 - val_accuracy: 0.4939 - val_f1_score: 0.4922 - val_loss: 0.7123 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 28ms/step - accuracy: 0.5437 - f1_score: 0.5375 - loss: 0.6965 - val_accuracy: 0.4837 - val_f1_score: 0.4819 - val_loss: 0.7127 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 28ms/step - accuracy: 0.5422 - f1_score: 0.5394 - loss: 0.6923 - val_accuracy: 0.4857 - val_f1_score: 0.4819 - val_loss: 0.7154 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 28ms/step - accuracy: 0.5354 - f1_score: 0.5262 - loss: 0.7003 - val_accuracy: 0.4898 - val_f1_score: 0.4809 - val_loss: 0.7059 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 28ms/step - accuracy: 0.5281 - f1_score: 0.5246 - loss: 0.6979 - val_accuracy: 0.4959 - val_f1_score: 0.4950 - val_loss: 0.7057 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 28ms/step - accuracy: 0.5193 - f1_score: 0.5135 - loss: 0.6974 - val_accuracy: 0.5122 - val_f1_score: 0.5081 - val_loss: 0.7088 - learning_rate: 7.9071e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\noldA (Fold 3) Macro F1: 0.5152\n              precision    recall  f1-score   support\n\n        Left       0.51      0.66      0.57       240\n       Right       0.54      0.39      0.46       250\n\n    accuracy                           0.52       490\n   macro avg       0.53      0.53      0.52       490\nweighted avg       0.53      0.52      0.51       490\n\n\nTraining oldB (Fold 3)\nEpoch 1/200\n30/30 - 13s - 439ms/step - accuracy: 0.4984 - f1_score: 0.4984 - loss: 5.1221 - val_accuracy: 0.4939 - val_f1_score: 0.4890 - val_loss: 0.9913 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 32ms/step - accuracy: 0.4932 - f1_score: 0.4928 - loss: 3.5597 - val_accuracy: 0.5082 - val_f1_score: 0.4762 - val_loss: 0.8231 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 37ms/step - accuracy: 0.4990 - f1_score: 0.4990 - loss: 2.7233 - val_accuracy: 0.4959 - val_f1_score: 0.4941 - val_loss: 1.3167 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 32ms/step - accuracy: 0.4995 - f1_score: 0.4995 - loss: 2.1120 - val_accuracy: 0.5041 - val_f1_score: 0.4821 - val_loss: 0.7590 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 32ms/step - accuracy: 0.5057 - f1_score: 0.5055 - loss: 1.5544 - val_accuracy: 0.4939 - val_f1_score: 0.3927 - val_loss: 0.7575 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 32ms/step - accuracy: 0.4807 - f1_score: 0.4796 - loss: 1.1648 - val_accuracy: 0.4939 - val_f1_score: 0.3826 - val_loss: 0.7665 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 32ms/step - accuracy: 0.4828 - f1_score: 0.4822 - loss: 1.0777 - val_accuracy: 0.4898 - val_f1_score: 0.4584 - val_loss: 0.7525 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 32ms/step - accuracy: 0.4958 - f1_score: 0.4955 - loss: 1.0038 - val_accuracy: 0.4878 - val_f1_score: 0.4275 - val_loss: 0.7493 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 32ms/step - accuracy: 0.5083 - f1_score: 0.5083 - loss: 0.8963 - val_accuracy: 0.4776 - val_f1_score: 0.4203 - val_loss: 0.7502 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 32ms/step - accuracy: 0.5005 - f1_score: 0.4995 - loss: 0.8653 - val_accuracy: 0.5041 - val_f1_score: 0.4335 - val_loss: 0.7492 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 32ms/step - accuracy: 0.5026 - f1_score: 0.4972 - loss: 0.8230 - val_accuracy: 0.5102 - val_f1_score: 0.4214 - val_loss: 0.7470 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 32ms/step - accuracy: 0.5026 - f1_score: 0.4970 - loss: 0.8314 - val_accuracy: 0.4959 - val_f1_score: 0.3551 - val_loss: 0.7505 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 32ms/step - accuracy: 0.5094 - f1_score: 0.5052 - loss: 0.8068 - val_accuracy: 0.5122 - val_f1_score: 0.3986 - val_loss: 0.7511 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 32ms/step - accuracy: 0.5104 - f1_score: 0.5011 - loss: 0.8053 - val_accuracy: 0.5082 - val_f1_score: 0.4222 - val_loss: 0.7480 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 38ms/step - accuracy: 0.5099 - f1_score: 0.5053 - loss: 0.8136 - val_accuracy: 0.5510 - val_f1_score: 0.5493 - val_loss: 0.7464 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 32ms/step - accuracy: 0.4953 - f1_score: 0.4912 - loss: 0.8040 - val_accuracy: 0.5041 - val_f1_score: 0.4719 - val_loss: 0.7475 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 32ms/step - accuracy: 0.5219 - f1_score: 0.5179 - loss: 0.7720 - val_accuracy: 0.4959 - val_f1_score: 0.4558 - val_loss: 0.7476 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 32ms/step - accuracy: 0.5026 - f1_score: 0.4965 - loss: 0.7724 - val_accuracy: 0.4980 - val_f1_score: 0.4460 - val_loss: 0.7474 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 32ms/step - accuracy: 0.4922 - f1_score: 0.4680 - loss: 0.7694 - val_accuracy: 0.4939 - val_f1_score: 0.3878 - val_loss: 0.7474 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 32ms/step - accuracy: 0.5161 - f1_score: 0.4835 - loss: 0.7627 - val_accuracy: 0.4939 - val_f1_score: 0.3661 - val_loss: 0.7482 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 32ms/step - accuracy: 0.4995 - f1_score: 0.4600 - loss: 0.7648 - val_accuracy: 0.4796 - val_f1_score: 0.3342 - val_loss: 0.7487 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 32ms/step - accuracy: 0.5188 - f1_score: 0.4757 - loss: 0.7582 - val_accuracy: 0.4776 - val_f1_score: 0.3456 - val_loss: 0.7483 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 32ms/step - accuracy: 0.4911 - f1_score: 0.4406 - loss: 0.7575 - val_accuracy: 0.4857 - val_f1_score: 0.3947 - val_loss: 0.7481 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 32ms/step - accuracy: 0.5016 - f1_score: 0.4613 - loss: 0.7644 - val_accuracy: 0.4959 - val_f1_score: 0.4475 - val_loss: 0.7476 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 32ms/step - accuracy: 0.4839 - f1_score: 0.4334 - loss: 0.7593 - val_accuracy: 0.4837 - val_f1_score: 0.4413 - val_loss: 0.7475 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 32ms/step - accuracy: 0.4932 - f1_score: 0.4365 - loss: 0.7571 - val_accuracy: 0.4980 - val_f1_score: 0.3823 - val_loss: 0.7471 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 32ms/step - accuracy: 0.5099 - f1_score: 0.4656 - loss: 0.7626 - val_accuracy: 0.4959 - val_f1_score: 0.3582 - val_loss: 0.7475 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 32ms/step - accuracy: 0.4995 - f1_score: 0.4435 - loss: 0.7655 - val_accuracy: 0.4898 - val_f1_score: 0.3424 - val_loss: 0.7472 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 32ms/step - accuracy: 0.4990 - f1_score: 0.4266 - loss: 0.7501 - val_accuracy: 0.5000 - val_f1_score: 0.3571 - val_loss: 0.7469 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 32ms/step - accuracy: 0.5135 - f1_score: 0.4297 - loss: 0.7543 - val_accuracy: 0.4796 - val_f1_score: 0.3309 - val_loss: 0.7473 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 32ms/step - accuracy: 0.5089 - f1_score: 0.4261 - loss: 0.7519 - val_accuracy: 0.4898 - val_f1_score: 0.3456 - val_loss: 0.7469 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 32ms/step - accuracy: 0.5135 - f1_score: 0.4385 - loss: 0.7470 - val_accuracy: 0.4898 - val_f1_score: 0.3488 - val_loss: 0.7469 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 32ms/step - accuracy: 0.4885 - f1_score: 0.4147 - loss: 0.7517 - val_accuracy: 0.4898 - val_f1_score: 0.3456 - val_loss: 0.7468 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 32ms/step - accuracy: 0.5078 - f1_score: 0.4482 - loss: 0.7487 - val_accuracy: 0.4939 - val_f1_score: 0.3444 - val_loss: 0.7465 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 32ms/step - accuracy: 0.5146 - f1_score: 0.4560 - loss: 0.7493 - val_accuracy: 0.4918 - val_f1_score: 0.3650 - val_loss: 0.7463 - learning_rate: 4.2723e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\noldB (Fold 3) Macro F1: 0.5493\n              precision    recall  f1-score   support\n\n        Left       0.54      0.62      0.58       240\n       Right       0.57      0.48      0.52       250\n\n    accuracy                           0.55       490\n   macro avg       0.55      0.55      0.55       490\nweighted avg       0.55      0.55      0.55       490\n\n\nTraining model5 (Fold 3)\nEpoch 1/200\n30/30 - 9s - 291ms/step - accuracy: 0.5083 - f1_score: 0.5082 - loss: 1.2431 - val_accuracy: 0.4959 - val_f1_score: 0.4332 - val_loss: 0.7719 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 43ms/step - accuracy: 0.5109 - f1_score: 0.5051 - loss: 0.7882 - val_accuracy: 0.4959 - val_f1_score: 0.4620 - val_loss: 0.7177 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 27ms/step - accuracy: 0.5318 - f1_score: 0.5318 - loss: 0.7356 - val_accuracy: 0.4898 - val_f1_score: 0.3853 - val_loss: 0.7806 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 41ms/step - accuracy: 0.5276 - f1_score: 0.5272 - loss: 0.7038 - val_accuracy: 0.4898 - val_f1_score: 0.4895 - val_loss: 0.7414 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 25ms/step - accuracy: 0.5865 - f1_score: 0.5825 - loss: 0.6911 - val_accuracy: 0.4837 - val_f1_score: 0.4644 - val_loss: 0.7268 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 24ms/step - accuracy: 0.5932 - f1_score: 0.5926 - loss: 0.6619 - val_accuracy: 0.4959 - val_f1_score: 0.4545 - val_loss: 0.7672 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 41ms/step - accuracy: 0.6938 - f1_score: 0.6930 - loss: 0.5706 - val_accuracy: 0.5286 - val_f1_score: 0.5206 - val_loss: 0.8325 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 24ms/step - accuracy: 0.7661 - f1_score: 0.7659 - loss: 0.4634 - val_accuracy: 0.5020 - val_f1_score: 0.5004 - val_loss: 1.0168 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 24ms/step - accuracy: 0.8385 - f1_score: 0.8384 - loss: 0.3635 - val_accuracy: 0.4857 - val_f1_score: 0.4811 - val_loss: 1.2949 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 24ms/step - accuracy: 0.8719 - f1_score: 0.8718 - loss: 0.2949 - val_accuracy: 0.4939 - val_f1_score: 0.4914 - val_loss: 1.4222 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 24ms/step - accuracy: 0.8964 - f1_score: 0.8962 - loss: 0.2687 - val_accuracy: 0.5020 - val_f1_score: 0.4891 - val_loss: 1.4816 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 24ms/step - accuracy: 0.9266 - f1_score: 0.9266 - loss: 0.1947 - val_accuracy: 0.5204 - val_f1_score: 0.5197 - val_loss: 1.6474 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 40ms/step - accuracy: 0.9484 - f1_score: 0.9484 - loss: 0.1336 - val_accuracy: 0.5388 - val_f1_score: 0.5318 - val_loss: 1.9250 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 24ms/step - accuracy: 0.9568 - f1_score: 0.9568 - loss: 0.1094 - val_accuracy: 0.5245 - val_f1_score: 0.5242 - val_loss: 2.0301 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 24ms/step - accuracy: 0.9620 - f1_score: 0.9620 - loss: 0.0950 - val_accuracy: 0.5143 - val_f1_score: 0.5139 - val_loss: 2.2744 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 24ms/step - accuracy: 0.9786 - f1_score: 0.9786 - loss: 0.0657 - val_accuracy: 0.5286 - val_f1_score: 0.5283 - val_loss: 2.6264 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 24ms/step - accuracy: 0.9828 - f1_score: 0.9828 - loss: 0.0456 - val_accuracy: 0.5224 - val_f1_score: 0.5213 - val_loss: 2.8100 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 40ms/step - accuracy: 0.9927 - f1_score: 0.9927 - loss: 0.0308 - val_accuracy: 0.5388 - val_f1_score: 0.5387 - val_loss: 2.9940 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 39ms/step - accuracy: 0.9911 - f1_score: 0.9911 - loss: 0.0264 - val_accuracy: 0.5429 - val_f1_score: 0.5428 - val_loss: 3.1426 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 24ms/step - accuracy: 0.9937 - f1_score: 0.9937 - loss: 0.0202 - val_accuracy: 0.5245 - val_f1_score: 0.5226 - val_loss: 3.3566 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 24ms/step - accuracy: 0.9901 - f1_score: 0.9901 - loss: 0.0352 - val_accuracy: 0.5306 - val_f1_score: 0.5305 - val_loss: 3.0957 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 24ms/step - accuracy: 0.9917 - f1_score: 0.9917 - loss: 0.0225 - val_accuracy: 0.5327 - val_f1_score: 0.5314 - val_loss: 3.6660 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 24ms/step - accuracy: 0.9927 - f1_score: 0.9927 - loss: 0.0194 - val_accuracy: 0.5367 - val_f1_score: 0.5335 - val_loss: 3.5637 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 24ms/step - accuracy: 0.9948 - f1_score: 0.9948 - loss: 0.0162 - val_accuracy: 0.5143 - val_f1_score: 0.5140 - val_loss: 3.8051 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 24ms/step - accuracy: 0.9927 - f1_score: 0.9927 - loss: 0.0246 - val_accuracy: 0.5306 - val_f1_score: 0.5301 - val_loss: 3.9139 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 24ms/step - accuracy: 0.9880 - f1_score: 0.9880 - loss: 0.0531 - val_accuracy: 0.5327 - val_f1_score: 0.5305 - val_loss: 3.6323 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 24ms/step - accuracy: 0.9859 - f1_score: 0.9859 - loss: 0.0680 - val_accuracy: 0.5184 - val_f1_score: 0.5182 - val_loss: 2.9422 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 24ms/step - accuracy: 0.9901 - f1_score: 0.9901 - loss: 0.0343 - val_accuracy: 0.5327 - val_f1_score: 0.5279 - val_loss: 3.0378 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 24ms/step - accuracy: 0.9906 - f1_score: 0.9906 - loss: 0.0284 - val_accuracy: 0.5306 - val_f1_score: 0.5301 - val_loss: 3.2934 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 24ms/step - accuracy: 0.9937 - f1_score: 0.9937 - loss: 0.0209 - val_accuracy: 0.5367 - val_f1_score: 0.5362 - val_loss: 3.6154 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 24ms/step - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0107 - val_accuracy: 0.5245 - val_f1_score: 0.5245 - val_loss: 3.5390 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 24ms/step - accuracy: 0.9974 - f1_score: 0.9974 - loss: 0.0094 - val_accuracy: 0.5265 - val_f1_score: 0.5265 - val_loss: 3.7664 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 24ms/step - accuracy: 0.9984 - f1_score: 0.9984 - loss: 0.0036 - val_accuracy: 0.5388 - val_f1_score: 0.5388 - val_loss: 3.8032 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - val_accuracy: 0.5224 - val_f1_score: 0.5222 - val_loss: 3.9618 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 24ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0030 - val_accuracy: 0.5102 - val_f1_score: 0.5100 - val_loss: 3.9961 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - val_accuracy: 0.5184 - val_f1_score: 0.5183 - val_loss: 4.0026 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 24ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0012 - val_accuracy: 0.5245 - val_f1_score: 0.5244 - val_loss: 4.0293 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9317e-04 - val_accuracy: 0.5224 - val_f1_score: 0.5224 - val_loss: 4.0551 - learning_rate: 3.3498e-04\nEpoch 39/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8422e-04 - val_accuracy: 0.5204 - val_f1_score: 0.5204 - val_loss: 4.0770 - learning_rate: 3.0602e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\nmodel5 (Fold 3) Macro F1: 0.5428\n              precision    recall  f1-score   support\n\n        Left       0.53      0.57      0.55       240\n       Right       0.56      0.52      0.54       250\n\n    accuracy                           0.54       490\n   macro avg       0.54      0.54      0.54       490\nweighted avg       0.54      0.54      0.54       490\n\n\nTraining model6 (Fold 3)\nEpoch 1/200\n30/30 - 7s - 241ms/step - accuracy: 0.5016 - f1_score: 0.5012 - loss: 3.3108 - val_accuracy: 0.4816 - val_f1_score: 0.3853 - val_loss: 2.0626 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 41ms/step - accuracy: 0.5036 - f1_score: 0.5036 - loss: 1.4467 - val_accuracy: 0.5061 - val_f1_score: 0.5061 - val_loss: 0.8761 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 39ms/step - accuracy: 0.4958 - f1_score: 0.4945 - loss: 0.9730 - val_accuracy: 0.4816 - val_f1_score: 0.4794 - val_loss: 0.8288 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 39ms/step - accuracy: 0.5417 - f1_score: 0.5402 - loss: 0.7728 - val_accuracy: 0.4714 - val_f1_score: 0.4708 - val_loss: 0.7618 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 39ms/step - accuracy: 0.5000 - f1_score: 0.4998 - loss: 0.7629 - val_accuracy: 0.4714 - val_f1_score: 0.4698 - val_loss: 0.7612 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 39ms/step - accuracy: 0.4865 - f1_score: 0.4864 - loss: 0.7373 - val_accuracy: 0.4816 - val_f1_score: 0.4682 - val_loss: 0.7132 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 39ms/step - accuracy: 0.4776 - f1_score: 0.4675 - loss: 0.7134 - val_accuracy: 0.5143 - val_f1_score: 0.4763 - val_loss: 0.7019 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 39ms/step - accuracy: 0.5047 - f1_score: 0.5045 - loss: 0.7296 - val_accuracy: 0.4898 - val_f1_score: 0.3288 - val_loss: 0.7940 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 39ms/step - accuracy: 0.5052 - f1_score: 0.4987 - loss: 0.7384 - val_accuracy: 0.4980 - val_f1_score: 0.4812 - val_loss: 0.7145 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 39ms/step - accuracy: 0.5094 - f1_score: 0.5051 - loss: 0.7247 - val_accuracy: 0.4980 - val_f1_score: 0.4533 - val_loss: 0.6948 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 39ms/step - accuracy: 0.4984 - f1_score: 0.4938 - loss: 0.6954 - val_accuracy: 0.4918 - val_f1_score: 0.4816 - val_loss: 0.7019 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 39ms/step - accuracy: 0.5130 - f1_score: 0.5130 - loss: 0.6970 - val_accuracy: 0.4939 - val_f1_score: 0.4867 - val_loss: 0.6979 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 39ms/step - accuracy: 0.5234 - f1_score: 0.5233 - loss: 0.6920 - val_accuracy: 0.4714 - val_f1_score: 0.4714 - val_loss: 0.6994 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.5152 - loss: 0.6916 - val_accuracy: 0.4776 - val_f1_score: 0.4737 - val_loss: 0.6978 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 39ms/step - accuracy: 0.5177 - f1_score: 0.4967 - loss: 0.6924 - val_accuracy: 0.4714 - val_f1_score: 0.4307 - val_loss: 0.6965 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 39ms/step - accuracy: 0.5109 - f1_score: 0.4988 - loss: 0.6971 - val_accuracy: 0.4959 - val_f1_score: 0.3915 - val_loss: 0.6972 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 39ms/step - accuracy: 0.5094 - f1_score: 0.5074 - loss: 0.6940 - val_accuracy: 0.4551 - val_f1_score: 0.4516 - val_loss: 0.6986 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 39ms/step - accuracy: 0.5125 - f1_score: 0.5123 - loss: 0.6944 - val_accuracy: 0.5102 - val_f1_score: 0.4146 - val_loss: 0.6949 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 39ms/step - accuracy: 0.5000 - f1_score: 0.4963 - loss: 0.6925 - val_accuracy: 0.4694 - val_f1_score: 0.4412 - val_loss: 0.6975 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 39ms/step - accuracy: 0.5281 - f1_score: 0.5277 - loss: 0.6920 - val_accuracy: 0.4857 - val_f1_score: 0.4845 - val_loss: 0.6972 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 39ms/step - accuracy: 0.5214 - f1_score: 0.5186 - loss: 0.6934 - val_accuracy: 0.4571 - val_f1_score: 0.4510 - val_loss: 0.6998 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 42ms/step - accuracy: 0.5255 - f1_score: 0.5252 - loss: 0.6910 - val_accuracy: 0.5184 - val_f1_score: 0.5083 - val_loss: 0.6980 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 39ms/step - accuracy: 0.5255 - f1_score: 0.5253 - loss: 0.6927 - val_accuracy: 0.4816 - val_f1_score: 0.4644 - val_loss: 0.6953 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 39ms/step - accuracy: 0.5427 - f1_score: 0.5378 - loss: 0.6910 - val_accuracy: 0.4531 - val_f1_score: 0.4501 - val_loss: 0.6976 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.4833 - loss: 0.6894 - val_accuracy: 0.4898 - val_f1_score: 0.4181 - val_loss: 0.6944 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 39ms/step - accuracy: 0.5240 - f1_score: 0.5231 - loss: 0.6905 - val_accuracy: 0.5082 - val_f1_score: 0.4999 - val_loss: 0.6991 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 39ms/step - accuracy: 0.5333 - f1_score: 0.5322 - loss: 0.6904 - val_accuracy: 0.4816 - val_f1_score: 0.4816 - val_loss: 0.6932 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 39ms/step - accuracy: 0.5292 - f1_score: 0.5175 - loss: 0.6899 - val_accuracy: 0.4571 - val_f1_score: 0.4010 - val_loss: 0.6957 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 39ms/step - accuracy: 0.5359 - f1_score: 0.5159 - loss: 0.6892 - val_accuracy: 0.4551 - val_f1_score: 0.4374 - val_loss: 0.6962 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 39ms/step - accuracy: 0.5578 - f1_score: 0.5169 - loss: 0.6863 - val_accuracy: 0.4653 - val_f1_score: 0.4548 - val_loss: 0.6951 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 39ms/step - accuracy: 0.5370 - f1_score: 0.5264 - loss: 0.6862 - val_accuracy: 0.4939 - val_f1_score: 0.4930 - val_loss: 0.6947 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 39ms/step - accuracy: 0.5380 - f1_score: 0.5288 - loss: 0.6864 - val_accuracy: 0.4776 - val_f1_score: 0.4696 - val_loss: 0.6945 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 39ms/step - accuracy: 0.5474 - f1_score: 0.5406 - loss: 0.6858 - val_accuracy: 0.5061 - val_f1_score: 0.4976 - val_loss: 0.6927 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 39ms/step - accuracy: 0.5234 - f1_score: 0.5234 - loss: 0.6848 - val_accuracy: 0.4673 - val_f1_score: 0.4178 - val_loss: 0.7012 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 39ms/step - accuracy: 0.5302 - f1_score: 0.5260 - loss: 0.6877 - val_accuracy: 0.5082 - val_f1_score: 0.5014 - val_loss: 0.6947 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 40ms/step - accuracy: 0.5396 - f1_score: 0.5273 - loss: 0.6790 - val_accuracy: 0.4939 - val_f1_score: 0.4627 - val_loss: 0.7008 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 39ms/step - accuracy: 0.5766 - f1_score: 0.5754 - loss: 0.6844 - val_accuracy: 0.4776 - val_f1_score: 0.4716 - val_loss: 0.6942 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 39ms/step - accuracy: 0.5219 - f1_score: 0.5212 - loss: 0.6854 - val_accuracy: 0.5224 - val_f1_score: 0.4999 - val_loss: 0.6928 - learning_rate: 3.3498e-04\nEpoch 39/200\n30/30 - 1s - 40ms/step - accuracy: 0.5437 - f1_score: 0.5401 - loss: 0.6859 - val_accuracy: 0.4939 - val_f1_score: 0.4927 - val_loss: 0.6912 - learning_rate: 3.0602e-04\nEpoch 40/200\n30/30 - 1s - 40ms/step - accuracy: 0.5646 - f1_score: 0.5607 - loss: 0.6819 - val_accuracy: 0.4898 - val_f1_score: 0.4888 - val_loss: 0.6929 - learning_rate: 2.7820e-04\nEpoch 41/200\n30/30 - 1s - 39ms/step - accuracy: 0.5245 - f1_score: 0.5234 - loss: 0.6853 - val_accuracy: 0.4959 - val_f1_score: 0.4904 - val_loss: 0.6949 - learning_rate: 2.5163e-04\nEpoch 42/200\n30/30 - 1s - 39ms/step - accuracy: 0.5312 - f1_score: 0.5312 - loss: 0.6854 - val_accuracy: 0.4837 - val_f1_score: 0.4617 - val_loss: 0.6952 - learning_rate: 2.2643e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\nmodel6 (Fold 3) Macro F1: 0.5083\n              precision    recall  f1-score   support\n\n        Left       0.51      0.38      0.44       240\n       Right       0.52      0.65      0.58       250\n\n    accuracy                           0.52       490\n   macro avg       0.52      0.52      0.51       490\nweighted avg       0.52      0.52      0.51       490\n\n\n=== Fold 4/5 ===\nComputing rank from data with rank=None\n    Using tolerance 3e+03 (2.2e-16 eps * 4 dim * 3.4e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\nTraining oldA (Fold 4)\nEpoch 1/200\n30/30 - 9s - 300ms/step - accuracy: 0.5245 - f1_score: 0.5245 - loss: 0.8387 - val_accuracy: 0.5143 - val_f1_score: 0.5074 - val_loss: 0.7228 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 28ms/step - accuracy: 0.5151 - f1_score: 0.5146 - loss: 0.7850 - val_accuracy: 0.4714 - val_f1_score: 0.4020 - val_loss: 0.7675 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 28ms/step - accuracy: 0.5141 - f1_score: 0.5096 - loss: 0.7519 - val_accuracy: 0.4592 - val_f1_score: 0.4321 - val_loss: 0.7115 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 28ms/step - accuracy: 0.5198 - f1_score: 0.5196 - loss: 0.7258 - val_accuracy: 0.4796 - val_f1_score: 0.4535 - val_loss: 0.7052 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 30ms/step - accuracy: 0.5240 - f1_score: 0.5198 - loss: 0.7185 - val_accuracy: 0.5184 - val_f1_score: 0.5155 - val_loss: 0.7069 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 28ms/step - accuracy: 0.5312 - f1_score: 0.5278 - loss: 0.7146 - val_accuracy: 0.4939 - val_f1_score: 0.4460 - val_loss: 0.7051 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 28ms/step - accuracy: 0.5307 - f1_score: 0.5215 - loss: 0.7049 - val_accuracy: 0.4878 - val_f1_score: 0.4780 - val_loss: 0.7047 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 28ms/step - accuracy: 0.5208 - f1_score: 0.5181 - loss: 0.7079 - val_accuracy: 0.5122 - val_f1_score: 0.5073 - val_loss: 0.7079 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 28ms/step - accuracy: 0.5125 - f1_score: 0.5001 - loss: 0.7047 - val_accuracy: 0.4633 - val_f1_score: 0.4036 - val_loss: 0.7064 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 30ms/step - accuracy: 0.5339 - f1_score: 0.5338 - loss: 0.7031 - val_accuracy: 0.5306 - val_f1_score: 0.5164 - val_loss: 0.7033 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 30ms/step - accuracy: 0.5125 - f1_score: 0.5119 - loss: 0.7056 - val_accuracy: 0.5429 - val_f1_score: 0.5276 - val_loss: 0.6988 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 28ms/step - accuracy: 0.5297 - f1_score: 0.5279 - loss: 0.7017 - val_accuracy: 0.4918 - val_f1_score: 0.4401 - val_loss: 0.7044 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 28ms/step - accuracy: 0.5391 - f1_score: 0.5285 - loss: 0.7016 - val_accuracy: 0.4735 - val_f1_score: 0.3826 - val_loss: 0.7059 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 28ms/step - accuracy: 0.5188 - f1_score: 0.5059 - loss: 0.7016 - val_accuracy: 0.4714 - val_f1_score: 0.3981 - val_loss: 0.7050 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 28ms/step - accuracy: 0.5328 - f1_score: 0.5244 - loss: 0.6954 - val_accuracy: 0.4959 - val_f1_score: 0.4665 - val_loss: 0.7078 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 28ms/step - accuracy: 0.5141 - f1_score: 0.5104 - loss: 0.7023 - val_accuracy: 0.4714 - val_f1_score: 0.4038 - val_loss: 0.7127 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 28ms/step - accuracy: 0.5396 - f1_score: 0.5310 - loss: 0.6982 - val_accuracy: 0.4673 - val_f1_score: 0.3954 - val_loss: 0.7118 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 28ms/step - accuracy: 0.5323 - f1_score: 0.5242 - loss: 0.6982 - val_accuracy: 0.5020 - val_f1_score: 0.5017 - val_loss: 0.7096 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 28ms/step - accuracy: 0.5120 - f1_score: 0.4998 - loss: 0.7023 - val_accuracy: 0.5143 - val_f1_score: 0.5140 - val_loss: 0.7030 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 30ms/step - accuracy: 0.5391 - f1_score: 0.5389 - loss: 0.6967 - val_accuracy: 0.5306 - val_f1_score: 0.5281 - val_loss: 0.6990 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 30ms/step - accuracy: 0.5380 - f1_score: 0.5378 - loss: 0.6953 - val_accuracy: 0.5551 - val_f1_score: 0.5373 - val_loss: 0.6970 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 28ms/step - accuracy: 0.5115 - f1_score: 0.4977 - loss: 0.6983 - val_accuracy: 0.5000 - val_f1_score: 0.4910 - val_loss: 0.7057 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 28ms/step - accuracy: 0.5354 - f1_score: 0.5183 - loss: 0.6970 - val_accuracy: 0.4918 - val_f1_score: 0.4600 - val_loss: 0.7165 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 28ms/step - accuracy: 0.5250 - f1_score: 0.5118 - loss: 0.7005 - val_accuracy: 0.5041 - val_f1_score: 0.5032 - val_loss: 0.7036 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 28ms/step - accuracy: 0.5130 - f1_score: 0.5068 - loss: 0.6980 - val_accuracy: 0.4735 - val_f1_score: 0.4422 - val_loss: 0.7021 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 28ms/step - accuracy: 0.5208 - f1_score: 0.5104 - loss: 0.6959 - val_accuracy: 0.5082 - val_f1_score: 0.4898 - val_loss: 0.7010 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 28ms/step - accuracy: 0.5380 - f1_score: 0.5279 - loss: 0.6961 - val_accuracy: 0.4959 - val_f1_score: 0.4953 - val_loss: 0.6985 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 28ms/step - accuracy: 0.5297 - f1_score: 0.5294 - loss: 0.6929 - val_accuracy: 0.5265 - val_f1_score: 0.5084 - val_loss: 0.6976 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 28ms/step - accuracy: 0.5458 - f1_score: 0.5454 - loss: 0.6944 - val_accuracy: 0.5224 - val_f1_score: 0.5221 - val_loss: 0.6998 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 29ms/step - accuracy: 0.5656 - f1_score: 0.5632 - loss: 0.6909 - val_accuracy: 0.5041 - val_f1_score: 0.5009 - val_loss: 0.7037 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 29ms/step - accuracy: 0.5464 - f1_score: 0.5441 - loss: 0.6940 - val_accuracy: 0.5286 - val_f1_score: 0.5262 - val_loss: 0.6994 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 29ms/step - accuracy: 0.5411 - f1_score: 0.5301 - loss: 0.6881 - val_accuracy: 0.4857 - val_f1_score: 0.4260 - val_loss: 0.7069 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 29ms/step - accuracy: 0.5385 - f1_score: 0.5172 - loss: 0.6957 - val_accuracy: 0.4918 - val_f1_score: 0.4588 - val_loss: 0.7028 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 29ms/step - accuracy: 0.5609 - f1_score: 0.5346 - loss: 0.6881 - val_accuracy: 0.4898 - val_f1_score: 0.4606 - val_loss: 0.7080 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 28ms/step - accuracy: 0.5469 - f1_score: 0.5250 - loss: 0.6954 - val_accuracy: 0.4714 - val_f1_score: 0.4038 - val_loss: 0.7094 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 28ms/step - accuracy: 0.5349 - f1_score: 0.5018 - loss: 0.6917 - val_accuracy: 0.5102 - val_f1_score: 0.4719 - val_loss: 0.7077 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 28ms/step - accuracy: 0.5578 - f1_score: 0.5420 - loss: 0.6881 - val_accuracy: 0.5122 - val_f1_score: 0.5035 - val_loss: 0.7044 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 28ms/step - accuracy: 0.5505 - f1_score: 0.5390 - loss: 0.6909 - val_accuracy: 0.5041 - val_f1_score: 0.4887 - val_loss: 0.7054 - learning_rate: 3.3498e-04\nEpoch 39/200\n30/30 - 1s - 28ms/step - accuracy: 0.5396 - f1_score: 0.5266 - loss: 0.6911 - val_accuracy: 0.4694 - val_f1_score: 0.4642 - val_loss: 0.7066 - learning_rate: 3.0602e-04\nEpoch 40/200\n30/30 - 1s - 28ms/step - accuracy: 0.5401 - f1_score: 0.5320 - loss: 0.6916 - val_accuracy: 0.5082 - val_f1_score: 0.5082 - val_loss: 0.7054 - learning_rate: 2.7820e-04\nEpoch 41/200\n30/30 - 1s - 28ms/step - accuracy: 0.5531 - f1_score: 0.5416 - loss: 0.6853 - val_accuracy: 0.5102 - val_f1_score: 0.5102 - val_loss: 0.7037 - learning_rate: 2.5163e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\noldA (Fold 4) Macro F1: 0.5373\n              precision    recall  f1-score   support\n\n        Left       0.56      0.71      0.63       260\n       Right       0.54      0.38      0.45       230\n\n    accuracy                           0.56       490\n   macro avg       0.55      0.55      0.54       490\nweighted avg       0.55      0.56      0.54       490\n\n\nTraining oldB (Fold 4)\nEpoch 1/200\n30/30 - 13s - 440ms/step - accuracy: 0.4984 - f1_score: 0.4984 - loss: 3.2126 - val_accuracy: 0.5061 - val_f1_score: 0.4939 - val_loss: 0.7855 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 37ms/step - accuracy: 0.5031 - f1_score: 0.5027 - loss: 2.2401 - val_accuracy: 0.5286 - val_f1_score: 0.5132 - val_loss: 0.7430 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 33ms/step - accuracy: 0.5135 - f1_score: 0.5112 - loss: 1.6217 - val_accuracy: 0.4878 - val_f1_score: 0.4669 - val_loss: 0.7526 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 33ms/step - accuracy: 0.4906 - f1_score: 0.4889 - loss: 1.2377 - val_accuracy: 0.5020 - val_f1_score: 0.5006 - val_loss: 0.7464 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 33ms/step - accuracy: 0.4818 - f1_score: 0.4802 - loss: 1.0535 - val_accuracy: 0.5000 - val_f1_score: 0.4980 - val_loss: 0.7465 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 33ms/step - accuracy: 0.5094 - f1_score: 0.5045 - loss: 0.9534 - val_accuracy: 0.4673 - val_f1_score: 0.3596 - val_loss: 0.7477 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 33ms/step - accuracy: 0.5120 - f1_score: 0.4968 - loss: 0.9145 - val_accuracy: 0.4653 - val_f1_score: 0.3240 - val_loss: 0.7475 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 33ms/step - accuracy: 0.5146 - f1_score: 0.5141 - loss: 0.8587 - val_accuracy: 0.4816 - val_f1_score: 0.3965 - val_loss: 0.7459 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 33ms/step - accuracy: 0.5167 - f1_score: 0.5066 - loss: 0.8439 - val_accuracy: 0.4653 - val_f1_score: 0.3303 - val_loss: 0.7487 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 33ms/step - accuracy: 0.4870 - f1_score: 0.4669 - loss: 0.7996 - val_accuracy: 0.4612 - val_f1_score: 0.3313 - val_loss: 0.7469 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 33ms/step - accuracy: 0.5167 - f1_score: 0.5023 - loss: 0.7815 - val_accuracy: 0.4673 - val_f1_score: 0.3250 - val_loss: 0.7483 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 33ms/step - accuracy: 0.4917 - f1_score: 0.4718 - loss: 0.8168 - val_accuracy: 0.4735 - val_f1_score: 0.3405 - val_loss: 0.7480 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 33ms/step - accuracy: 0.5214 - f1_score: 0.4942 - loss: 0.7863 - val_accuracy: 0.4776 - val_f1_score: 0.3456 - val_loss: 0.7477 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 33ms/step - accuracy: 0.5068 - f1_score: 0.4859 - loss: 0.7848 - val_accuracy: 0.4694 - val_f1_score: 0.3228 - val_loss: 0.7476 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 33ms/step - accuracy: 0.5146 - f1_score: 0.4861 - loss: 0.7738 - val_accuracy: 0.4694 - val_f1_score: 0.3194 - val_loss: 0.7483 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 33ms/step - accuracy: 0.5120 - f1_score: 0.4824 - loss: 0.7857 - val_accuracy: 0.4694 - val_f1_score: 0.3228 - val_loss: 0.7478 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 33ms/step - accuracy: 0.5083 - f1_score: 0.5035 - loss: 0.7694 - val_accuracy: 0.4878 - val_f1_score: 0.4641 - val_loss: 0.7466 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 32ms/step - accuracy: 0.5177 - f1_score: 0.4891 - loss: 0.7703 - val_accuracy: 0.4694 - val_f1_score: 0.3194 - val_loss: 0.7479 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 33ms/step - accuracy: 0.5042 - f1_score: 0.4723 - loss: 0.7702 - val_accuracy: 0.4735 - val_f1_score: 0.3280 - val_loss: 0.7488 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 33ms/step - accuracy: 0.5135 - f1_score: 0.4858 - loss: 0.7592 - val_accuracy: 0.4694 - val_f1_score: 0.3194 - val_loss: 0.7489 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 32ms/step - accuracy: 0.5083 - f1_score: 0.4816 - loss: 0.7597 - val_accuracy: 0.4939 - val_f1_score: 0.4638 - val_loss: 0.7470 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 33ms/step - accuracy: 0.5099 - f1_score: 0.4771 - loss: 0.7611 - val_accuracy: 0.4673 - val_f1_score: 0.3403 - val_loss: 0.7480 - learning_rate: 8.1479e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\noldB (Fold 4) Macro F1: 0.5132\n              precision    recall  f1-score   support\n\n        Left       0.55      0.67      0.60       260\n       Right       0.50      0.37      0.43       230\n\n    accuracy                           0.53       490\n   macro avg       0.52      0.52      0.51       490\nweighted avg       0.52      0.53      0.52       490\n\n\nTraining model5 (Fold 4)\nEpoch 1/200\n30/30 - 9s - 294ms/step - accuracy: 0.5146 - f1_score: 0.5145 - loss: 1.1820 - val_accuracy: 0.5143 - val_f1_score: 0.3676 - val_loss: 0.8236 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 42ms/step - accuracy: 0.5130 - f1_score: 0.5127 - loss: 0.7479 - val_accuracy: 0.5082 - val_f1_score: 0.4936 - val_loss: 0.7244 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 25ms/step - accuracy: 0.5156 - f1_score: 0.5057 - loss: 0.7334 - val_accuracy: 0.4694 - val_f1_score: 0.3845 - val_loss: 0.7611 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 24ms/step - accuracy: 0.4953 - f1_score: 0.4950 - loss: 0.7467 - val_accuracy: 0.4653 - val_f1_score: 0.3532 - val_loss: 0.7680 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 24ms/step - accuracy: 0.5031 - f1_score: 0.5011 - loss: 0.7115 - val_accuracy: 0.5102 - val_f1_score: 0.4653 - val_loss: 0.7056 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 25ms/step - accuracy: 0.5344 - f1_score: 0.5221 - loss: 0.7123 - val_accuracy: 0.4612 - val_f1_score: 0.3221 - val_loss: 0.7366 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 24ms/step - accuracy: 0.4979 - f1_score: 0.4975 - loss: 0.7045 - val_accuracy: 0.5041 - val_f1_score: 0.4934 - val_loss: 0.7099 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 24ms/step - accuracy: 0.5677 - f1_score: 0.5661 - loss: 0.6757 - val_accuracy: 0.5245 - val_f1_score: 0.4891 - val_loss: 0.7184 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 41ms/step - accuracy: 0.5740 - f1_score: 0.5607 - loss: 0.6741 - val_accuracy: 0.5122 - val_f1_score: 0.5108 - val_loss: 0.7187 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 24ms/step - accuracy: 0.6229 - f1_score: 0.6224 - loss: 0.6524 - val_accuracy: 0.5000 - val_f1_score: 0.4852 - val_loss: 0.7398 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 24ms/step - accuracy: 0.6984 - f1_score: 0.6984 - loss: 0.5617 - val_accuracy: 0.4367 - val_f1_score: 0.4367 - val_loss: 0.8863 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 25ms/step - accuracy: 0.7917 - f1_score: 0.7914 - loss: 0.4422 - val_accuracy: 0.4735 - val_f1_score: 0.4675 - val_loss: 1.2333 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 24ms/step - accuracy: 0.8104 - f1_score: 0.8100 - loss: 0.4042 - val_accuracy: 0.4571 - val_f1_score: 0.4465 - val_loss: 1.2439 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 26ms/step - accuracy: 0.8406 - f1_score: 0.8406 - loss: 0.3662 - val_accuracy: 0.4878 - val_f1_score: 0.4871 - val_loss: 1.3303 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 42ms/step - accuracy: 0.9042 - f1_score: 0.9042 - loss: 0.2505 - val_accuracy: 0.5184 - val_f1_score: 0.5182 - val_loss: 1.5751 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 24ms/step - accuracy: 0.9203 - f1_score: 0.9203 - loss: 0.2080 - val_accuracy: 0.4816 - val_f1_score: 0.4816 - val_loss: 1.6974 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 40ms/step - accuracy: 0.9266 - f1_score: 0.9266 - loss: 0.1750 - val_accuracy: 0.5490 - val_f1_score: 0.5387 - val_loss: 1.8057 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 24ms/step - accuracy: 0.9474 - f1_score: 0.9474 - loss: 0.1440 - val_accuracy: 0.5143 - val_f1_score: 0.5143 - val_loss: 2.1926 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 24ms/step - accuracy: 0.9594 - f1_score: 0.9594 - loss: 0.1077 - val_accuracy: 0.5347 - val_f1_score: 0.5329 - val_loss: 2.2123 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 24ms/step - accuracy: 0.9818 - f1_score: 0.9818 - loss: 0.0559 - val_accuracy: 0.5041 - val_f1_score: 0.5039 - val_loss: 2.6204 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 25ms/step - accuracy: 0.9901 - f1_score: 0.9901 - loss: 0.0277 - val_accuracy: 0.4980 - val_f1_score: 0.4971 - val_loss: 2.8659 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 25ms/step - accuracy: 0.9927 - f1_score: 0.9927 - loss: 0.0228 - val_accuracy: 0.4898 - val_f1_score: 0.4897 - val_loss: 3.0994 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 24ms/step - accuracy: 0.9953 - f1_score: 0.9953 - loss: 0.0155 - val_accuracy: 0.4816 - val_f1_score: 0.4816 - val_loss: 3.3296 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 24ms/step - accuracy: 0.9927 - f1_score: 0.9927 - loss: 0.0176 - val_accuracy: 0.4776 - val_f1_score: 0.4772 - val_loss: 3.5337 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 24ms/step - accuracy: 0.9922 - f1_score: 0.9922 - loss: 0.0224 - val_accuracy: 0.4959 - val_f1_score: 0.4927 - val_loss: 3.3445 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 24ms/step - accuracy: 0.9911 - f1_score: 0.9911 - loss: 0.0251 - val_accuracy: 0.5061 - val_f1_score: 0.5058 - val_loss: 3.4566 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 25ms/step - accuracy: 0.9979 - f1_score: 0.9979 - loss: 0.0129 - val_accuracy: 0.4837 - val_f1_score: 0.4834 - val_loss: 4.0231 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 24ms/step - accuracy: 0.9948 - f1_score: 0.9948 - loss: 0.0152 - val_accuracy: 0.5061 - val_f1_score: 0.5061 - val_loss: 4.0033 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 24ms/step - accuracy: 0.9911 - f1_score: 0.9911 - loss: 0.0263 - val_accuracy: 0.4980 - val_f1_score: 0.4980 - val_loss: 3.7837 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 24ms/step - accuracy: 0.9922 - f1_score: 0.9922 - loss: 0.0305 - val_accuracy: 0.4918 - val_f1_score: 0.4918 - val_loss: 4.1024 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 25ms/step - accuracy: 0.9922 - f1_score: 0.9922 - loss: 0.0346 - val_accuracy: 0.4898 - val_f1_score: 0.4898 - val_loss: 3.7478 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 24ms/step - accuracy: 0.9891 - f1_score: 0.9890 - loss: 0.0306 - val_accuracy: 0.5020 - val_f1_score: 0.5019 - val_loss: 3.6662 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 24ms/step - accuracy: 0.9958 - f1_score: 0.9958 - loss: 0.0144 - val_accuracy: 0.5163 - val_f1_score: 0.5162 - val_loss: 4.1364 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 25ms/step - accuracy: 0.9990 - f1_score: 0.9990 - loss: 0.0062 - val_accuracy: 0.5102 - val_f1_score: 0.5100 - val_loss: 4.2522 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 24ms/step - accuracy: 0.9990 - f1_score: 0.9990 - loss: 0.0031 - val_accuracy: 0.5224 - val_f1_score: 0.5224 - val_loss: 4.1949 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 24ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0067 - val_accuracy: 0.4918 - val_f1_score: 0.4918 - val_loss: 4.3884 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 24ms/step - accuracy: 0.9984 - f1_score: 0.9984 - loss: 0.0042 - val_accuracy: 0.5061 - val_f1_score: 0.5059 - val_loss: 4.3785 - learning_rate: 3.6494e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\nmodel5 (Fold 4) Macro F1: 0.5387\n              precision    recall  f1-score   support\n\n        Left       0.56      0.66      0.61       260\n       Right       0.52      0.43      0.47       230\n\n    accuracy                           0.55       490\n   macro avg       0.54      0.54      0.54       490\nweighted avg       0.55      0.55      0.54       490\n\n\nTraining model6 (Fold 4)\nEpoch 1/200\n30/30 - 7s - 242ms/step - accuracy: 0.4948 - f1_score: 0.4942 - loss: 3.4241 - val_accuracy: 0.5163 - val_f1_score: 0.3620 - val_loss: 3.3211 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 41ms/step - accuracy: 0.5125 - f1_score: 0.5100 - loss: 1.4787 - val_accuracy: 0.4592 - val_f1_score: 0.4024 - val_loss: 1.0731 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 40ms/step - accuracy: 0.4859 - f1_score: 0.4853 - loss: 1.0253 - val_accuracy: 0.4714 - val_f1_score: 0.3425 - val_loss: 1.3305 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 42ms/step - accuracy: 0.4812 - f1_score: 0.4754 - loss: 0.9105 - val_accuracy: 0.4673 - val_f1_score: 0.4662 - val_loss: 0.7190 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 40ms/step - accuracy: 0.4953 - f1_score: 0.4940 - loss: 0.8290 - val_accuracy: 0.5122 - val_f1_score: 0.4428 - val_loss: 0.7508 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 42ms/step - accuracy: 0.5146 - f1_score: 0.5100 - loss: 0.7979 - val_accuracy: 0.5000 - val_f1_score: 0.5000 - val_loss: 0.7236 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 39ms/step - accuracy: 0.5146 - f1_score: 0.5096 - loss: 0.7125 - val_accuracy: 0.4510 - val_f1_score: 0.4424 - val_loss: 0.7051 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 39ms/step - accuracy: 0.4927 - f1_score: 0.4857 - loss: 0.7042 - val_accuracy: 0.4714 - val_f1_score: 0.4594 - val_loss: 0.6996 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 39ms/step - accuracy: 0.5068 - f1_score: 0.4596 - loss: 0.7111 - val_accuracy: 0.4714 - val_f1_score: 0.3237 - val_loss: 0.7260 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 39ms/step - accuracy: 0.5047 - f1_score: 0.4620 - loss: 0.6941 - val_accuracy: 0.4735 - val_f1_score: 0.4206 - val_loss: 0.7141 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 39ms/step - accuracy: 0.4932 - f1_score: 0.4593 - loss: 0.6977 - val_accuracy: 0.4878 - val_f1_score: 0.4860 - val_loss: 0.6966 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 39ms/step - accuracy: 0.4964 - f1_score: 0.4798 - loss: 0.7112 - val_accuracy: 0.4898 - val_f1_score: 0.4595 - val_loss: 0.7212 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 39ms/step - accuracy: 0.5083 - f1_score: 0.4839 - loss: 0.7107 - val_accuracy: 0.4939 - val_f1_score: 0.4800 - val_loss: 0.7000 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 39ms/step - accuracy: 0.5203 - f1_score: 0.5200 - loss: 0.7359 - val_accuracy: 0.5020 - val_f1_score: 0.4263 - val_loss: 0.6996 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 39ms/step - accuracy: 0.4943 - f1_score: 0.4677 - loss: 0.7012 - val_accuracy: 0.4939 - val_f1_score: 0.4922 - val_loss: 0.7004 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 39ms/step - accuracy: 0.5188 - f1_score: 0.4902 - loss: 0.6993 - val_accuracy: 0.5061 - val_f1_score: 0.4939 - val_loss: 0.6951 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 39ms/step - accuracy: 0.5104 - f1_score: 0.5014 - loss: 0.7003 - val_accuracy: 0.4755 - val_f1_score: 0.4747 - val_loss: 0.6956 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 39ms/step - accuracy: 0.5036 - f1_score: 0.4859 - loss: 0.6960 - val_accuracy: 0.4653 - val_f1_score: 0.4597 - val_loss: 0.6970 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 39ms/step - accuracy: 0.5047 - f1_score: 0.4456 - loss: 0.7034 - val_accuracy: 0.4694 - val_f1_score: 0.4412 - val_loss: 0.6944 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 39ms/step - accuracy: 0.5250 - f1_score: 0.4502 - loss: 0.6930 - val_accuracy: 0.4714 - val_f1_score: 0.3593 - val_loss: 0.6952 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 39ms/step - accuracy: 0.4896 - f1_score: 0.4626 - loss: 0.6932 - val_accuracy: 0.4878 - val_f1_score: 0.4695 - val_loss: 0.6941 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 39ms/step - accuracy: 0.5276 - f1_score: 0.4716 - loss: 0.6909 - val_accuracy: 0.5061 - val_f1_score: 0.4622 - val_loss: 0.6955 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 39ms/step - accuracy: 0.5151 - f1_score: 0.4370 - loss: 0.6921 - val_accuracy: 0.4918 - val_f1_score: 0.4796 - val_loss: 0.6950 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 39ms/step - accuracy: 0.5057 - f1_score: 0.4658 - loss: 0.6924 - val_accuracy: 0.4776 - val_f1_score: 0.3756 - val_loss: 0.6971 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 39ms/step - accuracy: 0.5198 - f1_score: 0.4589 - loss: 0.6901 - val_accuracy: 0.4776 - val_f1_score: 0.3961 - val_loss: 0.6987 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 39ms/step - accuracy: 0.5063 - f1_score: 0.4419 - loss: 0.6937 - val_accuracy: 0.4898 - val_f1_score: 0.4637 - val_loss: 0.6925 - learning_rate: 7.1022e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\nmodel6 (Fold 4) Macro F1: 0.5000\n              precision    recall  f1-score   support\n\n        Left       0.53      0.47      0.50       260\n       Right       0.47      0.53      0.50       230\n\n    accuracy                           0.50       490\n   macro avg       0.50      0.50      0.50       490\nweighted avg       0.50      0.50      0.50       490\n\n\n=== Fold 5/5 ===\nComputing rank from data with rank=None\n    Using tolerance 3.1e+03 (2.2e-16 eps * 4 dim * 3.5e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\nTraining oldA (Fold 5)\nEpoch 1/200\n30/30 - 8s - 276ms/step - accuracy: 0.5052 - f1_score: 0.5040 - loss: 0.8994 - val_accuracy: 0.5020 - val_f1_score: 0.5019 - val_loss: 0.7881 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.5179 - loss: 0.7881 - val_accuracy: 0.5469 - val_f1_score: 0.4668 - val_loss: 0.7044 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 28ms/step - accuracy: 0.5203 - f1_score: 0.5203 - loss: 0.7504 - val_accuracy: 0.4959 - val_f1_score: 0.4912 - val_loss: 0.7059 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.5132 - loss: 0.7414 - val_accuracy: 0.4980 - val_f1_score: 0.4842 - val_loss: 0.7100 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 28ms/step - accuracy: 0.5146 - f1_score: 0.5144 - loss: 0.7385 - val_accuracy: 0.5102 - val_f1_score: 0.4653 - val_loss: 0.7272 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 30ms/step - accuracy: 0.5089 - f1_score: 0.5058 - loss: 0.7225 - val_accuracy: 0.5327 - val_f1_score: 0.5195 - val_loss: 0.7045 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 28ms/step - accuracy: 0.5052 - f1_score: 0.5042 - loss: 0.7216 - val_accuracy: 0.4939 - val_f1_score: 0.4690 - val_loss: 0.7014 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 28ms/step - accuracy: 0.5219 - f1_score: 0.5217 - loss: 0.7076 - val_accuracy: 0.4837 - val_f1_score: 0.4816 - val_loss: 0.7094 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 28ms/step - accuracy: 0.5161 - f1_score: 0.5139 - loss: 0.7066 - val_accuracy: 0.4857 - val_f1_score: 0.4762 - val_loss: 0.7032 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 29ms/step - accuracy: 0.5370 - f1_score: 0.5369 - loss: 0.6949 - val_accuracy: 0.5061 - val_f1_score: 0.4996 - val_loss: 0.7136 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 31ms/step - accuracy: 0.5318 - f1_score: 0.5309 - loss: 0.7071 - val_accuracy: 0.5204 - val_f1_score: 0.5195 - val_loss: 0.7014 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 28ms/step - accuracy: 0.5333 - f1_score: 0.5331 - loss: 0.6990 - val_accuracy: 0.5061 - val_f1_score: 0.5013 - val_loss: 0.7033 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 28ms/step - accuracy: 0.5349 - f1_score: 0.5345 - loss: 0.6989 - val_accuracy: 0.5143 - val_f1_score: 0.4885 - val_loss: 0.7015 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 28ms/step - accuracy: 0.5266 - f1_score: 0.5264 - loss: 0.7040 - val_accuracy: 0.4857 - val_f1_score: 0.4815 - val_loss: 0.7081 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 28ms/step - accuracy: 0.5547 - f1_score: 0.5515 - loss: 0.6949 - val_accuracy: 0.4878 - val_f1_score: 0.4545 - val_loss: 0.7090 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 28ms/step - accuracy: 0.5297 - f1_score: 0.5289 - loss: 0.7025 - val_accuracy: 0.4837 - val_f1_score: 0.4821 - val_loss: 0.7050 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 28ms/step - accuracy: 0.5302 - f1_score: 0.5225 - loss: 0.6992 - val_accuracy: 0.5429 - val_f1_score: 0.4836 - val_loss: 0.6987 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 28ms/step - accuracy: 0.5708 - f1_score: 0.5684 - loss: 0.6899 - val_accuracy: 0.5184 - val_f1_score: 0.4854 - val_loss: 0.6978 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 28ms/step - accuracy: 0.5505 - f1_score: 0.5502 - loss: 0.6972 - val_accuracy: 0.4980 - val_f1_score: 0.4963 - val_loss: 0.7059 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 28ms/step - accuracy: 0.5370 - f1_score: 0.5317 - loss: 0.6990 - val_accuracy: 0.5102 - val_f1_score: 0.5081 - val_loss: 0.7011 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 28ms/step - accuracy: 0.5286 - f1_score: 0.5259 - loss: 0.7003 - val_accuracy: 0.4939 - val_f1_score: 0.4543 - val_loss: 0.7043 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 28ms/step - accuracy: 0.5521 - f1_score: 0.5284 - loss: 0.6927 - val_accuracy: 0.4816 - val_f1_score: 0.4449 - val_loss: 0.7193 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 28ms/step - accuracy: 0.5146 - f1_score: 0.5114 - loss: 0.7012 - val_accuracy: 0.5163 - val_f1_score: 0.5065 - val_loss: 0.7055 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 28ms/step - accuracy: 0.5188 - f1_score: 0.5186 - loss: 0.7013 - val_accuracy: 0.5122 - val_f1_score: 0.5097 - val_loss: 0.7042 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 28ms/step - accuracy: 0.5266 - f1_score: 0.5261 - loss: 0.6966 - val_accuracy: 0.5245 - val_f1_score: 0.5125 - val_loss: 0.6989 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 28ms/step - accuracy: 0.5641 - f1_score: 0.5636 - loss: 0.6870 - val_accuracy: 0.5020 - val_f1_score: 0.5020 - val_loss: 0.7040 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 28ms/step - accuracy: 0.5646 - f1_score: 0.5644 - loss: 0.6893 - val_accuracy: 0.5000 - val_f1_score: 0.4867 - val_loss: 0.7031 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 28ms/step - accuracy: 0.5375 - f1_score: 0.5373 - loss: 0.6995 - val_accuracy: 0.4939 - val_f1_score: 0.4922 - val_loss: 0.7005 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 28ms/step - accuracy: 0.5474 - f1_score: 0.5474 - loss: 0.6947 - val_accuracy: 0.5102 - val_f1_score: 0.5066 - val_loss: 0.7120 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 28ms/step - accuracy: 0.5401 - f1_score: 0.5400 - loss: 0.6959 - val_accuracy: 0.4898 - val_f1_score: 0.4884 - val_loss: 0.7081 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 28ms/step - accuracy: 0.5250 - f1_score: 0.5250 - loss: 0.6904 - val_accuracy: 0.5000 - val_f1_score: 0.4997 - val_loss: 0.7056 - learning_rate: 5.5621e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\noldA (Fold 5) Macro F1: 0.5195\n              precision    recall  f1-score   support\n\n        Left       0.48      0.52      0.50       226\n       Right       0.56      0.52      0.54       264\n\n    accuracy                           0.52       490\n   macro avg       0.52      0.52      0.52       490\nweighted avg       0.52      0.52      0.52       490\n\n\nTraining oldB (Fold 5)\nEpoch 1/200\n30/30 - 14s - 483ms/step - accuracy: 0.5057 - f1_score: 0.4943 - loss: 2.6457 - val_accuracy: 0.4918 - val_f1_score: 0.4918 - val_loss: 0.8433 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 32ms/step - accuracy: 0.4964 - f1_score: 0.4941 - loss: 1.8072 - val_accuracy: 0.5306 - val_f1_score: 0.4250 - val_loss: 0.7444 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 32ms/step - accuracy: 0.5057 - f1_score: 0.5057 - loss: 1.5105 - val_accuracy: 0.4837 - val_f1_score: 0.4807 - val_loss: 0.7476 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 32ms/step - accuracy: 0.5115 - f1_score: 0.5078 - loss: 1.1834 - val_accuracy: 0.4939 - val_f1_score: 0.4827 - val_loss: 0.7465 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 32ms/step - accuracy: 0.5099 - f1_score: 0.5095 - loss: 1.0317 - val_accuracy: 0.5265 - val_f1_score: 0.3670 - val_loss: 0.7442 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 33ms/step - accuracy: 0.5156 - f1_score: 0.5104 - loss: 0.9019 - val_accuracy: 0.5327 - val_f1_score: 0.3591 - val_loss: 0.7438 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 32ms/step - accuracy: 0.5245 - f1_score: 0.5244 - loss: 0.9039 - val_accuracy: 0.5408 - val_f1_score: 0.3550 - val_loss: 0.7448 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 32ms/step - accuracy: 0.5130 - f1_score: 0.5062 - loss: 0.8347 - val_accuracy: 0.5408 - val_f1_score: 0.3550 - val_loss: 0.7451 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 33ms/step - accuracy: 0.5125 - f1_score: 0.5080 - loss: 0.7869 - val_accuracy: 0.5408 - val_f1_score: 0.3589 - val_loss: 0.7449 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 32ms/step - accuracy: 0.4927 - f1_score: 0.4734 - loss: 0.7876 - val_accuracy: 0.5408 - val_f1_score: 0.3550 - val_loss: 0.7459 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 32ms/step - accuracy: 0.5005 - f1_score: 0.4883 - loss: 0.8209 - val_accuracy: 0.5306 - val_f1_score: 0.3544 - val_loss: 0.7460 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 32ms/step - accuracy: 0.4938 - f1_score: 0.4713 - loss: 0.7888 - val_accuracy: 0.5347 - val_f1_score: 0.3846 - val_loss: 0.7455 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 33ms/step - accuracy: 0.5016 - f1_score: 0.4816 - loss: 0.8012 - val_accuracy: 0.5388 - val_f1_score: 0.3501 - val_loss: 0.7466 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 32ms/step - accuracy: 0.4901 - f1_score: 0.4279 - loss: 0.7772 - val_accuracy: 0.5388 - val_f1_score: 0.3501 - val_loss: 0.7467 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 32ms/step - accuracy: 0.4974 - f1_score: 0.4930 - loss: 0.7746 - val_accuracy: 0.4939 - val_f1_score: 0.4265 - val_loss: 0.7495 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 32ms/step - accuracy: 0.4984 - f1_score: 0.4941 - loss: 0.7711 - val_accuracy: 0.5388 - val_f1_score: 0.3501 - val_loss: 0.7469 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 32ms/step - accuracy: 0.4984 - f1_score: 0.4627 - loss: 0.7634 - val_accuracy: 0.5449 - val_f1_score: 0.3899 - val_loss: 0.7467 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 32ms/step - accuracy: 0.5026 - f1_score: 0.4509 - loss: 0.7653 - val_accuracy: 0.5367 - val_f1_score: 0.3493 - val_loss: 0.7471 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 33ms/step - accuracy: 0.4823 - f1_score: 0.4813 - loss: 0.7741 - val_accuracy: 0.4939 - val_f1_score: 0.4911 - val_loss: 0.7479 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 33ms/step - accuracy: 0.4984 - f1_score: 0.4909 - loss: 0.7555 - val_accuracy: 0.4633 - val_f1_score: 0.3671 - val_loss: 0.7488 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 32ms/step - accuracy: 0.5182 - f1_score: 0.5049 - loss: 0.7597 - val_accuracy: 0.4612 - val_f1_score: 0.3156 - val_loss: 0.7509 - learning_rate: 8.3736e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\noldB (Fold 5) Macro F1: 0.4918\n              precision    recall  f1-score   support\n\n        Left       0.46      0.54      0.50       226\n       Right       0.53      0.45      0.49       264\n\n    accuracy                           0.49       490\n   macro avg       0.50      0.50      0.49       490\nweighted avg       0.50      0.49      0.49       490\n\n\nTraining model5 (Fold 5)\nEpoch 1/200\n30/30 - 8s - 252ms/step - accuracy: 0.5198 - f1_score: 0.5197 - loss: 1.1304 - val_accuracy: 0.4878 - val_f1_score: 0.4677 - val_loss: 0.8908 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 25ms/step - accuracy: 0.5036 - f1_score: 0.5019 - loss: 0.8461 - val_accuracy: 0.4837 - val_f1_score: 0.4547 - val_loss: 0.8125 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 24ms/step - accuracy: 0.5052 - f1_score: 0.5045 - loss: 0.8111 - val_accuracy: 0.4612 - val_f1_score: 0.4378 - val_loss: 0.7970 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 39ms/step - accuracy: 0.5031 - f1_score: 0.4858 - loss: 0.7226 - val_accuracy: 0.4959 - val_f1_score: 0.4818 - val_loss: 0.7205 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 24ms/step - accuracy: 0.5109 - f1_score: 0.5104 - loss: 0.7037 - val_accuracy: 0.5408 - val_f1_score: 0.3628 - val_loss: 0.7056 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 24ms/step - accuracy: 0.5474 - f1_score: 0.5451 - loss: 0.6866 - val_accuracy: 0.4980 - val_f1_score: 0.4752 - val_loss: 0.7075 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 25ms/step - accuracy: 0.5562 - f1_score: 0.5444 - loss: 0.6850 - val_accuracy: 0.4939 - val_f1_score: 0.4189 - val_loss: 0.7191 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 24ms/step - accuracy: 0.5781 - f1_score: 0.5781 - loss: 0.6641 - val_accuracy: 0.4939 - val_f1_score: 0.4690 - val_loss: 0.7355 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 25ms/step - accuracy: 0.6818 - f1_score: 0.6818 - loss: 0.5908 - val_accuracy: 0.4653 - val_f1_score: 0.4630 - val_loss: 0.8656 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 24ms/step - accuracy: 0.7188 - f1_score: 0.7186 - loss: 0.5289 - val_accuracy: 0.5163 - val_f1_score: 0.4610 - val_loss: 0.8951 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 24ms/step - accuracy: 0.7917 - f1_score: 0.7917 - loss: 0.4409 - val_accuracy: 0.4735 - val_f1_score: 0.4590 - val_loss: 1.1221 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 39ms/step - accuracy: 0.8432 - f1_score: 0.8429 - loss: 0.3596 - val_accuracy: 0.5061 - val_f1_score: 0.4991 - val_loss: 1.1741 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 24ms/step - accuracy: 0.8609 - f1_score: 0.8609 - loss: 0.3168 - val_accuracy: 0.4796 - val_f1_score: 0.4714 - val_loss: 1.3987 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 39ms/step - accuracy: 0.9021 - f1_score: 0.9021 - loss: 0.2253 - val_accuracy: 0.5265 - val_f1_score: 0.5260 - val_loss: 1.5624 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 24ms/step - accuracy: 0.9130 - f1_score: 0.9130 - loss: 0.1932 - val_accuracy: 0.5204 - val_f1_score: 0.5197 - val_loss: 1.9163 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 24ms/step - accuracy: 0.9172 - f1_score: 0.9172 - loss: 0.2386 - val_accuracy: 0.5102 - val_f1_score: 0.5102 - val_loss: 2.0277 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 24ms/step - accuracy: 0.9177 - f1_score: 0.9176 - loss: 0.1909 - val_accuracy: 0.5184 - val_f1_score: 0.5124 - val_loss: 2.2061 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 24ms/step - accuracy: 0.9292 - f1_score: 0.9290 - loss: 0.1869 - val_accuracy: 0.5163 - val_f1_score: 0.5092 - val_loss: 2.2459 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 40ms/step - accuracy: 0.9396 - f1_score: 0.9395 - loss: 0.1497 - val_accuracy: 0.5367 - val_f1_score: 0.5351 - val_loss: 2.3610 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 41ms/step - accuracy: 0.9693 - f1_score: 0.9692 - loss: 0.0768 - val_accuracy: 0.5449 - val_f1_score: 0.5439 - val_loss: 2.5058 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 24ms/step - accuracy: 0.9776 - f1_score: 0.9776 - loss: 0.0602 - val_accuracy: 0.5327 - val_f1_score: 0.5310 - val_loss: 2.8331 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 24ms/step - accuracy: 0.9844 - f1_score: 0.9843 - loss: 0.0423 - val_accuracy: 0.5367 - val_f1_score: 0.5364 - val_loss: 2.9210 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 24ms/step - accuracy: 0.9880 - f1_score: 0.9880 - loss: 0.0399 - val_accuracy: 0.5306 - val_f1_score: 0.5297 - val_loss: 3.2064 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 24ms/step - accuracy: 0.9896 - f1_score: 0.9896 - loss: 0.0275 - val_accuracy: 0.5429 - val_f1_score: 0.5416 - val_loss: 3.3682 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 24ms/step - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0189 - val_accuracy: 0.5429 - val_f1_score: 0.5428 - val_loss: 3.4679 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 26ms/step - accuracy: 0.9953 - f1_score: 0.9953 - loss: 0.0134 - val_accuracy: 0.5327 - val_f1_score: 0.5326 - val_loss: 3.5487 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 25ms/step - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0113 - val_accuracy: 0.5347 - val_f1_score: 0.5345 - val_loss: 3.9577 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 24ms/step - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0107 - val_accuracy: 0.5429 - val_f1_score: 0.5424 - val_loss: 3.7304 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 24ms/step - accuracy: 0.9974 - f1_score: 0.9974 - loss: 0.0087 - val_accuracy: 0.5245 - val_f1_score: 0.5243 - val_loss: 4.0046 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 24ms/step - accuracy: 0.9984 - f1_score: 0.9984 - loss: 0.0102 - val_accuracy: 0.5327 - val_f1_score: 0.5290 - val_loss: 4.0912 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0040 - val_accuracy: 0.5245 - val_f1_score: 0.5242 - val_loss: 4.2868 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - val_accuracy: 0.5224 - val_f1_score: 0.5221 - val_loss: 4.3817 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 24ms/step - accuracy: 0.9979 - f1_score: 0.9979 - loss: 0.0045 - val_accuracy: 0.5204 - val_f1_score: 0.5202 - val_loss: 4.4217 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - val_accuracy: 0.5184 - val_f1_score: 0.5181 - val_loss: 4.4478 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - val_accuracy: 0.5245 - val_f1_score: 0.5236 - val_loss: 4.4745 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 24ms/step - accuracy: 0.9990 - f1_score: 0.9990 - loss: 0.0021 - val_accuracy: 0.5286 - val_f1_score: 0.5279 - val_loss: 4.5286 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - val_accuracy: 0.5204 - val_f1_score: 0.5203 - val_loss: 4.6144 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0021 - val_accuracy: 0.5245 - val_f1_score: 0.5234 - val_loss: 4.5989 - learning_rate: 3.3498e-04\nEpoch 39/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5737e-04 - val_accuracy: 0.5163 - val_f1_score: 0.5157 - val_loss: 4.6471 - learning_rate: 3.0602e-04\nEpoch 40/200\n30/30 - 1s - 24ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - val_accuracy: 0.5204 - val_f1_score: 0.5195 - val_loss: 4.6608 - learning_rate: 2.7820e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\nmodel5 (Fold 5) Macro F1: 0.5439\n              precision    recall  f1-score   support\n\n        Left       0.51      0.54      0.52       226\n       Right       0.58      0.55      0.57       264\n\n    accuracy                           0.54       490\n   macro avg       0.54      0.54      0.54       490\nweighted avg       0.55      0.54      0.55       490\n\n\nTraining model6 (Fold 5)\nEpoch 1/200\n30/30 - 9s - 286ms/step - accuracy: 0.4854 - f1_score: 0.4854 - loss: 2.9985 - val_accuracy: 0.5041 - val_f1_score: 0.4672 - val_loss: 1.8600 - learning_rate: 0.0010\nEpoch 2/200\n30/30 - 1s - 41ms/step - accuracy: 0.5104 - f1_score: 0.5095 - loss: 1.7190 - val_accuracy: 0.5163 - val_f1_score: 0.4713 - val_loss: 0.8123 - learning_rate: 9.9994e-04\nEpoch 3/200\n30/30 - 1s - 39ms/step - accuracy: 0.4885 - f1_score: 0.4874 - loss: 0.8559 - val_accuracy: 0.4551 - val_f1_score: 0.3795 - val_loss: 0.7623 - learning_rate: 9.9969e-04\nEpoch 4/200\n30/30 - 1s - 39ms/step - accuracy: 0.4979 - f1_score: 0.4865 - loss: 0.7203 - val_accuracy: 0.4612 - val_f1_score: 0.4472 - val_loss: 0.7797 - learning_rate: 9.9914e-04\nEpoch 5/200\n30/30 - 1s - 41ms/step - accuracy: 0.5276 - f1_score: 0.5273 - loss: 0.7351 - val_accuracy: 0.5082 - val_f1_score: 0.4914 - val_loss: 0.7369 - learning_rate: 9.9815e-04\nEpoch 6/200\n30/30 - 1s - 39ms/step - accuracy: 0.4917 - f1_score: 0.4875 - loss: 0.7405 - val_accuracy: 0.4837 - val_f1_score: 0.4789 - val_loss: 0.7376 - learning_rate: 9.9661e-04\nEpoch 7/200\n30/30 - 1s - 41ms/step - accuracy: 0.4943 - f1_score: 0.4855 - loss: 0.7076 - val_accuracy: 0.5061 - val_f1_score: 0.4976 - val_loss: 0.7056 - learning_rate: 9.9440e-04\nEpoch 8/200\n30/30 - 1s - 39ms/step - accuracy: 0.4948 - f1_score: 0.4884 - loss: 0.6970 - val_accuracy: 0.4612 - val_f1_score: 0.4358 - val_loss: 0.6976 - learning_rate: 9.9140e-04\nEpoch 9/200\n30/30 - 1s - 39ms/step - accuracy: 0.5141 - f1_score: 0.5129 - loss: 0.6943 - val_accuracy: 0.5367 - val_f1_score: 0.4496 - val_loss: 0.6954 - learning_rate: 9.8749e-04\nEpoch 10/200\n30/30 - 1s - 41ms/step - accuracy: 0.5057 - f1_score: 0.5044 - loss: 0.6946 - val_accuracy: 0.5020 - val_f1_score: 0.5020 - val_loss: 0.6949 - learning_rate: 9.8256e-04\nEpoch 11/200\n30/30 - 1s - 40ms/step - accuracy: 0.5042 - f1_score: 0.5038 - loss: 0.6952 - val_accuracy: 0.4857 - val_f1_score: 0.4750 - val_loss: 0.6945 - learning_rate: 9.7652e-04\nEpoch 12/200\n30/30 - 1s - 39ms/step - accuracy: 0.5271 - f1_score: 0.5261 - loss: 0.6916 - val_accuracy: 0.4980 - val_f1_score: 0.4659 - val_loss: 0.6955 - learning_rate: 9.6924e-04\nEpoch 13/200\n30/30 - 1s - 39ms/step - accuracy: 0.5141 - f1_score: 0.5101 - loss: 0.6917 - val_accuracy: 0.4816 - val_f1_score: 0.4757 - val_loss: 0.6968 - learning_rate: 9.6066e-04\nEpoch 14/200\n30/30 - 1s - 39ms/step - accuracy: 0.5307 - f1_score: 0.5243 - loss: 0.6917 - val_accuracy: 0.4735 - val_f1_score: 0.4399 - val_loss: 0.6994 - learning_rate: 9.5068e-04\nEpoch 15/200\n30/30 - 1s - 39ms/step - accuracy: 0.5177 - f1_score: 0.4685 - loss: 0.6927 - val_accuracy: 0.4714 - val_f1_score: 0.3767 - val_loss: 0.6970 - learning_rate: 9.3923e-04\nEpoch 16/200\n30/30 - 1s - 39ms/step - accuracy: 0.5036 - f1_score: 0.4716 - loss: 0.6927 - val_accuracy: 0.4796 - val_f1_score: 0.4748 - val_loss: 0.6941 - learning_rate: 9.2626e-04\nEpoch 17/200\n30/30 - 1s - 39ms/step - accuracy: 0.5146 - f1_score: 0.5012 - loss: 0.6920 - val_accuracy: 0.4776 - val_f1_score: 0.4733 - val_loss: 0.6948 - learning_rate: 9.1171e-04\nEpoch 18/200\n30/30 - 1s - 39ms/step - accuracy: 0.5161 - f1_score: 0.5024 - loss: 0.6921 - val_accuracy: 0.4837 - val_f1_score: 0.4399 - val_loss: 0.6934 - learning_rate: 8.9555e-04\nEpoch 19/200\n30/30 - 1s - 39ms/step - accuracy: 0.5229 - f1_score: 0.5220 - loss: 0.6883 - val_accuracy: 0.4633 - val_f1_score: 0.4518 - val_loss: 0.6986 - learning_rate: 8.7777e-04\nEpoch 20/200\n30/30 - 1s - 39ms/step - accuracy: 0.5328 - f1_score: 0.5122 - loss: 0.6890 - val_accuracy: 0.4694 - val_f1_score: 0.4061 - val_loss: 0.6962 - learning_rate: 8.5837e-04\nEpoch 21/200\n30/30 - 1s - 39ms/step - accuracy: 0.5448 - f1_score: 0.4855 - loss: 0.6897 - val_accuracy: 0.5041 - val_f1_score: 0.4915 - val_loss: 0.6950 - learning_rate: 8.3736e-04\nEpoch 22/200\n30/30 - 1s - 39ms/step - accuracy: 0.5453 - f1_score: 0.5098 - loss: 0.6940 - val_accuracy: 0.4673 - val_f1_score: 0.3516 - val_loss: 0.7004 - learning_rate: 8.1479e-04\nEpoch 23/200\n30/30 - 1s - 40ms/step - accuracy: 0.5063 - f1_score: 0.4301 - loss: 0.6900 - val_accuracy: 0.4592 - val_f1_score: 0.4462 - val_loss: 0.7016 - learning_rate: 7.9071e-04\nEpoch 24/200\n30/30 - 1s - 39ms/step - accuracy: 0.5312 - f1_score: 0.4957 - loss: 0.6918 - val_accuracy: 0.4694 - val_f1_score: 0.4237 - val_loss: 0.7010 - learning_rate: 7.6518e-04\nEpoch 25/200\n30/30 - 1s - 39ms/step - accuracy: 0.5479 - f1_score: 0.5297 - loss: 0.6879 - val_accuracy: 0.4388 - val_f1_score: 0.4362 - val_loss: 0.6950 - learning_rate: 7.3832e-04\nEpoch 26/200\n30/30 - 1s - 40ms/step - accuracy: 0.5208 - f1_score: 0.5176 - loss: 0.6872 - val_accuracy: 0.4980 - val_f1_score: 0.4835 - val_loss: 0.6935 - learning_rate: 7.1022e-04\nEpoch 27/200\n30/30 - 1s - 41ms/step - accuracy: 0.5474 - f1_score: 0.5438 - loss: 0.6858 - val_accuracy: 0.5163 - val_f1_score: 0.5136 - val_loss: 0.6939 - learning_rate: 6.8101e-04\nEpoch 28/200\n30/30 - 1s - 40ms/step - accuracy: 0.5578 - f1_score: 0.5578 - loss: 0.6812 - val_accuracy: 0.4673 - val_f1_score: 0.4524 - val_loss: 0.6970 - learning_rate: 6.5084e-04\nEpoch 29/200\n30/30 - 1s - 39ms/step - accuracy: 0.5453 - f1_score: 0.5390 - loss: 0.6862 - val_accuracy: 0.4755 - val_f1_score: 0.4460 - val_loss: 0.6944 - learning_rate: 6.1987e-04\nEpoch 30/200\n30/30 - 1s - 40ms/step - accuracy: 0.5224 - f1_score: 0.5145 - loss: 0.6909 - val_accuracy: 0.4755 - val_f1_score: 0.3968 - val_loss: 0.6988 - learning_rate: 5.8827e-04\nEpoch 31/200\n30/30 - 1s - 39ms/step - accuracy: 0.5177 - f1_score: 0.5165 - loss: 0.6887 - val_accuracy: 0.5041 - val_f1_score: 0.4934 - val_loss: 0.6968 - learning_rate: 5.5621e-04\nEpoch 32/200\n30/30 - 1s - 40ms/step - accuracy: 0.5385 - f1_score: 0.5282 - loss: 0.6888 - val_accuracy: 0.4980 - val_f1_score: 0.4961 - val_loss: 0.6967 - learning_rate: 5.2388e-04\nEpoch 33/200\n30/30 - 1s - 41ms/step - accuracy: 0.5396 - f1_score: 0.5366 - loss: 0.6872 - val_accuracy: 0.5122 - val_f1_score: 0.5103 - val_loss: 0.6923 - learning_rate: 4.9148e-04\nEpoch 34/200\n30/30 - 1s - 39ms/step - accuracy: 0.5344 - f1_score: 0.5344 - loss: 0.6838 - val_accuracy: 0.4898 - val_f1_score: 0.4891 - val_loss: 0.6947 - learning_rate: 4.5920e-04\nEpoch 35/200\n30/30 - 1s - 39ms/step - accuracy: 0.5281 - f1_score: 0.5281 - loss: 0.6835 - val_accuracy: 0.5122 - val_f1_score: 0.5073 - val_loss: 0.6939 - learning_rate: 4.2723e-04\nEpoch 36/200\n30/30 - 1s - 39ms/step - accuracy: 0.5667 - f1_score: 0.5631 - loss: 0.6792 - val_accuracy: 0.4837 - val_f1_score: 0.4833 - val_loss: 0.7006 - learning_rate: 3.9575e-04\nEpoch 37/200\n30/30 - 1s - 40ms/step - accuracy: 0.5682 - f1_score: 0.5520 - loss: 0.6780 - val_accuracy: 0.5061 - val_f1_score: 0.5001 - val_loss: 0.6988 - learning_rate: 3.6494e-04\nEpoch 38/200\n30/30 - 1s - 42ms/step - accuracy: 0.5458 - f1_score: 0.5351 - loss: 0.6808 - val_accuracy: 0.5184 - val_f1_score: 0.5168 - val_loss: 0.7009 - learning_rate: 3.3498e-04\nEpoch 39/200\n30/30 - 1s - 40ms/step - accuracy: 0.5562 - f1_score: 0.5391 - loss: 0.6785 - val_accuracy: 0.4694 - val_f1_score: 0.4633 - val_loss: 0.6999 - learning_rate: 3.0602e-04\nEpoch 40/200\n30/30 - 1s - 39ms/step - accuracy: 0.5479 - f1_score: 0.5366 - loss: 0.6761 - val_accuracy: 0.4796 - val_f1_score: 0.4593 - val_loss: 0.7049 - learning_rate: 2.7820e-04\nEpoch 41/200\n30/30 - 1s - 39ms/step - accuracy: 0.5526 - f1_score: 0.5224 - loss: 0.6777 - val_accuracy: 0.5000 - val_f1_score: 0.4460 - val_loss: 0.7024 - learning_rate: 2.5163e-04\nEpoch 42/200\n30/30 - 1s - 39ms/step - accuracy: 0.5448 - f1_score: 0.5239 - loss: 0.6781 - val_accuracy: 0.5143 - val_f1_score: 0.5096 - val_loss: 0.6974 - learning_rate: 2.2643e-04\nEpoch 43/200\n30/30 - 1s - 39ms/step - accuracy: 0.5667 - f1_score: 0.5248 - loss: 0.6756 - val_accuracy: 0.4898 - val_f1_score: 0.4785 - val_loss: 0.7007 - learning_rate: 2.0267e-04\nEpoch 44/200\n30/30 - 1s - 39ms/step - accuracy: 0.5719 - f1_score: 0.5697 - loss: 0.6757 - val_accuracy: 0.5041 - val_f1_score: 0.5035 - val_loss: 0.7091 - learning_rate: 1.8042e-04\nEpoch 45/200\n30/30 - 1s - 39ms/step - accuracy: 0.5656 - f1_score: 0.5451 - loss: 0.6780 - val_accuracy: 0.4959 - val_f1_score: 0.4939 - val_loss: 0.7026 - learning_rate: 1.5972e-04\nEpoch 46/200\n30/30 - 1s - 39ms/step - accuracy: 0.5656 - f1_score: 0.5569 - loss: 0.6737 - val_accuracy: 0.4918 - val_f1_score: 0.4911 - val_loss: 0.7022 - learning_rate: 1.4058e-04\nEpoch 47/200\n30/30 - 1s - 39ms/step - accuracy: 0.5724 - f1_score: 0.5670 - loss: 0.6731 - val_accuracy: 0.4898 - val_f1_score: 0.4809 - val_loss: 0.7032 - learning_rate: 1.2302e-04\nEpoch 48/200\n30/30 - 1s - 40ms/step - accuracy: 0.5635 - f1_score: 0.5535 - loss: 0.6720 - val_accuracy: 0.4837 - val_f1_score: 0.4816 - val_loss: 0.7041 - learning_rate: 1.0700e-04\nEpoch 49/200\n30/30 - 1s - 39ms/step - accuracy: 0.5625 - f1_score: 0.5521 - loss: 0.6689 - val_accuracy: 0.4776 - val_f1_score: 0.4767 - val_loss: 0.7053 - learning_rate: 9.2503e-05\nEpoch 50/200\n30/30 - 1s - 39ms/step - accuracy: 0.5625 - f1_score: 0.5579 - loss: 0.6709 - val_accuracy: 0.4735 - val_f1_score: 0.4699 - val_loss: 0.7048 - learning_rate: 7.9466e-05\nEpoch 51/200\n30/30 - 1s - 39ms/step - accuracy: 0.5729 - f1_score: 0.5668 - loss: 0.6674 - val_accuracy: 0.4939 - val_f1_score: 0.4924 - val_loss: 0.7086 - learning_rate: 6.7829e-05\nEpoch 52/200\n30/30 - 1s - 39ms/step - accuracy: 0.5703 - f1_score: 0.5683 - loss: 0.6690 - val_accuracy: 0.4755 - val_f1_score: 0.4753 - val_loss: 0.7055 - learning_rate: 5.7516e-05\nEpoch 53/200\n30/30 - 1s - 39ms/step - accuracy: 0.5922 - f1_score: 0.5833 - loss: 0.6658 - val_accuracy: 0.4735 - val_f1_score: 0.4675 - val_loss: 0.7102 - learning_rate: 4.8444e-05\nEpoch 54/200\n30/30 - 1s - 39ms/step - accuracy: 0.5651 - f1_score: 0.5597 - loss: 0.6652 - val_accuracy: 0.4959 - val_f1_score: 0.4954 - val_loss: 0.7041 - learning_rate: 4.0524e-05\nEpoch 55/200\n30/30 - 1s - 39ms/step - accuracy: 0.5682 - f1_score: 0.5680 - loss: 0.6671 - val_accuracy: 0.5041 - val_f1_score: 0.5038 - val_loss: 0.7053 - learning_rate: 3.3661e-05\nEpoch 56/200\n30/30 - 1s - 40ms/step - accuracy: 0.5839 - f1_score: 0.5783 - loss: 0.6648 - val_accuracy: 0.4878 - val_f1_score: 0.4866 - val_loss: 0.7052 - learning_rate: 2.7761e-05\nEpoch 57/200\n30/30 - 1s - 39ms/step - accuracy: 0.5750 - f1_score: 0.5730 - loss: 0.6654 - val_accuracy: 0.4959 - val_f1_score: 0.4959 - val_loss: 0.7074 - learning_rate: 2.2728e-05\nEpoch 58/200\n30/30 - 1s - 39ms/step - accuracy: 0.5625 - f1_score: 0.5624 - loss: 0.6652 - val_accuracy: 0.5000 - val_f1_score: 0.4982 - val_loss: 0.7083 - learning_rate: 1.8470e-05\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\nmodel6 (Fold 5) Macro F1: 0.5168\n              precision    recall  f1-score   support\n\n        Left       0.48      0.50      0.49       226\n       Right       0.56      0.53      0.54       264\n\n    accuracy                           0.52       490\n   macro avg       0.52      0.52      0.52       490\nweighted avg       0.52      0.52      0.52       490\n\n\n=== Cross-Validation Results ===\noldA:\n  Macro F1 Scores: ['0.5363', '0.5230', '0.5152', '0.5373', '0.5195']\n  Mean Macro F1: 0.5263 ± 0.0090\n\noldB:\n  Macro F1 Scores: ['0.5264', '0.5238', '0.5493', '0.5132', '0.4918']\n  Mean Macro F1: 0.5209 ± 0.0187\n\nmodel5:\n  Macro F1 Scores: ['0.5047', '0.5460', '0.5428', '0.5387', '0.5439']\n  Mean Macro F1: 0.5352 ± 0.0154\n\nmodel6:\n  Macro F1 Scores: ['0.5120', '0.5653', '0.5083', '0.5000', '0.5168']\n  Mean Macro F1: 0.5205 ± 0.0231\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}