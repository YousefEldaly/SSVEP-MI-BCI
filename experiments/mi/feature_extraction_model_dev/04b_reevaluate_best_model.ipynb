{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":106880,"databundleVersionId":13088836,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom scipy.signal import butter, filtfilt, iirnotch\n\n# Configuration\nBASE_PATH = '/kaggle/input/mtcaic3-phase-ii'\nOUTPUT_DIR = './preprocessed'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Filter design\ndef design_filters(fs=250.0):\n    # Bandpass 1-40 Hz\n    bp_b, bp_a = butter(4, [1/(fs/2), 40/(fs/2)], btype='band')\n    # Notch at 50 Hz\n    notch_b, notch_a = iirnotch(50/(fs/2), Q=30)\n    return bp_b, bp_a, notch_b, notch_a\n\n# Preprocessing steps for one trial\ndef preprocess_trial(df):\n    eeg_cols = ['FZ','C3','CZ','C4','PZ','PO7','OZ','PO8']\n    motion_cols = ['AccX','AccY','AccZ','Gyro1','Gyro2','Gyro3']\n    val_col = 'Validation'\n\n    # 1) Motion artifact detection\n    motion_mag = np.sqrt((df[motion_cols]**2).sum(axis=1))\n    mot_thresh = np.percentile(motion_mag, 95)\n    bad_mask = motion_mag > mot_thresh\n\n    # 2) Mask EEG\n    data = df[eeg_cols].copy().values\n    data[bad_mask, :] = np.nan\n    data[df[val_col] == 0, :] = np.nan\n\n    # 3) Interpolation\n    for ch in range(data.shape[1]):\n        col = data[:, ch]\n        nans = np.isnan(col)\n        if nans.all():\n            continue\n        idx = np.arange(len(col))\n        data[nans, ch] = np.interp(idx[nans], idx[~nans], col[~nans])\n\n    # 4) Filtering\n    bp_b, bp_a, notch_b, notch_a = design_filters()\n    for ch in range(data.shape[1]):\n        data[:, ch] = filtfilt(bp_b, bp_a, data[:, ch])\n        data[:, ch] = filtfilt(notch_b, notch_a, data[:, ch])\n\n    # 5) Baseline correction (first 0.5s)\n    bs = int(0.5 * 250)\n    baseline = data[:bs].mean(axis=0)\n    data -= baseline\n    return data\n\n# Load index DataFrame\ndef load_index(fname, label_col=True):\n    df = pd.read_csv(os.path.join(BASE_PATH, fname))\n    cols = ['id','subject_id','task','trial_session','trial'] + (['label'] if label_col else [])\n    return df[cols]\n\n# Process a split, grouping by task\ndef process_split(df, has_label=True):\n    data_dict = {'MI': {'X': [], 'y': []}, 'SSVEP': {'X': [], 'y': []}}\n    for _, row in df.iterrows():\n        # Identify folder\n        idx = row['id']\n        split = 'train' if idx <= 4800 else 'validation' if idx <= 4900 else 'test'\n        # Load EEGdata\n        path = os.path.join(BASE_PATH, row['task'], split, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n        df_eeg = pd.read_csv(path)\n        # Extract correct segment\n        n_samp = 2250 if row['task']=='MI' else 1750\n        start = (row['trial']-1)*n_samp\n        seg = df_eeg.iloc[int(start):int(start+n_samp)].reset_index(drop=True)\n        proc = preprocess_trial(seg)\n        data_dict[row['task']]['X'].append(proc.T)\n        if has_label:\n            data_dict[row['task']]['y'].append(row['label'])\n    # Stack\n    for t in data_dict:\n        X = np.stack(data_dict[t]['X'])\n        y = np.array(data_dict[t]['y']) if has_label else None\n        data_dict[t]['X'] = X\n        data_dict[t]['y'] = y\n    return data_dict\n\n# Execute processing and save\nfor fname, label_col in [('train.csv', True), ('validation.csv', True), ('test.csv', False)]:\n    df_idx = load_index(fname, label_col)\n    results = process_split(df_idx, label_col)\n    for task, d in results.items():\n        out_file = f\"{os.path.splitext(fname)[0]}_{task}.npz\"\n        path = os.path.join(OUTPUT_DIR, out_file)\n        if label_col:\n            np.savez_compressed(path, X=d['X'], y=d['y'])\n        else:\n            np.savez_compressed(path, X=d['X'])\n        print(f\"Saved {out_file}: X={d['X'].shape}\" + (f\", y={d['y'].shape}\" if d['y'] is not None else ''))\nprint('Preprocessing complete.')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T02:40:41.770805Z","iopub.execute_input":"2025-07-23T02:40:41.771588Z","iopub.status.idle":"2025-07-23T02:47:52.635481Z","shell.execute_reply.started":"2025-07-23T02:40:41.771551Z","shell.execute_reply":"2025-07-23T02:47:52.634781Z"}},"outputs":[{"name":"stdout","text":"Saved train_MI.npz: X=(2400, 8, 2250), y=(2400,)\nSaved train_SSVEP.npz: X=(2400, 8, 1750), y=(2400,)\nSaved validation_MI.npz: X=(50, 8, 2250), y=(50,)\nSaved validation_SSVEP.npz: X=(50, 8, 1750), y=(50,)\nSaved test_MI.npz: X=(100, 8, 2250)\nSaved test_SSVEP.npz: X=(100, 8, 1750)\nPreprocessing complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.metrics import f1_score, classification_report\nfrom mne.decoding import CSP\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import (\n    EarlyStopping,\n    ModelCheckpoint,\n    CSVLogger,\n    LearningRateScheduler,\n)\n\n# --- 0) (Optional) Reproducibility ---\n# os.environ['PYTHONHASHSEED'] = '0'\n# np.random.seed(0)\n# tf.random.set_seed(0)\n# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n# os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n\n# --- 1) Config ---\ndata_dir   = './preprocessed'\noutput_dir = './models'\nos.makedirs(output_dir, exist_ok=True)\n\n# --- 2) Load & binarize labels ---\ntrain_npz = np.load(os.path.join(data_dir, 'train_MI.npz'))\nval_npz   = np.load(os.path.join(data_dir, 'validation_MI.npz'))\nX_train, y_train = train_npz['X'], train_npz['y']\nX_val,   y_val   = val_npz['X'],   val_npz['y']\n\ny_train_bin = (y_train == 'Right').astype(int)\ny_val_bin   = (y_val   == 'Right').astype(int)\n\n# --- 3) CSP (4 components) ---\ncsp = CSP(n_components=4, log=False, norm_trace=False)\ncsp.fit(X_train, y_train_bin)\nW = csp.filters_[:4]\ndef apply_csp(X): return np.stack([W.dot(ep) for ep in X], axis=0)\n\nXtr = apply_csp(X_train).transpose(0,2,1).astype('float32')  # (n, T, 4)\nXvl = apply_csp(X_val)  .transpose(0,2,1).astype('float32')\n\n# --- 4) For Model3 only: add channel axis → (n, T, F=4, 1) ---\nXtr_spec = Xtr[..., np.newaxis]\nXvl_spec = Xvl[..., np.newaxis]\n\n# --- 5) One‑hot labels ---\nytr_oh = keras.utils.to_categorical(y_train_bin, 2)\nyvl_oh = keras.utils.to_categorical(y_val_bin,   2)\n\n# --- 6) Data‑augmentation gens ---\ndef aug_gen(X, y, seed=0, batch_size=32):\n    n   = X.shape[0]\n    rng = np.random.RandomState(seed)\n    while True:\n        idx = rng.randint(0, n, batch_size)\n        bx, by = X[idx].copy(), y[idx]\n        bx += rng.normal(0, 0.005, bx.shape)\n        yield bx, by\n\ntrain_gen_1d = aug_gen(Xtr,   ytr_oh, seed=0, batch_size=64)\ntrain_gen_2d = aug_gen(Xtr_spec, ytr_oh, seed=1, batch_size=64)\n\nsteps_1d = len(Xtr)      // 64\nsteps_2d = len(Xtr_spec) // 64\n\n# --- 7) LR schedule ---\ndef cosine_lr(epoch, lr_max=5e-5, epochs=200):\n    return lr_max * (1 + np.cos(np.pi * epoch / epochs)) / 2\n\n# --- 8) F1Score metric ---\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        # create the state variables up front\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        preds  = tf.argmax(y_pred, axis=1)\n        labels = tf.argmax(y_true, axis=1)\n        preds  = tf.cast(preds, tf.int32)\n        labels = tf.cast(labels, tf.int32)\n\n        tp = tf.reduce_sum(\n            tf.cast(tf.logical_and(preds == 1, labels == 1), tf.float32)\n        )\n        fp = tf.reduce_sum(\n            tf.cast(tf.logical_and(preds == 1, labels == 0), tf.float32)\n        )\n        fn = tf.reduce_sum(\n            tf.cast(tf.logical_and(preds == 0, labels == 1), tf.float32)\n        )\n\n        self.tp.assign_add(tp)\n        self.fp.assign_add(fp)\n        self.fn.assign_add(fn)\n\n    def result(self):\n        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n        recall    = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.assign(0.0)\n        self.fp.assign(0.0)\n        self.fn.assign(0.0)\n\n# --- 9) Callbacks factory ---\ndef get_callbacks(name):\n    return [\n        EarlyStopping(\"val_f1_score\", mode=\"max\", patience=20, restore_best_weights=True),\n        ModelCheckpoint(\n            os.path.join(output_dir, f\"best_{name}.h5\"),\n            \"val_f1_score\", mode=\"max\", save_best_only=True\n        ),\n        CSVLogger(os.path.join(output_dir, f\"log_{name}.csv\")),\n        LearningRateScheduler(cosine_lr)\n    ]\n\n# --- 10) Model builders (all output 2 classes) ---\n\ndef build_modelA(input_shape):\n    m = keras.Sequential([\n        layers.Input(input_shape),\n        layers.Conv1D(32, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(64, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(128,5,activation=\"relu\",padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling1D(),\n        layers.Dense(64, activation=\"relu\", \n                     kernel_regularizer=regularizers.l2(1e-4)),\n        layers.Dropout(0.7),\n        layers.Dense(2, activation=\"softmax\"),\n    ])\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_modelB(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for f in [16,32,64,128,256]:\n        x = layers.Conv1D(f,3,activation=\"relu\",padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.MaxPool1D(2)(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\",\n                         kernel_regularizer=regularizers.l2(1e-4))(x)\n        x = layers.Dropout(0.5)(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model1(input_shape):\n    inp = layers.Input(input_shape+(1,))\n    x = layers.Concatenate()([inp, inp, inp])\n    x = layers.Resizing(32,32)(x)\n    base = keras.applications.ResNet50(\n        include_top=False, weights=\"imagenet\",\n        input_shape=(32,32,3), pooling=\"avg\"\n    )\n    base.trainable = False\n    x = base(x)\n    x = layers.Reshape((1, x.shape[-1]))(x)\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.MultiHeadAttention(num_heads=4,key_dim=32)(x,x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model2(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(32,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model3(input_shape):\n    inp = layers.Input(input_shape)  # (T, F, 1)\n    x = inp\n    for _ in range(5):\n        x = layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model4(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.LSTM(128)(x)\n    for _ in range(4):\n        x = layers.Dense(64, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model5(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for _ in range(3):\n        x = layers.Dense(64, activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model6(input_shape):\n    C3, C4 = 0,2\n    eeg_in = layers.Input(input_shape)\n    c3 = layers.Lambda(lambda x: x[:,:,C3:C3+1])(eeg_in)\n    c4 = layers.Lambda(lambda x: x[:,:,C4:C4+1])(eeg_in)\n    def branch():\n        return models.Sequential([\n            layers.Conv1D(16,250,activation=\"relu\",padding=\"same\"),\n            layers.MaxPool1D(3),\n            layers.Conv1D(32,50,activation=\"relu\",padding=\"same\"),\n            layers.GlobalAveragePooling1D()\n        ])\n    b3, b4 = branch()(c3), branch()(c4)\n    x = layers.Concatenate()([b3,b4])\n    for _ in range(4):\n        x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2,activation=\"softmax\")(x)\n    m = models.Model(eeg_in,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\n# --- 11) Train & eval loop ---\nbuilders = {\n    'oldA': build_modelA,\n    'oldB': build_modelB,\n    'model1': build_model1,\n    'model2': build_model2,\n    'model3': build_model3,\n    'model4': build_model4,\n    'model5': build_model5,\n    'model6': build_model6,\n}\n\nresults = {}\nshape_1d = Xtr.shape[1:]      # (T, 4)\nshape_2d = Xtr_spec.shape[1:] # (T, 4, 1)\n\nfor name, build_fn in builders.items():\n    print(f\"\\n>>> Training {name}\")\n    if name == 'model3':\n        model = build_fn(shape_2d)\n        gen   = train_gen_2d\n        steps = steps_2d\n        val_x = Xvl_spec\n    else:\n        model = build_fn(shape_1d)\n        gen   = train_gen_1d\n        steps = steps_1d\n        val_x = Xvl\n\n    history = model.fit(\n        gen,\n        steps_per_epoch=steps,\n        validation_data=(val_x, yvl_oh),\n        epochs=200,\n        callbacks=get_callbacks(name),\n        verbose=2\n    )\n\n    # model now has best weights\n    preds = np.argmax(model.predict(val_x), axis=1)\n    f1    = f1_score(y_val_bin, preds)\n    print(f\"{name} →  val F1 = {f1:.4f}\")\n    print(classification_report(y_val_bin, preds, target_names=['Left','Right']))\n    results[name] = (f1, model)\n\n# --- 12) Pick & save final ---\nbest_name, (best_f1, best_model) = max(results.items(), key=lambda kv: kv[1][0])\nprint(f\"\\n=== Final best: {best_name} (F1={best_f1:.4f}) ===\")\nbest_model.save(os.path.join(output_dir, 'best_final.h5'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T02:49:10.609784Z","iopub.execute_input":"2025-07-23T02:49:10.610420Z","iopub.status.idle":"2025-07-23T02:59:47.837432Z","shell.execute_reply.started":"2025-07-23T02:49:10.610396Z","shell.execute_reply":"2025-07-23T02:59:47.836825Z"}},"outputs":[{"name":"stdout","text":"Computing rank from data with rank=None\n    Using tolerance 7.4e+03 (2.2e-16 eps * 8 dim * 4.2e+18  max singular value)\n    Estimated rank (data): 8\n    data: rank 8 computed from 8 data channels with 0 projectors\nReducing data rank from 8 -> 8\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1753238957.756579      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1753238963.014795     102 service.cc:148] XLA service 0x7dc4d0036c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1753238963.015438     102 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1753238963.457621     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1753238966.939560     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"37/37 - 10s - 280ms/step - accuracy: 0.5072 - f1_score: 0.4937 - loss: 0.9075 - val_accuracy: 0.5200 - val_f1_score: 0.2941 - val_loss: 0.7158 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 28ms/step - accuracy: 0.5013 - f1_score: 0.5065 - loss: 0.7847 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 0.7271 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 27ms/step - accuracy: 0.5093 - f1_score: 0.4939 - loss: 0.7442 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7120 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 27ms/step - accuracy: 0.5152 - f1_score: 0.5291 - loss: 0.7204 - val_accuracy: 0.5400 - val_f1_score: 0.0000e+00 - val_loss: 0.7228 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 27ms/step - accuracy: 0.5215 - f1_score: 0.5509 - loss: 0.7177 - val_accuracy: 0.5000 - val_f1_score: 0.0741 - val_loss: 0.7193 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 27ms/step - accuracy: 0.5296 - f1_score: 0.4828 - loss: 0.7054 - val_accuracy: 0.5400 - val_f1_score: 0.0800 - val_loss: 0.7101 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 28ms/step - accuracy: 0.5270 - f1_score: 0.4800 - loss: 0.7074 - val_accuracy: 0.6000 - val_f1_score: 0.5833 - val_loss: 0.7000 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 27ms/step - accuracy: 0.5169 - f1_score: 0.5086 - loss: 0.7111 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 0.7057 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 27ms/step - accuracy: 0.5469 - f1_score: 0.5357 - loss: 0.6950 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.7081 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 27ms/step - accuracy: 0.5068 - f1_score: 0.5427 - loss: 0.7118 - val_accuracy: 0.4600 - val_f1_score: 0.4000 - val_loss: 0.7430 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 27ms/step - accuracy: 0.5329 - f1_score: 0.5040 - loss: 0.7009 - val_accuracy: 0.6000 - val_f1_score: 0.2857 - val_loss: 0.6991 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 27ms/step - accuracy: 0.5131 - f1_score: 0.5037 - loss: 0.7001 - val_accuracy: 0.5200 - val_f1_score: 0.4000 - val_loss: 0.7029 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 29ms/step - accuracy: 0.5372 - f1_score: 0.5889 - loss: 0.6978 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 0.7084 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 28ms/step - accuracy: 0.5274 - f1_score: 0.5760 - loss: 0.7012 - val_accuracy: 0.4800 - val_f1_score: 0.6176 - val_loss: 0.7138 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 27ms/step - accuracy: 0.5118 - f1_score: 0.5394 - loss: 0.7014 - val_accuracy: 0.5600 - val_f1_score: 0.5217 - val_loss: 0.6868 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 27ms/step - accuracy: 0.5194 - f1_score: 0.5086 - loss: 0.7000 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.6929 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 27ms/step - accuracy: 0.5372 - f1_score: 0.5041 - loss: 0.6984 - val_accuracy: 0.5200 - val_f1_score: 0.6129 - val_loss: 0.6996 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 27ms/step - accuracy: 0.5460 - f1_score: 0.4410 - loss: 0.6977 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.6962 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 27ms/step - accuracy: 0.5443 - f1_score: 0.4918 - loss: 0.6943 - val_accuracy: 0.5600 - val_f1_score: 0.6071 - val_loss: 0.6899 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 27ms/step - accuracy: 0.5329 - f1_score: 0.5353 - loss: 0.6983 - val_accuracy: 0.5600 - val_f1_score: 0.5417 - val_loss: 0.6961 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 27ms/step - accuracy: 0.5452 - f1_score: 0.5368 - loss: 0.6953 - val_accuracy: 0.5200 - val_f1_score: 0.4545 - val_loss: 0.7547 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 27ms/step - accuracy: 0.5519 - f1_score: 0.4714 - loss: 0.6941 - val_accuracy: 0.4800 - val_f1_score: 0.5517 - val_loss: 0.7238 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 27ms/step - accuracy: 0.5515 - f1_score: 0.5633 - loss: 0.6950 - val_accuracy: 0.4400 - val_f1_score: 0.5882 - val_loss: 0.7342 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 27ms/step - accuracy: 0.5456 - f1_score: 0.5668 - loss: 0.6957 - val_accuracy: 0.5200 - val_f1_score: 0.6129 - val_loss: 0.7010 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 27ms/step - accuracy: 0.5401 - f1_score: 0.5803 - loss: 0.6954 - val_accuracy: 0.5200 - val_f1_score: 0.6000 - val_loss: 0.7002 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 27ms/step - accuracy: 0.5439 - f1_score: 0.5642 - loss: 0.6923 - val_accuracy: 0.4400 - val_f1_score: 0.5000 - val_loss: 0.7048 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 27ms/step - accuracy: 0.5334 - f1_score: 0.5436 - loss: 0.6967 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.7153 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 27ms/step - accuracy: 0.5456 - f1_score: 0.5637 - loss: 0.6930 - val_accuracy: 0.5200 - val_f1_score: 0.5556 - val_loss: 0.7191 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 27ms/step - accuracy: 0.5494 - f1_score: 0.5774 - loss: 0.6961 - val_accuracy: 0.4800 - val_f1_score: 0.5517 - val_loss: 0.7035 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 27ms/step - accuracy: 0.5439 - f1_score: 0.5840 - loss: 0.6942 - val_accuracy: 0.5200 - val_f1_score: 0.4000 - val_loss: 0.7201 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 27ms/step - accuracy: 0.5541 - f1_score: 0.5644 - loss: 0.6901 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.7039 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 1s - 28ms/step - accuracy: 0.5465 - f1_score: 0.5788 - loss: 0.6948 - val_accuracy: 0.6000 - val_f1_score: 0.6667 - val_loss: 0.6996 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 1s - 27ms/step - accuracy: 0.5566 - f1_score: 0.6017 - loss: 0.6908 - val_accuracy: 0.4600 - val_f1_score: 0.5846 - val_loss: 0.7152 - learning_rate: 4.9148e-04\nEpoch 34/200\n37/37 - 1s - 27ms/step - accuracy: 0.5595 - f1_score: 0.5741 - loss: 0.6859 - val_accuracy: 0.4600 - val_f1_score: 0.4706 - val_loss: 0.7047 - learning_rate: 4.5920e-04\nEpoch 35/200\n37/37 - 1s - 27ms/step - accuracy: 0.5676 - f1_score: 0.5616 - loss: 0.6834 - val_accuracy: 0.6200 - val_f1_score: 0.5128 - val_loss: 0.7040 - learning_rate: 4.2723e-04\nEpoch 36/200\n37/37 - 1s - 27ms/step - accuracy: 0.5456 - f1_score: 0.5846 - loss: 0.6926 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 0.7046 - learning_rate: 3.9575e-04\nEpoch 37/200\n37/37 - 1s - 27ms/step - accuracy: 0.5414 - f1_score: 0.5355 - loss: 0.6935 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.6972 - learning_rate: 3.6494e-04\nEpoch 38/200\n37/37 - 1s - 27ms/step - accuracy: 0.5583 - f1_score: 0.5741 - loss: 0.6830 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 0.6994 - learning_rate: 3.3498e-04\nEpoch 39/200\n37/37 - 1s - 27ms/step - accuracy: 0.5477 - f1_score: 0.5634 - loss: 0.6889 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 0.6924 - learning_rate: 3.0602e-04\nEpoch 40/200\n37/37 - 1s - 27ms/step - accuracy: 0.5621 - f1_score: 0.5604 - loss: 0.6880 - val_accuracy: 0.5600 - val_f1_score: 0.5000 - val_loss: 0.7175 - learning_rate: 2.7820e-04\nEpoch 41/200\n37/37 - 1s - 27ms/step - accuracy: 0.5688 - f1_score: 0.5646 - loss: 0.6853 - val_accuracy: 0.6000 - val_f1_score: 0.5455 - val_loss: 0.6925 - learning_rate: 2.5163e-04\nEpoch 42/200\n37/37 - 1s - 27ms/step - accuracy: 0.5655 - f1_score: 0.5616 - loss: 0.6844 - val_accuracy: 0.6200 - val_f1_score: 0.5957 - val_loss: 0.6908 - learning_rate: 2.2643e-04\nEpoch 43/200\n37/37 - 1s - 27ms/step - accuracy: 0.5705 - f1_score: 0.5693 - loss: 0.6802 - val_accuracy: 0.5000 - val_f1_score: 0.5283 - val_loss: 0.7046 - learning_rate: 2.0267e-04\nEpoch 44/200\n37/37 - 1s - 27ms/step - accuracy: 0.5625 - f1_score: 0.5614 - loss: 0.6888 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 0.6975 - learning_rate: 1.8042e-04\nEpoch 45/200\n37/37 - 1s - 27ms/step - accuracy: 0.5709 - f1_score: 0.5791 - loss: 0.6808 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 0.6976 - learning_rate: 1.5972e-04\nEpoch 46/200\n37/37 - 1s - 27ms/step - accuracy: 0.5621 - f1_score: 0.5563 - loss: 0.6876 - val_accuracy: 0.5200 - val_f1_score: 0.4545 - val_loss: 0.6968 - learning_rate: 1.4058e-04\nEpoch 47/200\n37/37 - 1s - 27ms/step - accuracy: 0.5693 - f1_score: 0.5634 - loss: 0.6802 - val_accuracy: 0.5000 - val_f1_score: 0.4681 - val_loss: 0.7050 - learning_rate: 1.2302e-04\nEpoch 48/200\n37/37 - 1s - 27ms/step - accuracy: 0.5621 - f1_score: 0.5612 - loss: 0.6860 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7025 - learning_rate: 1.0700e-04\nEpoch 49/200\n37/37 - 1s - 27ms/step - accuracy: 0.5579 - f1_score: 0.5386 - loss: 0.6866 - val_accuracy: 0.5000 - val_f1_score: 0.4681 - val_loss: 0.7084 - learning_rate: 9.2503e-05\nEpoch 50/200\n37/37 - 1s - 27ms/step - accuracy: 0.5591 - f1_score: 0.5519 - loss: 0.6867 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 0.7005 - learning_rate: 7.9466e-05\nEpoch 51/200\n37/37 - 1s - 27ms/step - accuracy: 0.5638 - f1_score: 0.5823 - loss: 0.6844 - val_accuracy: 0.6600 - val_f1_score: 0.6531 - val_loss: 0.6999 - learning_rate: 6.7829e-05\nEpoch 52/200\n37/37 - 1s - 27ms/step - accuracy: 0.5612 - f1_score: 0.5629 - loss: 0.6885 - val_accuracy: 0.6600 - val_f1_score: 0.6383 - val_loss: 0.7010 - learning_rate: 5.7516e-05\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\noldA →  val F1 = 0.6667\n              precision    recall  f1-score   support\n\n        Left       0.83      0.36      0.50        28\n       Right       0.53      0.91      0.67        22\n\n    accuracy                           0.60        50\n   macro avg       0.68      0.63      0.58        50\nweighted avg       0.70      0.60      0.57        50\n\n\n>>> Training oldB\nEpoch 1/200\n37/37 - 16s - 425ms/step - accuracy: 0.5097 - f1_score: 0.5156 - loss: 3.6181 - val_accuracy: 0.4400 - val_f1_score: 0.4400 - val_loss: 0.8070 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 36ms/step - accuracy: 0.5042 - f1_score: 0.4996 - loss: 2.2174 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 0.7602 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 36ms/step - accuracy: 0.4852 - f1_score: 0.4863 - loss: 1.5573 - val_accuracy: 0.5600 - val_f1_score: 0.6333 - val_loss: 0.7338 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 31ms/step - accuracy: 0.5034 - f1_score: 0.5071 - loss: 1.2409 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7608 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 31ms/step - accuracy: 0.4979 - f1_score: 0.4921 - loss: 1.0483 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 0.7493 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 31ms/step - accuracy: 0.5046 - f1_score: 0.5049 - loss: 0.9232 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.7388 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 32ms/step - accuracy: 0.5165 - f1_score: 0.5207 - loss: 0.8689 - val_accuracy: 0.5600 - val_f1_score: 0.2143 - val_loss: 0.7400 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 32ms/step - accuracy: 0.5068 - f1_score: 0.4913 - loss: 0.8407 - val_accuracy: 0.5400 - val_f1_score: 0.4103 - val_loss: 0.7417 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 31ms/step - accuracy: 0.5034 - f1_score: 0.4900 - loss: 0.8179 - val_accuracy: 0.5600 - val_f1_score: 0.5000 - val_loss: 0.7437 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 32ms/step - accuracy: 0.4916 - f1_score: 0.4557 - loss: 0.8002 - val_accuracy: 0.4600 - val_f1_score: 0.2703 - val_loss: 0.7475 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 31ms/step - accuracy: 0.4979 - f1_score: 0.4441 - loss: 0.8119 - val_accuracy: 0.6200 - val_f1_score: 0.4865 - val_loss: 0.7494 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 31ms/step - accuracy: 0.5051 - f1_score: 0.4692 - loss: 0.7721 - val_accuracy: 0.5000 - val_f1_score: 0.0741 - val_loss: 0.7453 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 31ms/step - accuracy: 0.5021 - f1_score: 0.4483 - loss: 0.7633 - val_accuracy: 0.5200 - val_f1_score: 0.0769 - val_loss: 0.7442 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 31ms/step - accuracy: 0.5110 - f1_score: 0.4267 - loss: 0.7770 - val_accuracy: 0.5600 - val_f1_score: 0.0833 - val_loss: 0.7442 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 31ms/step - accuracy: 0.5106 - f1_score: 0.4305 - loss: 0.7576 - val_accuracy: 0.5200 - val_f1_score: 0.2000 - val_loss: 0.7462 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 31ms/step - accuracy: 0.4916 - f1_score: 0.3845 - loss: 0.7659 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7444 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 31ms/step - accuracy: 0.4899 - f1_score: 0.4008 - loss: 0.7553 - val_accuracy: 0.5400 - val_f1_score: 0.0000e+00 - val_loss: 0.7450 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 31ms/step - accuracy: 0.5169 - f1_score: 0.4436 - loss: 0.7564 - val_accuracy: 0.5200 - val_f1_score: 0.2500 - val_loss: 0.7473 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 31ms/step - accuracy: 0.5084 - f1_score: 0.4571 - loss: 0.7523 - val_accuracy: 0.4600 - val_f1_score: 0.1290 - val_loss: 0.7471 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 31ms/step - accuracy: 0.5118 - f1_score: 0.4839 - loss: 0.7520 - val_accuracy: 0.4600 - val_f1_score: 0.4255 - val_loss: 0.7460 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 31ms/step - accuracy: 0.5177 - f1_score: 0.4633 - loss: 0.7517 - val_accuracy: 0.5200 - val_f1_score: 0.3333 - val_loss: 0.7448 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 31ms/step - accuracy: 0.5101 - f1_score: 0.4021 - loss: 0.7531 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7453 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 31ms/step - accuracy: 0.5017 - f1_score: 0.4552 - loss: 0.7525 - val_accuracy: 0.4600 - val_f1_score: 0.4000 - val_loss: 0.7474 - learning_rate: 7.9071e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702ms/step\noldB →  val F1 = 0.6333\n              precision    recall  f1-score   support\n\n        Left       0.75      0.32      0.45        28\n       Right       0.50      0.86      0.63        22\n\n    accuracy                           0.56        50\n   macro avg       0.62      0.59      0.54        50\nweighted avg       0.64      0.56      0.53        50\n\n\n>>> Training model1\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\nEpoch 1/200\n37/37 - 29s - 779ms/step - accuracy: 0.4865 - f1_score: 0.4171 - loss: 0.6935 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6939 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 22ms/step - accuracy: 0.5215 - f1_score: 0.6855 - loss: 0.6926 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6995 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 22ms/step - accuracy: 0.5008 - f1_score: 0.6674 - loss: 0.6934 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6948 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 21ms/step - accuracy: 0.4945 - f1_score: 0.4112 - loss: 0.6934 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 0.6953 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 22ms/step - accuracy: 0.5025 - f1_score: 0.3780 - loss: 0.6932 - val_accuracy: 0.5000 - val_f1_score: 0.3590 - val_loss: 0.6956 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 22ms/step - accuracy: 0.5068 - f1_score: 0.3767 - loss: 0.6926 - val_accuracy: 0.5400 - val_f1_score: 0.0000e+00 - val_loss: 0.6931 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 22ms/step - accuracy: 0.4865 - f1_score: 0.4242 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6978 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 22ms/step - accuracy: 0.5110 - f1_score: 0.6764 - loss: 0.6935 - val_accuracy: 0.4400 - val_f1_score: 0.5172 - val_loss: 0.6937 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 21ms/step - accuracy: 0.5232 - f1_score: 0.6378 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6967 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 21ms/step - accuracy: 0.5084 - f1_score: 0.6741 - loss: 0.6929 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6959 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 21ms/step - accuracy: 0.5068 - f1_score: 0.6249 - loss: 0.6890 - val_accuracy: 0.4800 - val_f1_score: 0.0000e+00 - val_loss: 0.7113 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 25ms/step - accuracy: 0.5046 - f1_score: 0.0548 - loss: 0.6892 - val_accuracy: 0.5400 - val_f1_score: 0.4390 - val_loss: 1.1698 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 23ms/step - accuracy: 0.4886 - f1_score: 0.3320 - loss: 0.6920 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6940 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 22ms/step - accuracy: 0.5241 - f1_score: 0.6877 - loss: 0.6866 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7342 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 22ms/step - accuracy: 0.5160 - f1_score: 0.3930 - loss: 0.6848 - val_accuracy: 0.6400 - val_f1_score: 0.4000 - val_loss: 0.7058 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 22ms/step - accuracy: 0.5068 - f1_score: 0.1244 - loss: 0.6845 - val_accuracy: 0.6000 - val_f1_score: 0.4737 - val_loss: 0.7312 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 21ms/step - accuracy: 0.5486 - f1_score: 0.1549 - loss: 0.6793 - val_accuracy: 0.5400 - val_f1_score: 0.4103 - val_loss: 0.9305 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 21ms/step - accuracy: 0.5160 - f1_score: 0.1075 - loss: 0.6865 - val_accuracy: 0.6200 - val_f1_score: 0.4242 - val_loss: 0.7528 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 21ms/step - accuracy: 0.4907 - f1_score: 0.4333 - loss: 0.6788 - val_accuracy: 0.5200 - val_f1_score: 0.1429 - val_loss: 0.8387 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 21ms/step - accuracy: 0.5346 - f1_score: 0.1309 - loss: 0.6780 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 1.0868 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 21ms/step - accuracy: 0.5173 - f1_score: 0.1174 - loss: 0.6765 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 1.4799 - learning_rate: 8.3736e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step\nmodel1 →  val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model2\nEpoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"37/37 - 5s - 135ms/step - accuracy: 0.4958 - f1_score: 0.4341 - loss: 0.6992 - val_accuracy: 0.5200 - val_f1_score: 0.0769 - val_loss: 0.7043 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 22ms/step - accuracy: 0.5059 - f1_score: 0.5447 - loss: 0.6921 - val_accuracy: 0.4200 - val_f1_score: 0.4528 - val_loss: 0.7090 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 20ms/step - accuracy: 0.5106 - f1_score: 0.5248 - loss: 0.6894 - val_accuracy: 0.4200 - val_f1_score: 0.4528 - val_loss: 0.7454 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 21ms/step - accuracy: 0.5152 - f1_score: 0.6148 - loss: 0.6954 - val_accuracy: 0.3600 - val_f1_score: 0.3043 - val_loss: 0.7109 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 21ms/step - accuracy: 0.5106 - f1_score: 0.4530 - loss: 0.6921 - val_accuracy: 0.5600 - val_f1_score: 0.2667 - val_loss: 0.7138 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 21ms/step - accuracy: 0.5262 - f1_score: 0.3321 - loss: 0.6900 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7101 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 21ms/step - accuracy: 0.5177 - f1_score: 0.4933 - loss: 0.6888 - val_accuracy: 0.4400 - val_f1_score: 0.2222 - val_loss: 0.7482 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 20ms/step - accuracy: 0.5211 - f1_score: 0.4143 - loss: 0.6934 - val_accuracy: 0.4800 - val_f1_score: 0.3810 - val_loss: 0.7300 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 20ms/step - accuracy: 0.5452 - f1_score: 0.4723 - loss: 0.6881 - val_accuracy: 0.5000 - val_f1_score: 0.3902 - val_loss: 0.7434 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 21ms/step - accuracy: 0.5224 - f1_score: 0.4088 - loss: 0.6908 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 0.7291 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 20ms/step - accuracy: 0.5351 - f1_score: 0.3504 - loss: 0.6893 - val_accuracy: 0.4200 - val_f1_score: 0.3830 - val_loss: 0.7385 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 20ms/step - accuracy: 0.5072 - f1_score: 0.4168 - loss: 0.6921 - val_accuracy: 0.4400 - val_f1_score: 0.1765 - val_loss: 0.7180 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 23ms/step - accuracy: 0.5076 - f1_score: 0.5264 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.4815 - val_loss: 0.7241 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 21ms/step - accuracy: 0.5177 - f1_score: 0.5384 - loss: 0.6882 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.7539 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 20ms/step - accuracy: 0.5228 - f1_score: 0.4504 - loss: 0.6898 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 0.7264 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 21ms/step - accuracy: 0.5249 - f1_score: 0.5978 - loss: 0.6908 - val_accuracy: 0.4400 - val_f1_score: 0.5625 - val_loss: 0.7272 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 20ms/step - accuracy: 0.5351 - f1_score: 0.5190 - loss: 0.6894 - val_accuracy: 0.5800 - val_f1_score: 0.4000 - val_loss: 0.7395 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 20ms/step - accuracy: 0.5169 - f1_score: 0.5431 - loss: 0.6904 - val_accuracy: 0.4800 - val_f1_score: 0.4348 - val_loss: 0.7210 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 20ms/step - accuracy: 0.5317 - f1_score: 0.4863 - loss: 0.6892 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 0.7346 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 20ms/step - accuracy: 0.5245 - f1_score: 0.5184 - loss: 0.6864 - val_accuracy: 0.4600 - val_f1_score: 0.4906 - val_loss: 0.7590 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 20ms/step - accuracy: 0.5148 - f1_score: 0.6104 - loss: 0.6865 - val_accuracy: 0.3600 - val_f1_score: 0.3043 - val_loss: 0.7561 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 21ms/step - accuracy: 0.5258 - f1_score: 0.4884 - loss: 0.6890 - val_accuracy: 0.4800 - val_f1_score: 0.3158 - val_loss: 0.7343 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 21ms/step - accuracy: 0.5372 - f1_score: 0.5210 - loss: 0.6852 - val_accuracy: 0.4400 - val_f1_score: 0.4167 - val_loss: 0.7649 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 20ms/step - accuracy: 0.5177 - f1_score: 0.4318 - loss: 0.6920 - val_accuracy: 0.5000 - val_f1_score: 0.2857 - val_loss: 0.7460 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 20ms/step - accuracy: 0.5253 - f1_score: 0.5762 - loss: 0.6862 - val_accuracy: 0.4000 - val_f1_score: 0.4828 - val_loss: 0.7423 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 21ms/step - accuracy: 0.5325 - f1_score: 0.6362 - loss: 0.6880 - val_accuracy: 0.4400 - val_f1_score: 0.5625 - val_loss: 0.7471 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 20ms/step - accuracy: 0.5148 - f1_score: 0.6127 - loss: 0.6878 - val_accuracy: 0.4000 - val_f1_score: 0.4643 - val_loss: 0.7755 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 21ms/step - accuracy: 0.5325 - f1_score: 0.5718 - loss: 0.6856 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 0.7851 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 21ms/step - accuracy: 0.5194 - f1_score: 0.4712 - loss: 0.6907 - val_accuracy: 0.4000 - val_f1_score: 0.2500 - val_loss: 0.7420 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 21ms/step - accuracy: 0.5215 - f1_score: 0.6048 - loss: 0.6883 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 0.7565 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 21ms/step - accuracy: 0.5203 - f1_score: 0.5199 - loss: 0.6864 - val_accuracy: 0.4600 - val_f1_score: 0.3415 - val_loss: 0.7470 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 1s - 20ms/step - accuracy: 0.5431 - f1_score: 0.4633 - loss: 0.6871 - val_accuracy: 0.4800 - val_f1_score: 0.2353 - val_loss: 0.7360 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 1s - 21ms/step - accuracy: 0.5342 - f1_score: 0.3744 - loss: 0.6870 - val_accuracy: 0.4800 - val_f1_score: 0.3158 - val_loss: 0.7636 - learning_rate: 4.9148e-04\nEpoch 34/200\n37/37 - 1s - 20ms/step - accuracy: 0.5131 - f1_score: 0.5137 - loss: 0.6861 - val_accuracy: 0.4400 - val_f1_score: 0.2632 - val_loss: 0.7745 - learning_rate: 4.5920e-04\nEpoch 35/200\n37/37 - 1s - 20ms/step - accuracy: 0.5448 - f1_score: 0.5060 - loss: 0.6842 - val_accuracy: 0.4600 - val_f1_score: 0.2703 - val_loss: 0.7747 - learning_rate: 4.2723e-04\nEpoch 36/200\n37/37 - 1s - 22ms/step - accuracy: 0.5342 - f1_score: 0.5007 - loss: 0.6862 - val_accuracy: 0.4400 - val_f1_score: 0.3636 - val_loss: 0.7652 - learning_rate: 3.9575e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step\nmodel2 →  val F1 = 0.5625\n              precision    recall  f1-score   support\n\n        Left       0.50      0.14      0.22        28\n       Right       0.43      0.82      0.56        22\n\n    accuracy                           0.44        50\n   macro avg       0.46      0.48      0.39        50\nweighted avg       0.47      0.44      0.37        50\n\n\n>>> Training model3\nEpoch 1/200\n37/37 - 13s - 340ms/step - accuracy: 0.4949 - f1_score: 0.5280 - loss: 0.6999 - val_accuracy: 0.4000 - val_f1_score: 0.4231 - val_loss: 0.7164 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 3s - 85ms/step - accuracy: 0.5300 - f1_score: 0.6649 - loss: 0.6893 - val_accuracy: 0.4200 - val_f1_score: 0.5797 - val_loss: 0.7057 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 38ms/step - accuracy: 0.5389 - f1_score: 0.6742 - loss: 0.6842 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 0.7134 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 38ms/step - accuracy: 0.6263 - f1_score: 0.6040 - loss: 0.6520 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 1.5843 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 38ms/step - accuracy: 0.6423 - f1_score: 0.6394 - loss: 0.6299 - val_accuracy: 0.4800 - val_f1_score: 0.4348 - val_loss: 2.0536 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 38ms/step - accuracy: 0.7420 - f1_score: 0.7543 - loss: 0.5103 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 1.9295 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 38ms/step - accuracy: 0.8374 - f1_score: 0.8361 - loss: 0.3482 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 2.0627 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 38ms/step - accuracy: 0.9109 - f1_score: 0.9119 - loss: 0.2410 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 2.5123 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 3s - 86ms/step - accuracy: 0.9337 - f1_score: 0.9356 - loss: 0.1818 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 3.4361 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 38ms/step - accuracy: 0.9662 - f1_score: 0.9668 - loss: 0.0900 - val_accuracy: 0.4800 - val_f1_score: 0.4091 - val_loss: 4.6296 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 38ms/step - accuracy: 0.9831 - f1_score: 0.9826 - loss: 0.0533 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 5.1516 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 3s - 84ms/step - accuracy: 0.9865 - f1_score: 0.9865 - loss: 0.0551 - val_accuracy: 0.6200 - val_f1_score: 0.6122 - val_loss: 4.2001 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 3s - 85ms/step - accuracy: 0.9937 - f1_score: 0.9937 - loss: 0.0248 - val_accuracy: 0.6800 - val_f1_score: 0.6667 - val_loss: 6.7003 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 38ms/step - accuracy: 0.9975 - f1_score: 0.9974 - loss: 0.0103 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 9.1413 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 38ms/step - accuracy: 0.9987 - f1_score: 0.9988 - loss: 0.0027 - val_accuracy: 0.6000 - val_f1_score: 0.6296 - val_loss: 9.4538 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 38ms/step - accuracy: 0.9992 - f1_score: 0.9992 - loss: 0.0027 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 9.8867 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0039e-04 - val_accuracy: 0.5800 - val_f1_score: 0.6038 - val_loss: 10.7727 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4542e-05 - val_accuracy: 0.5800 - val_f1_score: 0.6038 - val_loss: 10.9471 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.4173e-05 - val_accuracy: 0.5600 - val_f1_score: 0.5926 - val_loss: 11.1840 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4867e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 10.4004 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7601e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 11.2524 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5878e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 11.8498 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1122e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 12.2137 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.9271e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 12.4670 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2087e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 12.7185 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1557e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 12.8921 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2974e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 12.9976 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5325e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 13.0877 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1042e-05 - val_accuracy: 0.5800 - val_f1_score: 0.6038 - val_loss: 13.1972 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6640e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 13.3010 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9545e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 13.3775 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1018e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 13.4720 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3551e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 13.5439 - learning_rate: 4.9148e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step\nmodel3 →  val F1 = 0.6667\n              precision    recall  f1-score   support\n\n        Left       0.75      0.64      0.69        28\n       Right       0.62      0.73      0.67        22\n\n    accuracy                           0.68        50\n   macro avg       0.68      0.69      0.68        50\nweighted avg       0.69      0.68      0.68        50\n\n\n>>> Training model4\nEpoch 1/200\n37/37 - 10s - 276ms/step - accuracy: 0.5000 - f1_score: 0.4742 - loss: 0.6935 - val_accuracy: 0.5000 - val_f1_score: 0.5614 - val_loss: 0.7048 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 4s - 116ms/step - accuracy: 0.5317 - f1_score: 0.5047 - loss: 0.6915 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.6898 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 4s - 116ms/step - accuracy: 0.5253 - f1_score: 0.1925 - loss: 0.6905 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.6822 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 4s - 117ms/step - accuracy: 0.5304 - f1_score: 0.4506 - loss: 0.6914 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.6928 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 4s - 116ms/step - accuracy: 0.5397 - f1_score: 0.5121 - loss: 0.6900 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.7255 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 4s - 118ms/step - accuracy: 0.5367 - f1_score: 0.4217 - loss: 0.6855 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 0.8003 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 4s - 116ms/step - accuracy: 0.5469 - f1_score: 0.5292 - loss: 0.6902 - val_accuracy: 0.5000 - val_f1_score: 0.5283 - val_loss: 0.7155 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 4s - 116ms/step - accuracy: 0.5194 - f1_score: 0.4727 - loss: 0.6900 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.7108 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 4s - 116ms/step - accuracy: 0.5325 - f1_score: 0.4349 - loss: 0.6881 - val_accuracy: 0.5000 - val_f1_score: 0.5614 - val_loss: 0.7375 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 4s - 118ms/step - accuracy: 0.5469 - f1_score: 0.6080 - loss: 0.6865 - val_accuracy: 0.5400 - val_f1_score: 0.5818 - val_loss: 0.7368 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 4s - 116ms/step - accuracy: 0.5342 - f1_score: 0.5600 - loss: 0.6870 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.6884 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 4s - 117ms/step - accuracy: 0.5519 - f1_score: 0.4611 - loss: 0.6873 - val_accuracy: 0.5200 - val_f1_score: 0.5000 - val_loss: 0.6938 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 4s - 117ms/step - accuracy: 0.5557 - f1_score: 0.5214 - loss: 0.6838 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7000 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 4s - 117ms/step - accuracy: 0.5477 - f1_score: 0.5714 - loss: 0.6855 - val_accuracy: 0.4600 - val_f1_score: 0.5424 - val_loss: 0.7038 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 4s - 117ms/step - accuracy: 0.5524 - f1_score: 0.4928 - loss: 0.6858 - val_accuracy: 0.5600 - val_f1_score: 0.5769 - val_loss: 0.7172 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 4s - 116ms/step - accuracy: 0.5595 - f1_score: 0.5869 - loss: 0.6836 - val_accuracy: 0.4600 - val_f1_score: 0.5263 - val_loss: 0.7226 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 4s - 116ms/step - accuracy: 0.5566 - f1_score: 0.5850 - loss: 0.6823 - val_accuracy: 0.4800 - val_f1_score: 0.5357 - val_loss: 0.7454 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 4s - 118ms/step - accuracy: 0.5878 - f1_score: 0.6139 - loss: 0.6753 - val_accuracy: 0.4600 - val_f1_score: 0.5846 - val_loss: 0.7124 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 4s - 116ms/step - accuracy: 0.5600 - f1_score: 0.5829 - loss: 0.6834 - val_accuracy: 0.4600 - val_f1_score: 0.5424 - val_loss: 0.7245 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 4s - 117ms/step - accuracy: 0.5536 - f1_score: 0.5670 - loss: 0.6828 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.7025 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 4s - 117ms/step - accuracy: 0.5469 - f1_score: 0.5943 - loss: 0.6831 - val_accuracy: 0.4400 - val_f1_score: 0.5000 - val_loss: 0.7218 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 4s - 116ms/step - accuracy: 0.5866 - f1_score: 0.6359 - loss: 0.6746 - val_accuracy: 0.4600 - val_f1_score: 0.5263 - val_loss: 0.7110 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 4s - 116ms/step - accuracy: 0.5680 - f1_score: 0.5893 - loss: 0.6752 - val_accuracy: 0.3600 - val_f1_score: 0.4667 - val_loss: 0.7514 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 4s - 116ms/step - accuracy: 0.5899 - f1_score: 0.6281 - loss: 0.6697 - val_accuracy: 0.4200 - val_f1_score: 0.5085 - val_loss: 0.7918 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 4s - 117ms/step - accuracy: 0.5739 - f1_score: 0.6451 - loss: 0.6802 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7230 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 4s - 116ms/step - accuracy: 0.5676 - f1_score: 0.6003 - loss: 0.6802 - val_accuracy: 0.5000 - val_f1_score: 0.5763 - val_loss: 0.7075 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 4s - 117ms/step - accuracy: 0.5790 - f1_score: 0.6070 - loss: 0.6730 - val_accuracy: 0.4600 - val_f1_score: 0.5263 - val_loss: 0.7522 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 4s - 116ms/step - accuracy: 0.5743 - f1_score: 0.5263 - loss: 0.6698 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.7364 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 4s - 116ms/step - accuracy: 0.5861 - f1_score: 0.6074 - loss: 0.6707 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.7883 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 4s - 116ms/step - accuracy: 0.5988 - f1_score: 0.5937 - loss: 0.6627 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.8584 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 4s - 116ms/step - accuracy: 0.6047 - f1_score: 0.6031 - loss: 0.6567 - val_accuracy: 0.4600 - val_f1_score: 0.5424 - val_loss: 0.8417 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 4s - 116ms/step - accuracy: 0.5870 - f1_score: 0.6153 - loss: 0.6716 - val_accuracy: 0.5000 - val_f1_score: 0.5763 - val_loss: 0.7582 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 4s - 118ms/step - accuracy: 0.6026 - f1_score: 0.6051 - loss: 0.6630 - val_accuracy: 0.5200 - val_f1_score: 0.5862 - val_loss: 0.7689 - learning_rate: 4.9148e-04\nEpoch 34/200\n37/37 - 4s - 117ms/step - accuracy: 0.5773 - f1_score: 0.5372 - loss: 0.6653 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.8097 - learning_rate: 4.5920e-04\nEpoch 35/200\n37/37 - 4s - 117ms/step - accuracy: 0.6094 - f1_score: 0.6363 - loss: 0.6558 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 0.7650 - learning_rate: 4.2723e-04\nEpoch 36/200\n37/37 - 4s - 118ms/step - accuracy: 0.6187 - f1_score: 0.6282 - loss: 0.6438 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 0.7910 - learning_rate: 3.9575e-04\nEpoch 37/200\n37/37 - 4s - 117ms/step - accuracy: 0.6246 - f1_score: 0.6215 - loss: 0.6439 - val_accuracy: 0.4600 - val_f1_score: 0.5263 - val_loss: 0.8506 - learning_rate: 3.6494e-04\nEpoch 38/200\n37/37 - 4s - 116ms/step - accuracy: 0.6356 - f1_score: 0.6908 - loss: 0.6304 - val_accuracy: 0.4800 - val_f1_score: 0.5806 - val_loss: 0.9059 - learning_rate: 3.3498e-04\nEpoch 39/200\n37/37 - 4s - 116ms/step - accuracy: 0.6263 - f1_score: 0.6054 - loss: 0.6417 - val_accuracy: 0.4600 - val_f1_score: 0.4906 - val_loss: 0.8839 - learning_rate: 3.0602e-04\nEpoch 40/200\n37/37 - 4s - 116ms/step - accuracy: 0.6634 - f1_score: 0.6841 - loss: 0.6182 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 0.9346 - learning_rate: 2.7820e-04\nEpoch 41/200\n37/37 - 4s - 116ms/step - accuracy: 0.6478 - f1_score: 0.6436 - loss: 0.6205 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 0.8807 - learning_rate: 2.5163e-04\nEpoch 42/200\n37/37 - 4s - 116ms/step - accuracy: 0.6719 - f1_score: 0.6908 - loss: 0.6071 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.9543 - learning_rate: 2.2643e-04\nEpoch 43/200\n37/37 - 4s - 117ms/step - accuracy: 0.6516 - f1_score: 0.6612 - loss: 0.6131 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 0.9520 - learning_rate: 2.0267e-04\nEpoch 44/200\n37/37 - 4s - 118ms/step - accuracy: 0.6710 - f1_score: 0.6675 - loss: 0.6024 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 0.9136 - learning_rate: 1.8042e-04\nEpoch 45/200\n37/37 - 4s - 116ms/step - accuracy: 0.7086 - f1_score: 0.7156 - loss: 0.5682 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 0.9854 - learning_rate: 1.5972e-04\nEpoch 46/200\n37/37 - 4s - 116ms/step - accuracy: 0.6964 - f1_score: 0.6944 - loss: 0.5844 - val_accuracy: 0.5000 - val_f1_score: 0.5283 - val_loss: 1.0188 - learning_rate: 1.4058e-04\nEpoch 47/200\n37/37 - 4s - 117ms/step - accuracy: 0.6981 - f1_score: 0.6781 - loss: 0.5728 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0200 - learning_rate: 1.2302e-04\nEpoch 48/200\n37/37 - 4s - 117ms/step - accuracy: 0.7188 - f1_score: 0.7262 - loss: 0.5556 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0261 - learning_rate: 1.0700e-04\nEpoch 49/200\n37/37 - 4s - 117ms/step - accuracy: 0.7086 - f1_score: 0.7113 - loss: 0.5611 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0093 - learning_rate: 9.2503e-05\nEpoch 50/200\n37/37 - 4s - 117ms/step - accuracy: 0.7082 - f1_score: 0.7146 - loss: 0.5565 - val_accuracy: 0.4800 - val_f1_score: 0.4800 - val_loss: 1.0565 - learning_rate: 7.9466e-05\nEpoch 51/200\n37/37 - 4s - 116ms/step - accuracy: 0.7111 - f1_score: 0.7217 - loss: 0.5458 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 1.0579 - learning_rate: 6.7829e-05\nEpoch 52/200\n37/37 - 4s - 116ms/step - accuracy: 0.7280 - f1_score: 0.7280 - loss: 0.5434 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 1.0236 - learning_rate: 5.7516e-05\nEpoch 53/200\n37/37 - 4s - 116ms/step - accuracy: 0.7247 - f1_score: 0.7321 - loss: 0.5340 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 1.0541 - learning_rate: 4.8444e-05\nEpoch 54/200\n37/37 - 4s - 117ms/step - accuracy: 0.7454 - f1_score: 0.7470 - loss: 0.5168 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 1.0258 - learning_rate: 4.0524e-05\nEpoch 55/200\n37/37 - 4s - 116ms/step - accuracy: 0.7356 - f1_score: 0.7389 - loss: 0.5395 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 1.0508 - learning_rate: 3.3661e-05\nEpoch 56/200\n37/37 - 4s - 116ms/step - accuracy: 0.7209 - f1_score: 0.7254 - loss: 0.5339 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 1.0510 - learning_rate: 2.7761e-05\nEpoch 57/200\n37/37 - 4s - 116ms/step - accuracy: 0.7546 - f1_score: 0.7600 - loss: 0.5154 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 1.0416 - learning_rate: 2.2728e-05\nEpoch 58/200\n37/37 - 4s - 117ms/step - accuracy: 0.7551 - f1_score: 0.7534 - loss: 0.5140 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 1.0541 - learning_rate: 1.8470e-05\nEpoch 59/200\n37/37 - 4s - 116ms/step - accuracy: 0.7196 - f1_score: 0.7196 - loss: 0.5409 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 1.0508 - learning_rate: 1.4895e-05\nEpoch 60/200\n37/37 - 4s - 117ms/step - accuracy: 0.7508 - f1_score: 0.7498 - loss: 0.5189 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0507 - learning_rate: 1.1919e-05\nEpoch 61/200\n37/37 - 4s - 116ms/step - accuracy: 0.7610 - f1_score: 0.7591 - loss: 0.5109 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0552 - learning_rate: 9.4625e-06\nEpoch 62/200\n37/37 - 4s - 117ms/step - accuracy: 0.7635 - f1_score: 0.7621 - loss: 0.5025 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0605 - learning_rate: 7.4517e-06\nEpoch 63/200\n37/37 - 4s - 117ms/step - accuracy: 0.7420 - f1_score: 0.7383 - loss: 0.5178 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0587 - learning_rate: 5.8201e-06\nEpoch 64/200\n37/37 - 4s - 117ms/step - accuracy: 0.7411 - f1_score: 0.7449 - loss: 0.5263 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 1.0587 - learning_rate: 4.5077e-06\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step\nmodel4 →  val F1 = 0.6154\n              precision    recall  f1-score   support\n\n        Left       0.70      0.50      0.58        28\n       Right       0.53      0.73      0.62        22\n\n    accuracy                           0.60        50\n   macro avg       0.62      0.61      0.60        50\nweighted avg       0.63      0.60      0.60        50\n\n\n>>> Training model5\nEpoch 1/200\n37/37 - 10s - 264ms/step - accuracy: 0.5135 - f1_score: 0.4987 - loss: 1.1049 - val_accuracy: 0.5200 - val_f1_score: 0.5862 - val_loss: 1.0677 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 24ms/step - accuracy: 0.5038 - f1_score: 0.5339 - loss: 0.7843 - val_accuracy: 0.5000 - val_f1_score: 0.0741 - val_loss: 0.9368 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 22ms/step - accuracy: 0.5346 - f1_score: 0.5374 - loss: 0.7217 - val_accuracy: 0.5800 - val_f1_score: 0.5116 - val_loss: 0.7539 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 23ms/step - accuracy: 0.5680 - f1_score: 0.5678 - loss: 0.6789 - val_accuracy: 0.4400 - val_f1_score: 0.4815 - val_loss: 0.7458 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 25ms/step - accuracy: 0.6106 - f1_score: 0.6070 - loss: 0.6423 - val_accuracy: 0.5400 - val_f1_score: 0.3784 - val_loss: 1.0484 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 23ms/step - accuracy: 0.6748 - f1_score: 0.6794 - loss: 0.5971 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 1.6502 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 22ms/step - accuracy: 0.7644 - f1_score: 0.7669 - loss: 0.4830 - val_accuracy: 0.5200 - val_f1_score: 0.3333 - val_loss: 1.5477 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 23ms/step - accuracy: 0.8011 - f1_score: 0.8070 - loss: 0.4324 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 1.3986 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 23ms/step - accuracy: 0.8450 - f1_score: 0.8485 - loss: 0.3603 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 1.7661 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 22ms/step - accuracy: 0.8923 - f1_score: 0.8949 - loss: 0.2650 - val_accuracy: 0.4600 - val_f1_score: 0.4000 - val_loss: 2.7287 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 22ms/step - accuracy: 0.9329 - f1_score: 0.9334 - loss: 0.1811 - val_accuracy: 0.4800 - val_f1_score: 0.3500 - val_loss: 3.0188 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 22ms/step - accuracy: 0.9548 - f1_score: 0.9557 - loss: 0.1325 - val_accuracy: 0.3800 - val_f1_score: 0.3404 - val_loss: 4.1681 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 23ms/step - accuracy: 0.9590 - f1_score: 0.9595 - loss: 0.1229 - val_accuracy: 0.5200 - val_f1_score: 0.4286 - val_loss: 3.5643 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 23ms/step - accuracy: 0.9730 - f1_score: 0.9726 - loss: 0.0806 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 3.6606 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 22ms/step - accuracy: 0.9700 - f1_score: 0.9696 - loss: 0.0813 - val_accuracy: 0.4400 - val_f1_score: 0.4167 - val_loss: 4.4831 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 22ms/step - accuracy: 0.9717 - f1_score: 0.9732 - loss: 0.0842 - val_accuracy: 0.4200 - val_f1_score: 0.4082 - val_loss: 5.2717 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 22ms/step - accuracy: 0.9823 - f1_score: 0.9828 - loss: 0.0630 - val_accuracy: 0.4200 - val_f1_score: 0.3556 - val_loss: 5.9281 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 22ms/step - accuracy: 0.9776 - f1_score: 0.9785 - loss: 0.0841 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 4.6036 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 22ms/step - accuracy: 0.9666 - f1_score: 0.9664 - loss: 0.1148 - val_accuracy: 0.5600 - val_f1_score: 0.4762 - val_loss: 5.3497 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 22ms/step - accuracy: 0.9759 - f1_score: 0.9763 - loss: 0.0814 - val_accuracy: 0.4800 - val_f1_score: 0.4348 - val_loss: 3.9399 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 22ms/step - accuracy: 0.9844 - f1_score: 0.9850 - loss: 0.0516 - val_accuracy: 0.4600 - val_f1_score: 0.3415 - val_loss: 4.8129 - learning_rate: 8.3736e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step\nmodel5 →  val F1 = 0.5862\n              precision    recall  f1-score   support\n\n        Left       0.64      0.32      0.43        28\n       Right       0.47      0.77      0.59        22\n\n    accuracy                           0.52        50\n   macro avg       0.56      0.55      0.51        50\nweighted avg       0.57      0.52      0.50        50\n\n\n>>> Training model6\nEpoch 1/200\n37/37 - 8s - 222ms/step - accuracy: 0.4865 - f1_score: 0.6052 - loss: 0.6959 - val_accuracy: 0.6800 - val_f1_score: 0.6364 - val_loss: 0.6884 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 38ms/step - accuracy: 0.5080 - f1_score: 0.4412 - loss: 0.6917 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.7768 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 38ms/step - accuracy: 0.5106 - f1_score: 0.5929 - loss: 0.6930 - val_accuracy: 0.4600 - val_f1_score: 0.6087 - val_loss: 0.6952 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 38ms/step - accuracy: 0.4996 - f1_score: 0.2240 - loss: 0.6942 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6940 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 38ms/step - accuracy: 0.5063 - f1_score: 0.2107 - loss: 0.6932 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.6981 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 38ms/step - accuracy: 0.5165 - f1_score: 0.5411 - loss: 0.6920 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6890 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 38ms/step - accuracy: 0.4924 - f1_score: 0.3654 - loss: 0.6946 - val_accuracy: 0.5600 - val_f1_score: 0.4211 - val_loss: 0.6940 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 38ms/step - accuracy: 0.5110 - f1_score: 0.5633 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6949 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 38ms/step - accuracy: 0.5021 - f1_score: 0.6572 - loss: 0.6936 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6950 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 39ms/step - accuracy: 0.5072 - f1_score: 0.6697 - loss: 0.6932 - val_accuracy: 0.5800 - val_f1_score: 0.6441 - val_loss: 0.6916 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 38ms/step - accuracy: 0.5190 - f1_score: 0.5236 - loss: 0.6916 - val_accuracy: 0.4800 - val_f1_score: 0.6061 - val_loss: 0.6969 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 38ms/step - accuracy: 0.5241 - f1_score: 0.6785 - loss: 0.6911 - val_accuracy: 0.4800 - val_f1_score: 0.6061 - val_loss: 0.6921 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 38ms/step - accuracy: 0.5059 - f1_score: 0.6387 - loss: 0.6924 - val_accuracy: 0.5600 - val_f1_score: 0.6207 - val_loss: 0.6917 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 38ms/step - accuracy: 0.5287 - f1_score: 0.5500 - loss: 0.6912 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.6973 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 38ms/step - accuracy: 0.5106 - f1_score: 0.5340 - loss: 0.6924 - val_accuracy: 0.6200 - val_f1_score: 0.5128 - val_loss: 0.6884 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 38ms/step - accuracy: 0.5059 - f1_score: 0.4248 - loss: 0.6922 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.6969 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 37ms/step - accuracy: 0.5173 - f1_score: 0.3962 - loss: 0.6927 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6901 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 38ms/step - accuracy: 0.4954 - f1_score: 0.5608 - loss: 0.6934 - val_accuracy: 0.4400 - val_f1_score: 0.5882 - val_loss: 0.6945 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 38ms/step - accuracy: 0.4979 - f1_score: 0.6516 - loss: 0.6927 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6976 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 38ms/step - accuracy: 0.4979 - f1_score: 0.6367 - loss: 0.6932 - val_accuracy: 0.4200 - val_f1_score: 0.5397 - val_loss: 0.6969 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 38ms/step - accuracy: 0.5194 - f1_score: 0.6671 - loss: 0.6915 - val_accuracy: 0.4200 - val_f1_score: 0.5915 - val_loss: 0.7029 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 38ms/step - accuracy: 0.5021 - f1_score: 0.6535 - loss: 0.6914 - val_accuracy: 0.4200 - val_f1_score: 0.5672 - val_loss: 0.7097 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 38ms/step - accuracy: 0.4937 - f1_score: 0.6443 - loss: 0.6934 - val_accuracy: 0.4800 - val_f1_score: 0.6286 - val_loss: 0.6980 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 38ms/step - accuracy: 0.4945 - f1_score: 0.6426 - loss: 0.6937 - val_accuracy: 0.5600 - val_f1_score: 0.5769 - val_loss: 0.6949 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 38ms/step - accuracy: 0.4958 - f1_score: 0.6328 - loss: 0.6919 - val_accuracy: 0.5600 - val_f1_score: 0.5926 - val_loss: 0.7001 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 38ms/step - accuracy: 0.4958 - f1_score: 0.6028 - loss: 0.6911 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.6980 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 38ms/step - accuracy: 0.5152 - f1_score: 0.3835 - loss: 0.6946 - val_accuracy: 0.5600 - val_f1_score: 0.1538 - val_loss: 0.6938 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 38ms/step - accuracy: 0.5296 - f1_score: 0.2043 - loss: 0.6911 - val_accuracy: 0.5200 - val_f1_score: 0.5000 - val_loss: 0.7488 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 38ms/step - accuracy: 0.5127 - f1_score: 0.4628 - loss: 0.6925 - val_accuracy: 0.5800 - val_f1_score: 0.4878 - val_loss: 0.7146 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 38ms/step - accuracy: 0.5055 - f1_score: 0.3541 - loss: 0.6923 - val_accuracy: 0.5600 - val_f1_score: 0.4762 - val_loss: 0.7228 - learning_rate: 5.8827e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step\nmodel6 →  val F1 = 0.6441\n              precision    recall  f1-score   support\n\n        Left       0.77      0.36      0.49        28\n       Right       0.51      0.86      0.64        22\n\n    accuracy                           0.58        50\n   macro avg       0.64      0.61      0.57        50\nweighted avg       0.66      0.58      0.56        50\n\n\n=== Final best: model3 (F1=0.6667) ===\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.metrics import f1_score, classification_report\nfrom mne.decoding import CSP\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n\n# --- 1) Config ---\ndata_dir = './preprocessed'\noutput_dir = './models2'\nos.makedirs(output_dir, exist_ok=True)\n\n# --- 2) Load data ---\ntrain_npz = np.load(os.path.join(data_dir, 'train_MI.npz'))\nval_npz   = np.load(os.path.join(data_dir, 'validation_MI.npz'))\nX_train, y_train = train_npz['X'], train_npz['y']\nX_val,   y_val   = val_npz['X'],   val_npz['y']\n\ny_train_bin = (y_train == 'Right').astype(int)\ny_val_bin   = (y_val   == 'Right').astype(int)\n\n# --- 3) Select MI-related EEG channels: C3, CZ, C4, PZ (indices 2,3,4,5) ---\nmi_indices = [1, 2, 3, 4]\nX_train_mi = X_train[:, mi_indices, :]\nX_val_mi   = X_val[:,   mi_indices, :]\n\n# --- 4) CSP (n_components=4) ---\ncsp = CSP(n_components=4, log=False, norm_trace=False)\ncsp.fit(X_train_mi, y_train_bin)\nW = csp.filters_[:4]\ndef apply_csp(X): return np.stack([W.dot(ep) for ep in X], axis=0)\n\nXtr = apply_csp(X_train_mi).transpose(0, 2, 1).astype('float32')  # (n, T, 4)\nXvl = apply_csp(X_val_mi).transpose(0, 2, 1).astype('float32')\nXtr_spec = Xtr[..., np.newaxis]\nXvl_spec = Xvl[..., np.newaxis]\n\n# --- 5) One-hot encode labels ---\nytr_oh = keras.utils.to_categorical(y_train_bin, 2)\nyvl_oh = keras.utils.to_categorical(y_val_bin,   2)\n\n# --- 6) Data augmentation ---\ndef aug_gen(X, y, seed=0, batch_size=32):\n    n   = X.shape[0]\n    rng = np.random.RandomState(seed)\n    while True:\n        idx = rng.randint(0, n, batch_size)\n        bx, by = X[idx].copy(), y[idx]\n        bx += rng.normal(0, 0.005, bx.shape)\n        yield bx, by\n\ntrain_gen_1d = aug_gen(Xtr, ytr_oh, seed=0, batch_size=64)\ntrain_gen_2d = aug_gen(Xtr_spec, ytr_oh, seed=1, batch_size=64)\n\nsteps_1d = len(Xtr)      // 64\nsteps_2d = len(Xtr_spec) // 64\n\n# --- 7) Learning rate schedule ---\ndef cosine_lr(epoch, lr_max=5e-5, epochs=200):\n    return lr_max * (1 + np.cos(np.pi * epoch / epochs)) / 2\n\n# --- 8) F1 metric ---\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        preds  = tf.argmax(y_pred, axis=1)\n        labels = tf.argmax(y_true, axis=1)\n        preds  = tf.cast(preds, tf.int32)\n        labels = tf.cast(labels, tf.int32)\n        tp = tf.reduce_sum(tf.cast(tf.logical_and(preds==1, labels==1), tf.float32))\n        fp = tf.reduce_sum(tf.cast(tf.logical_and(preds==1, labels==0), tf.float32))\n        fn = tf.reduce_sum(tf.cast(tf.logical_and(preds==0, labels==1), tf.float32))\n        self.tp.assign_add(tp)\n        self.fp.assign_add(fp)\n        self.fn.assign_add(fn)\n\n    def result(self):\n        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n        recall    = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.assign(0.)\n        self.fp.assign(0.)\n        self.fn.assign(0.)\n\n# --- 9) Callbacks ---\ndef get_callbacks(name):\n    return [\n        EarlyStopping(\"val_f1_score\", mode=\"max\", patience=20, restore_best_weights=True),\n        ModelCheckpoint(f\"{output_dir}/best_{name}.h5\", \"val_f1_score\", mode=\"max\", save_best_only=True),\n        CSVLogger(f\"{output_dir}/log_{name}.csv\"),\n        LearningRateScheduler(cosine_lr)\n    ]\n\n# --- 10) Model builders ---\n\ndef build_modelA(input_shape):\n    m = keras.Sequential([\n        layers.Input(input_shape),\n        layers.Conv1D(32, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(64, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(128,5,activation=\"relu\",padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling1D(),\n        layers.Dense(64, activation=\"relu\", \n                     kernel_regularizer=regularizers.l2(1e-4)),\n        layers.Dropout(0.7),\n        layers.Dense(2, activation=\"softmax\"),\n    ])\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_modelB(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for f in [16,32,64,128,256]:\n        x = layers.Conv1D(f,3,activation=\"relu\",padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.MaxPool1D(2)(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\",\n                         kernel_regularizer=regularizers.l2(1e-4))(x)\n        x = layers.Dropout(0.5)(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model1(input_shape):\n    inp = layers.Input(input_shape+(1,))\n    x = layers.Concatenate()([inp, inp, inp])\n    x = layers.Resizing(32,32)(x)\n    base = keras.applications.ResNet50(\n        include_top=False, weights=\"imagenet\",\n        input_shape=(32,32,3), pooling=\"avg\"\n    )\n    base.trainable = False\n    x = base(x)\n    x = layers.Reshape((1, x.shape[-1]))(x)\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.MultiHeadAttention(num_heads=4,key_dim=32)(x,x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model2(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(32,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model3(input_shape):\n    inp = layers.Input(input_shape)  # (T, F, 1)\n    x = inp\n    for _ in range(5):\n        x = layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model4(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.LSTM(128)(x)\n    for _ in range(4):\n        x = layers.Dense(64, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model5(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for _ in range(3):\n        x = layers.Dense(64, activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model6(input_shape):\n    C3, C4 = 0,2\n    eeg_in = layers.Input(input_shape)\n    c3 = layers.Lambda(lambda x: x[:,:,C3:C3+1])(eeg_in)\n    c4 = layers.Lambda(lambda x: x[:,:,C4:C4+1])(eeg_in)\n    def branch():\n        return models.Sequential([\n            layers.Conv1D(16,250,activation=\"relu\",padding=\"same\"),\n            layers.MaxPool1D(3),\n            layers.Conv1D(32,50,activation=\"relu\",padding=\"same\"),\n            layers.GlobalAveragePooling1D()\n        ])\n    b3, b4 = branch()(c3), branch()(c4)\n    x = layers.Concatenate()([b3,b4])\n    for _ in range(4):\n        x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2,activation=\"softmax\")(x)\n    m = models.Model(eeg_in,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n# --- 11) Train + Evaluate ---\nbuilders = {\n    'oldA': build_modelA,\n    'oldB': build_modelB,\n    'model1': build_model1,\n    'model2': build_model2,\n    'model3': build_model3,\n    'model4': build_model4,\n    'model5': build_model5,\n    'model6': build_model6,\n}\n\nresults = {}\nshape_1d = Xtr.shape[1:]      # (T, 4)\nshape_2d = Xtr_spec.shape[1:] # (T, 4, 1)\n\nfor name, build_fn in builders.items():\n    print(f\"\\n>>> Training {name}\")\n    if name == 'model3':\n        model = build_fn(shape_2d)\n        gen   = train_gen_2d\n        steps = steps_2d\n        val_x = Xvl_spec\n    else:\n        model = build_fn(shape_1d)\n        gen   = train_gen_1d\n        steps = steps_1d\n        val_x = Xvl\n\n    history = model.fit(\n        gen, steps_per_epoch=steps,\n        validation_data=(val_x, yvl_oh),\n        epochs=200,\n        callbacks=get_callbacks(name),\n        verbose=2\n    )\n\n    preds = np.argmax(model.predict(val_x), axis=1)\n    f1 = f1_score(y_val_bin, preds)\n    print(f\"{name} → F1 = {f1:.4f}\")\n    print(classification_report(y_val_bin, preds, target_names=['Left','Right']))\n    results[name] = (f1, model)\n\n# --- 12) Save best ---\nbest_name, (best_f1, best_model) = max(results.items(), key=lambda kv: kv[1][0])\nprint(f\"\\n=== Final best: {best_name} (F1={best_f1:.4f}) ===\")\nbest_model.save(os.path.join(output_dir, 'best_final.h5'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T02:59:47.838571Z","iopub.execute_input":"2025-07-23T02:59:47.838820Z","iopub.status.idle":"2025-07-23T03:07:48.233239Z","shell.execute_reply.started":"2025-07-23T02:59:47.838794Z","shell.execute_reply":"2025-07-23T03:07:48.232417Z"}},"outputs":[{"name":"stdout","text":"Computing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA\nEpoch 1/200\n37/37 - 10s - 258ms/step - accuracy: 0.4937 - f1_score: 0.4839 - loss: 0.8629 - val_accuracy: 0.4800 - val_f1_score: 0.2778 - val_loss: 0.7061 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 28ms/step - accuracy: 0.5097 - f1_score: 0.5024 - loss: 0.7739 - val_accuracy: 0.5600 - val_f1_score: 0.3125 - val_loss: 0.6870 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 27ms/step - accuracy: 0.5059 - f1_score: 0.4855 - loss: 0.7470 - val_accuracy: 0.5400 - val_f1_score: 0.2581 - val_loss: 0.6986 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 27ms/step - accuracy: 0.5021 - f1_score: 0.5040 - loss: 0.7307 - val_accuracy: 0.5800 - val_f1_score: 0.2759 - val_loss: 0.6973 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 28ms/step - accuracy: 0.5055 - f1_score: 0.5123 - loss: 0.7133 - val_accuracy: 0.4600 - val_f1_score: 0.5091 - val_loss: 0.7065 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 28ms/step - accuracy: 0.4958 - f1_score: 0.4636 - loss: 0.7158 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.7068 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 27ms/step - accuracy: 0.5034 - f1_score: 0.4741 - loss: 0.7112 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.7101 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 27ms/step - accuracy: 0.5351 - f1_score: 0.5501 - loss: 0.6975 - val_accuracy: 0.4600 - val_f1_score: 0.4000 - val_loss: 0.6949 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 27ms/step - accuracy: 0.5258 - f1_score: 0.5426 - loss: 0.7046 - val_accuracy: 0.5400 - val_f1_score: 0.1481 - val_loss: 0.7064 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 27ms/step - accuracy: 0.5312 - f1_score: 0.5592 - loss: 0.7016 - val_accuracy: 0.4600 - val_f1_score: 0.4000 - val_loss: 0.7005 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 27ms/step - accuracy: 0.5236 - f1_score: 0.4991 - loss: 0.7011 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 0.7353 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 27ms/step - accuracy: 0.5173 - f1_score: 0.5367 - loss: 0.7009 - val_accuracy: 0.4200 - val_f1_score: 0.4082 - val_loss: 0.6965 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 28ms/step - accuracy: 0.5228 - f1_score: 0.5647 - loss: 0.7006 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7014 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 28ms/step - accuracy: 0.5300 - f1_score: 0.5763 - loss: 0.7020 - val_accuracy: 0.4600 - val_f1_score: 0.5574 - val_loss: 0.7130 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 27ms/step - accuracy: 0.5055 - f1_score: 0.5553 - loss: 0.7026 - val_accuracy: 0.5600 - val_f1_score: 0.3529 - val_loss: 0.6930 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 27ms/step - accuracy: 0.5515 - f1_score: 0.5721 - loss: 0.6952 - val_accuracy: 0.5800 - val_f1_score: 0.2222 - val_loss: 0.6845 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 29ms/step - accuracy: 0.5118 - f1_score: 0.4658 - loss: 0.7022 - val_accuracy: 0.6200 - val_f1_score: 0.3448 - val_loss: 0.6962 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 27ms/step - accuracy: 0.5342 - f1_score: 0.4421 - loss: 0.6939 - val_accuracy: 0.5600 - val_f1_score: 0.0833 - val_loss: 0.7361 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 27ms/step - accuracy: 0.5270 - f1_score: 0.4791 - loss: 0.7015 - val_accuracy: 0.4800 - val_f1_score: 0.4091 - val_loss: 0.6932 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 27ms/step - accuracy: 0.5249 - f1_score: 0.5566 - loss: 0.6963 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 0.7365 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 27ms/step - accuracy: 0.5097 - f1_score: 0.5305 - loss: 0.7002 - val_accuracy: 0.5800 - val_f1_score: 0.2222 - val_loss: 0.6688 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 27ms/step - accuracy: 0.5287 - f1_score: 0.4236 - loss: 0.6959 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 0.7004 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 27ms/step - accuracy: 0.5051 - f1_score: 0.4860 - loss: 0.7030 - val_accuracy: 0.4800 - val_f1_score: 0.4091 - val_loss: 0.7039 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 27ms/step - accuracy: 0.5346 - f1_score: 0.5975 - loss: 0.6968 - val_accuracy: 0.5200 - val_f1_score: 0.5000 - val_loss: 0.6807 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 27ms/step - accuracy: 0.5329 - f1_score: 0.6024 - loss: 0.6957 - val_accuracy: 0.4400 - val_f1_score: 0.3913 - val_loss: 0.6966 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 27ms/step - accuracy: 0.5376 - f1_score: 0.5809 - loss: 0.6950 - val_accuracy: 0.6400 - val_f1_score: 0.4375 - val_loss: 0.6834 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 27ms/step - accuracy: 0.5253 - f1_score: 0.5265 - loss: 0.6983 - val_accuracy: 0.5800 - val_f1_score: 0.2759 - val_loss: 0.6796 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 27ms/step - accuracy: 0.5329 - f1_score: 0.5522 - loss: 0.6993 - val_accuracy: 0.6000 - val_f1_score: 0.2308 - val_loss: 0.7036 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 27ms/step - accuracy: 0.5325 - f1_score: 0.5505 - loss: 0.6921 - val_accuracy: 0.5600 - val_f1_score: 0.3889 - val_loss: 0.7288 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 27ms/step - accuracy: 0.5519 - f1_score: 0.5958 - loss: 0.6912 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.7203 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 28ms/step - accuracy: 0.5351 - f1_score: 0.5504 - loss: 0.6971 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 0.6860 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 1s - 27ms/step - accuracy: 0.5351 - f1_score: 0.5875 - loss: 0.6962 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7024 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 1s - 27ms/step - accuracy: 0.5460 - f1_score: 0.6089 - loss: 0.6875 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.6855 - learning_rate: 4.9148e-04\nEpoch 34/200\n37/37 - 1s - 27ms/step - accuracy: 0.5448 - f1_score: 0.5698 - loss: 0.6894 - val_accuracy: 0.6200 - val_f1_score: 0.4571 - val_loss: 0.7058 - learning_rate: 4.5920e-04\nEpoch 35/200\n37/37 - 1s - 27ms/step - accuracy: 0.5363 - f1_score: 0.5205 - loss: 0.6953 - val_accuracy: 0.5400 - val_f1_score: 0.0800 - val_loss: 0.7121 - learning_rate: 4.2723e-04\nEpoch 36/200\n37/37 - 1s - 27ms/step - accuracy: 0.5473 - f1_score: 0.5578 - loss: 0.6934 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.7025 - learning_rate: 3.9575e-04\nEpoch 37/200\n37/37 - 1s - 27ms/step - accuracy: 0.5380 - f1_score: 0.5770 - loss: 0.6951 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 0.7066 - learning_rate: 3.6494e-04\nEpoch 38/200\n37/37 - 1s - 27ms/step - accuracy: 0.5393 - f1_score: 0.5574 - loss: 0.6940 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 0.6934 - learning_rate: 3.3498e-04\nEpoch 39/200\n37/37 - 1s - 27ms/step - accuracy: 0.5456 - f1_score: 0.5780 - loss: 0.6955 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.6860 - learning_rate: 3.0602e-04\nEpoch 40/200\n37/37 - 1s - 27ms/step - accuracy: 0.5671 - f1_score: 0.5821 - loss: 0.6881 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6796 - learning_rate: 2.7820e-04\nEpoch 41/200\n37/37 - 1s - 27ms/step - accuracy: 0.5498 - f1_score: 0.5448 - loss: 0.6898 - val_accuracy: 0.5800 - val_f1_score: 0.3636 - val_loss: 0.6807 - learning_rate: 2.5163e-04\nEpoch 42/200\n37/37 - 1s - 27ms/step - accuracy: 0.5591 - f1_score: 0.5484 - loss: 0.6893 - val_accuracy: 0.6000 - val_f1_score: 0.4444 - val_loss: 0.6911 - learning_rate: 2.2643e-04\nEpoch 43/200\n37/37 - 1s - 27ms/step - accuracy: 0.5621 - f1_score: 0.5563 - loss: 0.6857 - val_accuracy: 0.6000 - val_f1_score: 0.4118 - val_loss: 0.6992 - learning_rate: 2.0267e-04\nEpoch 44/200\n37/37 - 1s - 27ms/step - accuracy: 0.5422 - f1_score: 0.5336 - loss: 0.6912 - val_accuracy: 0.5600 - val_f1_score: 0.4500 - val_loss: 0.7214 - learning_rate: 1.8042e-04\nEpoch 45/200\n37/37 - 1s - 27ms/step - accuracy: 0.5570 - f1_score: 0.5720 - loss: 0.6879 - val_accuracy: 0.5200 - val_f1_score: 0.2941 - val_loss: 0.7190 - learning_rate: 1.5972e-04\nEpoch 46/200\n37/37 - 1s - 27ms/step - accuracy: 0.5549 - f1_score: 0.5545 - loss: 0.6884 - val_accuracy: 0.5400 - val_f1_score: 0.2069 - val_loss: 0.7285 - learning_rate: 1.4058e-04\nEpoch 47/200\n37/37 - 1s - 27ms/step - accuracy: 0.5528 - f1_score: 0.5472 - loss: 0.6863 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.7314 - learning_rate: 1.2302e-04\nEpoch 48/200\n37/37 - 1s - 27ms/step - accuracy: 0.5389 - f1_score: 0.5427 - loss: 0.6897 - val_accuracy: 0.5800 - val_f1_score: 0.3636 - val_loss: 0.7219 - learning_rate: 1.0700e-04\nEpoch 49/200\n37/37 - 1s - 28ms/step - accuracy: 0.5549 - f1_score: 0.5612 - loss: 0.6864 - val_accuracy: 0.5400 - val_f1_score: 0.2581 - val_loss: 0.7233 - learning_rate: 9.2503e-05\nEpoch 50/200\n37/37 - 1s - 27ms/step - accuracy: 0.5735 - f1_score: 0.5884 - loss: 0.6887 - val_accuracy: 0.5800 - val_f1_score: 0.4878 - val_loss: 0.7357 - learning_rate: 7.9466e-05\nEpoch 51/200\n37/37 - 1s - 27ms/step - accuracy: 0.5671 - f1_score: 0.5950 - loss: 0.6836 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.7369 - learning_rate: 6.7829e-05\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step\noldA → F1 = 0.5660\n              precision    recall  f1-score   support\n\n        Left       0.63      0.43      0.51        28\n       Right       0.48      0.68      0.57        22\n\n    accuracy                           0.54        50\n   macro avg       0.56      0.56      0.54        50\nweighted avg       0.57      0.54      0.54        50\n\n\n>>> Training oldB\nEpoch 1/200\n37/37 - 14s - 373ms/step - accuracy: 0.5008 - f1_score: 0.5440 - loss: 3.2655 - val_accuracy: 0.5000 - val_f1_score: 0.4681 - val_loss: 0.7443 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 32ms/step - accuracy: 0.4886 - f1_score: 0.5123 - loss: 2.0578 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7452 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 32ms/step - accuracy: 0.4928 - f1_score: 0.4977 - loss: 1.4307 - val_accuracy: 0.5200 - val_f1_score: 0.1429 - val_loss: 0.7575 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 32ms/step - accuracy: 0.5093 - f1_score: 0.4660 - loss: 1.0991 - val_accuracy: 0.5200 - val_f1_score: 0.1429 - val_loss: 0.7467 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 31ms/step - accuracy: 0.5173 - f1_score: 0.4940 - loss: 0.9802 - val_accuracy: 0.5200 - val_f1_score: 0.0000e+00 - val_loss: 0.7412 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 31ms/step - accuracy: 0.5042 - f1_score: 0.4664 - loss: 0.9101 - val_accuracy: 0.5200 - val_f1_score: 0.0000e+00 - val_loss: 0.7450 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 31ms/step - accuracy: 0.5076 - f1_score: 0.4686 - loss: 0.8414 - val_accuracy: 0.5800 - val_f1_score: 0.2222 - val_loss: 0.7462 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 31ms/step - accuracy: 0.4844 - f1_score: 0.4447 - loss: 0.8573 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7435 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 31ms/step - accuracy: 0.4996 - f1_score: 0.4295 - loss: 0.8196 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7401 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 32ms/step - accuracy: 0.5106 - f1_score: 0.4004 - loss: 0.8315 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7413 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 32ms/step - accuracy: 0.5046 - f1_score: 0.3270 - loss: 0.8191 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7442 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 32ms/step - accuracy: 0.4882 - f1_score: 0.3916 - loss: 0.7775 - val_accuracy: 0.5400 - val_f1_score: 0.4103 - val_loss: 0.7488 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 32ms/step - accuracy: 0.5182 - f1_score: 0.4321 - loss: 0.7814 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7433 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 32ms/step - accuracy: 0.5089 - f1_score: 0.3477 - loss: 0.7861 - val_accuracy: 0.5200 - val_f1_score: 0.4000 - val_loss: 0.7497 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 32ms/step - accuracy: 0.5051 - f1_score: 0.3225 - loss: 0.7661 - val_accuracy: 0.5400 - val_f1_score: 0.0000e+00 - val_loss: 0.7432 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 31ms/step - accuracy: 0.5051 - f1_score: 0.4008 - loss: 0.7633 - val_accuracy: 0.4800 - val_f1_score: 0.3500 - val_loss: 0.7491 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 31ms/step - accuracy: 0.5042 - f1_score: 0.3061 - loss: 0.7690 - val_accuracy: 0.4800 - val_f1_score: 0.3158 - val_loss: 0.7461 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 31ms/step - accuracy: 0.5038 - f1_score: 0.3915 - loss: 0.7627 - val_accuracy: 0.5200 - val_f1_score: 0.0000e+00 - val_loss: 0.7452 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 36ms/step - accuracy: 0.4962 - f1_score: 0.4032 - loss: 0.7570 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 0.7489 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 32ms/step - accuracy: 0.4856 - f1_score: 0.3916 - loss: 0.7655 - val_accuracy: 0.5000 - val_f1_score: 0.3590 - val_loss: 0.7455 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 31ms/step - accuracy: 0.5156 - f1_score: 0.4364 - loss: 0.7636 - val_accuracy: 0.5600 - val_f1_score: 0.0833 - val_loss: 0.7433 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 31ms/step - accuracy: 0.5080 - f1_score: 0.3747 - loss: 0.7521 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7410 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 32ms/step - accuracy: 0.4835 - f1_score: 0.2022 - loss: 0.7582 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7421 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 35ms/step - accuracy: 0.5165 - f1_score: 0.4993 - loss: 0.7530 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7487 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 32ms/step - accuracy: 0.5038 - f1_score: 0.4332 - loss: 0.7509 - val_accuracy: 0.4400 - val_f1_score: 0.2632 - val_loss: 0.7470 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 32ms/step - accuracy: 0.5038 - f1_score: 0.4491 - loss: 0.7568 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7476 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 32ms/step - accuracy: 0.5148 - f1_score: 0.4712 - loss: 0.7473 - val_accuracy: 0.4000 - val_f1_score: 0.5312 - val_loss: 0.7488 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 32ms/step - accuracy: 0.5215 - f1_score: 0.4497 - loss: 0.7482 - val_accuracy: 0.5800 - val_f1_score: 0.1600 - val_loss: 0.7444 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 32ms/step - accuracy: 0.5030 - f1_score: 0.4440 - loss: 0.7507 - val_accuracy: 0.4600 - val_f1_score: 0.4490 - val_loss: 0.7484 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 32ms/step - accuracy: 0.4958 - f1_score: 0.4083 - loss: 0.7478 - val_accuracy: 0.4000 - val_f1_score: 0.2500 - val_loss: 0.7467 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 32ms/step - accuracy: 0.5144 - f1_score: 0.4121 - loss: 0.7545 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7464 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 1s - 32ms/step - accuracy: 0.5122 - f1_score: 0.5165 - loss: 0.7500 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7464 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 1s - 32ms/step - accuracy: 0.5186 - f1_score: 0.5312 - loss: 0.7439 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7469 - learning_rate: 4.9148e-04\nEpoch 34/200\n37/37 - 1s - 32ms/step - accuracy: 0.4966 - f1_score: 0.5131 - loss: 0.7468 - val_accuracy: 0.5800 - val_f1_score: 0.2222 - val_loss: 0.7429 - learning_rate: 4.5920e-04\nEpoch 35/200\n37/37 - 1s - 32ms/step - accuracy: 0.5025 - f1_score: 0.4495 - loss: 0.7440 - val_accuracy: 0.5800 - val_f1_score: 0.0870 - val_loss: 0.7415 - learning_rate: 4.2723e-04\nEpoch 36/200\n37/37 - 1s - 32ms/step - accuracy: 0.4789 - f1_score: 0.3704 - loss: 0.7520 - val_accuracy: 0.5800 - val_f1_score: 0.0870 - val_loss: 0.7413 - learning_rate: 3.9575e-04\nEpoch 37/200\n37/37 - 1s - 32ms/step - accuracy: 0.4937 - f1_score: 0.4216 - loss: 0.7461 - val_accuracy: 0.5600 - val_f1_score: 0.2143 - val_loss: 0.7430 - learning_rate: 3.6494e-04\nEpoch 38/200\n37/37 - 1s - 32ms/step - accuracy: 0.5013 - f1_score: 0.5319 - loss: 0.7478 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7440 - learning_rate: 3.3498e-04\nEpoch 39/200\n37/37 - 1s - 32ms/step - accuracy: 0.5186 - f1_score: 0.5882 - loss: 0.7436 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7445 - learning_rate: 3.0602e-04\nEpoch 40/200\n37/37 - 1s - 36ms/step - accuracy: 0.5021 - f1_score: 0.5757 - loss: 0.7510 - val_accuracy: 0.5200 - val_f1_score: 0.5556 - val_loss: 0.7443 - learning_rate: 2.7820e-04\nEpoch 41/200\n37/37 - 1s - 32ms/step - accuracy: 0.4932 - f1_score: 0.5509 - loss: 0.7474 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.7439 - learning_rate: 2.5163e-04\nEpoch 42/200\n37/37 - 1s - 32ms/step - accuracy: 0.5186 - f1_score: 0.5652 - loss: 0.7446 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7443 - learning_rate: 2.2643e-04\nEpoch 43/200\n37/37 - 1s - 32ms/step - accuracy: 0.5169 - f1_score: 0.5735 - loss: 0.7419 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7449 - learning_rate: 2.0267e-04\nEpoch 44/200\n37/37 - 1s - 32ms/step - accuracy: 0.5258 - f1_score: 0.5873 - loss: 0.7469 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 0.7452 - learning_rate: 1.8042e-04\nEpoch 45/200\n37/37 - 1s - 32ms/step - accuracy: 0.5144 - f1_score: 0.5647 - loss: 0.7451 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7451 - learning_rate: 1.5972e-04\nEpoch 46/200\n37/37 - 1s - 32ms/step - accuracy: 0.5127 - f1_score: 0.5534 - loss: 0.7448 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7453 - learning_rate: 1.4058e-04\nEpoch 47/200\n37/37 - 1s - 32ms/step - accuracy: 0.5215 - f1_score: 0.5684 - loss: 0.7450 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7457 - learning_rate: 1.2302e-04\nEpoch 48/200\n37/37 - 1s - 32ms/step - accuracy: 0.5097 - f1_score: 0.5564 - loss: 0.7466 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7466 - learning_rate: 1.0700e-04\nEpoch 49/200\n37/37 - 1s - 32ms/step - accuracy: 0.5004 - f1_score: 0.5469 - loss: 0.7461 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7466 - learning_rate: 9.2503e-05\nEpoch 50/200\n37/37 - 1s - 32ms/step - accuracy: 0.5169 - f1_score: 0.5435 - loss: 0.7427 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7454 - learning_rate: 7.9466e-05\nEpoch 51/200\n37/37 - 1s - 32ms/step - accuracy: 0.5013 - f1_score: 0.5146 - loss: 0.7464 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7446 - learning_rate: 6.7829e-05\nEpoch 52/200\n37/37 - 1s - 32ms/step - accuracy: 0.5279 - f1_score: 0.5330 - loss: 0.7432 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7445 - learning_rate: 5.7516e-05\nEpoch 53/200\n37/37 - 1s - 32ms/step - accuracy: 0.5169 - f1_score: 0.5039 - loss: 0.7426 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7446 - learning_rate: 4.8444e-05\nEpoch 54/200\n37/37 - 1s - 32ms/step - accuracy: 0.5042 - f1_score: 0.4887 - loss: 0.7428 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7445 - learning_rate: 4.0524e-05\nEpoch 55/200\n37/37 - 1s - 32ms/step - accuracy: 0.5008 - f1_score: 0.4747 - loss: 0.7494 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7444 - learning_rate: 3.3661e-05\nEpoch 56/200\n37/37 - 1s - 32ms/step - accuracy: 0.5030 - f1_score: 0.4946 - loss: 0.7442 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7441 - learning_rate: 2.7761e-05\nEpoch 57/200\n37/37 - 1s - 32ms/step - accuracy: 0.5106 - f1_score: 0.4865 - loss: 0.7476 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 0.7438 - learning_rate: 2.2728e-05\nEpoch 58/200\n37/37 - 1s - 32ms/step - accuracy: 0.5156 - f1_score: 0.5007 - loss: 0.7439 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 0.7437 - learning_rate: 1.8470e-05\nEpoch 59/200\n37/37 - 1s - 32ms/step - accuracy: 0.5270 - f1_score: 0.5000 - loss: 0.7436 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 0.7438 - learning_rate: 1.4895e-05\nEpoch 60/200\n37/37 - 1s - 32ms/step - accuracy: 0.5110 - f1_score: 0.4788 - loss: 0.7427 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 0.7439 - learning_rate: 1.1919e-05\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step\noldB → F1 = 0.5556\n              precision    recall  f1-score   support\n\n        Left       0.61      0.39      0.48        28\n       Right       0.47      0.68      0.56        22\n\n    accuracy                           0.52        50\n   macro avg       0.54      0.54      0.52        50\nweighted avg       0.55      0.52      0.51        50\n\n\n>>> Training model1\nEpoch 1/200\n37/37 - 27s - 724ms/step - accuracy: 0.4983 - f1_score: 0.5693 - loss: 0.6934 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6979 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 23ms/step - accuracy: 0.5008 - f1_score: 0.4918 - loss: 0.6937 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6908 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 22ms/step - accuracy: 0.4903 - f1_score: 0.6072 - loss: 0.6937 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6990 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 23ms/step - accuracy: 0.4945 - f1_score: 0.3663 - loss: 0.6941 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6934 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 23ms/step - accuracy: 0.5127 - f1_score: 0.6778 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6980 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 22ms/step - accuracy: 0.5144 - f1_score: 0.6793 - loss: 0.6930 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6970 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 22ms/step - accuracy: 0.4810 - f1_score: 0.5869 - loss: 0.6937 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6933 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 22ms/step - accuracy: 0.5139 - f1_score: 0.6789 - loss: 0.6928 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7067 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 22ms/step - accuracy: 0.5055 - f1_score: 0.4946 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7245 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 22ms/step - accuracy: 0.5144 - f1_score: 0.6793 - loss: 0.6923 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7053 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 22ms/step - accuracy: 0.5224 - f1_score: 0.6863 - loss: 0.6904 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7880 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 22ms/step - accuracy: 0.5106 - f1_score: 0.6760 - loss: 0.6885 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7404 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 22ms/step - accuracy: 0.4924 - f1_score: 0.5498 - loss: 0.6882 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7775 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 24ms/step - accuracy: 0.5017 - f1_score: 0.4496 - loss: 0.6873 - val_accuracy: 0.4800 - val_f1_score: 0.3158 - val_loss: 0.8550 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 25ms/step - accuracy: 0.5017 - f1_score: 0.6650 - loss: 0.6823 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.8444 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 23ms/step - accuracy: 0.5072 - f1_score: 0.4214 - loss: 0.6808 - val_accuracy: 0.5400 - val_f1_score: 0.2069 - val_loss: 0.8014 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 23ms/step - accuracy: 0.5397 - f1_score: 0.0840 - loss: 0.6811 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 1.1160 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 22ms/step - accuracy: 0.5110 - f1_score: 0.0736 - loss: 0.6864 - val_accuracy: 0.4200 - val_f1_score: 0.4912 - val_loss: 0.7899 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 22ms/step - accuracy: 0.5156 - f1_score: 0.5482 - loss: 0.6853 - val_accuracy: 0.5000 - val_f1_score: 0.2857 - val_loss: 0.7294 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 23ms/step - accuracy: 0.5127 - f1_score: 0.5073 - loss: 0.6834 - val_accuracy: 0.5400 - val_f1_score: 0.2581 - val_loss: 0.8436 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 22ms/step - accuracy: 0.5203 - f1_score: 0.1083 - loss: 0.6739 - val_accuracy: 0.5600 - val_f1_score: 0.2143 - val_loss: 0.8486 - learning_rate: 8.3736e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step\nmodel1 → F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model2\nEpoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"37/37 - 5s - 122ms/step - accuracy: 0.5055 - f1_score: 0.4566 - loss: 0.6949 - val_accuracy: 0.4800 - val_f1_score: 0.4800 - val_loss: 0.7015 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 22ms/step - accuracy: 0.5025 - f1_score: 0.3721 - loss: 0.6944 - val_accuracy: 0.5000 - val_f1_score: 0.3590 - val_loss: 0.6964 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 21ms/step - accuracy: 0.5190 - f1_score: 0.2991 - loss: 0.6915 - val_accuracy: 0.6000 - val_f1_score: 0.4118 - val_loss: 0.6857 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 20ms/step - accuracy: 0.5076 - f1_score: 0.3697 - loss: 0.6942 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 0.6899 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 23ms/step - accuracy: 0.5118 - f1_score: 0.4197 - loss: 0.6927 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.7105 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 20ms/step - accuracy: 0.5173 - f1_score: 0.4177 - loss: 0.6936 - val_accuracy: 0.5400 - val_f1_score: 0.3784 - val_loss: 0.6900 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 22ms/step - accuracy: 0.4996 - f1_score: 0.6106 - loss: 0.6932 - val_accuracy: 0.4400 - val_f1_score: 0.5625 - val_loss: 0.7002 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 20ms/step - accuracy: 0.5055 - f1_score: 0.5709 - loss: 0.6928 - val_accuracy: 0.5400 - val_f1_score: 0.4390 - val_loss: 0.6980 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 20ms/step - accuracy: 0.4958 - f1_score: 0.3567 - loss: 0.6943 - val_accuracy: 0.5800 - val_f1_score: 0.3636 - val_loss: 0.6945 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 22ms/step - accuracy: 0.5000 - f1_score: 0.4897 - loss: 0.6933 - val_accuracy: 0.5600 - val_f1_score: 0.6452 - val_loss: 0.6950 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 20ms/step - accuracy: 0.5051 - f1_score: 0.6518 - loss: 0.6927 - val_accuracy: 0.5000 - val_f1_score: 0.6377 - val_loss: 0.6921 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 20ms/step - accuracy: 0.5380 - f1_score: 0.5103 - loss: 0.6921 - val_accuracy: 0.5800 - val_f1_score: 0.5116 - val_loss: 0.6921 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 20ms/step - accuracy: 0.5046 - f1_score: 0.4700 - loss: 0.6944 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 0.7043 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 21ms/step - accuracy: 0.5063 - f1_score: 0.6313 - loss: 0.6925 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7065 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 23ms/step - accuracy: 0.5190 - f1_score: 0.3633 - loss: 0.6908 - val_accuracy: 0.5800 - val_f1_score: 0.4615 - val_loss: 0.6982 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 21ms/step - accuracy: 0.5072 - f1_score: 0.4435 - loss: 0.6931 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 0.7024 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 21ms/step - accuracy: 0.5139 - f1_score: 0.5966 - loss: 0.6904 - val_accuracy: 0.4800 - val_f1_score: 0.5667 - val_loss: 0.7077 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 21ms/step - accuracy: 0.5114 - f1_score: 0.5843 - loss: 0.6921 - val_accuracy: 0.4800 - val_f1_score: 0.6176 - val_loss: 0.6988 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 21ms/step - accuracy: 0.5131 - f1_score: 0.5984 - loss: 0.6912 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.6802 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 20ms/step - accuracy: 0.5051 - f1_score: 0.4922 - loss: 0.6944 - val_accuracy: 0.6000 - val_f1_score: 0.5000 - val_loss: 0.6942 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 20ms/step - accuracy: 0.5051 - f1_score: 0.3733 - loss: 0.6922 - val_accuracy: 0.5600 - val_f1_score: 0.5000 - val_loss: 0.7009 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 20ms/step - accuracy: 0.5084 - f1_score: 0.6353 - loss: 0.6922 - val_accuracy: 0.5200 - val_f1_score: 0.6250 - val_loss: 0.6999 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 20ms/step - accuracy: 0.5198 - f1_score: 0.3790 - loss: 0.6911 - val_accuracy: 0.5400 - val_f1_score: 0.3030 - val_loss: 0.6987 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 20ms/step - accuracy: 0.5173 - f1_score: 0.5122 - loss: 0.6905 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.6961 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 20ms/step - accuracy: 0.5203 - f1_score: 0.6115 - loss: 0.6896 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.6947 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 20ms/step - accuracy: 0.5072 - f1_score: 0.4976 - loss: 0.6934 - val_accuracy: 0.5800 - val_f1_score: 0.2222 - val_loss: 0.6924 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 21ms/step - accuracy: 0.5106 - f1_score: 0.5734 - loss: 0.6907 - val_accuracy: 0.5000 - val_f1_score: 0.5763 - val_loss: 0.6983 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 20ms/step - accuracy: 0.5110 - f1_score: 0.4693 - loss: 0.6900 - val_accuracy: 0.5600 - val_f1_score: 0.2143 - val_loss: 0.6945 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 20ms/step - accuracy: 0.5270 - f1_score: 0.3396 - loss: 0.6893 - val_accuracy: 0.6000 - val_f1_score: 0.3333 - val_loss: 0.6918 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 20ms/step - accuracy: 0.5283 - f1_score: 0.3185 - loss: 0.6906 - val_accuracy: 0.6800 - val_f1_score: 0.5789 - val_loss: 0.6904 - learning_rate: 5.8827e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step\nmodel2 → F1 = 0.6452\n              precision    recall  f1-score   support\n\n        Left       0.80      0.29      0.42        28\n       Right       0.50      0.91      0.65        22\n\n    accuracy                           0.56        50\n   macro avg       0.65      0.60      0.53        50\nweighted avg       0.67      0.56      0.52        50\n\n\n>>> Training model3\nEpoch 1/200\n37/37 - 9s - 245ms/step - accuracy: 0.5245 - f1_score: 0.5857 - loss: 0.7113 - val_accuracy: 0.4600 - val_f1_score: 0.5846 - val_loss: 0.7159 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 38ms/step - accuracy: 0.5384 - f1_score: 0.6687 - loss: 0.6851 - val_accuracy: 0.4400 - val_f1_score: 0.5758 - val_loss: 0.7471 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 38ms/step - accuracy: 0.5832 - f1_score: 0.6713 - loss: 0.6734 - val_accuracy: 0.4200 - val_f1_score: 0.5672 - val_loss: 1.0426 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 38ms/step - accuracy: 0.6330 - f1_score: 0.6310 - loss: 0.6392 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.8019 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 3s - 86ms/step - accuracy: 0.7035 - f1_score: 0.7402 - loss: 0.5712 - val_accuracy: 0.5600 - val_f1_score: 0.5926 - val_loss: 1.0777 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 38ms/step - accuracy: 0.7825 - f1_score: 0.7952 - loss: 0.4369 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 2.1614 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 3s - 86ms/step - accuracy: 0.8780 - f1_score: 0.8805 - loss: 0.2796 - val_accuracy: 0.5000 - val_f1_score: 0.6269 - val_loss: 4.6448 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 38ms/step - accuracy: 0.9299 - f1_score: 0.9301 - loss: 0.1845 - val_accuracy: 0.3400 - val_f1_score: 0.4000 - val_loss: 3.5604 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 38ms/step - accuracy: 0.9405 - f1_score: 0.9413 - loss: 0.1506 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 2.8766 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 38ms/step - accuracy: 0.9654 - f1_score: 0.9652 - loss: 0.0919 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 6.2940 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 39ms/step - accuracy: 0.9742 - f1_score: 0.9731 - loss: 0.0704 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 6.1599 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 38ms/step - accuracy: 0.9747 - f1_score: 0.9747 - loss: 0.0658 - val_accuracy: 0.5800 - val_f1_score: 0.5116 - val_loss: 4.2310 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 38ms/step - accuracy: 0.9856 - f1_score: 0.9857 - loss: 0.0340 - val_accuracy: 0.5000 - val_f1_score: 0.4681 - val_loss: 4.8393 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 38ms/step - accuracy: 0.9797 - f1_score: 0.9795 - loss: 0.0475 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 4.3651 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 38ms/step - accuracy: 0.9751 - f1_score: 0.9754 - loss: 0.0398 - val_accuracy: 0.4800 - val_f1_score: 0.5357 - val_loss: 8.9923 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 38ms/step - accuracy: 0.9890 - f1_score: 0.9891 - loss: 0.0231 - val_accuracy: 0.4600 - val_f1_score: 0.4490 - val_loss: 9.1054 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 38ms/step - accuracy: 0.9831 - f1_score: 0.9832 - loss: 0.0282 - val_accuracy: 0.5000 - val_f1_score: 0.5283 - val_loss: 11.6270 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 39ms/step - accuracy: 0.9899 - f1_score: 0.9900 - loss: 0.0197 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 11.6763 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 38ms/step - accuracy: 0.9899 - f1_score: 0.9900 - loss: 0.0291 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 4.8235 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 38ms/step - accuracy: 0.9966 - f1_score: 0.9967 - loss: 0.0110 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 5.8350 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 38ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0054 - val_accuracy: 0.5600 - val_f1_score: 0.5217 - val_loss: 5.0930 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 38ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0060 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 5.9713 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 38ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0025 - val_accuracy: 0.5600 - val_f1_score: 0.4762 - val_loss: 6.1423 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0940e-04 - val_accuracy: 0.5800 - val_f1_score: 0.4878 - val_loss: 6.8666 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 38ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0026 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 7.3155 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6342e-04 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 7.3225 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7015e-04 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 7.9224 - learning_rate: 6.8101e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step\nmodel3 → F1 = 0.6269\n              precision    recall  f1-score   support\n\n        Left       0.80      0.14      0.24        28\n       Right       0.47      0.95      0.63        22\n\n    accuracy                           0.50        50\n   macro avg       0.63      0.55      0.43        50\nweighted avg       0.65      0.50      0.41        50\n\n\n>>> Training model4\nEpoch 1/200\n37/37 - 9s - 244ms/step - accuracy: 0.5127 - f1_score: 0.4602 - loss: 0.6917 - val_accuracy: 0.4600 - val_f1_score: 0.5574 - val_loss: 0.7609 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 4s - 117ms/step - accuracy: 0.5127 - f1_score: 0.4706 - loss: 0.6915 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7236 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 4s - 117ms/step - accuracy: 0.5414 - f1_score: 0.5082 - loss: 0.6892 - val_accuracy: 0.5400 - val_f1_score: 0.4103 - val_loss: 0.6868 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 4s - 117ms/step - accuracy: 0.5363 - f1_score: 0.4122 - loss: 0.6906 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7482 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 4s - 117ms/step - accuracy: 0.5220 - f1_score: 0.3310 - loss: 0.6925 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.6956 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 4s - 117ms/step - accuracy: 0.5190 - f1_score: 0.4958 - loss: 0.6892 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 0.7487 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 4s - 118ms/step - accuracy: 0.5317 - f1_score: 0.5007 - loss: 0.6921 - val_accuracy: 0.4800 - val_f1_score: 0.5937 - val_loss: 0.7123 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 4s - 117ms/step - accuracy: 0.5182 - f1_score: 0.6178 - loss: 0.6894 - val_accuracy: 0.4200 - val_f1_score: 0.5797 - val_loss: 0.6975 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 4s - 117ms/step - accuracy: 0.5346 - f1_score: 0.5480 - loss: 0.6896 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.7023 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 4s - 117ms/step - accuracy: 0.5481 - f1_score: 0.5311 - loss: 0.6878 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7198 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 4s - 117ms/step - accuracy: 0.5405 - f1_score: 0.4693 - loss: 0.6849 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7217 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 4s - 117ms/step - accuracy: 0.5452 - f1_score: 0.5299 - loss: 0.6867 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.7152 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 4s - 117ms/step - accuracy: 0.5549 - f1_score: 0.5523 - loss: 0.6840 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.7007 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 4s - 116ms/step - accuracy: 0.5574 - f1_score: 0.4812 - loss: 0.6856 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7045 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 4s - 117ms/step - accuracy: 0.5317 - f1_score: 0.4854 - loss: 0.6855 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.7062 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 4s - 117ms/step - accuracy: 0.5503 - f1_score: 0.4392 - loss: 0.6842 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.7493 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 4s - 117ms/step - accuracy: 0.5557 - f1_score: 0.3585 - loss: 0.6848 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 0.7384 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 4s - 117ms/step - accuracy: 0.5376 - f1_score: 0.4593 - loss: 0.6763 - val_accuracy: 0.5800 - val_f1_score: 0.5532 - val_loss: 0.7712 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 4s - 117ms/step - accuracy: 0.5346 - f1_score: 0.4555 - loss: 0.6887 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 0.7034 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 4s - 117ms/step - accuracy: 0.5274 - f1_score: 0.6200 - loss: 0.6823 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.7495 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 4s - 118ms/step - accuracy: 0.5752 - f1_score: 0.5273 - loss: 0.6771 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7045 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 4s - 117ms/step - accuracy: 0.5431 - f1_score: 0.4411 - loss: 0.6854 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 0.7111 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 4s - 117ms/step - accuracy: 0.5629 - f1_score: 0.5525 - loss: 0.6746 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7800 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 4s - 118ms/step - accuracy: 0.5697 - f1_score: 0.5002 - loss: 0.6738 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7275 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 4s - 117ms/step - accuracy: 0.5756 - f1_score: 0.5143 - loss: 0.6728 - val_accuracy: 0.5000 - val_f1_score: 0.5283 - val_loss: 0.7328 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 4s - 117ms/step - accuracy: 0.5359 - f1_score: 0.4852 - loss: 0.6866 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7148 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 4s - 117ms/step - accuracy: 0.5705 - f1_score: 0.5506 - loss: 0.6756 - val_accuracy: 0.4600 - val_f1_score: 0.4255 - val_loss: 0.7393 - learning_rate: 6.8101e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step\nmodel4 → F1 = 0.5938\n              precision    recall  f1-score   support\n\n        Left       0.62      0.18      0.28        28\n       Right       0.45      0.86      0.59        22\n\n    accuracy                           0.48        50\n   macro avg       0.54      0.52      0.44        50\nweighted avg       0.55      0.48      0.42        50\n\n\n>>> Training model5\nEpoch 1/200\n37/37 - 9s - 230ms/step - accuracy: 0.5068 - f1_score: 0.4944 - loss: 1.0395 - val_accuracy: 0.4000 - val_f1_score: 0.3478 - val_loss: 1.0000 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 38ms/step - accuracy: 0.5021 - f1_score: 0.4903 - loss: 0.7580 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 1.0513 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 22ms/step - accuracy: 0.5203 - f1_score: 0.5031 - loss: 0.7051 - val_accuracy: 0.5000 - val_f1_score: 0.3243 - val_loss: 0.6977 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 22ms/step - accuracy: 0.5106 - f1_score: 0.5377 - loss: 0.7067 - val_accuracy: 0.4200 - val_f1_score: 0.5538 - val_loss: 0.7637 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 22ms/step - accuracy: 0.5321 - f1_score: 0.5492 - loss: 0.7178 - val_accuracy: 0.6200 - val_f1_score: 0.2400 - val_loss: 0.7268 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 22ms/step - accuracy: 0.5655 - f1_score: 0.5608 - loss: 0.6907 - val_accuracy: 0.6000 - val_f1_score: 0.3750 - val_loss: 0.6891 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 23ms/step - accuracy: 0.6470 - f1_score: 0.6703 - loss: 0.6275 - val_accuracy: 0.4200 - val_f1_score: 0.5538 - val_loss: 1.0353 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 36ms/step - accuracy: 0.7010 - f1_score: 0.6982 - loss: 0.5592 - val_accuracy: 0.6400 - val_f1_score: 0.6400 - val_loss: 1.0649 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 22ms/step - accuracy: 0.7175 - f1_score: 0.7223 - loss: 0.5403 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 1.3695 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 22ms/step - accuracy: 0.7905 - f1_score: 0.7891 - loss: 0.4356 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 1.8767 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 22ms/step - accuracy: 0.8552 - f1_score: 0.8550 - loss: 0.3423 - val_accuracy: 0.4400 - val_f1_score: 0.4815 - val_loss: 2.8246 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 22ms/step - accuracy: 0.8991 - f1_score: 0.8973 - loss: 0.2593 - val_accuracy: 0.4600 - val_f1_score: 0.3721 - val_loss: 2.8124 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 22ms/step - accuracy: 0.9117 - f1_score: 0.9137 - loss: 0.2320 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 3.3747 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 23ms/step - accuracy: 0.9206 - f1_score: 0.9211 - loss: 0.2054 - val_accuracy: 0.4800 - val_f1_score: 0.4800 - val_loss: 3.9415 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 22ms/step - accuracy: 0.9379 - f1_score: 0.9399 - loss: 0.1562 - val_accuracy: 0.4600 - val_f1_score: 0.4906 - val_loss: 5.1106 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 22ms/step - accuracy: 0.9413 - f1_score: 0.9427 - loss: 0.1661 - val_accuracy: 0.5800 - val_f1_score: 0.5532 - val_loss: 3.9801 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 22ms/step - accuracy: 0.9649 - f1_score: 0.9660 - loss: 0.0950 - val_accuracy: 0.5200 - val_f1_score: 0.5000 - val_loss: 4.6457 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 23ms/step - accuracy: 0.9671 - f1_score: 0.9672 - loss: 0.1007 - val_accuracy: 0.4800 - val_f1_score: 0.4800 - val_loss: 4.6323 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 22ms/step - accuracy: 0.9810 - f1_score: 0.9810 - loss: 0.0615 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 4.6281 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 22ms/step - accuracy: 0.9873 - f1_score: 0.9875 - loss: 0.0421 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 5.4783 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 22ms/step - accuracy: 0.9886 - f1_score: 0.9885 - loss: 0.0334 - val_accuracy: 0.4400 - val_f1_score: 0.4400 - val_loss: 7.0177 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 22ms/step - accuracy: 0.9755 - f1_score: 0.9757 - loss: 0.0663 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 6.7635 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 22ms/step - accuracy: 0.9835 - f1_score: 0.9842 - loss: 0.0490 - val_accuracy: 0.5600 - val_f1_score: 0.5769 - val_loss: 6.3263 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 22ms/step - accuracy: 0.9916 - f1_score: 0.9918 - loss: 0.0315 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 6.7446 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 23ms/step - accuracy: 0.9954 - f1_score: 0.9955 - loss: 0.0163 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 6.8645 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 23ms/step - accuracy: 0.9979 - f1_score: 0.9979 - loss: 0.0098 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 6.7764 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 22ms/step - accuracy: 0.9992 - f1_score: 0.9992 - loss: 0.0032 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 7.1084 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 23ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 7.3238 - learning_rate: 6.5084e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step\nmodel5 → F1 = 0.6400\n              precision    recall  f1-score   support\n\n        Left       0.73      0.57      0.64        28\n       Right       0.57      0.73      0.64        22\n\n    accuracy                           0.64        50\n   macro avg       0.65      0.65      0.64        50\nweighted avg       0.66      0.64      0.64        50\n\n\n>>> Training model6\nEpoch 1/200\n37/37 - 7s - 199ms/step - accuracy: 0.4903 - f1_score: 0.5851 - loss: 0.6955 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 0.6924 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 38ms/step - accuracy: 0.5342 - f1_score: 0.5569 - loss: 0.6897 - val_accuracy: 0.4800 - val_f1_score: 0.5517 - val_loss: 0.7261 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 38ms/step - accuracy: 0.4941 - f1_score: 0.5029 - loss: 0.6930 - val_accuracy: 0.5000 - val_f1_score: 0.0741 - val_loss: 0.6992 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 39ms/step - accuracy: 0.5245 - f1_score: 0.2909 - loss: 0.6929 - val_accuracy: 0.6200 - val_f1_score: 0.6122 - val_loss: 0.7258 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 38ms/step - accuracy: 0.5021 - f1_score: 0.3205 - loss: 0.6946 - val_accuracy: 0.5200 - val_f1_score: 0.5556 - val_loss: 0.7089 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 38ms/step - accuracy: 0.5076 - f1_score: 0.4394 - loss: 0.6930 - val_accuracy: 0.5400 - val_f1_score: 0.0000e+00 - val_loss: 0.6891 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 38ms/step - accuracy: 0.5089 - f1_score: 0.3203 - loss: 0.6935 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 0.7057 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 38ms/step - accuracy: 0.5173 - f1_score: 0.5830 - loss: 0.6920 - val_accuracy: 0.4800 - val_f1_score: 0.3810 - val_loss: 0.7072 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 38ms/step - accuracy: 0.4987 - f1_score: 0.5332 - loss: 0.6949 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7015 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 38ms/step - accuracy: 0.4983 - f1_score: 0.6518 - loss: 0.6935 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 0.7022 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 38ms/step - accuracy: 0.5004 - f1_score: 0.3829 - loss: 0.6933 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 0.7040 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 37ms/step - accuracy: 0.5177 - f1_score: 0.6801 - loss: 0.6912 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7486 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 37ms/step - accuracy: 0.5118 - f1_score: 0.5699 - loss: 0.6927 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.7377 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 37ms/step - accuracy: 0.5270 - f1_score: 0.6051 - loss: 0.6922 - val_accuracy: 0.4200 - val_f1_score: 0.4912 - val_loss: 0.7390 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 37ms/step - accuracy: 0.5139 - f1_score: 0.4909 - loss: 0.6927 - val_accuracy: 0.4800 - val_f1_score: 0.3158 - val_loss: 0.7080 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 37ms/step - accuracy: 0.5270 - f1_score: 0.3785 - loss: 0.6920 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 0.6838 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 38ms/step - accuracy: 0.5266 - f1_score: 0.3456 - loss: 0.6920 - val_accuracy: 0.5400 - val_f1_score: 0.5818 - val_loss: 0.7341 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 38ms/step - accuracy: 0.5127 - f1_score: 0.5290 - loss: 0.6930 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 0.7103 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 37ms/step - accuracy: 0.5182 - f1_score: 0.5360 - loss: 0.6912 - val_accuracy: 0.5600 - val_f1_score: 0.5926 - val_loss: 0.7145 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 38ms/step - accuracy: 0.4996 - f1_score: 0.4899 - loss: 0.6941 - val_accuracy: 0.5800 - val_f1_score: 0.4615 - val_loss: 0.6984 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 38ms/step - accuracy: 0.5220 - f1_score: 0.5751 - loss: 0.6904 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 0.6867 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 38ms/step - accuracy: 0.5346 - f1_score: 0.5480 - loss: 0.6903 - val_accuracy: 0.6000 - val_f1_score: 0.4444 - val_loss: 0.7001 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 37ms/step - accuracy: 0.5042 - f1_score: 0.4891 - loss: 0.6935 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.7013 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 37ms/step - accuracy: 0.5051 - f1_score: 0.4099 - loss: 0.6905 - val_accuracy: 0.5600 - val_f1_score: 0.5000 - val_loss: 0.7024 - learning_rate: 7.6518e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step\nmodel6 → F1 = 0.6122\n              precision    recall  f1-score   support\n\n        Left       0.70      0.57      0.63        28\n       Right       0.56      0.68      0.61        22\n\n    accuracy                           0.62        50\n   macro avg       0.63      0.63      0.62        50\nweighted avg       0.63      0.62      0.62        50\n\n\n=== Final best: model2 (F1=0.6452) ===\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.metrics import f1_score, classification_report\nfrom mne.decoding import CSP\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n\n# --- 0) Config ---\ndata_dir   = './preprocessed'\noutput_dir = './models3'\nos.makedirs(output_dir, exist_ok=True)\n\neeg_indices = [1, 2, 3, 4]  # C3, CZ, C4, PZ\n\n# --- 1) Load & filter data ---\ntrain_npz = np.load(os.path.join(data_dir, 'train_MI.npz'))\nval_npz   = np.load(os.path.join(data_dir, 'validation_MI.npz'))\n\nX_train_all, y_train = train_npz['X'], train_npz['y']\nX_val_all,   y_val   = val_npz['X'],   val_npz['y']\n\n# Filter for EEG channels only\nX_train_raw = X_train_all[:, eeg_indices, :].transpose(0, 2, 1).astype('float32')  # (n, T, 4)\nX_val_raw   = X_val_all[:,   eeg_indices, :].transpose(0, 2, 1).astype('float32')  # (n, T, 4)\n\n# --- 2) Binarize labels ---\ny_train_bin = (y_train == 'Right').astype(int)\ny_val_bin   = (y_val   == 'Right').astype(int)\n\n# --- 3) CSP for models 3, 4, 5 ---\ncsp = CSP(n_components=4, log=False, norm_trace=False)\nX_train_csp_input = X_train_raw.transpose(0, 2, 1).astype('float64').copy()  # (n, channels, time)\ncsp.fit(X_train_csp_input, y_train_bin)  # ← NO 'rank' argument\n\nW = csp.filters_[:4]\n\ndef apply_csp(X):  # X: (n, T, C)\n    return np.stack([W.dot(ep.T) for ep in X], axis=0)\n\n\nXtr_csp = apply_csp(X_train_raw).astype('float32')\nXvl_csp = apply_csp(X_val_raw).astype('float32')\n\nXtr_csp = Xtr_csp.transpose(0, 2, 1)  # (n, T, 4)\nXvl_csp = Xvl_csp.transpose(0, 2, 1)\n\n\n# For 2D models\nXtr_csp_2d = Xtr_csp[..., np.newaxis]\nXvl_csp_2d = Xvl_csp[..., np.newaxis]\n\n# --- 4) One-hot labels ---\nytr_oh = keras.utils.to_categorical(y_train_bin, 2)\nyvl_oh = keras.utils.to_categorical(y_val_bin,   2)\n\n# --- 5) Data augmentation ---\ndef aug_gen(X, y, seed=0, batch_size=32):\n    n = X.shape[0]\n    rng = np.random.RandomState(seed)\n    while True:\n        idx = rng.randint(0, n, batch_size)\n        bx, by = X[idx].copy(), y[idx]\n        bx += rng.normal(0, 0.005, bx.shape)\n        yield bx, by\n\ntrain_gen_raw   = aug_gen(X_train_raw,  ytr_oh, seed=0, batch_size=64)\ntrain_gen_csp1d = aug_gen(Xtr_csp,      ytr_oh, seed=1, batch_size=64)\ntrain_gen_csp2d = aug_gen(Xtr_csp_2d,   ytr_oh, seed=2, batch_size=64)\n\nsteps_raw   = len(X_train_raw)  // 64\nsteps_csp1d = len(Xtr_csp)      // 64\nsteps_csp2d = len(Xtr_csp_2d)   // 64\n\n# --- 6) Cosine LR schedule ---\ndef cosine_lr(epoch, lr_max=5e-5, epochs=200):\n    return lr_max * (1 + np.cos(np.pi * epoch / epochs)) / 2\n\n# --- 7) F1 Score Metric ---\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        preds  = tf.argmax(y_pred, axis=1)\n        labels = tf.argmax(y_true, axis=1)\n        self.tp.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(preds == 1, labels == 1), tf.float32)))\n        self.fp.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(preds == 1, labels == 0), tf.float32)))\n        self.fn.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(preds == 0, labels == 1), tf.float32)))\n\n    def result(self):\n        p = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n        r = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n        return 2 * (p * r) / (p + r + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.assign(0.0)\n        self.fp.assign(0.0)\n        self.fn.assign(0.0)\n\n# --- 8) Callback factory ---\ndef get_callbacks(name):\n    return [\n        EarlyStopping(\"val_f1_score\", mode=\"max\", patience=20, restore_best_weights=True),\n        ModelCheckpoint(os.path.join(output_dir, f\"best_{name}.h5\"),\n                        \"val_f1_score\", mode=\"max\", save_best_only=True),\n        CSVLogger(os.path.join(output_dir, f\"log_{name}.csv\")),\n        LearningRateScheduler(cosine_lr)\n    ]\n\n# --- 9) Model Builders ---\n# [All model builder functions remain unchanged — see previous message if needed.]\ndef build_modelA(input_shape):\n    m = keras.Sequential([\n        layers.Input(input_shape),\n        layers.Conv1D(32, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(64, 5, activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(), layers.MaxPool1D(2),\n        layers.Conv1D(128,5,activation=\"relu\",padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling1D(),\n        layers.Dense(64, activation=\"relu\", \n                     kernel_regularizer=regularizers.l2(1e-4)),\n        layers.Dropout(0.7),\n        layers.Dense(2, activation=\"softmax\"),\n    ])\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_modelB(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for f in [16,32,64,128,256]:\n        x = layers.Conv1D(f,3,activation=\"relu\",padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.MaxPool1D(2)(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\",\n                         kernel_regularizer=regularizers.l2(1e-4))(x)\n        x = layers.Dropout(0.5)(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp, out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model1(input_shape):\n    inp = layers.Input(input_shape+(1,))\n    x = layers.Concatenate()([inp, inp, inp])\n    x = layers.Resizing(32,32)(x)\n    base = keras.applications.ResNet50(\n        include_top=False, weights=\"imagenet\",\n        input_shape=(32,32,3), pooling=\"avg\"\n    )\n    base.trainable = False\n    x = base(x)\n    x = layers.Reshape((1, x.shape[-1]))(x)\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.MultiHeadAttention(num_heads=4,key_dim=32)(x,x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model2(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(32,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64,activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model3(input_shape):\n    inp = layers.Input(input_shape)  # (T, F, 1)\n    x = inp\n    for _ in range(5):\n        x = layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for u in [128,64,32]:\n        x = layers.Dense(u, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model4(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(3):\n        x = layers.Conv1D(64,3,activation=\"relu\",padding=\"same\")(x)\n    x = layers.LSTM(128)(x)\n    for _ in range(4):\n        x = layers.Dense(64, activation=\"relu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model5(input_shape):\n    inp = layers.Input(input_shape)\n    x = inp\n    for _ in range(7):\n        x = layers.Conv1D(64,3,activation=\"elu\",padding=\"same\")(x)\n    x = layers.Flatten()(x)\n    for _ in range(3):\n        x = layers.Dense(64, activation=\"elu\")(x)\n    out = layers.Dense(2, activation=\"softmax\")(x)\n    m = models.Model(inp,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n\ndef build_model6(input_shape):\n    C3, C4 = 0,2\n    eeg_in = layers.Input(input_shape)\n    c3 = layers.Lambda(lambda x: x[:,:,C3:C3+1])(eeg_in)\n    c4 = layers.Lambda(lambda x: x[:,:,C4:C4+1])(eeg_in)\n    def branch():\n        return models.Sequential([\n            layers.Conv1D(16,250,activation=\"relu\",padding=\"same\"),\n            layers.MaxPool1D(3),\n            layers.Conv1D(32,50,activation=\"relu\",padding=\"same\"),\n            layers.GlobalAveragePooling1D()\n        ])\n    b3, b4 = branch()(c3), branch()(c4)\n    x = layers.Concatenate()([b3,b4])\n    for _ in range(4):\n        x = layers.Dense(64,activation=\"relu\")(x)\n    out = layers.Dense(2,activation=\"softmax\")(x)\n    m = models.Model(eeg_in,out)\n    m.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\n    return m\n# (You can paste model builders here unchanged if needed)\n\n# --- 10) Train & evaluate ---\nbuilders = {\n    'oldA': build_modelA,\n    'oldB': build_modelB,\n    'model1': build_model1,\n    'model2': build_model2,\n    'model3': build_model3,\n    'model4': build_model4,\n    'model5': build_model5,\n    'model6': build_model6,\n}\n\nresults = {}\nshape_raw   = X_train_raw.shape[1:]\nshape_csp1d = Xtr_csp.shape[1:]\nshape_csp2d = Xtr_csp_2d.shape[1:]\n\nfor name, build_fn in builders.items():\n    print(f\"\\n>>> Training {name}\")\n    if name in ['model3']:\n        model = build_fn(shape_csp2d)\n        gen, steps, val_x = train_gen_csp2d, steps_csp2d, Xvl_csp_2d\n    elif name in ['model4', 'model5']:\n        model = build_fn(shape_csp1d)\n        gen, steps, val_x = train_gen_csp1d, steps_csp1d, Xvl_csp\n    else:\n        model = build_fn(shape_raw)\n        gen, steps, val_x = train_gen_raw, steps_raw, X_val_raw\n\n    model.fit(\n        gen, steps_per_epoch=steps,\n        validation_data=(val_x, yvl_oh),\n        epochs=200, callbacks=get_callbacks(name), verbose=2\n    )\n\n    preds = np.argmax(model.predict(val_x), axis=1)\n    f1 = f1_score(y_val_bin, preds)\n    print(f\"{name} → val F1 = {f1:.4f}\")\n    print(classification_report(y_val_bin, preds, target_names=[\"Left\", \"Right\"]))\n    results[name] = (f1, model)\n\n# --- 11) Save best model ---\nbest_name, (best_f1, best_model) = max(results.items(), key=lambda kv: kv[1][0])\nprint(f\"\\n=== Final best: {best_name} (F1={best_f1:.4f}) ===\")\nbest_model.save(os.path.join(output_dir, 'best_final.h5'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T03:09:11.779116Z","iopub.execute_input":"2025-07-23T03:09:11.779428Z","iopub.status.idle":"2025-07-23T03:16:32.376712Z","shell.execute_reply.started":"2025-07-23T03:09:11.779406Z","shell.execute_reply":"2025-07-23T03:16:32.376067Z"}},"outputs":[{"name":"stdout","text":"Computing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA\nEpoch 1/200\n37/37 - 10s - 266ms/step - accuracy: 0.5135 - f1_score: 0.4627 - loss: 0.8540 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 0.8687 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 28ms/step - accuracy: 0.5114 - f1_score: 0.5079 - loss: 0.7700 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 0.7301 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 28ms/step - accuracy: 0.5241 - f1_score: 0.5283 - loss: 0.7350 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.8295 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 27ms/step - accuracy: 0.5110 - f1_score: 0.5508 - loss: 0.7238 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7871 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 27ms/step - accuracy: 0.5156 - f1_score: 0.5457 - loss: 0.7136 - val_accuracy: 0.6000 - val_f1_score: 0.2308 - val_loss: 0.6998 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 27ms/step - accuracy: 0.5072 - f1_score: 0.5219 - loss: 0.7172 - val_accuracy: 0.5800 - val_f1_score: 0.3636 - val_loss: 0.7021 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 27ms/step - accuracy: 0.5076 - f1_score: 0.4913 - loss: 0.7088 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.8321 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 27ms/step - accuracy: 0.5106 - f1_score: 0.5362 - loss: 0.7086 - val_accuracy: 0.5400 - val_f1_score: 0.4889 - val_loss: 0.7042 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 27ms/step - accuracy: 0.5211 - f1_score: 0.5386 - loss: 0.7037 - val_accuracy: 0.4800 - val_f1_score: 0.4800 - val_loss: 0.7004 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 28ms/step - accuracy: 0.5376 - f1_score: 0.5869 - loss: 0.6999 - val_accuracy: 0.5600 - val_f1_score: 0.6207 - val_loss: 0.7000 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 27ms/step - accuracy: 0.5245 - f1_score: 0.5415 - loss: 0.7027 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 0.7178 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 27ms/step - accuracy: 0.5152 - f1_score: 0.5310 - loss: 0.7072 - val_accuracy: 0.4800 - val_f1_score: 0.4348 - val_loss: 0.7073 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 27ms/step - accuracy: 0.5114 - f1_score: 0.5953 - loss: 0.7018 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7174 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 27ms/step - accuracy: 0.5232 - f1_score: 0.6304 - loss: 0.7051 - val_accuracy: 0.4600 - val_f1_score: 0.6087 - val_loss: 0.7490 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 27ms/step - accuracy: 0.5013 - f1_score: 0.5691 - loss: 0.7026 - val_accuracy: 0.5200 - val_f1_score: 0.5200 - val_loss: 0.7109 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 27ms/step - accuracy: 0.5448 - f1_score: 0.5941 - loss: 0.6966 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 0.7064 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 27ms/step - accuracy: 0.5224 - f1_score: 0.5015 - loss: 0.7020 - val_accuracy: 0.5800 - val_f1_score: 0.3636 - val_loss: 0.7005 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 27ms/step - accuracy: 0.5253 - f1_score: 0.5109 - loss: 0.6970 - val_accuracy: 0.5600 - val_f1_score: 0.5217 - val_loss: 0.7117 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 27ms/step - accuracy: 0.5317 - f1_score: 0.5311 - loss: 0.6999 - val_accuracy: 0.5200 - val_f1_score: 0.6129 - val_loss: 0.7028 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 27ms/step - accuracy: 0.5182 - f1_score: 0.5950 - loss: 0.6996 - val_accuracy: 0.5600 - val_f1_score: 0.6207 - val_loss: 0.7023 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 27ms/step - accuracy: 0.5203 - f1_score: 0.5802 - loss: 0.6970 - val_accuracy: 0.6200 - val_f1_score: 0.4865 - val_loss: 0.6940 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 27ms/step - accuracy: 0.5312 - f1_score: 0.5088 - loss: 0.6965 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.7043 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 27ms/step - accuracy: 0.5148 - f1_score: 0.5749 - loss: 0.7010 - val_accuracy: 0.4600 - val_f1_score: 0.5970 - val_loss: 0.7132 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 27ms/step - accuracy: 0.5055 - f1_score: 0.6035 - loss: 0.6989 - val_accuracy: 0.4400 - val_f1_score: 0.6000 - val_loss: 0.7063 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 28ms/step - accuracy: 0.5072 - f1_score: 0.5857 - loss: 0.6956 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7282 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 29ms/step - accuracy: 0.5342 - f1_score: 0.6112 - loss: 0.6930 - val_accuracy: 0.5200 - val_f1_score: 0.6364 - val_loss: 0.7009 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 27ms/step - accuracy: 0.5486 - f1_score: 0.5961 - loss: 0.6958 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.6996 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 27ms/step - accuracy: 0.5173 - f1_score: 0.5899 - loss: 0.6966 - val_accuracy: 0.5800 - val_f1_score: 0.6038 - val_loss: 0.7147 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 28ms/step - accuracy: 0.5431 - f1_score: 0.6083 - loss: 0.6969 - val_accuracy: 0.6200 - val_f1_score: 0.6415 - val_loss: 0.7021 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 27ms/step - accuracy: 0.5203 - f1_score: 0.6112 - loss: 0.6958 - val_accuracy: 0.5000 - val_f1_score: 0.6377 - val_loss: 0.7099 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 27ms/step - accuracy: 0.5355 - f1_score: 0.5662 - loss: 0.6975 - val_accuracy: 0.5800 - val_f1_score: 0.6316 - val_loss: 0.7057 - learning_rate: 5.5621e-04\nEpoch 32/200\n37/37 - 1s - 27ms/step - accuracy: 0.5418 - f1_score: 0.6157 - loss: 0.6932 - val_accuracy: 0.5000 - val_f1_score: 0.6154 - val_loss: 0.7009 - learning_rate: 5.2388e-04\nEpoch 33/200\n37/37 - 1s - 27ms/step - accuracy: 0.5431 - f1_score: 0.6230 - loss: 0.6942 - val_accuracy: 0.4800 - val_f1_score: 0.5806 - val_loss: 0.7131 - learning_rate: 4.9148e-04\nEpoch 34/200\n37/37 - 1s - 29ms/step - accuracy: 0.5367 - f1_score: 0.5789 - loss: 0.6962 - val_accuracy: 0.6400 - val_f1_score: 0.6897 - val_loss: 0.7025 - learning_rate: 4.5920e-04\nEpoch 35/200\n37/37 - 1s - 27ms/step - accuracy: 0.5317 - f1_score: 0.5653 - loss: 0.6963 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 0.7076 - learning_rate: 4.2723e-04\nEpoch 36/200\n37/37 - 1s - 27ms/step - accuracy: 0.5342 - f1_score: 0.5931 - loss: 0.6918 - val_accuracy: 0.6400 - val_f1_score: 0.6897 - val_loss: 0.7397 - learning_rate: 3.9575e-04\nEpoch 37/200\n37/37 - 1s - 27ms/step - accuracy: 0.5279 - f1_score: 0.5859 - loss: 0.6971 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 0.7309 - learning_rate: 3.6494e-04\nEpoch 38/200\n37/37 - 1s - 27ms/step - accuracy: 0.5638 - f1_score: 0.6056 - loss: 0.6926 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 0.7079 - learning_rate: 3.3498e-04\nEpoch 39/200\n37/37 - 1s - 27ms/step - accuracy: 0.5372 - f1_score: 0.5901 - loss: 0.6940 - val_accuracy: 0.6200 - val_f1_score: 0.6667 - val_loss: 0.7130 - learning_rate: 3.0602e-04\nEpoch 40/200\n37/37 - 1s - 27ms/step - accuracy: 0.5553 - f1_score: 0.5790 - loss: 0.6893 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 0.7070 - learning_rate: 2.7820e-04\nEpoch 41/200\n37/37 - 1s - 27ms/step - accuracy: 0.5439 - f1_score: 0.5439 - loss: 0.6904 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7078 - learning_rate: 2.5163e-04\nEpoch 42/200\n37/37 - 1s - 27ms/step - accuracy: 0.5494 - f1_score: 0.5678 - loss: 0.6920 - val_accuracy: 0.6400 - val_f1_score: 0.6897 - val_loss: 0.7121 - learning_rate: 2.2643e-04\nEpoch 43/200\n37/37 - 1s - 28ms/step - accuracy: 0.5684 - f1_score: 0.6054 - loss: 0.6886 - val_accuracy: 0.6600 - val_f1_score: 0.6909 - val_loss: 0.7130 - learning_rate: 2.0267e-04\nEpoch 44/200\n37/37 - 1s - 27ms/step - accuracy: 0.5338 - f1_score: 0.5681 - loss: 0.6968 - val_accuracy: 0.5800 - val_f1_score: 0.6769 - val_loss: 0.7050 - learning_rate: 1.8042e-04\nEpoch 45/200\n37/37 - 1s - 27ms/step - accuracy: 0.5448 - f1_score: 0.5987 - loss: 0.6917 - val_accuracy: 0.6400 - val_f1_score: 0.6897 - val_loss: 0.7090 - learning_rate: 1.5972e-04\nEpoch 46/200\n37/37 - 1s - 27ms/step - accuracy: 0.5372 - f1_score: 0.5895 - loss: 0.6916 - val_accuracy: 0.6400 - val_f1_score: 0.6538 - val_loss: 0.7086 - learning_rate: 1.4058e-04\nEpoch 47/200\n37/37 - 1s - 27ms/step - accuracy: 0.5541 - f1_score: 0.5951 - loss: 0.6901 - val_accuracy: 0.6600 - val_f1_score: 0.6792 - val_loss: 0.7104 - learning_rate: 1.2302e-04\nEpoch 48/200\n37/37 - 1s - 28ms/step - accuracy: 0.5389 - f1_score: 0.5882 - loss: 0.6914 - val_accuracy: 0.7000 - val_f1_score: 0.7273 - val_loss: 0.7096 - learning_rate: 1.0700e-04\nEpoch 49/200\n37/37 - 1s - 27ms/step - accuracy: 0.5524 - f1_score: 0.6012 - loss: 0.6895 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 0.7059 - learning_rate: 9.2503e-05\nEpoch 50/200\n37/37 - 1s - 27ms/step - accuracy: 0.5363 - f1_score: 0.5718 - loss: 0.6949 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.7029 - learning_rate: 7.9466e-05\nEpoch 51/200\n37/37 - 1s - 27ms/step - accuracy: 0.5541 - f1_score: 0.5988 - loss: 0.6866 - val_accuracy: 0.6400 - val_f1_score: 0.6538 - val_loss: 0.7005 - learning_rate: 6.7829e-05\nEpoch 52/200\n37/37 - 1s - 27ms/step - accuracy: 0.5346 - f1_score: 0.5692 - loss: 0.6920 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.6995 - learning_rate: 5.7516e-05\nEpoch 53/200\n37/37 - 1s - 27ms/step - accuracy: 0.5456 - f1_score: 0.5813 - loss: 0.6930 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.6981 - learning_rate: 4.8444e-05\nEpoch 54/200\n37/37 - 1s - 27ms/step - accuracy: 0.5397 - f1_score: 0.5732 - loss: 0.6897 - val_accuracy: 0.6600 - val_f1_score: 0.6792 - val_loss: 0.6995 - learning_rate: 4.0524e-05\nEpoch 55/200\n37/37 - 1s - 27ms/step - accuracy: 0.5515 - f1_score: 0.5947 - loss: 0.6868 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 0.6985 - learning_rate: 3.3661e-05\nEpoch 56/200\n37/37 - 1s - 27ms/step - accuracy: 0.5570 - f1_score: 0.5872 - loss: 0.6859 - val_accuracy: 0.6400 - val_f1_score: 0.6538 - val_loss: 0.6997 - learning_rate: 2.7761e-05\nEpoch 57/200\n37/37 - 1s - 28ms/step - accuracy: 0.5312 - f1_score: 0.5640 - loss: 0.6878 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.6997 - learning_rate: 2.2728e-05\nEpoch 58/200\n37/37 - 1s - 27ms/step - accuracy: 0.5410 - f1_score: 0.5811 - loss: 0.6925 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7015 - learning_rate: 1.8470e-05\nEpoch 59/200\n37/37 - 1s - 27ms/step - accuracy: 0.5414 - f1_score: 0.5701 - loss: 0.6883 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 0.7016 - learning_rate: 1.4895e-05\nEpoch 60/200\n37/37 - 1s - 27ms/step - accuracy: 0.5452 - f1_score: 0.5751 - loss: 0.6898 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 0.7012 - learning_rate: 1.1919e-05\nEpoch 61/200\n37/37 - 1s - 27ms/step - accuracy: 0.5693 - f1_score: 0.5946 - loss: 0.6885 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7014 - learning_rate: 9.4625e-06\nEpoch 62/200\n37/37 - 1s - 27ms/step - accuracy: 0.5486 - f1_score: 0.5852 - loss: 0.6864 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 0.7013 - learning_rate: 7.4517e-06\nEpoch 63/200\n37/37 - 1s - 27ms/step - accuracy: 0.5621 - f1_score: 0.5929 - loss: 0.6888 - val_accuracy: 0.6400 - val_f1_score: 0.6538 - val_loss: 0.7011 - learning_rate: 5.8201e-06\nEpoch 64/200\n37/37 - 1s - 27ms/step - accuracy: 0.5494 - f1_score: 0.5847 - loss: 0.6932 - val_accuracy: 0.6400 - val_f1_score: 0.6538 - val_loss: 0.7014 - learning_rate: 4.5077e-06\nEpoch 65/200\n37/37 - 1s - 27ms/step - accuracy: 0.5532 - f1_score: 0.5805 - loss: 0.6878 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7011 - learning_rate: 3.4615e-06\nEpoch 66/200\n37/37 - 1s - 27ms/step - accuracy: 0.5465 - f1_score: 0.5704 - loss: 0.6896 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7012 - learning_rate: 2.6351e-06\nEpoch 67/200\n37/37 - 1s - 27ms/step - accuracy: 0.5604 - f1_score: 0.5906 - loss: 0.6881 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7009 - learning_rate: 1.9882e-06\nEpoch 68/200\n37/37 - 1s - 27ms/step - accuracy: 0.5528 - f1_score: 0.5803 - loss: 0.6868 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.7016 - learning_rate: 1.4867e-06\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step\noldA → val F1 = 0.7273\n              precision    recall  f1-score   support\n\n        Left       0.88      0.54      0.67        28\n       Right       0.61      0.91      0.73        22\n\n    accuracy                           0.70        50\n   macro avg       0.74      0.72      0.70        50\nweighted avg       0.76      0.70      0.69        50\n\n\n>>> Training oldB\nEpoch 1/200\n37/37 - 14s - 375ms/step - accuracy: 0.5017 - f1_score: 0.4665 - loss: 2.9870 - val_accuracy: 0.4600 - val_f1_score: 0.5714 - val_loss: 0.8237 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 36ms/step - accuracy: 0.4928 - f1_score: 0.4726 - loss: 2.1045 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 1.1017 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 31ms/step - accuracy: 0.5156 - f1_score: 0.5313 - loss: 1.4523 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 0.8567 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 35ms/step - accuracy: 0.4932 - f1_score: 0.5177 - loss: 1.2407 - val_accuracy: 0.5600 - val_f1_score: 0.6333 - val_loss: 0.7188 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 36ms/step - accuracy: 0.5021 - f1_score: 0.5081 - loss: 1.0294 - val_accuracy: 0.5400 - val_f1_score: 0.6462 - val_loss: 0.7220 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 32ms/step - accuracy: 0.5000 - f1_score: 0.5275 - loss: 0.9288 - val_accuracy: 0.4400 - val_f1_score: 0.6000 - val_loss: 0.7518 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 31ms/step - accuracy: 0.5084 - f1_score: 0.5527 - loss: 0.8568 - val_accuracy: 0.4800 - val_f1_score: 0.6176 - val_loss: 0.7470 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 36ms/step - accuracy: 0.4987 - f1_score: 0.5468 - loss: 0.8372 - val_accuracy: 0.5200 - val_f1_score: 0.6471 - val_loss: 0.7517 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 31ms/step - accuracy: 0.4996 - f1_score: 0.5426 - loss: 0.8111 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7479 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 31ms/step - accuracy: 0.5034 - f1_score: 0.5586 - loss: 0.8067 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7506 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 31ms/step - accuracy: 0.4983 - f1_score: 0.5445 - loss: 0.7828 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7508 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 31ms/step - accuracy: 0.4979 - f1_score: 0.5659 - loss: 0.7862 - val_accuracy: 0.4200 - val_f1_score: 0.5797 - val_loss: 0.7504 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 31ms/step - accuracy: 0.4920 - f1_score: 0.5668 - loss: 0.7938 - val_accuracy: 0.4200 - val_f1_score: 0.5797 - val_loss: 0.7522 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 31ms/step - accuracy: 0.5249 - f1_score: 0.6076 - loss: 0.7647 - val_accuracy: 0.4800 - val_f1_score: 0.6176 - val_loss: 0.7488 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 31ms/step - accuracy: 0.5291 - f1_score: 0.6061 - loss: 0.7571 - val_accuracy: 0.4400 - val_f1_score: 0.6000 - val_loss: 0.7487 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 31ms/step - accuracy: 0.5169 - f1_score: 0.5992 - loss: 0.7613 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7541 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 31ms/step - accuracy: 0.5068 - f1_score: 0.6025 - loss: 0.7660 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7500 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 31ms/step - accuracy: 0.4928 - f1_score: 0.5697 - loss: 0.7711 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7499 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 31ms/step - accuracy: 0.5152 - f1_score: 0.5868 - loss: 0.7615 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7484 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 31ms/step - accuracy: 0.5025 - f1_score: 0.5913 - loss: 0.7690 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7516 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 31ms/step - accuracy: 0.5165 - f1_score: 0.6220 - loss: 0.7591 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7509 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 31ms/step - accuracy: 0.4924 - f1_score: 0.5964 - loss: 0.7566 - val_accuracy: 0.4800 - val_f1_score: 0.6286 - val_loss: 0.7466 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 31ms/step - accuracy: 0.5080 - f1_score: 0.5891 - loss: 0.7626 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7444 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 31ms/step - accuracy: 0.4945 - f1_score: 0.5976 - loss: 0.7527 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7412 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 31ms/step - accuracy: 0.5021 - f1_score: 0.5761 - loss: 0.7594 - val_accuracy: 0.4600 - val_f1_score: 0.6197 - val_loss: 0.7416 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 31ms/step - accuracy: 0.5198 - f1_score: 0.6126 - loss: 0.7523 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7462 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 31ms/step - accuracy: 0.5084 - f1_score: 0.6060 - loss: 0.7521 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7471 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 32ms/step - accuracy: 0.4975 - f1_score: 0.5908 - loss: 0.7494 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7462 - learning_rate: 6.5084e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\noldB → val F1 = 0.6471\n              precision    recall  f1-score   support\n\n        Left       1.00      0.14      0.25        28\n       Right       0.48      1.00      0.65        22\n\n    accuracy                           0.52        50\n   macro avg       0.74      0.57      0.45        50\nweighted avg       0.77      0.52      0.42        50\n\n\n>>> Training model1\nEpoch 1/200\n37/37 - 27s - 730ms/step - accuracy: 0.4979 - f1_score: 0.5372 - loss: 0.6951 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6912 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 2s - 41ms/step - accuracy: 0.5076 - f1_score: 0.5772 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6937 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 23ms/step - accuracy: 0.5135 - f1_score: 0.6291 - loss: 0.6926 - val_accuracy: 0.5000 - val_f1_score: 0.4186 - val_loss: 0.6968 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 22ms/step - accuracy: 0.5131 - f1_score: 0.6705 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6965 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 24ms/step - accuracy: 0.4890 - f1_score: 0.5195 - loss: 0.6934 - val_accuracy: 0.4800 - val_f1_score: 0.6061 - val_loss: 0.6932 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 25ms/step - accuracy: 0.5144 - f1_score: 0.0527 - loss: 0.6929 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.6907 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 25ms/step - accuracy: 0.5198 - f1_score: 0.4335 - loss: 0.6921 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.6973 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 24ms/step - accuracy: 0.4945 - f1_score: 0.3877 - loss: 0.6949 - val_accuracy: 0.5800 - val_f1_score: 0.0870 - val_loss: 0.6904 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 28ms/step - accuracy: 0.4945 - f1_score: 0.5175 - loss: 0.6931 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 0.6910 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 27ms/step - accuracy: 0.4949 - f1_score: 0.2981 - loss: 0.6940 - val_accuracy: 0.5800 - val_f1_score: 0.1600 - val_loss: 0.6898 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 2s - 45ms/step - accuracy: 0.5025 - f1_score: 0.2157 - loss: 0.6941 - val_accuracy: 0.5200 - val_f1_score: 0.6471 - val_loss: 0.6945 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 22ms/step - accuracy: 0.4911 - f1_score: 0.4703 - loss: 0.6937 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6953 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 24ms/step - accuracy: 0.5076 - f1_score: 0.6714 - loss: 0.6933 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6943 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 24ms/step - accuracy: 0.5038 - f1_score: 0.6700 - loss: 0.6932 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6949 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 25ms/step - accuracy: 0.5055 - f1_score: 0.6715 - loss: 0.6931 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6941 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 24ms/step - accuracy: 0.5186 - f1_score: 0.6830 - loss: 0.6927 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6959 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 24ms/step - accuracy: 0.4911 - f1_score: 0.6587 - loss: 0.6936 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6932 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 23ms/step - accuracy: 0.5182 - f1_score: 0.6826 - loss: 0.6928 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6943 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 24ms/step - accuracy: 0.4911 - f1_score: 0.6455 - loss: 0.6926 - val_accuracy: 0.4800 - val_f1_score: 0.4091 - val_loss: 0.6929 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 23ms/step - accuracy: 0.5038 - f1_score: 0.6549 - loss: 0.6912 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7013 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 22ms/step - accuracy: 0.5059 - f1_score: 0.6465 - loss: 0.6918 - val_accuracy: 0.5000 - val_f1_score: 0.6154 - val_loss: 0.7045 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 22ms/step - accuracy: 0.5106 - f1_score: 0.5435 - loss: 0.6896 - val_accuracy: 0.5600 - val_f1_score: 0.0833 - val_loss: 0.7097 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 21ms/step - accuracy: 0.5042 - f1_score: 0.4462 - loss: 0.6856 - val_accuracy: 0.4200 - val_f1_score: 0.5915 - val_loss: 0.7301 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 21ms/step - accuracy: 0.5203 - f1_score: 0.2642 - loss: 0.6905 - val_accuracy: 0.5800 - val_f1_score: 0.1600 - val_loss: 0.7053 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 21ms/step - accuracy: 0.5097 - f1_score: 0.6311 - loss: 0.6846 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7601 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 22ms/step - accuracy: 0.5042 - f1_score: 0.5825 - loss: 0.6836 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7744 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 22ms/step - accuracy: 0.5165 - f1_score: 0.6766 - loss: 0.6853 - val_accuracy: 0.6200 - val_f1_score: 0.3448 - val_loss: 0.7181 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 22ms/step - accuracy: 0.5389 - f1_score: 0.3546 - loss: 0.6730 - val_accuracy: 0.5600 - val_f1_score: 0.6071 - val_loss: 0.7328 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 21ms/step - accuracy: 0.5553 - f1_score: 0.3575 - loss: 0.6735 - val_accuracy: 0.6000 - val_f1_score: 0.6154 - val_loss: 0.7277 - learning_rate: 6.1987e-04\nEpoch 30/200\n37/37 - 1s - 22ms/step - accuracy: 0.5553 - f1_score: 0.5725 - loss: 0.6686 - val_accuracy: 0.5400 - val_f1_score: 0.5818 - val_loss: 0.7764 - learning_rate: 5.8827e-04\nEpoch 31/200\n37/37 - 1s - 21ms/step - accuracy: 0.5667 - f1_score: 0.4177 - loss: 0.6682 - val_accuracy: 0.7000 - val_f1_score: 0.5946 - val_loss: 0.8106 - learning_rate: 5.5621e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step\nmodel1 → val F1 = 0.6471\n              precision    recall  f1-score   support\n\n        Left       1.00      0.14      0.25        28\n       Right       0.48      1.00      0.65        22\n\n    accuracy                           0.52        50\n   macro avg       0.74      0.57      0.45        50\nweighted avg       0.77      0.52      0.42        50\n\n\n>>> Training model2\nEpoch 1/200\n37/37 - 4s - 121ms/step - accuracy: 0.5030 - f1_score: 0.4371 - loss: 13.7913 - val_accuracy: 0.4400 - val_f1_score: 0.3913 - val_loss: 4.9958 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 22ms/step - accuracy: 0.4958 - f1_score: 0.4066 - loss: 1.8023 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 5.3408 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 21ms/step - accuracy: 0.5266 - f1_score: 0.4989 - loss: 1.2789 - val_accuracy: 0.6200 - val_f1_score: 0.6667 - val_loss: 3.6832 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 21ms/step - accuracy: 0.5228 - f1_score: 0.5074 - loss: 1.2222 - val_accuracy: 0.7000 - val_f1_score: 0.6939 - val_loss: 1.8995 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 20ms/step - accuracy: 0.5182 - f1_score: 0.5159 - loss: 0.9856 - val_accuracy: 0.6200 - val_f1_score: 0.5957 - val_loss: 1.8014 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 21ms/step - accuracy: 0.5422 - f1_score: 0.5254 - loss: 0.9674 - val_accuracy: 0.5600 - val_f1_score: 0.5000 - val_loss: 1.9996 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 21ms/step - accuracy: 0.5389 - f1_score: 0.5252 - loss: 0.9703 - val_accuracy: 0.6200 - val_f1_score: 0.6122 - val_loss: 1.5983 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 21ms/step - accuracy: 0.5646 - f1_score: 0.5488 - loss: 0.8399 - val_accuracy: 0.5600 - val_f1_score: 0.5417 - val_loss: 1.9808 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 20ms/step - accuracy: 0.5536 - f1_score: 0.5538 - loss: 0.8436 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 1.8488 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 22ms/step - accuracy: 0.5566 - f1_score: 0.5618 - loss: 0.8023 - val_accuracy: 0.5000 - val_f1_score: 0.5763 - val_loss: 2.0294 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 20ms/step - accuracy: 0.5503 - f1_score: 0.5623 - loss: 0.8650 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 2.2784 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 21ms/step - accuracy: 0.5579 - f1_score: 0.5711 - loss: 0.8156 - val_accuracy: 0.5000 - val_f1_score: 0.5098 - val_loss: 1.6356 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 21ms/step - accuracy: 0.5739 - f1_score: 0.5812 - loss: 0.7366 - val_accuracy: 0.6400 - val_f1_score: 0.6400 - val_loss: 1.6068 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 22ms/step - accuracy: 0.5579 - f1_score: 0.5520 - loss: 0.7585 - val_accuracy: 0.5600 - val_f1_score: 0.6071 - val_loss: 1.4781 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 21ms/step - accuracy: 0.5680 - f1_score: 0.5893 - loss: 0.7361 - val_accuracy: 0.5400 - val_f1_score: 0.5965 - val_loss: 1.5200 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 20ms/step - accuracy: 0.5680 - f1_score: 0.5952 - loss: 0.7422 - val_accuracy: 0.5800 - val_f1_score: 0.5532 - val_loss: 1.6023 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 20ms/step - accuracy: 0.5946 - f1_score: 0.5833 - loss: 0.7241 - val_accuracy: 0.5600 - val_f1_score: 0.5417 - val_loss: 1.3384 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 20ms/step - accuracy: 0.5752 - f1_score: 0.5867 - loss: 0.7094 - val_accuracy: 0.4600 - val_f1_score: 0.4706 - val_loss: 1.5562 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 20ms/step - accuracy: 0.5722 - f1_score: 0.6007 - loss: 0.7193 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 1.4504 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 20ms/step - accuracy: 0.5718 - f1_score: 0.5323 - loss: 0.7245 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 1.4734 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 20ms/step - accuracy: 0.5781 - f1_score: 0.5651 - loss: 0.7215 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 1.4281 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 20ms/step - accuracy: 0.5857 - f1_score: 0.6214 - loss: 0.6740 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 1.3914 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 21ms/step - accuracy: 0.6035 - f1_score: 0.6218 - loss: 0.6840 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 1.3355 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 21ms/step - accuracy: 0.5752 - f1_score: 0.5853 - loss: 0.7106 - val_accuracy: 0.6400 - val_f1_score: 0.6667 - val_loss: 1.4357 - learning_rate: 7.6518e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step\nmodel2 → val F1 = 0.6939\n              precision    recall  f1-score   support\n\n        Left       0.78      0.64      0.71        28\n       Right       0.63      0.77      0.69        22\n\n    accuracy                           0.70        50\n   macro avg       0.71      0.71      0.70        50\nweighted avg       0.72      0.70      0.70        50\n\n\n>>> Training model3\nEpoch 1/200\n37/37 - 9s - 252ms/step - accuracy: 0.5122 - f1_score: 0.6443 - loss: 0.7150 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7020 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 38ms/step - accuracy: 0.5207 - f1_score: 0.6370 - loss: 0.6918 - val_accuracy: 0.4600 - val_f1_score: 0.5970 - val_loss: 0.7113 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 39ms/step - accuracy: 0.5807 - f1_score: 0.6030 - loss: 0.6722 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7099 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 38ms/step - accuracy: 0.5655 - f1_score: 0.6321 - loss: 0.6724 - val_accuracy: 0.4800 - val_f1_score: 0.5357 - val_loss: 0.8231 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 38ms/step - accuracy: 0.6242 - f1_score: 0.6667 - loss: 0.6275 - val_accuracy: 0.5200 - val_f1_score: 0.3333 - val_loss: 1.1159 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 38ms/step - accuracy: 0.7137 - f1_score: 0.6896 - loss: 0.5153 - val_accuracy: 0.5600 - val_f1_score: 0.4500 - val_loss: 1.6072 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 38ms/step - accuracy: 0.8171 - f1_score: 0.8087 - loss: 0.3938 - val_accuracy: 0.5800 - val_f1_score: 0.5116 - val_loss: 2.2699 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 38ms/step - accuracy: 0.8944 - f1_score: 0.8958 - loss: 0.2458 - val_accuracy: 0.5600 - val_f1_score: 0.5000 - val_loss: 1.8375 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 3s - 85ms/step - accuracy: 0.9278 - f1_score: 0.9252 - loss: 0.1812 - val_accuracy: 0.6400 - val_f1_score: 0.6400 - val_loss: 3.8087 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 38ms/step - accuracy: 0.9578 - f1_score: 0.9581 - loss: 0.1377 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 4.0799 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 38ms/step - accuracy: 0.9654 - f1_score: 0.9630 - loss: 0.0932 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 2.1319 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 38ms/step - accuracy: 0.9709 - f1_score: 0.9707 - loss: 0.0745 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 5.0784 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 38ms/step - accuracy: 0.9734 - f1_score: 0.9738 - loss: 0.0971 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 5.0039 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 38ms/step - accuracy: 0.9797 - f1_score: 0.9802 - loss: 0.0472 - val_accuracy: 0.5600 - val_f1_score: 0.4762 - val_loss: 4.0044 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 38ms/step - accuracy: 0.9865 - f1_score: 0.9863 - loss: 0.0408 - val_accuracy: 0.6000 - val_f1_score: 0.5238 - val_loss: 3.8257 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 38ms/step - accuracy: 0.9970 - f1_score: 0.9971 - loss: 0.0125 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 8.7666 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 38ms/step - accuracy: 0.9907 - f1_score: 0.9910 - loss: 0.0219 - val_accuracy: 0.5400 - val_f1_score: 0.5106 - val_loss: 7.7635 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 38ms/step - accuracy: 0.9966 - f1_score: 0.9966 - loss: 0.0133 - val_accuracy: 0.6200 - val_f1_score: 0.6275 - val_loss: 5.0949 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 38ms/step - accuracy: 0.9907 - f1_score: 0.9911 - loss: 0.0341 - val_accuracy: 0.6600 - val_f1_score: 0.5854 - val_loss: 6.1580 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 38ms/step - accuracy: 0.9954 - f1_score: 0.9954 - loss: 0.0160 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 5.1538 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 38ms/step - accuracy: 0.9958 - f1_score: 0.9959 - loss: 0.0184 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 3.4258 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 38ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0046 - val_accuracy: 0.6000 - val_f1_score: 0.5652 - val_loss: 5.1219 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0025 - val_accuracy: 0.6200 - val_f1_score: 0.6122 - val_loss: 6.6223 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 39ms/step - accuracy: 0.9992 - f1_score: 0.9991 - loss: 0.0015 - val_accuracy: 0.6400 - val_f1_score: 0.5909 - val_loss: 7.6987 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 7.9381 - learning_rate: 7.3832e-04\nEpoch 26/200\n37/37 - 1s - 38ms/step - accuracy: 0.9992 - f1_score: 0.9992 - loss: 0.0014 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 8.3741 - learning_rate: 7.1022e-04\nEpoch 27/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0785e-04 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 8.7035 - learning_rate: 6.8101e-04\nEpoch 28/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2183e-04 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 8.9717 - learning_rate: 6.5084e-04\nEpoch 29/200\n37/37 - 1s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7771e-04 - val_accuracy: 0.6200 - val_f1_score: 0.5778 - val_loss: 9.2335 - learning_rate: 6.1987e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step\nmodel3 → val F1 = 0.6400\n              precision    recall  f1-score   support\n\n        Left       0.73      0.57      0.64        28\n       Right       0.57      0.73      0.64        22\n\n    accuracy                           0.64        50\n   macro avg       0.65      0.65      0.64        50\nweighted avg       0.66      0.64      0.64        50\n\n\n>>> Training model4\nEpoch 1/200\n37/37 - 9s - 240ms/step - accuracy: 0.4924 - f1_score: 0.3186 - loss: 0.6943 - val_accuracy: 0.5400 - val_f1_score: 0.5818 - val_loss: 0.6957 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 4s - 117ms/step - accuracy: 0.5127 - f1_score: 0.6616 - loss: 0.6928 - val_accuracy: 0.4200 - val_f1_score: 0.5915 - val_loss: 0.6976 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 4s - 117ms/step - accuracy: 0.5072 - f1_score: 0.5980 - loss: 0.6929 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6985 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 4s - 116ms/step - accuracy: 0.5080 - f1_score: 0.5562 - loss: 0.6902 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7385 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 4s - 116ms/step - accuracy: 0.5177 - f1_score: 0.5324 - loss: 0.6919 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.7001 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 4s - 116ms/step - accuracy: 0.5051 - f1_score: 0.6337 - loss: 0.6921 - val_accuracy: 0.4400 - val_f1_score: 0.6111 - val_loss: 0.6992 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 4s - 116ms/step - accuracy: 0.5342 - f1_score: 0.5514 - loss: 0.6900 - val_accuracy: 0.5600 - val_f1_score: 0.4762 - val_loss: 0.6933 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 4s - 116ms/step - accuracy: 0.5380 - f1_score: 0.3902 - loss: 0.6892 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 0.7107 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 4s - 116ms/step - accuracy: 0.5279 - f1_score: 0.5013 - loss: 0.6887 - val_accuracy: 0.5600 - val_f1_score: 0.4762 - val_loss: 0.6949 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 4s - 116ms/step - accuracy: 0.5473 - f1_score: 0.4629 - loss: 0.6885 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7033 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 4s - 116ms/step - accuracy: 0.5325 - f1_score: 0.2971 - loss: 0.6914 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.6925 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 4s - 116ms/step - accuracy: 0.5503 - f1_score: 0.5265 - loss: 0.6872 - val_accuracy: 0.5600 - val_f1_score: 0.5769 - val_loss: 0.7060 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 4s - 115ms/step - accuracy: 0.5431 - f1_score: 0.5212 - loss: 0.6865 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.7264 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 4s - 116ms/step - accuracy: 0.5617 - f1_score: 0.4328 - loss: 0.6867 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.6954 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 4s - 116ms/step - accuracy: 0.5469 - f1_score: 0.5173 - loss: 0.6886 - val_accuracy: 0.5600 - val_f1_score: 0.5769 - val_loss: 0.7079 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 4s - 116ms/step - accuracy: 0.5465 - f1_score: 0.5037 - loss: 0.6855 - val_accuracy: 0.6200 - val_f1_score: 0.5957 - val_loss: 0.6949 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 4s - 116ms/step - accuracy: 0.5389 - f1_score: 0.4949 - loss: 0.6897 - val_accuracy: 0.5600 - val_f1_score: 0.5600 - val_loss: 0.6990 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 4s - 116ms/step - accuracy: 0.5524 - f1_score: 0.4962 - loss: 0.6823 - val_accuracy: 0.5600 - val_f1_score: 0.5217 - val_loss: 0.7075 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 4s - 116ms/step - accuracy: 0.5693 - f1_score: 0.5312 - loss: 0.6808 - val_accuracy: 0.5400 - val_f1_score: 0.5306 - val_loss: 0.6950 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 4s - 116ms/step - accuracy: 0.5663 - f1_score: 0.5126 - loss: 0.6795 - val_accuracy: 0.5800 - val_f1_score: 0.5882 - val_loss: 0.7105 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 4s - 116ms/step - accuracy: 0.5633 - f1_score: 0.5592 - loss: 0.6823 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7029 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 4s - 116ms/step - accuracy: 0.5579 - f1_score: 0.5595 - loss: 0.6824 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 0.7186 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 4s - 116ms/step - accuracy: 0.5536 - f1_score: 0.5283 - loss: 0.6804 - val_accuracy: 0.5200 - val_f1_score: 0.4783 - val_loss: 0.6999 - learning_rate: 7.9071e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step\nmodel4 → val F1 = 0.6111\n              precision    recall  f1-score   support\n\n        Left       0.00      0.00      0.00        28\n       Right       0.44      1.00      0.61        22\n\n    accuracy                           0.44        50\n   macro avg       0.22      0.50      0.31        50\nweighted avg       0.19      0.44      0.27        50\n\n\n>>> Training model5\nEpoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"37/37 - 7s - 198ms/step - accuracy: 0.5000 - f1_score: 0.4918 - loss: 1.1224 - val_accuracy: 0.4000 - val_f1_score: 0.5588 - val_loss: 0.7465 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 22ms/step - accuracy: 0.5051 - f1_score: 0.4869 - loss: 0.7420 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 1.0477 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 23ms/step - accuracy: 0.5059 - f1_score: 0.5595 - loss: 0.7280 - val_accuracy: 0.4800 - val_f1_score: 0.3158 - val_loss: 0.7059 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 22ms/step - accuracy: 0.5089 - f1_score: 0.5553 - loss: 0.7356 - val_accuracy: 0.6000 - val_f1_score: 0.3750 - val_loss: 0.6824 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 35ms/step - accuracy: 0.5127 - f1_score: 0.5384 - loss: 0.7244 - val_accuracy: 0.5600 - val_f1_score: 0.6071 - val_loss: 0.6740 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 22ms/step - accuracy: 0.5321 - f1_score: 0.5027 - loss: 0.6979 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.6908 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 23ms/step - accuracy: 0.5232 - f1_score: 0.5438 - loss: 0.7180 - val_accuracy: 0.5600 - val_f1_score: 0.0000e+00 - val_loss: 0.7394 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 22ms/step - accuracy: 0.5401 - f1_score: 0.5034 - loss: 0.6978 - val_accuracy: 0.4800 - val_f1_score: 0.4348 - val_loss: 0.8165 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 24ms/step - accuracy: 0.5764 - f1_score: 0.5548 - loss: 0.6679 - val_accuracy: 0.5400 - val_f1_score: 0.3429 - val_loss: 0.8344 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 25ms/step - accuracy: 0.6634 - f1_score: 0.6740 - loss: 0.6089 - val_accuracy: 0.4600 - val_f1_score: 0.5091 - val_loss: 0.9808 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 22ms/step - accuracy: 0.7023 - f1_score: 0.6968 - loss: 0.5525 - val_accuracy: 0.5800 - val_f1_score: 0.4000 - val_loss: 1.1669 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 22ms/step - accuracy: 0.7897 - f1_score: 0.7930 - loss: 0.4405 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 1.5860 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 23ms/step - accuracy: 0.8222 - f1_score: 0.8217 - loss: 0.4121 - val_accuracy: 0.5400 - val_f1_score: 0.5490 - val_loss: 1.6726 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 22ms/step - accuracy: 0.8594 - f1_score: 0.8619 - loss: 0.3315 - val_accuracy: 0.4800 - val_f1_score: 0.4583 - val_loss: 1.6939 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 22ms/step - accuracy: 0.8978 - f1_score: 0.8978 - loss: 0.2407 - val_accuracy: 0.5400 - val_f1_score: 0.5660 - val_loss: 2.0423 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 21ms/step - accuracy: 0.9396 - f1_score: 0.9393 - loss: 0.1560 - val_accuracy: 0.4600 - val_f1_score: 0.4490 - val_loss: 2.3369 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 22ms/step - accuracy: 0.9535 - f1_score: 0.9523 - loss: 0.1271 - val_accuracy: 0.4600 - val_f1_score: 0.4706 - val_loss: 3.4844 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 22ms/step - accuracy: 0.9645 - f1_score: 0.9651 - loss: 0.0950 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 3.9583 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 23ms/step - accuracy: 0.9818 - f1_score: 0.9822 - loss: 0.0617 - val_accuracy: 0.5000 - val_f1_score: 0.4898 - val_loss: 3.5796 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 22ms/step - accuracy: 0.9878 - f1_score: 0.9880 - loss: 0.0484 - val_accuracy: 0.4600 - val_f1_score: 0.4906 - val_loss: 5.8425 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 22ms/step - accuracy: 0.9810 - f1_score: 0.9810 - loss: 0.0563 - val_accuracy: 0.5200 - val_f1_score: 0.5556 - val_loss: 5.1083 - learning_rate: 8.3736e-04\nEpoch 22/200\n37/37 - 1s - 21ms/step - accuracy: 0.9894 - f1_score: 0.9895 - loss: 0.0363 - val_accuracy: 0.4800 - val_f1_score: 0.4348 - val_loss: 5.3819 - learning_rate: 8.1479e-04\nEpoch 23/200\n37/37 - 1s - 22ms/step - accuracy: 0.9894 - f1_score: 0.9896 - loss: 0.0408 - val_accuracy: 0.4800 - val_f1_score: 0.5000 - val_loss: 6.3890 - learning_rate: 7.9071e-04\nEpoch 24/200\n37/37 - 1s - 22ms/step - accuracy: 0.9823 - f1_score: 0.9825 - loss: 0.0560 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 6.8627 - learning_rate: 7.6518e-04\nEpoch 25/200\n37/37 - 1s - 22ms/step - accuracy: 0.9848 - f1_score: 0.9848 - loss: 0.0472 - val_accuracy: 0.4400 - val_f1_score: 0.4167 - val_loss: 6.3101 - learning_rate: 7.3832e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377ms/step\nmodel5 → val F1 = 0.6071\n              precision    recall  f1-score   support\n\n        Left       0.69      0.39      0.50        28\n       Right       0.50      0.77      0.61        22\n\n    accuracy                           0.56        50\n   macro avg       0.59      0.58      0.55        50\nweighted avg       0.60      0.56      0.55        50\n\n\n>>> Training model6\nEpoch 1/200\n37/37 - 9s - 235ms/step - accuracy: 0.5076 - f1_score: 0.4970 - loss: 3.0390 - val_accuracy: 0.5600 - val_f1_score: 0.6207 - val_loss: 4.9895 - learning_rate: 0.0010\nEpoch 2/200\n37/37 - 1s - 37ms/step - accuracy: 0.5211 - f1_score: 0.5275 - loss: 1.6156 - val_accuracy: 0.4600 - val_f1_score: 0.4490 - val_loss: 2.2759 - learning_rate: 9.9994e-04\nEpoch 3/200\n37/37 - 1s - 37ms/step - accuracy: 0.5017 - f1_score: 0.5332 - loss: 1.0667 - val_accuracy: 0.5800 - val_f1_score: 0.0870 - val_loss: 2.4269 - learning_rate: 9.9969e-04\nEpoch 4/200\n37/37 - 1s - 38ms/step - accuracy: 0.5093 - f1_score: 0.5130 - loss: 0.9531 - val_accuracy: 0.4600 - val_f1_score: 0.4706 - val_loss: 0.6937 - learning_rate: 9.9914e-04\nEpoch 5/200\n37/37 - 1s - 38ms/step - accuracy: 0.4882 - f1_score: 0.5299 - loss: 0.7476 - val_accuracy: 0.4400 - val_f1_score: 0.3636 - val_loss: 1.3472 - learning_rate: 9.9815e-04\nEpoch 6/200\n37/37 - 1s - 38ms/step - accuracy: 0.5080 - f1_score: 0.5006 - loss: 0.7906 - val_accuracy: 0.5400 - val_f1_score: 0.4651 - val_loss: 0.7777 - learning_rate: 9.9661e-04\nEpoch 7/200\n37/37 - 1s - 38ms/step - accuracy: 0.5080 - f1_score: 0.4423 - loss: 0.7086 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.7950 - learning_rate: 9.9440e-04\nEpoch 8/200\n37/37 - 1s - 38ms/step - accuracy: 0.5000 - f1_score: 0.5298 - loss: 0.7003 - val_accuracy: 0.5600 - val_f1_score: 0.2143 - val_loss: 0.7325 - learning_rate: 9.9140e-04\nEpoch 9/200\n37/37 - 1s - 38ms/step - accuracy: 0.5152 - f1_score: 0.4956 - loss: 0.6938 - val_accuracy: 0.5400 - val_f1_score: 0.2069 - val_loss: 0.7155 - learning_rate: 9.8749e-04\nEpoch 10/200\n37/37 - 1s - 37ms/step - accuracy: 0.5089 - f1_score: 0.3977 - loss: 0.7000 - val_accuracy: 0.4600 - val_f1_score: 0.2286 - val_loss: 0.7277 - learning_rate: 9.8256e-04\nEpoch 11/200\n37/37 - 1s - 37ms/step - accuracy: 0.5097 - f1_score: 0.4865 - loss: 0.6954 - val_accuracy: 0.5200 - val_f1_score: 0.2500 - val_loss: 0.7240 - learning_rate: 9.7652e-04\nEpoch 12/200\n37/37 - 1s - 38ms/step - accuracy: 0.5215 - f1_score: 0.3709 - loss: 0.6937 - val_accuracy: 0.5200 - val_f1_score: 0.5385 - val_loss: 0.7875 - learning_rate: 9.6924e-04\nEpoch 13/200\n37/37 - 1s - 37ms/step - accuracy: 0.5207 - f1_score: 0.4530 - loss: 0.6913 - val_accuracy: 0.4600 - val_f1_score: 0.3077 - val_loss: 0.7788 - learning_rate: 9.6066e-04\nEpoch 14/200\n37/37 - 1s - 38ms/step - accuracy: 0.5148 - f1_score: 0.3057 - loss: 0.6932 - val_accuracy: 0.5800 - val_f1_score: 0.3226 - val_loss: 0.6960 - learning_rate: 9.5068e-04\nEpoch 15/200\n37/37 - 1s - 38ms/step - accuracy: 0.5008 - f1_score: 0.3726 - loss: 0.6957 - val_accuracy: 0.5800 - val_f1_score: 0.5333 - val_loss: 0.7565 - learning_rate: 9.3923e-04\nEpoch 16/200\n37/37 - 1s - 38ms/step - accuracy: 0.4970 - f1_score: 0.2940 - loss: 0.6942 - val_accuracy: 0.5800 - val_f1_score: 0.5714 - val_loss: 0.6985 - learning_rate: 9.2626e-04\nEpoch 17/200\n37/37 - 1s - 37ms/step - accuracy: 0.5089 - f1_score: 0.4697 - loss: 0.6933 - val_accuracy: 0.4600 - val_f1_score: 0.2286 - val_loss: 0.7134 - learning_rate: 9.1171e-04\nEpoch 18/200\n37/37 - 1s - 38ms/step - accuracy: 0.5397 - f1_score: 0.5443 - loss: 0.6923 - val_accuracy: 0.4600 - val_f1_score: 0.4255 - val_loss: 0.7134 - learning_rate: 8.9555e-04\nEpoch 19/200\n37/37 - 1s - 38ms/step - accuracy: 0.5118 - f1_score: 0.6365 - loss: 0.6917 - val_accuracy: 0.3800 - val_f1_score: 0.5507 - val_loss: 0.7289 - learning_rate: 8.7777e-04\nEpoch 20/200\n37/37 - 1s - 37ms/step - accuracy: 0.5080 - f1_score: 0.5979 - loss: 0.6917 - val_accuracy: 0.4200 - val_f1_score: 0.4314 - val_loss: 0.7465 - learning_rate: 8.5837e-04\nEpoch 21/200\n37/37 - 1s - 38ms/step - accuracy: 0.5127 - f1_score: 0.5290 - loss: 0.6901 - val_accuracy: 0.4600 - val_f1_score: 0.3415 - val_loss: 0.7127 - learning_rate: 8.3736e-04\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step\nmodel6 → val F1 = 0.6207\n              precision    recall  f1-score   support\n\n        Left       0.71      0.36      0.48        28\n       Right       0.50      0.82      0.62        22\n\n    accuracy                           0.56        50\n   macro avg       0.61      0.59      0.55        50\nweighted avg       0.62      0.56      0.54        50\n\n\n=== Final best: oldA (F1=0.7273) ===\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.metrics import f1_score\nimport tensorflow as tf\n\n# Function to compute best threshold for a model\ndef find_best_threshold(model, val_x, y_true_bin):\n    probs = model.predict(val_x)[:, 1]\n    thresholds = np.linspace(0.1, 1.0, 100)\n    best_f1 = 0\n    best_threshold = 0.5\n    for t in thresholds:\n        preds = (probs > t).astype(int)\n        f1 = f1_score(y_true_bin, preds)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = t\n    return best_threshold, best_f1\n\n# Load validation data\nval_npz = np.load(\"/kaggle/working/preprocessed/validation_MI.npz\")\nX_val_all, y_val = val_npz[\"X\"], val_npz[\"y\"]\ny_val_bin = (y_val == \"Right\").astype(int)\n\n# Use only EEG channels: C3, CZ, C4, PZ\neeg_indices = [1, 2, 3, 4]\nX_val_raw = X_val_all[:, eeg_indices, :].transpose(0, 2, 1).astype('float32')\n\n# Directories to check\ndirs = [\"/kaggle/working/models\", \"/kaggle/working/models2\", \"/kaggle/working/models3\"]\n# \n# Loop through models\nresults = {}\nfor model_dir in dirs:\n    for file in os.listdir(model_dir):\n        if file.endswith(\".h5\"):\n            path = os.path.join(model_dir, file)\n            try:\n                model = tf.keras.models.load_model(path, compile=False)\n                threshold, f1 = find_best_threshold(model, X_val_raw, y_val_bin)\n                results[path] = (threshold, f1)\n            except Exception as e:\n                results[path] = f\"Error: {e}\"\n\n# Print results\nfor model_path, (threshold, f1) in results.items():\n    print(f\"{model_path} → Best threshold = {threshold:.2f}, F1 score = {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T03:19:51.900607Z","iopub.execute_input":"2025-07-23T03:19:51.900934Z","iopub.status.idle":"2025-07-23T03:20:47.982839Z","shell.execute_reply.started":"2025-07-23T03:19:51.900911Z","shell.execute_reply":"2025-07-23T03:20:47.982164Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step\n/kaggle/working/models/best_final.h5 → Best threshold = 0.10, F1 score = 0.6333\n/kaggle/working/models/best_model1.h5 → Best threshold = 0.10, F1 score = 0.6111\n/kaggle/working/models/best_model5.h5 → Best threshold = 0.10, F1 score = 0.0870\n/kaggle/working/models/best_model2.h5 → Best threshold = 0.10, F1 score = 0.6667\n/kaggle/working/models/best_oldA.h5 → Best threshold = 0.10, F1 score = 0.5797\n/kaggle/working/models/best_oldB.h5 → Best threshold = 0.10, F1 score = 0.5217\n/kaggle/working/models/best_model6.h5 → Best threshold = 0.38, F1 score = 0.3784\n/kaggle/working/models/best_model4.h5 → Best threshold = 0.48, F1 score = 0.6269\n/kaggle/working/models/best_model3.h5 → Best threshold = 0.10, F1 score = 0.6333\n/kaggle/working/models2/best_final.h5 → Best threshold = 0.13, F1 score = 0.6176\n/kaggle/working/models2/best_model1.h5 → Best threshold = 0.10, F1 score = 0.6111\n/kaggle/working/models2/best_model5.h5 → Best threshold = 0.15, F1 score = 0.6197\n/kaggle/working/models2/best_model2.h5 → Best threshold = 0.13, F1 score = 0.6176\n/kaggle/working/models2/best_oldA.h5 → Best threshold = 0.10, F1 score = 0.6000\n/kaggle/working/models2/best_oldB.h5 → Best threshold = 0.85, F1 score = 0.6207\n/kaggle/working/models2/best_model6.h5 → Best threshold = 0.93, F1 score = 0.6087\n/kaggle/working/models2/best_model4.h5 → Best threshold = 0.58, F1 score = 0.6774\n/kaggle/working/models2/best_model3.h5 → Best threshold = 0.10, F1 score = 0.6286\n/kaggle/working/models3/best_final.h5 → Best threshold = 0.50, F1 score = 0.7273\n/kaggle/working/models3/best_model1.h5 → Best threshold = 0.50, F1 score = 0.6471\n/kaggle/working/models3/best_model5.h5 → Best threshold = 0.10, F1 score = 0.4000\n/kaggle/working/models3/best_model2.h5 → Best threshold = 0.50, F1 score = 0.6939\n/kaggle/working/models3/best_oldA.h5 → Best threshold = 0.50, F1 score = 0.7273\n/kaggle/working/models3/best_oldB.h5 → Best threshold = 0.50, F1 score = 0.6471\n/kaggle/working/models3/best_model6.h5 → Best threshold = 0.51, F1 score = 0.6429\n/kaggle/working/models3/best_model4.h5 → Best threshold = 0.10, F1 score = 0.6111\n/kaggle/working/models3/best_model3.h5 → Best threshold = 0.10, F1 score = 0.6269\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.metrics import f1_score, classification_report\nimport tensorflow as tf\n\n# Function to compute best threshold and generate classification report\ndef evaluate_model(model, val_x, y_true_str):\n    # Convert true labels to binary (Right=1, Left=0)\n    y_true_bin = np.array([1 if label == \"Right\" else 0 for label in y_true_str])\n    \n    # Get prediction probabilities for class 1 (Right)\n    probs = model.predict(val_x, verbose=0)[:, 1]\n    \n    # Find best threshold\n    thresholds = np.linspace(0.1, 1.0, 100)\n    best_f1 = 0\n    best_threshold = 0.5\n    for t in thresholds:\n        preds_bin = (probs > t).astype(int)\n        f1 = f1_score(y_true_bin, preds_bin)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = t\n    \n    # Generate predictions using best threshold\n    pred_labels = [\"Right\" if prob > best_threshold else \"Left\" for prob in probs]\n    \n    # Generate classification report\n    report = classification_report(\n        y_true_str, \n        pred_labels,\n        target_names=[\"Left\", \"Right\"],\n        digits=4\n    )\n    \n    return best_threshold, best_f1, report\n\n# Load validation data\nval_npz = np.load(\"/kaggle/working/preprocessed/validation_MI.npz\")\nX_val_all, y_val = val_npz[\"X\"], val_npz[\"y\"]\n\n# Use only EEG channels: C3, CZ, C4, PZ\neeg_indices = [1, 2, 3, 4]  # Update if your channel order differs\nX_val_raw = X_val_all[:, eeg_indices, :].transpose(0, 2, 1).astype('float32')\n\n# Directories to check\ndirs = [\n    \"/kaggle/working/models3\", \"/kaggle/working/models2\", \"/kaggle/working/models\"]\n\n# Evaluate models\nresults = {}\nfor model_dir in dirs:\n    for file in os.listdir(model_dir):\n        if file.endswith(\".h5\"):\n            path = os.path.join(model_dir, file)\n            try:\n                model = tf.keras.models.load_model(path, compile=False)\n                threshold, f1, report = evaluate_model(model, X_val_raw, y_val)\n                results[path] = {\n                    \"threshold\": threshold,\n                    \"f1\": f1,\n                    \"report\": report\n                }\n            except Exception as e:\n                results[path] = f\"Error: {e}\"\n\n# Print results with classification reports\nfor path, result in results.items():\n    if isinstance(result, str):\n        print(f\"\\n{path} → {result}\")\n    else:\n        print(f\"\\n{'-'*80}\")\n        print(f\"Model: {path}\")\n        print(f\"Best threshold: {result['threshold']:.4f}\")\n        print(f\"Best F1-score: {result['f1']:.4f}\")\n        print(\"\\nClassification Report:\")\n        print(result['report'])\n        print(f\"{'-'*80}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T03:20:47.983959Z","iopub.execute_input":"2025-07-23T03:20:47.984266Z","iopub.status.idle":"2025-07-23T03:21:43.515831Z","shell.execute_reply.started":"2025-07-23T03:20:47.984242Z","shell.execute_reply":"2025-07-23T03:21:43.515134Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_final.h5\nBest threshold: 0.5000\nBest F1-score: 0.7273\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.8824    0.5357    0.6667        28\n       Right     0.6061    0.9091    0.7273        22\n\n    accuracy                         0.7000        50\n   macro avg     0.7442    0.7224    0.6970        50\nweighted avg     0.7608    0.7000    0.6933        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_model1.h5\nBest threshold: 0.5000\nBest F1-score: 0.6471\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     1.0000    0.1429    0.2500        28\n       Right     0.4783    1.0000    0.6471        22\n\n    accuracy                         0.5200        50\n   macro avg     0.7391    0.5714    0.4485        50\nweighted avg     0.7704    0.5200    0.4247        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_model5.h5\nBest threshold: 0.1000\nBest F1-score: 0.4000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.5625    0.6429    0.6000        28\n       Right     0.4444    0.3636    0.4000        22\n\n    accuracy                         0.5200        50\n   macro avg     0.5035    0.5032    0.5000        50\nweighted avg     0.5106    0.5200    0.5120        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_model2.h5\nBest threshold: 0.5000\nBest F1-score: 0.6939\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7826    0.6429    0.7059        28\n       Right     0.6296    0.7727    0.6939        22\n\n    accuracy                         0.7000        50\n   macro avg     0.7061    0.7078    0.6999        50\nweighted avg     0.7153    0.7000    0.7006        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_oldA.h5\nBest threshold: 0.5000\nBest F1-score: 0.7273\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.8824    0.5357    0.6667        28\n       Right     0.6061    0.9091    0.7273        22\n\n    accuracy                         0.7000        50\n   macro avg     0.7442    0.7224    0.6970        50\nweighted avg     0.7608    0.7000    0.6933        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_oldB.h5\nBest threshold: 0.5000\nBest F1-score: 0.6471\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     1.0000    0.1429    0.2500        28\n       Right     0.4783    1.0000    0.6471        22\n\n    accuracy                         0.5200        50\n   macro avg     0.7391    0.5714    0.4485        50\nweighted avg     0.7704    0.5200    0.4247        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_model6.h5\nBest threshold: 0.5091\nBest F1-score: 0.6429\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7500    0.4286    0.5455        28\n       Right     0.5294    0.8182    0.6429        22\n\n    accuracy                         0.6000        50\n   macro avg     0.6397    0.6234    0.5942        50\nweighted avg     0.6529    0.6000    0.5883        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_model4.h5\nBest threshold: 0.1000\nBest F1-score: 0.6111\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.0000    0.0000    0.0000        28\n       Right     0.4400    1.0000    0.6111        22\n\n    accuracy                         0.4400        50\n   macro avg     0.2200    0.5000    0.3056        50\nweighted avg     0.1936    0.4400    0.2689        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models3/best_model3.h5\nBest threshold: 0.1000\nBest F1-score: 0.6269\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.8000    0.1429    0.2424        28\n       Right     0.4667    0.9545    0.6269        22\n\n    accuracy                         0.5000        50\n   macro avg     0.6333    0.5487    0.4346        50\nweighted avg     0.6533    0.5000    0.4116        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_final.h5\nBest threshold: 0.1273\nBest F1-score: 0.6176\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7500    0.1071    0.1875        28\n       Right     0.4565    0.9545    0.6176        22\n\n    accuracy                         0.4800        50\n   macro avg     0.6033    0.5308    0.4026        50\nweighted avg     0.6209    0.4800    0.3768        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_model1.h5\nBest threshold: 0.1000\nBest F1-score: 0.6111\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.0000    0.0000    0.0000        28\n       Right     0.4400    1.0000    0.6111        22\n\n    accuracy                         0.4400        50\n   macro avg     0.2200    0.5000    0.3056        50\nweighted avg     0.1936    0.4400    0.2689        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_model5.h5\nBest threshold: 0.1455\nBest F1-score: 0.6197\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     1.0000    0.0357    0.0690        28\n       Right     0.4490    1.0000    0.6197        22\n\n    accuracy                         0.4600        50\n   macro avg     0.7245    0.5179    0.3443        50\nweighted avg     0.7576    0.4600    0.3113        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_model2.h5\nBest threshold: 0.1273\nBest F1-score: 0.6176\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7500    0.1071    0.1875        28\n       Right     0.4565    0.9545    0.6176        22\n\n    accuracy                         0.4800        50\n   macro avg     0.6033    0.5308    0.4026        50\nweighted avg     0.6209    0.4800    0.3768        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_oldA.h5\nBest threshold: 0.1000\nBest F1-score: 0.6000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.6818    0.5357    0.6000        28\n       Right     0.5357    0.6818    0.6000        22\n\n    accuracy                         0.6000        50\n   macro avg     0.6088    0.6088    0.6000        50\nweighted avg     0.6175    0.6000    0.6000        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_oldB.h5\nBest threshold: 0.8545\nBest F1-score: 0.6207\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7143    0.3571    0.4762        28\n       Right     0.5000    0.8182    0.6207        22\n\n    accuracy                         0.5600        50\n   macro avg     0.6071    0.5877    0.5484        50\nweighted avg     0.6200    0.5600    0.5398        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_model6.h5\nBest threshold: 0.9273\nBest F1-score: 0.6087\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.6667    0.0714    0.1290        28\n       Right     0.4468    0.9545    0.6087        22\n\n    accuracy                         0.4600        50\n   macro avg     0.5567    0.5130    0.3689        50\nweighted avg     0.5699    0.4600    0.3401        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_model4.h5\nBest threshold: 0.5818\nBest F1-score: 0.6774\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.9000    0.3214    0.4737        28\n       Right     0.5250    0.9545    0.6774        22\n\n    accuracy                         0.6000        50\n   macro avg     0.7125    0.6380    0.5756        50\nweighted avg     0.7350    0.6000    0.5633        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models2/best_model3.h5\nBest threshold: 0.1000\nBest F1-score: 0.6286\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     1.0000    0.0714    0.1333        28\n       Right     0.4583    1.0000    0.6286        22\n\n    accuracy                         0.4800        50\n   macro avg     0.7292    0.5357    0.3810        50\nweighted avg     0.7617    0.4800    0.3512        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_final.h5\nBest threshold: 0.1000\nBest F1-score: 0.6333\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7500    0.3214    0.4500        28\n       Right     0.5000    0.8636    0.6333        22\n\n    accuracy                         0.5600        50\n   macro avg     0.6250    0.5925    0.5417        50\nweighted avg     0.6400    0.5600    0.5307        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_model1.h5\nBest threshold: 0.1000\nBest F1-score: 0.6111\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.0000    0.0000    0.0000        28\n       Right     0.4400    1.0000    0.6111        22\n\n    accuracy                         0.4400        50\n   macro avg     0.2200    0.5000    0.3056        50\nweighted avg     0.1936    0.4400    0.2689        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_model5.h5\nBest threshold: 0.1000\nBest F1-score: 0.0870\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.5714    1.0000    0.7273        28\n       Right     1.0000    0.0455    0.0870        22\n\n    accuracy                         0.5800        50\n   macro avg     0.7857    0.5227    0.4071        50\nweighted avg     0.7600    0.5800    0.4455        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_model2.h5\nBest threshold: 0.1000\nBest F1-score: 0.6667\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7407    0.7143    0.7273        28\n       Right     0.6522    0.6818    0.6667        22\n\n    accuracy                         0.7000        50\n   macro avg     0.6965    0.6981    0.6970        50\nweighted avg     0.7018    0.7000    0.7006        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_oldA.h5\nBest threshold: 0.1000\nBest F1-score: 0.5797\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.3333    0.0357    0.0645        28\n       Right     0.4255    0.9091    0.5797        22\n\n    accuracy                         0.4200        50\n   macro avg     0.3794    0.4724    0.3221        50\nweighted avg     0.3739    0.4200    0.2912        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_oldB.h5\nBest threshold: 0.1000\nBest F1-score: 0.5217\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.6154    0.5714    0.5926        28\n       Right     0.5000    0.5455    0.5217        22\n\n    accuracy                         0.5600        50\n   macro avg     0.5577    0.5584    0.5572        50\nweighted avg     0.5646    0.5600    0.5614        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_model6.h5\nBest threshold: 0.3818\nBest F1-score: 0.3784\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.5714    0.7143    0.6349        28\n       Right     0.4667    0.3182    0.3784        22\n\n    accuracy                         0.5400        50\n   macro avg     0.5190    0.5162    0.5066        50\nweighted avg     0.5253    0.5400    0.5220        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_model4.h5\nBest threshold: 0.4818\nBest F1-score: 0.6269\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.8000    0.1429    0.2424        28\n       Right     0.4667    0.9545    0.6269        22\n\n    accuracy                         0.5000        50\n   macro avg     0.6333    0.5487    0.4346        50\nweighted avg     0.6533    0.5000    0.4116        50\n\n--------------------------------------------------------------------------------\n\n--------------------------------------------------------------------------------\nModel: /kaggle/working/models/best_model3.h5\nBest threshold: 0.1000\nBest F1-score: 0.6333\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Left     0.7500    0.3214    0.4500        28\n       Right     0.5000    0.8636    0.6333        22\n\n    accuracy                         0.5600        50\n   macro avg     0.6250    0.5925    0.5417        50\nweighted avg     0.6400    0.5600    0.5307        50\n\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n# Configuration\nbase_path = \"/kaggle/input/mtcaic3-phase-ii\"\npreprocessed_dir = '/kaggle/working/preprocessed'  # Directory with preprocessed .npz files\nmodel_path = '/kaggle/working/models3/best_final.h5'\noutput_file = '/kaggle/working/submission.csv'\nthreshold = 0.5  # Prediction threshold for MI task\n\n# Load test data and sample submission\ntest_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\nsample_sub = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n\n# Fixed F1Score metric class\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        preds = tf.argmax(y_pred, axis=1)\n        labels = tf.argmax(y_true, axis=1)\n        \n        true_pos = tf.logical_and(tf.equal(preds, 1), tf.equal(labels, 1))\n        false_pos = tf.logical_and(tf.equal(preds, 1), tf.equal(labels, 0))\n        false_neg = tf.logical_and(tf.equal(preds, 0), tf.equal(labels, 1))\n        \n        self.tp.assign_add(tf.reduce_sum(tf.cast(true_pos, tf.float32)))\n        self.fp.assign_add(tf.reduce_sum(tf.cast(false_pos, tf.float32)))\n        self.fn.assign_add(tf.reduce_sum(tf.cast(false_neg, tf.float32)))\n\n    def result(self):\n        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.assign(0.0)\n        self.fp.assign(0.0)\n        self.fn.assign(0.0)\n\n# Load model with fixed metric\nmodel = load_model(model_path, custom_objects={'F1Score': F1Score})\n\n# Define EEG channels to extract and their indices in preprocessed data\nchannel_names = ['FZ','C3','CZ','C4','PZ','PO7','OZ','PO8']\ntarget_channels = ['C3','CZ','C4','PZ']\ntarget_indices = [channel_names.index(ch) for ch in target_channels]\n\n# Load preprocessed test data\ntest_mi = np.load(os.path.join(preprocessed_dir, 'test_MI.npz'))['X']  # Shape (n_mi, 8, 2250)\ntest_ssvep = np.load(os.path.join(preprocessed_dir, 'test_SSVEP.npz'))['X']  # Shape (n_ssvep, 8, 1750)\n\n# Extract target channels and transpose to (trials, time, channels)\ntest_mi = test_mi[:, target_indices, :].transpose(0, 2, 1)  # New shape: (n_mi, 2250, 4)\ntest_ssvep = test_ssvep[:, target_indices, :].transpose(0, 2, 1)  # New shape: (n_ssvep, 1750, 4)\n\n# Get indices of MI and SSVEP trials in test_df\nmi_mask = test_df['task'] == 'MI'\nssvep_mask = test_df['task'] == 'SSVEP'\n\n# Validate counts\nassert mi_mask.sum() == test_mi.shape[0], \"MI trial count mismatch\"\nassert ssvep_mask.sum() == test_ssvep.shape[0], \"SSVEP trial count mismatch\"\n\n# Generate predictions\npredictions = []\n# Predict MI trials\nif test_mi.shape[0] > 0:\n    mi_preds = model.predict(test_mi, verbose=0)\n    mi_labels = ['Right' if prob[1] >= threshold else 'Left' for prob in mi_preds]\n    predictions.extend(mi_labels)\n\n# Assign dummy labels for SSVEP trials\nif test_ssvep.shape[0] > 0:\n    predictions.extend(['Left'] * test_ssvep.shape[0])\n\n# Create submission file\nsubmission = sample_sub.copy()\nsubmission['label'] = predictions\nsubmission.to_csv(output_file, index=False)\n\nprint(f\"Submission file saved to {output_file}\")\nprint(\"Prediction distribution:\")\nprint(submission['label'].value_counts())\nprint(f\"\\nThreshold used for MI: {threshold}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T03:29:17.148493Z","iopub.execute_input":"2025-07-23T03:29:17.149016Z","iopub.status.idle":"2025-07-23T03:29:18.420555Z","shell.execute_reply.started":"2025-07-23T03:29:17.148994Z","shell.execute_reply":"2025-07-23T03:29:18.419866Z"}},"outputs":[{"name":"stdout","text":"Submission file saved to /kaggle/working/submission.csv\nPrediction distribution:\nlabel\nLeft     133\nRight     67\nName: count, dtype: int64\n\nThreshold used for MI: 0.5\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.metrics import f1_score, classification_report\nfrom mne.decoding import CSP\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\nimport gc\n\n# --- 0) Config ---\nBASE_PATH = '/kaggle/input/mtcaic3-phase-ii'  # Update this path\ndata_dir = './preprocessed'\noutput_dir = './models_loso'\nos.makedirs(output_dir, exist_ok=True)\n\neeg_indices = [1, 2, 3, 4]  # C3, CZ, C4, PZ\nbatch_size = 64\n\n# --- 1) Load & prepare data ---\n# Load subject information from train.csv\ntrain_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\nmi_train_df = train_df[train_df['task'] == 'MI'].reset_index(drop=True)\nsubject_ids = mi_train_df['subject_id'].values\n\n# Load preprocessed data\ntrain_npz = np.load(os.path.join(data_dir, 'train_MI.npz'))\nX_train_all = train_npz['X']  # (2400, 8, 2250)\ny_train = train_npz['y']      # (2400,)\n\n# Filter for EEG channels\nX_train_raw = X_train_all[:, eeg_indices, :].transpose(0, 2, 1).astype('float32')  # (2400, 2250, 4)\n\n# Binarize labels\ny_train_bin = (y_train == 'Right').astype(int)\n\n# --- 2) Setup LOSO Cross-Validation ---\nlogo = LeaveOneGroupOut()\ngroups = subject_ids\nn_folds = logo.get_n_splits(groups=groups)\n\n# --- 3) Model Builders (Unchanged from original) ---\n# [Include all model builder functions: build_modelA, build_modelB, build_model1, etc.]\n# ... (Paste all your model builder functions here unchanged) ...\n\n# --- 4) F1 Score Metric (Unchanged) ---\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        preds  = tf.argmax(y_pred, axis=1)\n        labels = tf.argmax(y_true, axis=1)\n        self.tp.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(preds == 1, labels == 1), tf.float32)))\n        self.fp.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(preds == 1, labels == 0), tf.float32)))\n        self.fn.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(preds == 0, labels == 1), tf.float32)))\n\n    def result(self):\n        p = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n        r = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n        return 2 * (p * r) / (p + r + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.assign(0.0)\n        self.fp.assign(0.0)\n        self.fn.assign(0.0)\n\n    # ... (Paste your F1Score class implementation here) ...\n\n# --- 5) Cosine LR Schedule (Unchanged) ---\ndef cosine_lr(epoch, lr_max=5e-5, epochs=200):\n    return lr_max * (1 + np.cos(np.pi * epoch / epochs)) / 2\n\n# --- 6) Callback Factory ---\ndef get_callbacks(name, fold_dir):\n    return [\n        EarlyStopping(monitor=\"val_f1_score\", mode=\"max\", patience=20, restore_best_weights=True),\n        ModelCheckpoint(os.path.join(fold_dir, f\"best_{name}.h5\")),\n        CSVLogger(os.path.join(fold_dir, f\"log_{name}.csv\")),\n        LearningRateScheduler(cosine_lr)\n    ]\n\n# --- 7) Data Augmentation Generator ---\ndef aug_gen(X, y, seed=0, batch_size=32):\n    n = X.shape[0]\n    rng = np.random.RandomState(seed)\n    while True:\n        idx = rng.randint(0, n, batch_size)\n        bx, by = X[idx].copy(), y[idx]\n        bx += rng.normal(0, 0.005, bx.shape)\n        yield bx, by\n\n# --- 8) LOSO Cross-Validation ---\n# Dictionary to store results\nbuilders = {\n    'oldA': build_modelA,\n    'oldB': build_modelB,\n    'model1': build_model1,\n    'model2': build_model2,\n    'model3': build_model3,\n    'model4': build_model4,\n    'model5': build_model5,\n    'model6': build_model6,\n}\n\n# Initialize results storage\nresults = {name: [] for name in builders.keys()}\n\nfor fold_idx, (train_idx, val_idx) in enumerate(logo.split(X_train_raw, y_train_bin, groups=groups)):\n    subject_id = groups[val_idx[0]]\n    print(f\"\\n{'='*50}\")\n    print(f\"Fold {fold_idx+1}/{n_folds} - Subject: {subject_id}\")\n    print(f\"{'='*50}\")\n    \n    # Create output directory for fold\n    fold_dir = os.path.join(output_dir, f\"fold_{fold_idx+1}\")\n    os.makedirs(fold_dir, exist_ok=True)\n    \n    # Split data\n    X_train_fold_raw = X_train_raw[train_idx]\n    y_train_fold_bin = y_train_bin[train_idx]\n    X_val_fold_raw = X_train_raw[val_idx]\n    y_val_fold_bin = y_train_bin[val_idx]\n    \n    # --- Compute CSP using ONLY training fold data ---\n    print(\"Computing CSP for current fold...\")\n    csp = CSP(n_components=4, log=False, norm_trace=False)\n    \n    # Prepare data for CSP: (n_trials, n_channels, n_times)\n    X_train_csp_input = X_train_fold_raw.transpose(0, 2, 1).astype('float64')\n    csp.fit(X_train_csp_input, y_train_fold_bin)\n    W = csp.filters_[:4]  # (4, 4) filter matrix\n    \n    # Apply CSP to both training and validation data\n    def apply_csp_fold(X):\n        return np.stack([W.T @ x.T for x in X], axis=0)  # (n, n_components, n_times)\n    \n    X_train_fold_csp = apply_csp_fold(X_train_fold_raw).transpose(0, 2, 1).astype('float32')\n    X_val_fold_csp = apply_csp_fold(X_val_fold_raw).transpose(0, 2, 1).astype('float32')\n    \n    # Create 2D versions for models that need it\n    X_train_fold_csp_2d = X_train_fold_csp[..., np.newaxis]\n    X_val_fold_csp_2d = X_val_fold_csp[..., np.newaxis]\n    \n    # One-hot encode labels\n    y_train_fold_oh = keras.utils.to_categorical(y_train_fold_bin, 2)\n    y_val_fold_oh = keras.utils.to_categorical(y_val_fold_bin, 2)\n    \n    # Steps per epoch\n    steps_per_epoch = len(X_train_fold_raw) // batch_size\n    \n    # --- Train all models on current fold ---\n    for name, build_fn in builders.items():\n        print(f\"\\n>>> Training {name} on Fold {fold_idx+1}\")\n        \n        # Clean up previous models\n        tf.keras.backend.clear_session()\n        gc.collect()\n        \n        # Select appropriate data format\n        if name == 'model3':\n            X_train = X_train_fold_csp_2d\n            X_val = X_val_fold_csp_2d\n            input_shape = X_train.shape[1:]\n            train_gen = aug_gen(X_train, y_train_fold_oh, seed=fold_idx, batch_size=batch_size)\n        elif name in ['model4', 'model5']:\n            X_train = X_train_fold_csp\n            X_val = X_val_fold_csp\n            input_shape = X_train.shape[1:]\n            train_gen = aug_gen(X_train, y_train_fold_oh, seed=fold_idx, batch_size=batch_size)\n        else:\n            X_train = X_train_fold_raw\n            X_val = X_val_fold_raw\n            input_shape = X_train.shape[1:]\n            train_gen = aug_gen(X_train, y_train_fold_oh, seed=fold_idx, batch_size=batch_size)\n        \n        # Build model\n        model = build_fn(input_shape)\n        \n        # Train model\n        history = model.fit(\n            train_gen,\n            steps_per_epoch=steps_per_epoch,\n            epochs=200,\n            validation_data=(X_val, y_val_fold_oh),\n            callbacks=get_callbacks(name, fold_dir),\n            verbose=2\n        )\n        \n        # Evaluate\n        preds = np.argmax(model.predict(X_val), axis=1)\n        f1 = f1_score(y_val_fold_bin, preds)\n        print(f\"{name} → Fold {fold_idx+1} Val F1 = {f1:.4f}\")\n        results[name].append(f1)\n        \n        # Save fold results\n        np.save(os.path.join(fold_dir, f\"results_{name}.npy\"), np.array([f1]))\n\n# --- 9) Final Results ---\nprint(\"\\n\\n=== Final LOSO Results ===\")\nfor name, f1_scores in results.items():\n    mean_f1 = np.mean(f1_scores)\n    std_f1 = np.std(f1_scores)\n    print(f\"{name}:\")\n    print(f\"  F1 Scores: {', '.join([f'{s:.4f}' for s in f1_scores])}\")\n    print(f\"  Mean F1 = {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n\n# Save all results\nnp.save(os.path.join(output_dir, \"all_results.npy\"), results)\nprint(\"LOSO complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T04:13:53.409567Z","iopub.execute_input":"2025-07-23T04:13:53.409826Z","execution_failed":"2025-07-23T05:14:47.271Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nFold 1/30 - Subject: S1\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 1\nEpoch 1/200\n36/36 - 8s - 235ms/step - accuracy: 0.5087 - f1_score: 0.5212 - loss: 0.8719 - val_accuracy: 0.5500 - val_f1_score: 0.2500 - val_loss: 0.6974 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 29ms/step - accuracy: 0.5056 - f1_score: 0.5105 - loss: 0.7853 - val_accuracy: 0.4625 - val_f1_score: 0.3944 - val_loss: 0.7013 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 29ms/step - accuracy: 0.4918 - f1_score: 0.4924 - loss: 0.7361 - val_accuracy: 0.5500 - val_f1_score: 0.4194 - val_loss: 0.6966 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 28ms/step - accuracy: 0.5286 - f1_score: 0.5199 - loss: 0.7181 - val_accuracy: 0.5500 - val_f1_score: 0.4000 - val_loss: 0.6977 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.5009 - f1_score: 0.5077 - loss: 0.7154 - val_accuracy: 0.5250 - val_f1_score: 0.2400 - val_loss: 0.7030 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 28ms/step - accuracy: 0.5161 - f1_score: 0.5391 - loss: 0.7087 - val_accuracy: 0.4625 - val_f1_score: 0.5657 - val_loss: 0.7040 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.5056 - f1_score: 0.5020 - loss: 0.7123 - val_accuracy: 0.5375 - val_f1_score: 0.4127 - val_loss: 0.6998 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5013 - f1_score: 0.5058 - loss: 0.7070 - val_accuracy: 0.5250 - val_f1_score: 0.4412 - val_loss: 0.7020 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5169 - f1_score: 0.5138 - loss: 0.7026 - val_accuracy: 0.5250 - val_f1_score: 0.6042 - val_loss: 0.7046 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.5204 - f1_score: 0.5644 - loss: 0.7002 - val_accuracy: 0.5000 - val_f1_score: 0.6226 - val_loss: 0.7063 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 29ms/step - accuracy: 0.5169 - f1_score: 0.5274 - loss: 0.7028 - val_accuracy: 0.4625 - val_f1_score: 0.4110 - val_loss: 0.7009 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5148 - f1_score: 0.5752 - loss: 0.7017 - val_accuracy: 0.5000 - val_f1_score: 0.5745 - val_loss: 0.7020 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5122 - f1_score: 0.5386 - loss: 0.7012 - val_accuracy: 0.4500 - val_f1_score: 0.5217 - val_loss: 0.7045 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5052 - f1_score: 0.5009 - loss: 0.7015 - val_accuracy: 0.4375 - val_f1_score: 0.5545 - val_loss: 0.7022 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 28ms/step - accuracy: 0.5078 - f1_score: 0.5514 - loss: 0.7015 - val_accuracy: 0.5750 - val_f1_score: 0.4138 - val_loss: 0.7001 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5139 - f1_score: 0.5447 - loss: 0.7014 - val_accuracy: 0.4375 - val_f1_score: 0.5631 - val_loss: 0.7034 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.5143 - f1_score: 0.5216 - loss: 0.7015 - val_accuracy: 0.5125 - val_f1_score: 0.2041 - val_loss: 0.7027 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.5321 - f1_score: 0.5009 - loss: 0.6984 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 0.7050 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5191 - f1_score: 0.5835 - loss: 0.6993 - val_accuracy: 0.4625 - val_f1_score: 0.5743 - val_loss: 0.7050 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 28ms/step - accuracy: 0.5360 - f1_score: 0.6128 - loss: 0.6968 - val_accuracy: 0.4625 - val_f1_score: 0.5905 - val_loss: 0.7058 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 28ms/step - accuracy: 0.5148 - f1_score: 0.5318 - loss: 0.6987 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.7022 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 28ms/step - accuracy: 0.5282 - f1_score: 0.4975 - loss: 0.6979 - val_accuracy: 0.5250 - val_f1_score: 0.2963 - val_loss: 0.7019 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 28ms/step - accuracy: 0.5369 - f1_score: 0.4520 - loss: 0.6974 - val_accuracy: 0.5250 - val_f1_score: 0.2692 - val_loss: 0.7017 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 28ms/step - accuracy: 0.5117 - f1_score: 0.5174 - loss: 0.7001 - val_accuracy: 0.4500 - val_f1_score: 0.5319 - val_loss: 0.7083 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 28ms/step - accuracy: 0.5165 - f1_score: 0.5457 - loss: 0.6986 - val_accuracy: 0.4750 - val_f1_score: 0.3636 - val_loss: 0.7052 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 28ms/step - accuracy: 0.5421 - f1_score: 0.5145 - loss: 0.6944 - val_accuracy: 0.4875 - val_f1_score: 0.3692 - val_loss: 0.7048 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 28ms/step - accuracy: 0.5256 - f1_score: 0.4565 - loss: 0.6965 - val_accuracy: 0.4375 - val_f1_score: 0.2105 - val_loss: 0.7033 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 29ms/step - accuracy: 0.5326 - f1_score: 0.4937 - loss: 0.6932 - val_accuracy: 0.4625 - val_f1_score: 0.2712 - val_loss: 0.7045 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 30ms/step - accuracy: 0.5326 - f1_score: 0.5258 - loss: 0.6961 - val_accuracy: 0.4625 - val_f1_score: 0.4267 - val_loss: 0.7056 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 28ms/step - accuracy: 0.5538 - f1_score: 0.5302 - loss: 0.6942 - val_accuracy: 0.5250 - val_f1_score: 0.2963 - val_loss: 0.7029 - learning_rate: 5.8827e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step\noldA → Fold 1 Val F1 = 0.6226\n\n>>> Training oldB on Fold 1\nEpoch 1/200\n36/36 - 13s - 373ms/step - accuracy: 0.5061 - f1_score: 0.5048 - loss: 3.0873 - val_accuracy: 0.6125 - val_f1_score: 0.5974 - val_loss: 0.7396 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 36ms/step - accuracy: 0.5026 - f1_score: 0.4978 - loss: 2.1747 - val_accuracy: 0.5250 - val_f1_score: 0.1364 - val_loss: 0.7363 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 36ms/step - accuracy: 0.4965 - f1_score: 0.4899 - loss: 1.5861 - val_accuracy: 0.5125 - val_f1_score: 0.2041 - val_loss: 0.7500 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.4939 - f1_score: 0.4790 - loss: 1.3684 - val_accuracy: 0.5625 - val_f1_score: 0.2222 - val_loss: 0.7394 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 36ms/step - accuracy: 0.4970 - f1_score: 0.4937 - loss: 1.0382 - val_accuracy: 0.5125 - val_f1_score: 0.5618 - val_loss: 0.7461 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 36ms/step - accuracy: 0.5052 - f1_score: 0.5198 - loss: 0.9738 - val_accuracy: 0.5125 - val_f1_score: 0.6139 - val_loss: 0.7462 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 35ms/step - accuracy: 0.5122 - f1_score: 0.5309 - loss: 0.8822 - val_accuracy: 0.5375 - val_f1_score: 0.4308 - val_loss: 0.7457 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 36ms/step - accuracy: 0.4918 - f1_score: 0.4802 - loss: 0.8631 - val_accuracy: 0.5500 - val_f1_score: 0.6087 - val_loss: 0.7465 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 36ms/step - accuracy: 0.5156 - f1_score: 0.5500 - loss: 0.8327 - val_accuracy: 0.5000 - val_f1_score: 0.6000 - val_loss: 0.7469 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 36ms/step - accuracy: 0.4987 - f1_score: 0.5100 - loss: 0.8280 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7488 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 36ms/step - accuracy: 0.5126 - f1_score: 0.5956 - loss: 0.7989 - val_accuracy: 0.4875 - val_f1_score: 0.6435 - val_loss: 0.7485 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 36ms/step - accuracy: 0.4874 - f1_score: 0.5775 - loss: 0.7874 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7496 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 35ms/step - accuracy: 0.5039 - f1_score: 0.5656 - loss: 0.7836 - val_accuracy: 0.5250 - val_f1_score: 0.5366 - val_loss: 0.7478 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 35ms/step - accuracy: 0.5234 - f1_score: 0.6098 - loss: 0.7827 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7502 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 35ms/step - accuracy: 0.4970 - f1_score: 0.5291 - loss: 0.7731 - val_accuracy: 0.5125 - val_f1_score: 0.2909 - val_loss: 0.7478 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 35ms/step - accuracy: 0.5243 - f1_score: 0.5668 - loss: 0.7694 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7489 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 35ms/step - accuracy: 0.5191 - f1_score: 0.5668 - loss: 0.7759 - val_accuracy: 0.5875 - val_f1_score: 0.5600 - val_loss: 0.7470 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 35ms/step - accuracy: 0.5126 - f1_score: 0.5441 - loss: 0.7650 - val_accuracy: 0.6000 - val_f1_score: 0.4483 - val_loss: 0.7469 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 36ms/step - accuracy: 0.4974 - f1_score: 0.5522 - loss: 0.7662 - val_accuracy: 0.5250 - val_f1_score: 0.6607 - val_loss: 0.7483 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 36ms/step - accuracy: 0.5260 - f1_score: 0.5565 - loss: 0.7580 - val_accuracy: 0.4500 - val_f1_score: 0.6000 - val_loss: 0.7478 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.4948 - f1_score: 0.5230 - loss: 0.7729 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7471 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 35ms/step - accuracy: 0.5061 - f1_score: 0.4727 - loss: 0.7545 - val_accuracy: 0.5500 - val_f1_score: 0.0526 - val_loss: 0.7472 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 35ms/step - accuracy: 0.4978 - f1_score: 0.5100 - loss: 0.7607 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7471 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 35ms/step - accuracy: 0.4957 - f1_score: 0.5130 - loss: 0.7520 - val_accuracy: 0.4500 - val_f1_score: 0.2143 - val_loss: 0.7474 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 35ms/step - accuracy: 0.5022 - f1_score: 0.5563 - loss: 0.7591 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7459 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 35ms/step - accuracy: 0.4957 - f1_score: 0.4630 - loss: 0.7514 - val_accuracy: 0.4875 - val_f1_score: 0.5393 - val_loss: 0.7469 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 35ms/step - accuracy: 0.4974 - f1_score: 0.4589 - loss: 0.7539 - val_accuracy: 0.5125 - val_f1_score: 0.4179 - val_loss: 0.7465 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 36ms/step - accuracy: 0.4844 - f1_score: 0.5619 - loss: 0.7591 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7470 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 36ms/step - accuracy: 0.5026 - f1_score: 0.5818 - loss: 0.7549 - val_accuracy: 0.5375 - val_f1_score: 0.6476 - val_loss: 0.7466 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 35ms/step - accuracy: 0.5013 - f1_score: 0.5620 - loss: 0.7535 - val_accuracy: 0.4750 - val_f1_score: 0.6379 - val_loss: 0.7467 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 35ms/step - accuracy: 0.5004 - f1_score: 0.5523 - loss: 0.7547 - val_accuracy: 0.4625 - val_f1_score: 0.6261 - val_loss: 0.7472 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 36ms/step - accuracy: 0.4983 - f1_score: 0.5927 - loss: 0.7512 - val_accuracy: 0.4750 - val_f1_score: 0.5962 - val_loss: 0.7466 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 36ms/step - accuracy: 0.4987 - f1_score: 0.4635 - loss: 0.7552 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7460 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 35ms/step - accuracy: 0.5048 - f1_score: 0.5184 - loss: 0.7513 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7456 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 36ms/step - accuracy: 0.5139 - f1_score: 0.5488 - loss: 0.7504 - val_accuracy: 0.4875 - val_f1_score: 0.2545 - val_loss: 0.7463 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 36ms/step - accuracy: 0.4774 - f1_score: 0.4996 - loss: 0.7503 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7455 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 36ms/step - accuracy: 0.5104 - f1_score: 0.5212 - loss: 0.7530 - val_accuracy: 0.4250 - val_f1_score: 0.4390 - val_loss: 0.7462 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 35ms/step - accuracy: 0.5109 - f1_score: 0.5306 - loss: 0.7515 - val_accuracy: 0.3875 - val_f1_score: 0.3288 - val_loss: 0.7460 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 36ms/step - accuracy: 0.4809 - f1_score: 0.4468 - loss: 0.7514 - val_accuracy: 0.5250 - val_f1_score: 0.0000e+00 - val_loss: 0.7451 - learning_rate: 3.0602e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step\noldB → Fold 1 Val F1 = 0.6607\n\n>>> Training model1 on Fold 1\nEpoch 1/200\n36/36 - 26s - 733ms/step - accuracy: 0.4874 - f1_score: 0.5949 - loss: 0.6942 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6925 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 37ms/step - accuracy: 0.5043 - f1_score: 0.0052 - loss: 0.6933 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6929 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 37ms/step - accuracy: 0.4926 - f1_score: 0.5045 - loss: 0.6935 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6925 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 40ms/step - accuracy: 0.4983 - f1_score: 0.2917 - loss: 0.6933 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6944 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 31ms/step - accuracy: 0.5048 - f1_score: 0.5696 - loss: 0.6935 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6948 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 29ms/step - accuracy: 0.5130 - f1_score: 0.6781 - loss: 0.6936 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6955 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.4944 - f1_score: 0.5979 - loss: 0.6935 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6927 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.4887 - f1_score: 0.4670 - loss: 0.6939 - val_accuracy: 0.4625 - val_f1_score: 0.1887 - val_loss: 0.6933 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5004 - f1_score: 0.5054 - loss: 0.6936 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6980 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 29ms/step - accuracy: 0.4874 - f1_score: 0.5915 - loss: 0.6936 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6939 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 29ms/step - accuracy: 0.5126 - f1_score: 0.6778 - loss: 0.6930 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6946 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 29ms/step - accuracy: 0.5135 - f1_score: 0.6785 - loss: 0.6929 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6955 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 29ms/step - accuracy: 0.4944 - f1_score: 0.6616 - loss: 0.6934 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6937 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 30ms/step - accuracy: 0.5317 - f1_score: 0.6614 - loss: 0.6928 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6952 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 30ms/step - accuracy: 0.5061 - f1_score: 0.5000 - loss: 0.6912 - val_accuracy: 0.5375 - val_f1_score: 0.0976 - val_loss: 0.6975 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 29ms/step - accuracy: 0.4961 - f1_score: 0.3645 - loss: 0.6944 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6944 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 29ms/step - accuracy: 0.4939 - f1_score: 0.5573 - loss: 0.6934 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6927 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 30ms/step - accuracy: 0.5095 - f1_score: 0.5108 - loss: 0.6929 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6948 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 29ms/step - accuracy: 0.5130 - f1_score: 0.6781 - loss: 0.6932 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6953 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 30ms/step - accuracy: 0.5178 - f1_score: 0.6823 - loss: 0.6924 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6970 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 30ms/step - accuracy: 0.4878 - f1_score: 0.5783 - loss: 0.6940 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6926 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 30ms/step - accuracy: 0.4857 - f1_score: 0.2052 - loss: 0.6933 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6928 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 30ms/step - accuracy: 0.4796 - f1_score: 0.4702 - loss: 0.6933 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6934 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 29ms/step - accuracy: 0.5135 - f1_score: 0.6700 - loss: 0.6930 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6950 - learning_rate: 7.6518e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step\nmodel1 → Fold 1 Val F1 = 0.6325\n\n>>> Training model2 on Fold 1\nEpoch 1/200\n36/36 - 5s - 126ms/step - accuracy: 0.5161 - f1_score: 0.4892 - loss: 9.7377 - val_accuracy: 0.5375 - val_f1_score: 0.3934 - val_loss: 1.4525 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 23ms/step - accuracy: 0.4913 - f1_score: 0.4609 - loss: 2.1099 - val_accuracy: 0.6125 - val_f1_score: 0.4746 - val_loss: 1.4433 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 21ms/step - accuracy: 0.5122 - f1_score: 0.4723 - loss: 1.3531 - val_accuracy: 0.5750 - val_f1_score: 0.6047 - val_loss: 1.3830 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 20ms/step - accuracy: 0.5130 - f1_score: 0.5122 - loss: 1.0873 - val_accuracy: 0.5250 - val_f1_score: 0.5682 - val_loss: 1.2917 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 21ms/step - accuracy: 0.5386 - f1_score: 0.5108 - loss: 0.9774 - val_accuracy: 0.5625 - val_f1_score: 0.5882 - val_loss: 0.9478 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 20ms/step - accuracy: 0.5334 - f1_score: 0.5320 - loss: 0.9475 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.9246 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 20ms/step - accuracy: 0.5152 - f1_score: 0.5187 - loss: 0.9748 - val_accuracy: 0.4500 - val_f1_score: 0.6140 - val_loss: 1.0810 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 21ms/step - accuracy: 0.5273 - f1_score: 0.4923 - loss: 0.9205 - val_accuracy: 0.5500 - val_f1_score: 0.5500 - val_loss: 0.8757 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 21ms/step - accuracy: 0.5365 - f1_score: 0.5565 - loss: 0.9866 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 0.7786 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 21ms/step - accuracy: 0.5334 - f1_score: 0.5653 - loss: 0.8871 - val_accuracy: 0.5500 - val_f1_score: 0.5385 - val_loss: 0.7807 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 20ms/step - accuracy: 0.5512 - f1_score: 0.5710 - loss: 0.8217 - val_accuracy: 0.5500 - val_f1_score: 0.6000 - val_loss: 0.7644 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 21ms/step - accuracy: 0.5317 - f1_score: 0.5569 - loss: 0.8418 - val_accuracy: 0.5625 - val_f1_score: 0.5205 - val_loss: 0.7356 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 21ms/step - accuracy: 0.5534 - f1_score: 0.5649 - loss: 0.8883 - val_accuracy: 0.5125 - val_f1_score: 0.5063 - val_loss: 0.7890 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 21ms/step - accuracy: 0.5174 - f1_score: 0.5244 - loss: 0.8260 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 0.7635 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 22ms/step - accuracy: 0.5530 - f1_score: 0.5568 - loss: 0.7679 - val_accuracy: 0.4750 - val_f1_score: 0.5227 - val_loss: 0.8754 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5434 - f1_score: 0.5493 - loss: 0.8051 - val_accuracy: 0.5375 - val_f1_score: 0.5934 - val_loss: 0.8452 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 21ms/step - accuracy: 0.5725 - f1_score: 0.5723 - loss: 0.7255 - val_accuracy: 0.5000 - val_f1_score: 0.5652 - val_loss: 0.8001 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 20ms/step - accuracy: 0.5521 - f1_score: 0.5556 - loss: 0.7381 - val_accuracy: 0.4625 - val_f1_score: 0.4691 - val_loss: 0.7784 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 20ms/step - accuracy: 0.5807 - f1_score: 0.5934 - loss: 0.7439 - val_accuracy: 0.4875 - val_f1_score: 0.5684 - val_loss: 0.8733 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 21ms/step - accuracy: 0.5564 - f1_score: 0.5832 - loss: 0.7121 - val_accuracy: 0.5250 - val_f1_score: 0.5870 - val_loss: 0.9207 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 20ms/step - accuracy: 0.5734 - f1_score: 0.5765 - loss: 0.7008 - val_accuracy: 0.5500 - val_f1_score: 0.4857 - val_loss: 0.7505 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 21ms/step - accuracy: 0.5634 - f1_score: 0.5448 - loss: 0.7314 - val_accuracy: 0.5375 - val_f1_score: 0.6337 - val_loss: 0.9569 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 23ms/step - accuracy: 0.5712 - f1_score: 0.5537 - loss: 0.7191 - val_accuracy: 0.5500 - val_f1_score: 0.3333 - val_loss: 0.7736 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 22ms/step - accuracy: 0.5612 - f1_score: 0.5918 - loss: 0.7321 - val_accuracy: 0.4875 - val_f1_score: 0.5591 - val_loss: 0.8440 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 20ms/step - accuracy: 0.5911 - f1_score: 0.6062 - loss: 0.6871 - val_accuracy: 0.4500 - val_f1_score: 0.5769 - val_loss: 0.8528 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 20ms/step - accuracy: 0.5642 - f1_score: 0.5698 - loss: 0.7056 - val_accuracy: 0.4625 - val_f1_score: 0.5657 - val_loss: 0.8600 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 21ms/step - accuracy: 0.5881 - f1_score: 0.5943 - loss: 0.6786 - val_accuracy: 0.4875 - val_f1_score: 0.5941 - val_loss: 0.9009 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 22ms/step - accuracy: 0.5885 - f1_score: 0.5824 - loss: 0.6793 - val_accuracy: 0.5000 - val_f1_score: 0.5745 - val_loss: 0.8613 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 20ms/step - accuracy: 0.5564 - f1_score: 0.5506 - loss: 0.6969 - val_accuracy: 0.5000 - val_f1_score: 0.5745 - val_loss: 0.8826 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 21ms/step - accuracy: 0.5838 - f1_score: 0.5882 - loss: 0.6852 - val_accuracy: 0.5000 - val_f1_score: 0.6296 - val_loss: 0.9285 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 21ms/step - accuracy: 0.5833 - f1_score: 0.5833 - loss: 0.6795 - val_accuracy: 0.5000 - val_f1_score: 0.5918 - val_loss: 0.8094 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 21ms/step - accuracy: 0.5924 - f1_score: 0.5975 - loss: 0.6654 - val_accuracy: 0.4750 - val_f1_score: 0.5714 - val_loss: 0.8182 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 21ms/step - accuracy: 0.6042 - f1_score: 0.6017 - loss: 0.6535 - val_accuracy: 0.4500 - val_f1_score: 0.5686 - val_loss: 0.8658 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 21ms/step - accuracy: 0.6016 - f1_score: 0.5641 - loss: 0.6460 - val_accuracy: 0.5000 - val_f1_score: 0.5918 - val_loss: 0.8523 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 21ms/step - accuracy: 0.6089 - f1_score: 0.6138 - loss: 0.6541 - val_accuracy: 0.4875 - val_f1_score: 0.5941 - val_loss: 0.8279 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 21ms/step - accuracy: 0.5998 - f1_score: 0.6050 - loss: 0.6514 - val_accuracy: 0.4875 - val_f1_score: 0.5684 - val_loss: 0.8208 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 21ms/step - accuracy: 0.5946 - f1_score: 0.6115 - loss: 0.6578 - val_accuracy: 0.5000 - val_f1_score: 0.5833 - val_loss: 0.8821 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 21ms/step - accuracy: 0.6089 - f1_score: 0.6168 - loss: 0.6450 - val_accuracy: 0.4500 - val_f1_score: 0.5769 - val_loss: 0.8631 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 21ms/step - accuracy: 0.6007 - f1_score: 0.6085 - loss: 0.6466 - val_accuracy: 0.4750 - val_f1_score: 0.6111 - val_loss: 0.9637 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 1s - 21ms/step - accuracy: 0.5990 - f1_score: 0.6175 - loss: 0.6511 - val_accuracy: 0.4500 - val_f1_score: 0.5319 - val_loss: 0.8620 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 1s - 22ms/step - accuracy: 0.6089 - f1_score: 0.6365 - loss: 0.6511 - val_accuracy: 0.4750 - val_f1_score: 0.5962 - val_loss: 0.9821 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 1s - 21ms/step - accuracy: 0.6133 - f1_score: 0.6582 - loss: 0.6466 - val_accuracy: 0.4375 - val_f1_score: 0.5794 - val_loss: 0.9488 - learning_rate: 2.2643e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step\nmodel2 → Fold 1 Val F1 = 0.6337\n\n>>> Training model3 on Fold 1\nEpoch 1/200\n36/36 - 9s - 244ms/step - accuracy: 0.5048 - f1_score: 0.5352 - loss: 0.7215 - val_accuracy: 0.5375 - val_f1_score: 0.1778 - val_loss: 0.6926 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 3s - 86ms/step - accuracy: 0.5451 - f1_score: 0.3828 - loss: 0.6885 - val_accuracy: 0.6000 - val_f1_score: 0.5294 - val_loss: 0.6857 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 3s - 83ms/step - accuracy: 0.5690 - f1_score: 0.5703 - loss: 0.6733 - val_accuracy: 0.5875 - val_f1_score: 0.4762 - val_loss: 0.6881 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 3s - 89ms/step - accuracy: 0.6159 - f1_score: 0.5295 - loss: 0.6604 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 0.6836 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 3s - 83ms/step - accuracy: 0.6806 - f1_score: 0.6346 - loss: 0.5783 - val_accuracy: 0.5625 - val_f1_score: 0.4444 - val_loss: 0.7474 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 3s - 85ms/step - accuracy: 0.7522 - f1_score: 0.7468 - loss: 0.4934 - val_accuracy: 0.4500 - val_f1_score: 0.4884 - val_loss: 0.9079 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 3s - 89ms/step - accuracy: 0.8364 - f1_score: 0.8300 - loss: 0.3494 - val_accuracy: 0.4375 - val_f1_score: 0.4578 - val_loss: 1.3176 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 86ms/step - accuracy: 0.8815 - f1_score: 0.8786 - loss: 0.2699 - val_accuracy: 0.5000 - val_f1_score: 0.5000 - val_loss: 1.6579 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 3s - 86ms/step - accuracy: 0.9340 - f1_score: 0.9366 - loss: 0.1679 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 2.3190 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 3s - 87ms/step - accuracy: 0.9536 - f1_score: 0.9538 - loss: 0.1298 - val_accuracy: 0.4875 - val_f1_score: 0.5287 - val_loss: 1.2548 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 3s - 86ms/step - accuracy: 0.9744 - f1_score: 0.9750 - loss: 0.0845 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 2.6401 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 3s - 84ms/step - accuracy: 0.9874 - f1_score: 0.9878 - loss: 0.0376 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 2.2570 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 3s - 85ms/step - accuracy: 0.9948 - f1_score: 0.9947 - loss: 0.0186 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 2.8812 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 3s - 89ms/step - accuracy: 0.9965 - f1_score: 0.9967 - loss: 0.0124 - val_accuracy: 0.5375 - val_f1_score: 0.5934 - val_loss: 3.7277 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 88ms/step - accuracy: 0.9970 - f1_score: 0.9969 - loss: 0.0114 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 2.3431 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 94ms/step - accuracy: 0.9944 - f1_score: 0.9945 - loss: 0.0200 - val_accuracy: 0.5625 - val_f1_score: 0.6067 - val_loss: 3.2002 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 3s - 86ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0036 - val_accuracy: 0.5125 - val_f1_score: 0.5301 - val_loss: 3.9281 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 90ms/step - accuracy: 0.9991 - f1_score: 0.9992 - loss: 0.0023 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 4.4339 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 3s - 86ms/step - accuracy: 0.9957 - f1_score: 0.9958 - loss: 0.0234 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 4.1355 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 90ms/step - accuracy: 0.9891 - f1_score: 0.9896 - loss: 0.0491 - val_accuracy: 0.5500 - val_f1_score: 0.5385 - val_loss: 2.1597 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 3s - 85ms/step - accuracy: 0.9852 - f1_score: 0.9849 - loss: 0.0540 - val_accuracy: 0.5500 - val_f1_score: 0.5714 - val_loss: 3.2665 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 3s - 91ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0087 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 4.3448 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 3s - 86ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0050 - val_accuracy: 0.5625 - val_f1_score: 0.5882 - val_loss: 4.5319 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 3s - 86ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0012 - val_accuracy: 0.5875 - val_f1_score: 0.5823 - val_loss: 4.7034 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 3s - 86ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0047 - val_accuracy: 0.5625 - val_f1_score: 0.5679 - val_loss: 3.5900 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 3s - 87ms/step - accuracy: 0.9991 - f1_score: 0.9992 - loss: 0.0095 - val_accuracy: 0.5875 - val_f1_score: 0.6024 - val_loss: 3.7113 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 3s - 90ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3541e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 3.9397 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 3s - 85ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4745e-04 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.0869 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 3s - 88ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8414e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.2844 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 3s - 85ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.2390e-04 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.3328 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4510e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.4123 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 3s - 85ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0632e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.4834 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 3s - 89ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8875e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.5404 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 4s - 103ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2955e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.5847 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4013e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.6239 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 4s - 103ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0099e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.6437 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 3s - 81ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7394e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.6814 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 4s - 122ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2655e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.7288 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 3s - 95ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6321e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.7595 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 3s - 88ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1220e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.7831 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 3s - 87ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.9300e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.7700 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0860e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.7636 - learning_rate: 2.2643e-04\nEpoch 43/200\n36/36 - 4s - 113ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1333e-05 - val_accuracy: 0.5875 - val_f1_score: 0.5926 - val_loss: 4.7869 - learning_rate: 2.0267e-04\nEpoch 44/200\n36/36 - 3s - 88ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0188e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.8084 - learning_rate: 1.8042e-04\nEpoch 45/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5073e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.8210 - learning_rate: 1.5972e-04\nEpoch 46/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8214e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.8343 - learning_rate: 1.4058e-04\nEpoch 47/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6328e-05 - val_accuracy: 0.6000 - val_f1_score: 0.6098 - val_loss: 4.8454 - learning_rate: 1.2302e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step\nmodel3 → Fold 1 Val F1 = 0.6098\n\n>>> Training model4 on Fold 1\nEpoch 1/200\n36/36 - 9s - 245ms/step - accuracy: 0.5217 - f1_score: 0.5133 - loss: 0.6919 - val_accuracy: 0.5750 - val_f1_score: 0.4333 - val_loss: 0.6929 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 119ms/step - accuracy: 0.5347 - f1_score: 0.4393 - loss: 0.6919 - val_accuracy: 0.6500 - val_f1_score: 0.6410 - val_loss: 0.6885 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 118ms/step - accuracy: 0.5156 - f1_score: 0.4535 - loss: 0.6930 - val_accuracy: 0.5500 - val_f1_score: 0.4545 - val_loss: 0.6852 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 119ms/step - accuracy: 0.5191 - f1_score: 0.3754 - loss: 0.6917 - val_accuracy: 0.6000 - val_f1_score: 0.6735 - val_loss: 0.6930 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 118ms/step - accuracy: 0.5408 - f1_score: 0.5327 - loss: 0.6905 - val_accuracy: 0.6125 - val_f1_score: 0.5634 - val_loss: 0.6973 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 118ms/step - accuracy: 0.5304 - f1_score: 0.4524 - loss: 0.6893 - val_accuracy: 0.6625 - val_f1_score: 0.6667 - val_loss: 0.6894 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 118ms/step - accuracy: 0.5647 - f1_score: 0.5194 - loss: 0.6858 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6891 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 118ms/step - accuracy: 0.5499 - f1_score: 0.4475 - loss: 0.6876 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6902 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 118ms/step - accuracy: 0.5286 - f1_score: 0.4040 - loss: 0.6900 - val_accuracy: 0.5625 - val_f1_score: 0.6392 - val_loss: 0.6996 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 118ms/step - accuracy: 0.5143 - f1_score: 0.3311 - loss: 0.6908 - val_accuracy: 0.5625 - val_f1_score: 0.5455 - val_loss: 0.7041 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 118ms/step - accuracy: 0.5126 - f1_score: 0.4148 - loss: 0.6918 - val_accuracy: 0.5875 - val_f1_score: 0.5600 - val_loss: 0.6997 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 118ms/step - accuracy: 0.5126 - f1_score: 0.5676 - loss: 0.6889 - val_accuracy: 0.6125 - val_f1_score: 0.6593 - val_loss: 0.7088 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 118ms/step - accuracy: 0.5373 - f1_score: 0.4306 - loss: 0.6883 - val_accuracy: 0.5875 - val_f1_score: 0.5075 - val_loss: 0.6881 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 118ms/step - accuracy: 0.5486 - f1_score: 0.4990 - loss: 0.6849 - val_accuracy: 0.6750 - val_f1_score: 0.6750 - val_loss: 0.7026 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 119ms/step - accuracy: 0.5521 - f1_score: 0.4247 - loss: 0.6894 - val_accuracy: 0.6500 - val_f1_score: 0.6410 - val_loss: 0.6929 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 119ms/step - accuracy: 0.5321 - f1_score: 0.4302 - loss: 0.6898 - val_accuracy: 0.6125 - val_f1_score: 0.5634 - val_loss: 0.6987 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 118ms/step - accuracy: 0.5586 - f1_score: 0.3810 - loss: 0.6853 - val_accuracy: 0.5750 - val_f1_score: 0.5000 - val_loss: 0.7001 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 119ms/step - accuracy: 0.5352 - f1_score: 0.4106 - loss: 0.6871 - val_accuracy: 0.5875 - val_f1_score: 0.6526 - val_loss: 0.6919 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 118ms/step - accuracy: 0.5464 - f1_score: 0.4450 - loss: 0.6873 - val_accuracy: 0.6250 - val_f1_score: 0.5833 - val_loss: 0.6781 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 119ms/step - accuracy: 0.5543 - f1_score: 0.5248 - loss: 0.6863 - val_accuracy: 0.6375 - val_f1_score: 0.6133 - val_loss: 0.6830 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 119ms/step - accuracy: 0.5616 - f1_score: 0.4772 - loss: 0.6854 - val_accuracy: 0.6125 - val_f1_score: 0.5634 - val_loss: 0.6871 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 4s - 119ms/step - accuracy: 0.5499 - f1_score: 0.5012 - loss: 0.6882 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6822 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 4s - 118ms/step - accuracy: 0.5495 - f1_score: 0.4655 - loss: 0.6861 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6866 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 4s - 119ms/step - accuracy: 0.5191 - f1_score: 0.4004 - loss: 0.6901 - val_accuracy: 0.5875 - val_f1_score: 0.5352 - val_loss: 0.6856 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 4s - 118ms/step - accuracy: 0.5651 - f1_score: 0.4990 - loss: 0.6831 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6818 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 4s - 118ms/step - accuracy: 0.5608 - f1_score: 0.4975 - loss: 0.6815 - val_accuracy: 0.5625 - val_f1_score: 0.6535 - val_loss: 0.6910 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 4s - 118ms/step - accuracy: 0.5547 - f1_score: 0.4242 - loss: 0.6887 - val_accuracy: 0.6000 - val_f1_score: 0.6667 - val_loss: 0.6874 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 4s - 119ms/step - accuracy: 0.5612 - f1_score: 0.5206 - loss: 0.6829 - val_accuracy: 0.6500 - val_f1_score: 0.6585 - val_loss: 0.6666 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 4s - 118ms/step - accuracy: 0.5464 - f1_score: 0.5026 - loss: 0.6834 - val_accuracy: 0.6125 - val_f1_score: 0.5974 - val_loss: 0.6775 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 4s - 118ms/step - accuracy: 0.5820 - f1_score: 0.4950 - loss: 0.6764 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 0.6731 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 4s - 118ms/step - accuracy: 0.5651 - f1_score: 0.4798 - loss: 0.6814 - val_accuracy: 0.6500 - val_f1_score: 0.6585 - val_loss: 0.6744 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 4s - 118ms/step - accuracy: 0.5495 - f1_score: 0.4537 - loss: 0.6851 - val_accuracy: 0.6375 - val_f1_score: 0.5246 - val_loss: 0.6759 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 4s - 118ms/step - accuracy: 0.5677 - f1_score: 0.4587 - loss: 0.6792 - val_accuracy: 0.6125 - val_f1_score: 0.5231 - val_loss: 0.6721 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 4s - 119ms/step - accuracy: 0.5725 - f1_score: 0.4925 - loss: 0.6776 - val_accuracy: 0.6000 - val_f1_score: 0.5429 - val_loss: 0.6830 - learning_rate: 4.5920e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step\nmodel4 → Fold 1 Val F1 = 0.6750\n\n>>> Training model5 on Fold 1\nEpoch 1/200\n36/36 - 8s - 216ms/step - accuracy: 0.4996 - f1_score: 0.4918 - loss: 1.3379 - val_accuracy: 0.5000 - val_f1_score: 0.5122 - val_loss: 0.8017 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 37ms/step - accuracy: 0.5373 - f1_score: 0.5128 - loss: 0.8167 - val_accuracy: 0.5875 - val_f1_score: 0.6452 - val_loss: 0.8024 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 35ms/step - accuracy: 0.5182 - f1_score: 0.5301 - loss: 0.7707 - val_accuracy: 0.5625 - val_f1_score: 0.4776 - val_loss: 0.7054 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 35ms/step - accuracy: 0.5369 - f1_score: 0.5371 - loss: 0.7307 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7923 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 38ms/step - accuracy: 0.5751 - f1_score: 0.5651 - loss: 0.6805 - val_accuracy: 0.4500 - val_f1_score: 0.4762 - val_loss: 0.7211 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 35ms/step - accuracy: 0.6072 - f1_score: 0.6308 - loss: 0.6624 - val_accuracy: 0.5500 - val_f1_score: 0.5263 - val_loss: 0.7166 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 35ms/step - accuracy: 0.6315 - f1_score: 0.6118 - loss: 0.6330 - val_accuracy: 0.4500 - val_f1_score: 0.5510 - val_loss: 0.8579 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 34ms/step - accuracy: 0.6810 - f1_score: 0.6732 - loss: 0.5887 - val_accuracy: 0.5250 - val_f1_score: 0.6200 - val_loss: 0.9462 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 36ms/step - accuracy: 0.7244 - f1_score: 0.7413 - loss: 0.5318 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 1.0829 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 37ms/step - accuracy: 0.7773 - f1_score: 0.7799 - loss: 0.4391 - val_accuracy: 0.4750 - val_f1_score: 0.4878 - val_loss: 1.2401 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 36ms/step - accuracy: 0.8568 - f1_score: 0.8596 - loss: 0.3343 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 1.3695 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 35ms/step - accuracy: 0.8785 - f1_score: 0.8817 - loss: 0.2904 - val_accuracy: 0.5125 - val_f1_score: 0.4935 - val_loss: 1.5486 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 35ms/step - accuracy: 0.9045 - f1_score: 0.9035 - loss: 0.2162 - val_accuracy: 0.4875 - val_f1_score: 0.5287 - val_loss: 1.9477 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 34ms/step - accuracy: 0.9418 - f1_score: 0.9441 - loss: 0.1705 - val_accuracy: 0.5000 - val_f1_score: 0.5918 - val_loss: 2.3744 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 33ms/step - accuracy: 0.9275 - f1_score: 0.9270 - loss: 0.2018 - val_accuracy: 0.5625 - val_f1_score: 0.6067 - val_loss: 2.1361 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 34ms/step - accuracy: 0.9618 - f1_score: 0.9627 - loss: 0.1056 - val_accuracy: 0.5125 - val_f1_score: 0.5618 - val_loss: 2.3255 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 34ms/step - accuracy: 0.9735 - f1_score: 0.9732 - loss: 0.0860 - val_accuracy: 0.5500 - val_f1_score: 0.6087 - val_loss: 2.8888 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 35ms/step - accuracy: 0.9761 - f1_score: 0.9767 - loss: 0.0782 - val_accuracy: 0.5000 - val_f1_score: 0.5556 - val_loss: 2.7617 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 35ms/step - accuracy: 0.9839 - f1_score: 0.9844 - loss: 0.0525 - val_accuracy: 0.5625 - val_f1_score: 0.5882 - val_loss: 2.5841 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 35ms/step - accuracy: 0.9948 - f1_score: 0.9950 - loss: 0.0225 - val_accuracy: 0.5750 - val_f1_score: 0.6383 - val_loss: 3.2782 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 2s - 45ms/step - accuracy: 0.9983 - f1_score: 0.9982 - loss: 0.0116 - val_accuracy: 0.5500 - val_f1_score: 0.6170 - val_loss: 3.2195 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 35ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0067 - val_accuracy: 0.5500 - val_f1_score: 0.6087 - val_loss: 3.4686 - learning_rate: 8.1479e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step\nmodel5 → Fold 1 Val F1 = 0.6452\n\n>>> Training model6 on Fold 1\nEpoch 1/200\n36/36 - 7s - 205ms/step - accuracy: 0.5200 - f1_score: 0.5225 - loss: 3.8026 - val_accuracy: 0.5250 - val_f1_score: 0.5000 - val_loss: 1.0606 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 39ms/step - accuracy: 0.5009 - f1_score: 0.5009 - loss: 1.8230 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 1.3145 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 39ms/step - accuracy: 0.4905 - f1_score: 0.4957 - loss: 0.8761 - val_accuracy: 0.5250 - val_f1_score: 0.1739 - val_loss: 1.0021 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 39ms/step - accuracy: 0.4887 - f1_score: 0.4708 - loss: 0.8190 - val_accuracy: 0.5625 - val_f1_score: 0.4444 - val_loss: 0.7193 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 40ms/step - accuracy: 0.4952 - f1_score: 0.4981 - loss: 0.7981 - val_accuracy: 0.5000 - val_f1_score: 0.5238 - val_loss: 0.9528 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 40ms/step - accuracy: 0.4931 - f1_score: 0.4974 - loss: 0.8817 - val_accuracy: 0.4500 - val_f1_score: 0.5926 - val_loss: 1.0170 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 39ms/step - accuracy: 0.5035 - f1_score: 0.5368 - loss: 0.8287 - val_accuracy: 0.5125 - val_f1_score: 0.3607 - val_loss: 0.7304 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 39ms/step - accuracy: 0.5286 - f1_score: 0.5000 - loss: 0.7534 - val_accuracy: 0.4625 - val_f1_score: 0.6261 - val_loss: 0.8708 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 39ms/step - accuracy: 0.4931 - f1_score: 0.4767 - loss: 0.7536 - val_accuracy: 0.5250 - val_f1_score: 0.4722 - val_loss: 0.8771 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 40ms/step - accuracy: 0.4718 - f1_score: 0.4430 - loss: 0.7667 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 0.7590 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 39ms/step - accuracy: 0.4852 - f1_score: 0.4945 - loss: 0.7214 - val_accuracy: 0.4875 - val_f1_score: 0.6168 - val_loss: 0.7246 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 39ms/step - accuracy: 0.5078 - f1_score: 0.5199 - loss: 0.7270 - val_accuracy: 0.5125 - val_f1_score: 0.4179 - val_loss: 0.7048 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 39ms/step - accuracy: 0.5191 - f1_score: 0.4885 - loss: 0.6995 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7078 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 39ms/step - accuracy: 0.4957 - f1_score: 0.4386 - loss: 0.6998 - val_accuracy: 0.5500 - val_f1_score: 0.5135 - val_loss: 0.6838 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 39ms/step - accuracy: 0.5265 - f1_score: 0.4993 - loss: 0.7011 - val_accuracy: 0.3875 - val_f1_score: 0.4096 - val_loss: 0.7141 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 39ms/step - accuracy: 0.5009 - f1_score: 0.4256 - loss: 0.6934 - val_accuracy: 0.4500 - val_f1_score: 0.5000 - val_loss: 0.7164 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 39ms/step - accuracy: 0.5095 - f1_score: 0.4695 - loss: 0.6967 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 0.6944 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 40ms/step - accuracy: 0.5087 - f1_score: 0.5220 - loss: 0.6982 - val_accuracy: 0.4250 - val_f1_score: 0.5306 - val_loss: 0.7000 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 39ms/step - accuracy: 0.5017 - f1_score: 0.5792 - loss: 0.6964 - val_accuracy: 0.4750 - val_f1_score: 0.5882 - val_loss: 0.6972 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 39ms/step - accuracy: 0.5308 - f1_score: 0.6361 - loss: 0.6920 - val_accuracy: 0.4875 - val_f1_score: 0.5684 - val_loss: 0.7038 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 39ms/step - accuracy: 0.4905 - f1_score: 0.5300 - loss: 0.6932 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 0.6917 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 40ms/step - accuracy: 0.5109 - f1_score: 0.4823 - loss: 0.6933 - val_accuracy: 0.5500 - val_f1_score: 0.0526 - val_loss: 0.6971 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 39ms/step - accuracy: 0.4961 - f1_score: 0.5413 - loss: 0.6939 - val_accuracy: 0.4875 - val_f1_score: 0.2545 - val_loss: 0.6948 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 39ms/step - accuracy: 0.5109 - f1_score: 0.5123 - loss: 0.6945 - val_accuracy: 0.5125 - val_f1_score: 0.6139 - val_loss: 0.6903 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 39ms/step - accuracy: 0.5208 - f1_score: 0.5878 - loss: 0.6919 - val_accuracy: 0.5250 - val_f1_score: 0.2692 - val_loss: 0.6893 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 39ms/step - accuracy: 0.5204 - f1_score: 0.5243 - loss: 0.6964 - val_accuracy: 0.5250 - val_f1_score: 0.0952 - val_loss: 0.6928 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 40ms/step - accuracy: 0.5095 - f1_score: 0.4725 - loss: 0.6943 - val_accuracy: 0.5000 - val_f1_score: 0.6491 - val_loss: 0.6930 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 40ms/step - accuracy: 0.5187 - f1_score: 0.5983 - loss: 0.6917 - val_accuracy: 0.5250 - val_f1_score: 0.4865 - val_loss: 0.6894 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 39ms/step - accuracy: 0.5204 - f1_score: 0.5243 - loss: 0.6941 - val_accuracy: 0.5250 - val_f1_score: 0.1739 - val_loss: 0.6928 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 39ms/step - accuracy: 0.5122 - f1_score: 0.5670 - loss: 0.6912 - val_accuracy: 0.5250 - val_f1_score: 0.4722 - val_loss: 0.6902 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 39ms/step - accuracy: 0.5039 - f1_score: 0.5155 - loss: 0.6905 - val_accuracy: 0.5250 - val_f1_score: 0.6545 - val_loss: 0.6925 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 39ms/step - accuracy: 0.5178 - f1_score: 0.5572 - loss: 0.6911 - val_accuracy: 0.5000 - val_f1_score: 0.2857 - val_loss: 0.6939 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 39ms/step - accuracy: 0.5278 - f1_score: 0.4443 - loss: 0.6902 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 0.6929 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 39ms/step - accuracy: 0.5169 - f1_score: 0.5108 - loss: 0.6898 - val_accuracy: 0.5625 - val_f1_score: 0.3636 - val_loss: 0.6903 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 39ms/step - accuracy: 0.5326 - f1_score: 0.5423 - loss: 0.6902 - val_accuracy: 0.5375 - val_f1_score: 0.4127 - val_loss: 0.6913 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 39ms/step - accuracy: 0.5282 - f1_score: 0.4096 - loss: 0.6907 - val_accuracy: 0.5375 - val_f1_score: 0.2745 - val_loss: 0.6926 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 39ms/step - accuracy: 0.5304 - f1_score: 0.4394 - loss: 0.6885 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.6924 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 39ms/step - accuracy: 0.5143 - f1_score: 0.5336 - loss: 0.6928 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 0.6936 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 39ms/step - accuracy: 0.5365 - f1_score: 0.4461 - loss: 0.6888 - val_accuracy: 0.5375 - val_f1_score: 0.2449 - val_loss: 0.6933 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 1s - 39ms/step - accuracy: 0.5347 - f1_score: 0.4328 - loss: 0.6903 - val_accuracy: 0.5250 - val_f1_score: 0.4722 - val_loss: 0.6904 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 1s - 39ms/step - accuracy: 0.5547 - f1_score: 0.6415 - loss: 0.6881 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.6924 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 1s - 39ms/step - accuracy: 0.5386 - f1_score: 0.6873 - loss: 0.6847 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6955 - learning_rate: 2.2643e-04\nEpoch 43/200\n36/36 - 1s - 39ms/step - accuracy: 0.5260 - f1_score: 0.6656 - loss: 0.6860 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.6949 - learning_rate: 2.0267e-04\nEpoch 44/200\n36/36 - 1s - 39ms/step - accuracy: 0.5174 - f1_score: 0.6624 - loss: 0.6877 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.6952 - learning_rate: 1.8042e-04\nEpoch 45/200\n36/36 - 1s - 39ms/step - accuracy: 0.5299 - f1_score: 0.6530 - loss: 0.6855 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.6944 - learning_rate: 1.5972e-04\nEpoch 46/200\n36/36 - 1s - 39ms/step - accuracy: 0.5304 - f1_score: 0.6300 - loss: 0.6879 - val_accuracy: 0.4750 - val_f1_score: 0.6250 - val_loss: 0.6945 - learning_rate: 1.4058e-04\nEpoch 47/200\n36/36 - 1s - 39ms/step - accuracy: 0.5204 - f1_score: 0.6268 - loss: 0.6875 - val_accuracy: 0.5000 - val_f1_score: 0.6296 - val_loss: 0.6947 - learning_rate: 1.2302e-04\nEpoch 48/200\n36/36 - 1s - 39ms/step - accuracy: 0.5256 - f1_score: 0.5839 - loss: 0.6868 - val_accuracy: 0.4875 - val_f1_score: 0.5941 - val_loss: 0.6946 - learning_rate: 1.0700e-04\nEpoch 49/200\n36/36 - 1s - 39ms/step - accuracy: 0.5247 - f1_score: 0.5362 - loss: 0.6887 - val_accuracy: 0.4875 - val_f1_score: 0.5393 - val_loss: 0.6959 - learning_rate: 9.2503e-05\nEpoch 50/200\n36/36 - 1s - 40ms/step - accuracy: 0.5230 - f1_score: 0.5616 - loss: 0.6879 - val_accuracy: 0.5500 - val_f1_score: 0.6538 - val_loss: 0.6951 - learning_rate: 7.9466e-05\nEpoch 51/200\n36/36 - 1s - 39ms/step - accuracy: 0.5456 - f1_score: 0.6534 - loss: 0.6855 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.6949 - learning_rate: 6.7829e-05\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step\nmodel6 → Fold 1 Val F1 = 0.6545\n\n==================================================\nFold 2/30 - Subject: S10\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 2\nEpoch 1/200\n36/36 - 8s - 220ms/step - accuracy: 0.5122 - f1_score: 0.5205 - loss: 0.8553 - val_accuracy: 0.5375 - val_f1_score: 0.4478 - val_loss: 0.6961 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 28ms/step - accuracy: 0.5135 - f1_score: 0.4930 - loss: 0.7716 - val_accuracy: 0.4875 - val_f1_score: 0.0000e+00 - val_loss: 0.7043 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 28ms/step - accuracy: 0.5052 - f1_score: 0.4906 - loss: 0.7391 - val_accuracy: 0.4375 - val_f1_score: 0.0426 - val_loss: 0.7049 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 29ms/step - accuracy: 0.5000 - f1_score: 0.5094 - loss: 0.7243 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.7022 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.4965 - f1_score: 0.5017 - loss: 0.7237 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.7030 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 28ms/step - accuracy: 0.4987 - f1_score: 0.4738 - loss: 0.7138 - val_accuracy: 0.4375 - val_f1_score: 0.4828 - val_loss: 0.7026 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.5117 - f1_score: 0.4912 - loss: 0.7054 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7027 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5100 - f1_score: 0.4823 - loss: 0.7063 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7046 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5191 - f1_score: 0.5321 - loss: 0.7030 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7091 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.4996 - f1_score: 0.5104 - loss: 0.7060 - val_accuracy: 0.5125 - val_f1_score: 0.6355 - val_loss: 0.7008 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 28ms/step - accuracy: 0.5074 - f1_score: 0.5820 - loss: 0.7058 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.7021 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.5211 - loss: 0.7036 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7045 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5273 - f1_score: 0.5941 - loss: 0.7004 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7010 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5330 - f1_score: 0.5131 - loss: 0.6987 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7031 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 28ms/step - accuracy: 0.5065 - f1_score: 0.4899 - loss: 0.7025 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 0.7027 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5113 - f1_score: 0.5044 - loss: 0.7006 - val_accuracy: 0.5000 - val_f1_score: 0.0476 - val_loss: 0.7035 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 29ms/step - accuracy: 0.5343 - f1_score: 0.5647 - loss: 0.7011 - val_accuracy: 0.5250 - val_f1_score: 0.2963 - val_loss: 0.7031 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 29ms/step - accuracy: 0.5425 - f1_score: 0.4947 - loss: 0.6966 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7081 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5291 - f1_score: 0.5373 - loss: 0.6987 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 0.7055 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 28ms/step - accuracy: 0.5234 - f1_score: 0.5176 - loss: 0.6994 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.7078 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 28ms/step - accuracy: 0.5404 - f1_score: 0.5589 - loss: 0.6998 - val_accuracy: 0.4625 - val_f1_score: 0.3385 - val_loss: 0.7079 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 28ms/step - accuracy: 0.5295 - f1_score: 0.5661 - loss: 0.7005 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7080 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 28ms/step - accuracy: 0.5204 - f1_score: 0.5672 - loss: 0.6968 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7053 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 28ms/step - accuracy: 0.5469 - f1_score: 0.5668 - loss: 0.6953 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7079 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 28ms/step - accuracy: 0.5551 - f1_score: 0.5610 - loss: 0.6909 - val_accuracy: 0.5125 - val_f1_score: 0.3158 - val_loss: 0.7056 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 28ms/step - accuracy: 0.5352 - f1_score: 0.5591 - loss: 0.6972 - val_accuracy: 0.5250 - val_f1_score: 0.3667 - val_loss: 0.7041 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 28ms/step - accuracy: 0.5386 - f1_score: 0.5787 - loss: 0.6931 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 0.7046 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 28ms/step - accuracy: 0.5365 - f1_score: 0.5728 - loss: 0.6958 - val_accuracy: 0.4625 - val_f1_score: 0.6261 - val_loss: 0.7061 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 28ms/step - accuracy: 0.5352 - f1_score: 0.5847 - loss: 0.6951 - val_accuracy: 0.5250 - val_f1_score: 0.0952 - val_loss: 0.7026 - learning_rate: 6.1987e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step\noldA → Fold 2 Val F1 = 0.6667\n\n>>> Training oldB on Fold 2\nEpoch 1/200\n36/36 - 13s - 360ms/step - accuracy: 0.5187 - f1_score: 0.4984 - loss: 3.3280 - val_accuracy: 0.4875 - val_f1_score: 0.6372 - val_loss: 0.7588 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 36ms/step - accuracy: 0.5200 - f1_score: 0.5027 - loss: 2.6001 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7557 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 35ms/step - accuracy: 0.5048 - f1_score: 0.5208 - loss: 1.8783 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7578 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.4974 - f1_score: 0.5179 - loss: 1.3803 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7604 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 36ms/step - accuracy: 0.4753 - f1_score: 0.4944 - loss: 1.1399 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7472 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 36ms/step - accuracy: 0.5026 - f1_score: 0.5181 - loss: 0.9530 - val_accuracy: 0.4875 - val_f1_score: 0.4675 - val_loss: 0.7477 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 35ms/step - accuracy: 0.4857 - f1_score: 0.5060 - loss: 0.8931 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.7464 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 35ms/step - accuracy: 0.4965 - f1_score: 0.5183 - loss: 0.8717 - val_accuracy: 0.4875 - val_f1_score: 0.5773 - val_loss: 0.7473 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 35ms/step - accuracy: 0.5009 - f1_score: 0.5437 - loss: 0.8555 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7477 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 35ms/step - accuracy: 0.5221 - f1_score: 0.5698 - loss: 0.8378 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7479 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 35ms/step - accuracy: 0.5026 - f1_score: 0.5656 - loss: 0.8031 - val_accuracy: 0.5125 - val_f1_score: 0.0488 - val_loss: 0.7487 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 35ms/step - accuracy: 0.5130 - f1_score: 0.5638 - loss: 0.7968 - val_accuracy: 0.5375 - val_f1_score: 0.6606 - val_loss: 0.7485 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 36ms/step - accuracy: 0.5104 - f1_score: 0.5862 - loss: 0.7894 - val_accuracy: 0.4875 - val_f1_score: 0.5773 - val_loss: 0.7478 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 39ms/step - accuracy: 0.4991 - f1_score: 0.5697 - loss: 0.7885 - val_accuracy: 0.5250 - val_f1_score: 0.6667 - val_loss: 0.7476 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 36ms/step - accuracy: 0.5135 - f1_score: 0.5755 - loss: 0.7701 - val_accuracy: 0.5125 - val_f1_score: 0.6723 - val_loss: 0.7474 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 35ms/step - accuracy: 0.5039 - f1_score: 0.5652 - loss: 0.7792 - val_accuracy: 0.4750 - val_f1_score: 0.6441 - val_loss: 0.7482 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 36ms/step - accuracy: 0.5174 - f1_score: 0.5832 - loss: 0.7618 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7477 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 35ms/step - accuracy: 0.5095 - f1_score: 0.5569 - loss: 0.7633 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.7489 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 35ms/step - accuracy: 0.4913 - f1_score: 0.5393 - loss: 0.7657 - val_accuracy: 0.5000 - val_f1_score: 0.6610 - val_loss: 0.7474 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 36ms/step - accuracy: 0.5200 - f1_score: 0.5746 - loss: 0.7596 - val_accuracy: 0.5125 - val_f1_score: 0.0930 - val_loss: 0.7472 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.5260 - f1_score: 0.5557 - loss: 0.7593 - val_accuracy: 0.5250 - val_f1_score: 0.3448 - val_loss: 0.7470 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 35ms/step - accuracy: 0.5104 - f1_score: 0.5607 - loss: 0.7574 - val_accuracy: 0.5500 - val_f1_score: 0.4375 - val_loss: 0.7474 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 35ms/step - accuracy: 0.4948 - f1_score: 0.5899 - loss: 0.7687 - val_accuracy: 0.5125 - val_f1_score: 0.6723 - val_loss: 0.7478 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 35ms/step - accuracy: 0.5004 - f1_score: 0.6030 - loss: 0.7609 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7475 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 35ms/step - accuracy: 0.4961 - f1_score: 0.5899 - loss: 0.7611 - val_accuracy: 0.4875 - val_f1_score: 0.6555 - val_loss: 0.7474 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 35ms/step - accuracy: 0.5100 - f1_score: 0.5992 - loss: 0.7552 - val_accuracy: 0.5125 - val_f1_score: 0.6723 - val_loss: 0.7470 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 35ms/step - accuracy: 0.5074 - f1_score: 0.6220 - loss: 0.7541 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7469 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 35ms/step - accuracy: 0.4974 - f1_score: 0.6198 - loss: 0.7537 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7468 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 36ms/step - accuracy: 0.5065 - f1_score: 0.6341 - loss: 0.7535 - val_accuracy: 0.5000 - val_f1_score: 0.6610 - val_loss: 0.7466 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 35ms/step - accuracy: 0.5109 - f1_score: 0.6344 - loss: 0.7495 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7464 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 35ms/step - accuracy: 0.5000 - f1_score: 0.6116 - loss: 0.7542 - val_accuracy: 0.4625 - val_f1_score: 0.5743 - val_loss: 0.7470 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 35ms/step - accuracy: 0.5017 - f1_score: 0.6261 - loss: 0.7488 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7465 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 35ms/step - accuracy: 0.5000 - f1_score: 0.6380 - loss: 0.7498 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7463 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 35ms/step - accuracy: 0.5178 - f1_score: 0.6551 - loss: 0.7499 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7461 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 35ms/step - accuracy: 0.4991 - f1_score: 0.6369 - loss: 0.7505 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7460 - learning_rate: 4.2723e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\noldB → Fold 2 Val F1 = 0.6723\n\n>>> Training model1 on Fold 2\nEpoch 1/200\n36/36 - 26s - 723ms/step - accuracy: 0.4887 - f1_score: 0.5823 - loss: 0.6938 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6933 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 38ms/step - accuracy: 0.4965 - f1_score: 0.4835 - loss: 0.6925 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6932 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 40ms/step - accuracy: 0.5139 - f1_score: 0.4747 - loss: 0.6931 - val_accuracy: 0.5000 - val_f1_score: 0.5833 - val_loss: 0.6933 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.4944 - f1_score: 0.5524 - loss: 0.6937 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6936 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 32ms/step - accuracy: 0.5061 - f1_score: 0.5262 - loss: 0.6928 - val_accuracy: 0.4875 - val_f1_score: 0.0000e+00 - val_loss: 0.6942 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 30ms/step - accuracy: 0.4861 - f1_score: 0.2754 - loss: 0.6934 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6987 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.4983 - f1_score: 0.5909 - loss: 0.6936 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6933 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.4961 - f1_score: 0.3854 - loss: 0.6932 - val_accuracy: 0.4875 - val_f1_score: 0.0000e+00 - val_loss: 0.6938 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 29ms/step - accuracy: 0.5056 - f1_score: 0.4675 - loss: 0.6926 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7137 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 29ms/step - accuracy: 0.4896 - f1_score: 0.5108 - loss: 0.6939 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6941 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 30ms/step - accuracy: 0.5026 - f1_score: 0.6649 - loss: 0.6928 - val_accuracy: 0.4250 - val_f1_score: 0.4250 - val_loss: 0.7013 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 29ms/step - accuracy: 0.5204 - f1_score: 0.3534 - loss: 0.6877 - val_accuracy: 0.5375 - val_f1_score: 0.6476 - val_loss: 0.7457 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5234 - f1_score: 0.5718 - loss: 0.6844 - val_accuracy: 0.4250 - val_f1_score: 0.0800 - val_loss: 0.7304 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 29ms/step - accuracy: 0.4957 - f1_score: 0.4386 - loss: 0.6909 - val_accuracy: 0.4250 - val_f1_score: 0.1154 - val_loss: 0.7532 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 30ms/step - accuracy: 0.5243 - f1_score: 0.2126 - loss: 0.6831 - val_accuracy: 0.4750 - val_f1_score: 0.2759 - val_loss: 0.7892 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 29ms/step - accuracy: 0.5095 - f1_score: 0.3791 - loss: 0.6805 - val_accuracy: 0.4375 - val_f1_score: 0.2373 - val_loss: 0.8747 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 30ms/step - accuracy: 0.5456 - f1_score: 0.2505 - loss: 0.6724 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6997 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 29ms/step - accuracy: 0.5586 - f1_score: 0.3152 - loss: 0.6696 - val_accuracy: 0.4625 - val_f1_score: 0.2456 - val_loss: 0.8560 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 29ms/step - accuracy: 0.5525 - f1_score: 0.4677 - loss: 0.6611 - val_accuracy: 0.5375 - val_f1_score: 0.6408 - val_loss: 0.9051 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 29ms/step - accuracy: 0.5595 - f1_score: 0.5164 - loss: 0.6594 - val_accuracy: 0.4750 - val_f1_score: 0.3000 - val_loss: 1.0079 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 30ms/step - accuracy: 0.5638 - f1_score: 0.5152 - loss: 0.6489 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 1.1120 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\nmodel1 → Fold 2 Val F1 = 0.6667\n\n>>> Training model2 on Fold 2\nEpoch 1/200\n36/36 - 4s - 120ms/step - accuracy: 0.5152 - f1_score: 0.5208 - loss: 4.4946 - val_accuracy: 0.5750 - val_f1_score: 0.5000 - val_loss: 0.6752 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 22ms/step - accuracy: 0.5130 - f1_score: 0.5109 - loss: 1.4415 - val_accuracy: 0.6000 - val_f1_score: 0.6279 - val_loss: 0.6589 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 21ms/step - accuracy: 0.5308 - f1_score: 0.5314 - loss: 1.2074 - val_accuracy: 0.5375 - val_f1_score: 0.6263 - val_loss: 0.6770 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 21ms/step - accuracy: 0.5221 - f1_score: 0.5160 - loss: 0.9860 - val_accuracy: 0.5625 - val_f1_score: 0.5783 - val_loss: 0.6914 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 21ms/step - accuracy: 0.5208 - f1_score: 0.5137 - loss: 1.2878 - val_accuracy: 0.5125 - val_f1_score: 0.6609 - val_loss: 0.7409 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 20ms/step - accuracy: 0.5339 - f1_score: 0.5476 - loss: 0.9472 - val_accuracy: 0.5625 - val_f1_score: 0.6316 - val_loss: 0.6740 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 21ms/step - accuracy: 0.5438 - f1_score: 0.5601 - loss: 0.8981 - val_accuracy: 0.5000 - val_f1_score: 0.6491 - val_loss: 0.7222 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 21ms/step - accuracy: 0.5278 - f1_score: 0.5228 - loss: 0.8653 - val_accuracy: 0.5375 - val_f1_score: 0.4638 - val_loss: 0.7051 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 20ms/step - accuracy: 0.5334 - f1_score: 0.5312 - loss: 0.8602 - val_accuracy: 0.5000 - val_f1_score: 0.6491 - val_loss: 0.7120 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 20ms/step - accuracy: 0.5456 - f1_score: 0.5562 - loss: 0.8069 - val_accuracy: 0.5125 - val_f1_score: 0.5806 - val_loss: 0.6999 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 21ms/step - accuracy: 0.5425 - f1_score: 0.5616 - loss: 0.7435 - val_accuracy: 0.4875 - val_f1_score: 0.6019 - val_loss: 0.7283 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 21ms/step - accuracy: 0.5495 - f1_score: 0.5704 - loss: 0.7300 - val_accuracy: 0.4750 - val_f1_score: 0.6250 - val_loss: 0.7139 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 20ms/step - accuracy: 0.5634 - f1_score: 0.5884 - loss: 0.7100 - val_accuracy: 0.5375 - val_f1_score: 0.6105 - val_loss: 0.7000 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 20ms/step - accuracy: 0.5625 - f1_score: 0.5621 - loss: 0.7366 - val_accuracy: 0.5625 - val_f1_score: 0.5977 - val_loss: 0.6840 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 20ms/step - accuracy: 0.5343 - f1_score: 0.5304 - loss: 0.8706 - val_accuracy: 0.4875 - val_f1_score: 0.4225 - val_loss: 0.7280 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5634 - f1_score: 0.5603 - loss: 0.7553 - val_accuracy: 0.4500 - val_f1_score: 0.3333 - val_loss: 0.6885 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 20ms/step - accuracy: 0.5326 - f1_score: 0.5514 - loss: 0.7607 - val_accuracy: 0.5125 - val_f1_score: 0.6609 - val_loss: 0.7123 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 21ms/step - accuracy: 0.5660 - f1_score: 0.5202 - loss: 0.7343 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.6948 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 20ms/step - accuracy: 0.5760 - f1_score: 0.5652 - loss: 0.7104 - val_accuracy: 0.5125 - val_f1_score: 0.6286 - val_loss: 0.7086 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 20ms/step - accuracy: 0.5694 - f1_score: 0.5587 - loss: 0.7088 - val_accuracy: 0.4875 - val_f1_score: 0.6095 - val_loss: 0.7091 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 21ms/step - accuracy: 0.5725 - f1_score: 0.5789 - loss: 0.7031 - val_accuracy: 0.4625 - val_f1_score: 0.5657 - val_loss: 0.6950 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 20ms/step - accuracy: 0.5647 - f1_score: 0.5823 - loss: 0.7039 - val_accuracy: 0.4875 - val_f1_score: 0.4225 - val_loss: 0.7081 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 22ms/step - accuracy: 0.5503 - f1_score: 0.5603 - loss: 0.7071 - val_accuracy: 0.5375 - val_f1_score: 0.5934 - val_loss: 0.7093 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 22ms/step - accuracy: 0.5742 - f1_score: 0.5563 - loss: 0.6869 - val_accuracy: 0.5375 - val_f1_score: 0.6105 - val_loss: 0.6951 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 20ms/step - accuracy: 0.5781 - f1_score: 0.5533 - loss: 0.7058 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 0.7057 - learning_rate: 7.3832e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step\nmodel2 → Fold 2 Val F1 = 0.6609\n\n>>> Training model3 on Fold 2\nEpoch 1/200\n36/36 - 9s - 240ms/step - accuracy: 0.5373 - f1_score: 0.5909 - loss: 0.7338 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6933 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 3s - 81ms/step - accuracy: 0.5443 - f1_score: 0.4526 - loss: 0.6887 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6960 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 3s - 83ms/step - accuracy: 0.5608 - f1_score: 0.4740 - loss: 0.6830 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6940 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 3s - 85ms/step - accuracy: 0.6107 - f1_score: 0.5771 - loss: 0.6479 - val_accuracy: 0.4500 - val_f1_score: 0.2903 - val_loss: 0.6948 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 116ms/step - accuracy: 0.6862 - f1_score: 0.6620 - loss: 0.5601 - val_accuracy: 0.5500 - val_f1_score: 0.4000 - val_loss: 0.6887 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 3s - 84ms/step - accuracy: 0.7652 - f1_score: 0.7718 - loss: 0.4754 - val_accuracy: 0.5375 - val_f1_score: 0.4638 - val_loss: 0.7497 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 3s - 97ms/step - accuracy: 0.8511 - f1_score: 0.8535 - loss: 0.3561 - val_accuracy: 0.4625 - val_f1_score: 0.3582 - val_loss: 0.7962 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 94ms/step - accuracy: 0.9089 - f1_score: 0.9077 - loss: 0.2230 - val_accuracy: 0.5125 - val_f1_score: 0.3810 - val_loss: 1.0374 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 3s - 80ms/step - accuracy: 0.9536 - f1_score: 0.9546 - loss: 0.1462 - val_accuracy: 0.4375 - val_f1_score: 0.4000 - val_loss: 1.4437 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 3s - 80ms/step - accuracy: 0.9714 - f1_score: 0.9717 - loss: 0.0889 - val_accuracy: 0.4625 - val_f1_score: 0.3385 - val_loss: 1.4643 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 3s - 87ms/step - accuracy: 0.9831 - f1_score: 0.9832 - loss: 0.0782 - val_accuracy: 0.5000 - val_f1_score: 0.4286 - val_loss: 1.6410 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 3s - 84ms/step - accuracy: 0.9909 - f1_score: 0.9912 - loss: 0.0475 - val_accuracy: 0.4625 - val_f1_score: 0.4557 - val_loss: 1.9491 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 3s - 84ms/step - accuracy: 0.9913 - f1_score: 0.9915 - loss: 0.0295 - val_accuracy: 0.4875 - val_f1_score: 0.4810 - val_loss: 2.0243 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 3s - 85ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0043 - val_accuracy: 0.4500 - val_f1_score: 0.3714 - val_loss: 2.8449 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 88ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0031 - val_accuracy: 0.4750 - val_f1_score: 0.3437 - val_loss: 1.8632 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 84ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0038 - val_accuracy: 0.4875 - val_f1_score: 0.4384 - val_loss: 2.3105 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 3s - 79ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9894e-04 - val_accuracy: 0.4875 - val_f1_score: 0.4225 - val_loss: 2.6991 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 78ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6441e-04 - val_accuracy: 0.4750 - val_f1_score: 0.4000 - val_loss: 2.9169 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 3s - 81ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.0975e-04 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 3.0823 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 85ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6234e-05 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 3.2525 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 3s - 86ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9402e-05 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 3.3639 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step\nmodel3 → Fold 2 Val F1 = 0.6667\n\n>>> Training model4 on Fold 2\nEpoch 1/200\n36/36 - 9s - 241ms/step - accuracy: 0.5087 - f1_score: 0.5568 - loss: 0.6922 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6922 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 118ms/step - accuracy: 0.5052 - f1_score: 0.3709 - loss: 0.6943 - val_accuracy: 0.5250 - val_f1_score: 0.1364 - val_loss: 0.6922 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 118ms/step - accuracy: 0.5282 - f1_score: 0.4679 - loss: 0.6919 - val_accuracy: 0.5375 - val_f1_score: 0.1778 - val_loss: 0.6914 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 117ms/step - accuracy: 0.5239 - f1_score: 0.5007 - loss: 0.6913 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6940 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 118ms/step - accuracy: 0.5208 - f1_score: 0.4583 - loss: 0.6908 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6937 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 118ms/step - accuracy: 0.5451 - f1_score: 0.4653 - loss: 0.6899 - val_accuracy: 0.5000 - val_f1_score: 0.2593 - val_loss: 0.6924 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 118ms/step - accuracy: 0.5308 - f1_score: 0.4619 - loss: 0.6906 - val_accuracy: 0.5125 - val_f1_score: 0.0488 - val_loss: 0.6930 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 118ms/step - accuracy: 0.5490 - f1_score: 0.4808 - loss: 0.6867 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6961 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 118ms/step - accuracy: 0.5117 - f1_score: 0.4144 - loss: 0.6924 - val_accuracy: 0.5750 - val_f1_score: 0.5000 - val_loss: 0.6878 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 118ms/step - accuracy: 0.5365 - f1_score: 0.5211 - loss: 0.6915 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 0.6902 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 118ms/step - accuracy: 0.5339 - f1_score: 0.5762 - loss: 0.6887 - val_accuracy: 0.5250 - val_f1_score: 0.2400 - val_loss: 0.6924 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 117ms/step - accuracy: 0.5382 - f1_score: 0.5119 - loss: 0.6901 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6879 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 118ms/step - accuracy: 0.5260 - f1_score: 0.5784 - loss: 0.6903 - val_accuracy: 0.5250 - val_f1_score: 0.2963 - val_loss: 0.6898 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 118ms/step - accuracy: 0.5464 - f1_score: 0.5451 - loss: 0.6870 - val_accuracy: 0.4875 - val_f1_score: 0.2264 - val_loss: 0.6904 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 118ms/step - accuracy: 0.5516 - f1_score: 0.4988 - loss: 0.6859 - val_accuracy: 0.5375 - val_f1_score: 0.1778 - val_loss: 0.6916 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 118ms/step - accuracy: 0.5547 - f1_score: 0.5188 - loss: 0.6856 - val_accuracy: 0.5000 - val_f1_score: 0.0476 - val_loss: 0.6937 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 117ms/step - accuracy: 0.5495 - f1_score: 0.4389 - loss: 0.6861 - val_accuracy: 0.5250 - val_f1_score: 0.2400 - val_loss: 0.6901 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 118ms/step - accuracy: 0.5612 - f1_score: 0.4502 - loss: 0.6853 - val_accuracy: 0.5125 - val_f1_score: 0.0488 - val_loss: 0.6965 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 117ms/step - accuracy: 0.5512 - f1_score: 0.4921 - loss: 0.6851 - val_accuracy: 0.5000 - val_f1_score: 0.0476 - val_loss: 0.6984 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 117ms/step - accuracy: 0.5603 - f1_score: 0.4907 - loss: 0.6820 - val_accuracy: 0.4875 - val_f1_score: 0.1277 - val_loss: 0.6955 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 118ms/step - accuracy: 0.5547 - f1_score: 0.4706 - loss: 0.6810 - val_accuracy: 0.5750 - val_f1_score: 0.4848 - val_loss: 0.6910 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step\nmodel4 → Fold 2 Val F1 = 0.6667\n\n>>> Training model5 on Fold 2\nEpoch 1/200\n36/36 - 7s - 198ms/step - accuracy: 0.4991 - f1_score: 0.5030 - loss: 1.1462 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.7086 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 33ms/step - accuracy: 0.5230 - f1_score: 0.4989 - loss: 0.7746 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6999 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 34ms/step - accuracy: 0.5373 - f1_score: 0.5529 - loss: 0.7174 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7330 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 32ms/step - accuracy: 0.5551 - f1_score: 0.5389 - loss: 0.6924 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7468 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 32ms/step - accuracy: 0.5933 - f1_score: 0.5796 - loss: 0.6743 - val_accuracy: 0.4875 - val_f1_score: 0.0000e+00 - val_loss: 0.7193 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 33ms/step - accuracy: 0.6120 - f1_score: 0.6336 - loss: 0.6422 - val_accuracy: 0.4125 - val_f1_score: 0.4471 - val_loss: 0.7255 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 37ms/step - accuracy: 0.6827 - f1_score: 0.6758 - loss: 0.5796 - val_accuracy: 0.4250 - val_f1_score: 0.5000 - val_loss: 0.7917 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 34ms/step - accuracy: 0.7426 - f1_score: 0.7421 - loss: 0.4900 - val_accuracy: 0.3875 - val_f1_score: 0.3467 - val_loss: 0.9961 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 33ms/step - accuracy: 0.7808 - f1_score: 0.7863 - loss: 0.4364 - val_accuracy: 0.4125 - val_f1_score: 0.4337 - val_loss: 1.1707 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 32ms/step - accuracy: 0.8498 - f1_score: 0.8510 - loss: 0.3393 - val_accuracy: 0.4625 - val_f1_score: 0.5169 - val_loss: 1.1402 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 32ms/step - accuracy: 0.8746 - f1_score: 0.8768 - loss: 0.2935 - val_accuracy: 0.3875 - val_f1_score: 0.3288 - val_loss: 1.6222 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 32ms/step - accuracy: 0.8576 - f1_score: 0.8610 - loss: 0.3185 - val_accuracy: 0.3875 - val_f1_score: 0.3099 - val_loss: 1.5283 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 32ms/step - accuracy: 0.8915 - f1_score: 0.8933 - loss: 0.2613 - val_accuracy: 0.4500 - val_f1_score: 0.4054 - val_loss: 1.5736 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 33ms/step - accuracy: 0.9197 - f1_score: 0.9197 - loss: 0.1957 - val_accuracy: 0.3875 - val_f1_score: 0.2899 - val_loss: 1.8047 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 32ms/step - accuracy: 0.9501 - f1_score: 0.9506 - loss: 0.1384 - val_accuracy: 0.3750 - val_f1_score: 0.3056 - val_loss: 1.9555 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 32ms/step - accuracy: 0.9562 - f1_score: 0.9563 - loss: 0.1354 - val_accuracy: 0.4375 - val_f1_score: 0.3662 - val_loss: 2.1192 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 33ms/step - accuracy: 0.9431 - f1_score: 0.9437 - loss: 0.1818 - val_accuracy: 0.5000 - val_f1_score: 0.4595 - val_loss: 2.0755 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 32ms/step - accuracy: 0.9553 - f1_score: 0.9542 - loss: 0.1133 - val_accuracy: 0.4625 - val_f1_score: 0.3944 - val_loss: 2.7148 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 33ms/step - accuracy: 0.9701 - f1_score: 0.9698 - loss: 0.0858 - val_accuracy: 0.4000 - val_f1_score: 0.3514 - val_loss: 2.5820 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 33ms/step - accuracy: 0.9787 - f1_score: 0.9784 - loss: 0.0641 - val_accuracy: 0.4625 - val_f1_score: 0.3768 - val_loss: 3.2540 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 32ms/step - accuracy: 0.9857 - f1_score: 0.9861 - loss: 0.0480 - val_accuracy: 0.4000 - val_f1_score: 0.2727 - val_loss: 2.8640 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 32ms/step - accuracy: 0.9891 - f1_score: 0.9891 - loss: 0.0380 - val_accuracy: 0.4375 - val_f1_score: 0.3284 - val_loss: 3.1928 - learning_rate: 8.1479e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step\nmodel5 → Fold 2 Val F1 = 0.6667\n\n>>> Training model6 on Fold 2\nEpoch 1/200\n36/36 - 7s - 198ms/step - accuracy: 0.5156 - f1_score: 0.5110 - loss: 2.4008 - val_accuracy: 0.4750 - val_f1_score: 0.5435 - val_loss: 0.7763 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 40ms/step - accuracy: 0.5200 - f1_score: 0.5220 - loss: 1.0432 - val_accuracy: 0.5125 - val_f1_score: 0.4348 - val_loss: 0.7057 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 40ms/step - accuracy: 0.5061 - f1_score: 0.5294 - loss: 1.1272 - val_accuracy: 0.5750 - val_f1_score: 0.6136 - val_loss: 0.7019 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 40ms/step - accuracy: 0.4848 - f1_score: 0.4859 - loss: 1.0273 - val_accuracy: 0.5125 - val_f1_score: 0.6667 - val_loss: 0.7201 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 39ms/step - accuracy: 0.5161 - f1_score: 0.4845 - loss: 0.8641 - val_accuracy: 0.5625 - val_f1_score: 0.4262 - val_loss: 0.6799 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 40ms/step - accuracy: 0.5048 - f1_score: 0.4954 - loss: 0.7798 - val_accuracy: 0.5500 - val_f1_score: 0.6400 - val_loss: 0.7071 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 39ms/step - accuracy: 0.4939 - f1_score: 0.5125 - loss: 0.7563 - val_accuracy: 0.5125 - val_f1_score: 0.3158 - val_loss: 0.6866 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 40ms/step - accuracy: 0.5065 - f1_score: 0.5264 - loss: 0.7080 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 0.6926 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 39ms/step - accuracy: 0.4987 - f1_score: 0.5363 - loss: 0.7200 - val_accuracy: 0.5625 - val_f1_score: 0.6316 - val_loss: 0.6931 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 39ms/step - accuracy: 0.5039 - f1_score: 0.4918 - loss: 0.7276 - val_accuracy: 0.3500 - val_f1_score: 0.4800 - val_loss: 0.7006 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 39ms/step - accuracy: 0.5247 - f1_score: 0.5738 - loss: 0.6966 - val_accuracy: 0.5125 - val_f1_score: 0.2353 - val_loss: 0.6957 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 40ms/step - accuracy: 0.5074 - f1_score: 0.5977 - loss: 0.6945 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6954 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 40ms/step - accuracy: 0.5122 - f1_score: 0.6393 - loss: 0.6927 - val_accuracy: 0.5125 - val_f1_score: 0.6667 - val_loss: 0.6932 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 39ms/step - accuracy: 0.5182 - f1_score: 0.6293 - loss: 0.6924 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6955 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 39ms/step - accuracy: 0.5004 - f1_score: 0.6126 - loss: 0.6932 - val_accuracy: 0.5375 - val_f1_score: 0.4127 - val_loss: 0.6916 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 39ms/step - accuracy: 0.5022 - f1_score: 0.6068 - loss: 0.6912 - val_accuracy: 0.4875 - val_f1_score: 0.6168 - val_loss: 0.6978 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 39ms/step - accuracy: 0.5148 - f1_score: 0.5499 - loss: 0.6914 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 0.6914 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 39ms/step - accuracy: 0.5113 - f1_score: 0.3225 - loss: 0.6945 - val_accuracy: 0.5125 - val_f1_score: 0.2909 - val_loss: 0.6922 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 39ms/step - accuracy: 0.5087 - f1_score: 0.3004 - loss: 0.6932 - val_accuracy: 0.5500 - val_f1_score: 0.5385 - val_loss: 0.6919 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 40ms/step - accuracy: 0.5148 - f1_score: 0.3477 - loss: 0.6927 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6935 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 40ms/step - accuracy: 0.4965 - f1_score: 0.4008 - loss: 0.6931 - val_accuracy: 0.4750 - val_f1_score: 0.6038 - val_loss: 0.6953 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 40ms/step - accuracy: 0.5174 - f1_score: 0.4412 - loss: 0.6947 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.6930 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 40ms/step - accuracy: 0.5056 - f1_score: 0.5748 - loss: 0.6909 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 0.6940 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 40ms/step - accuracy: 0.5295 - f1_score: 0.3148 - loss: 0.6892 - val_accuracy: 0.5250 - val_f1_score: 0.4722 - val_loss: 0.6931 - learning_rate: 7.6518e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step\nmodel6 → Fold 2 Val F1 = 0.6667\n\n==================================================\nFold 3/30 - Subject: S11\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 3\nEpoch 1/200\n36/36 - 8s - 219ms/step - accuracy: 0.4931 - f1_score: 0.5000 - loss: 0.8534 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6984 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 28ms/step - accuracy: 0.4891 - f1_score: 0.4785 - loss: 0.7853 - val_accuracy: 0.4125 - val_f1_score: 0.2295 - val_loss: 0.7126 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 28ms/step - accuracy: 0.5048 - f1_score: 0.4922 - loss: 0.7445 - val_accuracy: 0.5500 - val_f1_score: 0.2174 - val_loss: 0.6993 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 28ms/step - accuracy: 0.5187 - f1_score: 0.5519 - loss: 0.7202 - val_accuracy: 0.4750 - val_f1_score: 0.5333 - val_loss: 0.7042 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.5260 - f1_score: 0.5767 - loss: 0.7169 - val_accuracy: 0.4250 - val_f1_score: 0.5306 - val_loss: 0.7053 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 29ms/step - accuracy: 0.5087 - f1_score: 0.5424 - loss: 0.7131 - val_accuracy: 0.4500 - val_f1_score: 0.5217 - val_loss: 0.7062 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.5122 - f1_score: 0.5596 - loss: 0.7076 - val_accuracy: 0.4250 - val_f1_score: 0.5106 - val_loss: 0.7096 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5443 - f1_score: 0.5898 - loss: 0.7004 - val_accuracy: 0.4375 - val_f1_score: 0.5361 - val_loss: 0.7077 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5165 - f1_score: 0.5135 - loss: 0.7076 - val_accuracy: 0.4250 - val_f1_score: 0.3429 - val_loss: 0.7079 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.5130 - f1_score: 0.4677 - loss: 0.7043 - val_accuracy: 0.5000 - val_f1_score: 0.3548 - val_loss: 0.7062 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 28ms/step - accuracy: 0.5347 - f1_score: 0.4890 - loss: 0.7001 - val_accuracy: 0.4875 - val_f1_score: 0.2807 - val_loss: 0.7062 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5191 - f1_score: 0.5418 - loss: 0.7037 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 0.7050 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5178 - f1_score: 0.5603 - loss: 0.7028 - val_accuracy: 0.4375 - val_f1_score: 0.5794 - val_loss: 0.7081 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5347 - f1_score: 0.5132 - loss: 0.6969 - val_accuracy: 0.4375 - val_f1_score: 0.4944 - val_loss: 0.7225 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 28ms/step - accuracy: 0.5252 - f1_score: 0.4475 - loss: 0.7008 - val_accuracy: 0.5000 - val_f1_score: 0.4118 - val_loss: 0.7143 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5356 - f1_score: 0.5265 - loss: 0.6960 - val_accuracy: 0.4500 - val_f1_score: 0.3125 - val_loss: 0.7226 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.5260 - f1_score: 0.5454 - loss: 0.6975 - val_accuracy: 0.4000 - val_f1_score: 0.5294 - val_loss: 0.7284 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.5365 - f1_score: 0.5676 - loss: 0.6970 - val_accuracy: 0.5125 - val_f1_score: 0.4800 - val_loss: 0.7071 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5239 - f1_score: 0.5203 - loss: 0.6995 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 0.7098 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 29ms/step - accuracy: 0.5204 - f1_score: 0.5748 - loss: 0.6994 - val_accuracy: 0.4250 - val_f1_score: 0.5208 - val_loss: 0.7230 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 29ms/step - accuracy: 0.5308 - f1_score: 0.5330 - loss: 0.6962 - val_accuracy: 0.4250 - val_f1_score: 0.5306 - val_loss: 0.7284 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 28ms/step - accuracy: 0.5382 - f1_score: 0.5723 - loss: 0.6962 - val_accuracy: 0.4875 - val_f1_score: 0.4675 - val_loss: 0.7159 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 28ms/step - accuracy: 0.5148 - f1_score: 0.5470 - loss: 0.7014 - val_accuracy: 0.4875 - val_f1_score: 0.5941 - val_loss: 0.7068 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 28ms/step - accuracy: 0.5269 - f1_score: 0.5207 - loss: 0.6966 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 0.7095 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 28ms/step - accuracy: 0.5469 - f1_score: 0.5488 - loss: 0.6955 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 0.7168 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 28ms/step - accuracy: 0.5330 - f1_score: 0.4920 - loss: 0.6964 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 0.7072 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 28ms/step - accuracy: 0.5495 - f1_score: 0.5374 - loss: 0.6943 - val_accuracy: 0.4125 - val_f1_score: 0.4051 - val_loss: 0.7159 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 28ms/step - accuracy: 0.5443 - f1_score: 0.5370 - loss: 0.6920 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 0.7187 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 28ms/step - accuracy: 0.5295 - f1_score: 0.5597 - loss: 0.6970 - val_accuracy: 0.4625 - val_f1_score: 0.4819 - val_loss: 0.7162 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 29ms/step - accuracy: 0.5204 - f1_score: 0.5662 - loss: 0.6951 - val_accuracy: 0.4625 - val_f1_score: 0.5275 - val_loss: 0.7104 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 28ms/step - accuracy: 0.5395 - f1_score: 0.5636 - loss: 0.6930 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.7053 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 28ms/step - accuracy: 0.5165 - f1_score: 0.5431 - loss: 0.6921 - val_accuracy: 0.4125 - val_f1_score: 0.4719 - val_loss: 0.7107 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.4922 - loss: 0.6967 - val_accuracy: 0.5000 - val_f1_score: 0.4737 - val_loss: 0.7038 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 28ms/step - accuracy: 0.5382 - f1_score: 0.5088 - loss: 0.6958 - val_accuracy: 0.5125 - val_f1_score: 0.4935 - val_loss: 0.7026 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 28ms/step - accuracy: 0.5352 - f1_score: 0.5513 - loss: 0.6967 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 0.7007 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 29ms/step - accuracy: 0.5503 - f1_score: 0.6009 - loss: 0.6910 - val_accuracy: 0.5000 - val_f1_score: 0.6364 - val_loss: 0.7075 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 28ms/step - accuracy: 0.5204 - f1_score: 0.5787 - loss: 0.6929 - val_accuracy: 0.4875 - val_f1_score: 0.6168 - val_loss: 0.7087 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 28ms/step - accuracy: 0.5382 - f1_score: 0.5788 - loss: 0.6946 - val_accuracy: 0.5375 - val_f1_score: 0.6263 - val_loss: 0.7044 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 28ms/step - accuracy: 0.5421 - f1_score: 0.5375 - loss: 0.6925 - val_accuracy: 0.4250 - val_f1_score: 0.4651 - val_loss: 0.7060 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 1s - 28ms/step - accuracy: 0.5343 - f1_score: 0.4993 - loss: 0.6910 - val_accuracy: 0.4750 - val_f1_score: 0.5714 - val_loss: 0.7157 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 1s - 28ms/step - accuracy: 0.5378 - f1_score: 0.5439 - loss: 0.6883 - val_accuracy: 0.4875 - val_f1_score: 0.5591 - val_loss: 0.7102 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 1s - 28ms/step - accuracy: 0.5538 - f1_score: 0.5483 - loss: 0.6884 - val_accuracy: 0.5125 - val_f1_score: 0.4935 - val_loss: 0.7077 - learning_rate: 2.2643e-04\nEpoch 43/200\n36/36 - 1s - 28ms/step - accuracy: 0.5265 - f1_score: 0.5083 - loss: 0.6983 - val_accuracy: 0.4375 - val_f1_score: 0.4304 - val_loss: 0.7078 - learning_rate: 2.0267e-04\nEpoch 44/200\n36/36 - 1s - 28ms/step - accuracy: 0.5503 - f1_score: 0.5404 - loss: 0.6878 - val_accuracy: 0.4750 - val_f1_score: 0.4324 - val_loss: 0.7094 - learning_rate: 1.8042e-04\nEpoch 45/200\n36/36 - 1s - 28ms/step - accuracy: 0.5516 - f1_score: 0.5545 - loss: 0.6889 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.7087 - learning_rate: 1.5972e-04\nEpoch 46/200\n36/36 - 1s - 28ms/step - accuracy: 0.5434 - f1_score: 0.5349 - loss: 0.6899 - val_accuracy: 0.4625 - val_f1_score: 0.4691 - val_loss: 0.7105 - learning_rate: 1.4058e-04\nEpoch 47/200\n36/36 - 1s - 28ms/step - accuracy: 0.5651 - f1_score: 0.5754 - loss: 0.6900 - val_accuracy: 0.4750 - val_f1_score: 0.4878 - val_loss: 0.7097 - learning_rate: 1.2302e-04\nEpoch 48/200\n36/36 - 1s - 28ms/step - accuracy: 0.5469 - f1_score: 0.5561 - loss: 0.6896 - val_accuracy: 0.4625 - val_f1_score: 0.4691 - val_loss: 0.7089 - learning_rate: 1.0700e-04\nEpoch 49/200\n36/36 - 1s - 28ms/step - accuracy: 0.5482 - f1_score: 0.5587 - loss: 0.6890 - val_accuracy: 0.4750 - val_f1_score: 0.5000 - val_loss: 0.7084 - learning_rate: 9.2503e-05\nEpoch 50/200\n36/36 - 1s - 28ms/step - accuracy: 0.5503 - f1_score: 0.5859 - loss: 0.6896 - val_accuracy: 0.4875 - val_f1_score: 0.5495 - val_loss: 0.7094 - learning_rate: 7.9466e-05\nEpoch 51/200\n36/36 - 1s - 29ms/step - accuracy: 0.5742 - f1_score: 0.5971 - loss: 0.6875 - val_accuracy: 0.4625 - val_f1_score: 0.5474 - val_loss: 0.7102 - learning_rate: 6.7829e-05\nEpoch 52/200\n36/36 - 1s - 29ms/step - accuracy: 0.5373 - f1_score: 0.5656 - loss: 0.6890 - val_accuracy: 0.4875 - val_f1_score: 0.5393 - val_loss: 0.7109 - learning_rate: 5.7516e-05\nEpoch 53/200\n36/36 - 1s - 28ms/step - accuracy: 0.5530 - f1_score: 0.5754 - loss: 0.6882 - val_accuracy: 0.4500 - val_f1_score: 0.4634 - val_loss: 0.7109 - learning_rate: 4.8444e-05\nEpoch 54/200\n36/36 - 1s - 28ms/step - accuracy: 0.5486 - f1_score: 0.5713 - loss: 0.6874 - val_accuracy: 0.4750 - val_f1_score: 0.4615 - val_loss: 0.7104 - learning_rate: 4.0524e-05\nEpoch 55/200\n36/36 - 1s - 28ms/step - accuracy: 0.5369 - f1_score: 0.5477 - loss: 0.6888 - val_accuracy: 0.4750 - val_f1_score: 0.4750 - val_loss: 0.7095 - learning_rate: 3.3661e-05\nEpoch 56/200\n36/36 - 1s - 28ms/step - accuracy: 0.5495 - f1_score: 0.5475 - loss: 0.6873 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.7096 - learning_rate: 2.7761e-05\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step\noldA → Fold 3 Val F1 = 0.6364\n\n>>> Training oldB on Fold 3\nEpoch 1/200\n36/36 - 13s - 357ms/step - accuracy: 0.5165 - f1_score: 0.4968 - loss: 3.4501 - val_accuracy: 0.5250 - val_f1_score: 0.6122 - val_loss: 0.8253 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 35ms/step - accuracy: 0.5148 - f1_score: 0.5222 - loss: 2.3125 - val_accuracy: 0.5875 - val_f1_score: 0.5479 - val_loss: 0.7408 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 35ms/step - accuracy: 0.4952 - f1_score: 0.5160 - loss: 1.6773 - val_accuracy: 0.5000 - val_f1_score: 0.4118 - val_loss: 0.7664 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 35ms/step - accuracy: 0.5109 - f1_score: 0.5461 - loss: 1.2388 - val_accuracy: 0.4000 - val_f1_score: 0.4419 - val_loss: 0.7621 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 36ms/step - accuracy: 0.5004 - f1_score: 0.5146 - loss: 1.0516 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.7516 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 35ms/step - accuracy: 0.5143 - f1_score: 0.5412 - loss: 0.9754 - val_accuracy: 0.4750 - val_f1_score: 0.5962 - val_loss: 0.7473 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 35ms/step - accuracy: 0.5004 - f1_score: 0.5558 - loss: 0.8625 - val_accuracy: 0.5125 - val_f1_score: 0.6061 - val_loss: 0.7463 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 35ms/step - accuracy: 0.5065 - f1_score: 0.5504 - loss: 0.8427 - val_accuracy: 0.4375 - val_f1_score: 0.6087 - val_loss: 0.7519 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 36ms/step - accuracy: 0.5182 - f1_score: 0.5546 - loss: 0.8432 - val_accuracy: 0.4625 - val_f1_score: 0.4416 - val_loss: 0.7468 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 36ms/step - accuracy: 0.4957 - f1_score: 0.5047 - loss: 0.8402 - val_accuracy: 0.5500 - val_f1_score: 0.2500 - val_loss: 0.7455 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 35ms/step - accuracy: 0.5056 - f1_score: 0.4739 - loss: 0.7936 - val_accuracy: 0.5250 - val_f1_score: 0.0500 - val_loss: 0.7461 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 36ms/step - accuracy: 0.5022 - f1_score: 0.4494 - loss: 0.8137 - val_accuracy: 0.5750 - val_f1_score: 0.3200 - val_loss: 0.7462 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 36ms/step - accuracy: 0.4957 - f1_score: 0.4908 - loss: 0.7888 - val_accuracy: 0.5000 - val_f1_score: 0.1667 - val_loss: 0.7474 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 35ms/step - accuracy: 0.4939 - f1_score: 0.4490 - loss: 0.7969 - val_accuracy: 0.5625 - val_f1_score: 0.4615 - val_loss: 0.7473 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 35ms/step - accuracy: 0.5065 - f1_score: 0.4510 - loss: 0.7692 - val_accuracy: 0.5375 - val_f1_score: 0.0976 - val_loss: 0.7476 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 36ms/step - accuracy: 0.4991 - f1_score: 0.4293 - loss: 0.7639 - val_accuracy: 0.5125 - val_f1_score: 0.0000e+00 - val_loss: 0.7475 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 36ms/step - accuracy: 0.4822 - f1_score: 0.4423 - loss: 0.7802 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7475 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 35ms/step - accuracy: 0.5208 - f1_score: 0.5183 - loss: 0.7744 - val_accuracy: 0.5125 - val_f1_score: 0.0930 - val_loss: 0.7472 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 36ms/step - accuracy: 0.5039 - f1_score: 0.4913 - loss: 0.7675 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7463 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 36ms/step - accuracy: 0.5069 - f1_score: 0.5174 - loss: 0.7614 - val_accuracy: 0.5375 - val_f1_score: 0.0513 - val_loss: 0.7466 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.4926 - f1_score: 0.4570 - loss: 0.7560 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.7459 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step\noldB → Fold 3 Val F1 = 0.6122\n\n>>> Training model1 on Fold 3\nEpoch 1/200\n36/36 - 26s - 733ms/step - accuracy: 0.4870 - f1_score: 0.5910 - loss: 0.6940 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6956 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 37ms/step - accuracy: 0.4918 - f1_score: 0.5359 - loss: 0.6937 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6923 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 37ms/step - accuracy: 0.5117 - f1_score: 0.5856 - loss: 0.6929 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6959 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 34ms/step - accuracy: 0.5282 - f1_score: 0.6913 - loss: 0.6914 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7000 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 31ms/step - accuracy: 0.5052 - f1_score: 0.6621 - loss: 0.6934 - val_accuracy: 0.5125 - val_f1_score: 0.6214 - val_loss: 0.6930 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 30ms/step - accuracy: 0.5217 - f1_score: 0.6819 - loss: 0.6923 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6999 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 29ms/step - accuracy: 0.5200 - f1_score: 0.6730 - loss: 0.6926 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6958 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5156 - f1_score: 0.6595 - loss: 0.6913 - val_accuracy: 0.4875 - val_f1_score: 0.1277 - val_loss: 0.6952 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 29ms/step - accuracy: 0.5087 - f1_score: 0.5022 - loss: 0.6921 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6918 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 29ms/step - accuracy: 0.5200 - f1_score: 0.3828 - loss: 0.6926 - val_accuracy: 0.4750 - val_f1_score: 0.6038 - val_loss: 0.6932 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 29ms/step - accuracy: 0.5187 - f1_score: 0.3897 - loss: 0.6896 - val_accuracy: 0.5125 - val_f1_score: 0.0488 - val_loss: 0.6949 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 29ms/step - accuracy: 0.5352 - f1_score: 0.6206 - loss: 0.6876 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.7121 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 29ms/step - accuracy: 0.5169 - f1_score: 0.6497 - loss: 0.6933 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6942 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 30ms/step - accuracy: 0.5069 - f1_score: 0.5538 - loss: 0.6922 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.6946 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 30ms/step - accuracy: 0.5004 - f1_score: 0.1957 - loss: 0.6895 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6940 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 34ms/step - accuracy: 0.4896 - f1_score: 0.4896 - loss: 0.6937 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6933 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.5104 - f1_score: 0.6723 - loss: 0.6929 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6942 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 30ms/step - accuracy: 0.4991 - f1_score: 0.6639 - loss: 0.6927 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6938 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 29ms/step - accuracy: 0.5273 - f1_score: 0.6570 - loss: 0.6820 - val_accuracy: 0.4625 - val_f1_score: 0.6325 - val_loss: 0.6985 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 30ms/step - accuracy: 0.5395 - f1_score: 0.6552 - loss: 0.6865 - val_accuracy: 0.4250 - val_f1_score: 0.5490 - val_loss: 0.7024 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 2s - 44ms/step - accuracy: 0.5477 - f1_score: 0.4932 - loss: 0.6704 - val_accuracy: 0.4750 - val_f1_score: 0.6316 - val_loss: 0.7000 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\nmodel1 → Fold 3 Val F1 = 0.6325\n\n>>> Training model2 on Fold 3\nEpoch 1/200\n36/36 - 4s - 122ms/step - accuracy: 0.4991 - f1_score: 0.4628 - loss: 4.9549 - val_accuracy: 0.5500 - val_f1_score: 0.4545 - val_loss: 1.0343 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 22ms/step - accuracy: 0.5048 - f1_score: 0.3941 - loss: 1.4664 - val_accuracy: 0.6000 - val_f1_score: 0.4483 - val_loss: 0.8223 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 21ms/step - accuracy: 0.5356 - f1_score: 0.4991 - loss: 1.1140 - val_accuracy: 0.5250 - val_f1_score: 0.1739 - val_loss: 0.8377 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 20ms/step - accuracy: 0.5443 - f1_score: 0.5161 - loss: 0.8909 - val_accuracy: 0.5500 - val_f1_score: 0.3571 - val_loss: 0.8264 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 20ms/step - accuracy: 0.5282 - f1_score: 0.5158 - loss: 0.8552 - val_accuracy: 0.5625 - val_f1_score: 0.4444 - val_loss: 0.8224 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 20ms/step - accuracy: 0.5282 - f1_score: 0.5419 - loss: 0.9867 - val_accuracy: 0.5500 - val_f1_score: 0.4545 - val_loss: 0.8816 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 21ms/step - accuracy: 0.5326 - f1_score: 0.5376 - loss: 0.9305 - val_accuracy: 0.5625 - val_f1_score: 0.5070 - val_loss: 0.8010 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 20ms/step - accuracy: 0.5516 - f1_score: 0.5538 - loss: 0.7852 - val_accuracy: 0.5500 - val_f1_score: 0.4706 - val_loss: 0.7675 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 21ms/step - accuracy: 0.5395 - f1_score: 0.5282 - loss: 0.8002 - val_accuracy: 0.4750 - val_f1_score: 0.4615 - val_loss: 0.7413 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 21ms/step - accuracy: 0.5438 - f1_score: 0.5483 - loss: 0.7669 - val_accuracy: 0.5625 - val_f1_score: 0.5070 - val_loss: 0.6930 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 21ms/step - accuracy: 0.5608 - f1_score: 0.5319 - loss: 0.7869 - val_accuracy: 0.6000 - val_f1_score: 0.4286 - val_loss: 0.6586 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 22ms/step - accuracy: 0.5495 - f1_score: 0.5628 - loss: 0.7372 - val_accuracy: 0.5000 - val_f1_score: 0.5652 - val_loss: 0.7556 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 23ms/step - accuracy: 0.5673 - f1_score: 0.5637 - loss: 0.7077 - val_accuracy: 0.5500 - val_f1_score: 0.3333 - val_loss: 0.7163 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 21ms/step - accuracy: 0.5417 - f1_score: 0.5200 - loss: 0.7195 - val_accuracy: 0.5250 - val_f1_score: 0.5250 - val_loss: 0.6919 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 21ms/step - accuracy: 0.5673 - f1_score: 0.5450 - loss: 0.7152 - val_accuracy: 0.5500 - val_f1_score: 0.4857 - val_loss: 0.7281 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5473 - f1_score: 0.5119 - loss: 0.7577 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 0.7355 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 21ms/step - accuracy: 0.5503 - f1_score: 0.5751 - loss: 0.7527 - val_accuracy: 0.5875 - val_f1_score: 0.3265 - val_loss: 0.6962 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 20ms/step - accuracy: 0.5543 - f1_score: 0.5401 - loss: 0.7196 - val_accuracy: 0.5125 - val_f1_score: 0.4348 - val_loss: 0.7011 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 20ms/step - accuracy: 0.5681 - f1_score: 0.5504 - loss: 0.6944 - val_accuracy: 0.5250 - val_f1_score: 0.6346 - val_loss: 0.7106 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 20ms/step - accuracy: 0.5521 - f1_score: 0.5653 - loss: 0.6863 - val_accuracy: 0.5500 - val_f1_score: 0.2500 - val_loss: 0.6890 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 21ms/step - accuracy: 0.5885 - f1_score: 0.5952 - loss: 0.6689 - val_accuracy: 0.5000 - val_f1_score: 0.5652 - val_loss: 0.7087 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 20ms/step - accuracy: 0.5829 - f1_score: 0.6040 - loss: 0.6916 - val_accuracy: 0.5125 - val_f1_score: 0.3810 - val_loss: 0.6908 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 21ms/step - accuracy: 0.5703 - f1_score: 0.5725 - loss: 0.6788 - val_accuracy: 0.5625 - val_f1_score: 0.4776 - val_loss: 0.6811 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 20ms/step - accuracy: 0.5734 - f1_score: 0.5801 - loss: 0.6756 - val_accuracy: 0.6125 - val_f1_score: 0.4746 - val_loss: 0.6825 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 20ms/step - accuracy: 0.5938 - f1_score: 0.6189 - loss: 0.6677 - val_accuracy: 0.6125 - val_f1_score: 0.4364 - val_loss: 0.6626 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 21ms/step - accuracy: 0.5942 - f1_score: 0.5677 - loss: 0.6578 - val_accuracy: 0.6500 - val_f1_score: 0.5333 - val_loss: 0.6681 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 20ms/step - accuracy: 0.6024 - f1_score: 0.6089 - loss: 0.6546 - val_accuracy: 0.6250 - val_f1_score: 0.5312 - val_loss: 0.6688 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 20ms/step - accuracy: 0.5977 - f1_score: 0.5989 - loss: 0.6643 - val_accuracy: 0.5250 - val_f1_score: 0.4865 - val_loss: 0.6789 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 20ms/step - accuracy: 0.6011 - f1_score: 0.6020 - loss: 0.6703 - val_accuracy: 0.6125 - val_f1_score: 0.5753 - val_loss: 0.6763 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 20ms/step - accuracy: 0.6137 - f1_score: 0.5943 - loss: 0.6424 - val_accuracy: 0.6000 - val_f1_score: 0.4667 - val_loss: 0.6790 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 20ms/step - accuracy: 0.6163 - f1_score: 0.5996 - loss: 0.6411 - val_accuracy: 0.5000 - val_f1_score: 0.5238 - val_loss: 0.7059 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 20ms/step - accuracy: 0.6042 - f1_score: 0.6028 - loss: 0.6553 - val_accuracy: 0.6000 - val_f1_score: 0.4839 - val_loss: 0.6789 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 21ms/step - accuracy: 0.6211 - f1_score: 0.6424 - loss: 0.6459 - val_accuracy: 0.5500 - val_f1_score: 0.5135 - val_loss: 0.6785 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 20ms/step - accuracy: 0.6111 - f1_score: 0.6288 - loss: 0.6472 - val_accuracy: 0.6000 - val_f1_score: 0.5000 - val_loss: 0.6714 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 20ms/step - accuracy: 0.6133 - f1_score: 0.6446 - loss: 0.6480 - val_accuracy: 0.5500 - val_f1_score: 0.5500 - val_loss: 0.6813 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 21ms/step - accuracy: 0.6155 - f1_score: 0.6487 - loss: 0.6476 - val_accuracy: 0.4875 - val_f1_score: 0.5287 - val_loss: 0.6849 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 21ms/step - accuracy: 0.6263 - f1_score: 0.6362 - loss: 0.6378 - val_accuracy: 0.5750 - val_f1_score: 0.4848 - val_loss: 0.6805 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 20ms/step - accuracy: 0.6163 - f1_score: 0.6261 - loss: 0.6356 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 0.6822 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 21ms/step - accuracy: 0.6363 - f1_score: 0.5959 - loss: 0.6285 - val_accuracy: 0.4875 - val_f1_score: 0.5060 - val_loss: 0.7041 - learning_rate: 3.0602e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\nmodel2 → Fold 3 Val F1 = 0.6346\n\n>>> Training model3 on Fold 3\nEpoch 1/200\n36/36 - 9s - 256ms/step - accuracy: 0.5026 - f1_score: 0.5619 - loss: 0.7289 - val_accuracy: 0.4750 - val_f1_score: 0.6379 - val_loss: 0.6945 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 3s - 80ms/step - accuracy: 0.5234 - f1_score: 0.5608 - loss: 0.6899 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 0.6933 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 3s - 80ms/step - accuracy: 0.5503 - f1_score: 0.4881 - loss: 0.6843 - val_accuracy: 0.5125 - val_f1_score: 0.2909 - val_loss: 0.6906 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 3s - 93ms/step - accuracy: 0.5907 - f1_score: 0.6706 - loss: 0.6722 - val_accuracy: 0.4875 - val_f1_score: 0.5495 - val_loss: 0.6975 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 116ms/step - accuracy: 0.5998 - f1_score: 0.6676 - loss: 0.6441 - val_accuracy: 0.6125 - val_f1_score: 0.6076 - val_loss: 0.6582 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 3s - 95ms/step - accuracy: 0.6897 - f1_score: 0.7420 - loss: 0.5569 - val_accuracy: 0.5500 - val_f1_score: 0.6087 - val_loss: 1.4732 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 3s - 78ms/step - accuracy: 0.7873 - f1_score: 0.7962 - loss: 0.4335 - val_accuracy: 0.5250 - val_f1_score: 0.4242 - val_loss: 1.5437 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 80ms/step - accuracy: 0.8728 - f1_score: 0.8744 - loss: 0.3153 - val_accuracy: 0.5500 - val_f1_score: 0.5135 - val_loss: 1.7524 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 3s - 80ms/step - accuracy: 0.9197 - f1_score: 0.9204 - loss: 0.2066 - val_accuracy: 0.6125 - val_f1_score: 0.6076 - val_loss: 1.5277 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 3s - 79ms/step - accuracy: 0.9557 - f1_score: 0.9550 - loss: 0.1110 - val_accuracy: 0.5500 - val_f1_score: 0.5263 - val_loss: 1.9313 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 3s - 77ms/step - accuracy: 0.9848 - f1_score: 0.9845 - loss: 0.0484 - val_accuracy: 0.6000 - val_f1_score: 0.5897 - val_loss: 2.2550 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 3s - 80ms/step - accuracy: 0.9944 - f1_score: 0.9945 - loss: 0.0189 - val_accuracy: 0.5500 - val_f1_score: 0.5000 - val_loss: 4.2424 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 3s - 96ms/step - accuracy: 0.9909 - f1_score: 0.9910 - loss: 0.0356 - val_accuracy: 0.5250 - val_f1_score: 0.5250 - val_loss: 3.9326 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 3s - 84ms/step - accuracy: 0.9922 - f1_score: 0.9921 - loss: 0.0632 - val_accuracy: 0.5500 - val_f1_score: 0.4706 - val_loss: 3.1277 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 83ms/step - accuracy: 0.9948 - f1_score: 0.9946 - loss: 0.0440 - val_accuracy: 0.5625 - val_f1_score: 0.5205 - val_loss: 2.0763 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 81ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0052 - val_accuracy: 0.6125 - val_f1_score: 0.5231 - val_loss: 4.9650 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 3s - 80ms/step - accuracy: 0.9974 - f1_score: 0.9975 - loss: 0.0060 - val_accuracy: 0.5750 - val_f1_score: 0.5405 - val_loss: 4.3869 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 85ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0084 - val_accuracy: 0.5500 - val_f1_score: 0.5263 - val_loss: 4.6588 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 3s - 84ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0035 - val_accuracy: 0.5625 - val_f1_score: 0.5333 - val_loss: 6.0217 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 96ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0061 - val_accuracy: 0.5000 - val_f1_score: 0.5349 - val_loss: 5.1136 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 3s - 96ms/step - accuracy: 0.9970 - f1_score: 0.9970 - loss: 0.0170 - val_accuracy: 0.6000 - val_f1_score: 0.5789 - val_loss: 4.4339 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step\nmodel3 → Fold 3 Val F1 = 0.6379\n\n>>> Training model4 on Fold 3\nEpoch 1/200\n36/36 - 9s - 243ms/step - accuracy: 0.5069 - f1_score: 0.5922 - loss: 0.6920 - val_accuracy: 0.4500 - val_f1_score: 0.6071 - val_loss: 0.6956 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 118ms/step - accuracy: 0.5282 - f1_score: 0.4772 - loss: 0.6920 - val_accuracy: 0.5250 - val_f1_score: 0.4242 - val_loss: 0.6894 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 119ms/step - accuracy: 0.5399 - f1_score: 0.5580 - loss: 0.6894 - val_accuracy: 0.4500 - val_f1_score: 0.5417 - val_loss: 0.6964 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 119ms/step - accuracy: 0.5577 - f1_score: 0.6150 - loss: 0.6868 - val_accuracy: 0.4500 - val_f1_score: 0.5319 - val_loss: 0.6965 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 119ms/step - accuracy: 0.5195 - f1_score: 0.5366 - loss: 0.6907 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.6956 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 118ms/step - accuracy: 0.5430 - f1_score: 0.6238 - loss: 0.6906 - val_accuracy: 0.4375 - val_f1_score: 0.5161 - val_loss: 0.6958 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 118ms/step - accuracy: 0.5417 - f1_score: 0.5991 - loss: 0.6900 - val_accuracy: 0.5500 - val_f1_score: 0.3333 - val_loss: 0.6870 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 119ms/step - accuracy: 0.5356 - f1_score: 0.5983 - loss: 0.6898 - val_accuracy: 0.5625 - val_f1_score: 0.4444 - val_loss: 0.6865 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 119ms/step - accuracy: 0.5330 - f1_score: 0.5162 - loss: 0.6906 - val_accuracy: 0.5625 - val_f1_score: 0.2857 - val_loss: 0.6884 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 119ms/step - accuracy: 0.5547 - f1_score: 0.4478 - loss: 0.6878 - val_accuracy: 0.5250 - val_f1_score: 0.4062 - val_loss: 0.6927 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 119ms/step - accuracy: 0.5530 - f1_score: 0.4881 - loss: 0.6869 - val_accuracy: 0.5500 - val_f1_score: 0.0526 - val_loss: 0.6903 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 119ms/step - accuracy: 0.5451 - f1_score: 0.4642 - loss: 0.6882 - val_accuracy: 0.5375 - val_f1_score: 0.0000e+00 - val_loss: 0.6892 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 118ms/step - accuracy: 0.5525 - f1_score: 0.4873 - loss: 0.6850 - val_accuracy: 0.5375 - val_f1_score: 0.0976 - val_loss: 0.6878 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 118ms/step - accuracy: 0.5586 - f1_score: 0.4582 - loss: 0.6854 - val_accuracy: 0.6000 - val_f1_score: 0.3846 - val_loss: 0.6882 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 118ms/step - accuracy: 0.5521 - f1_score: 0.4130 - loss: 0.6867 - val_accuracy: 0.5375 - val_f1_score: 0.4478 - val_loss: 0.6927 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 119ms/step - accuracy: 0.5365 - f1_score: 0.4967 - loss: 0.6886 - val_accuracy: 0.5500 - val_f1_score: 0.3077 - val_loss: 0.6885 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 119ms/step - accuracy: 0.5369 - f1_score: 0.5178 - loss: 0.6883 - val_accuracy: 0.5000 - val_f1_score: 0.3750 - val_loss: 0.6935 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 119ms/step - accuracy: 0.5521 - f1_score: 0.4824 - loss: 0.6858 - val_accuracy: 0.5125 - val_f1_score: 0.3158 - val_loss: 0.6941 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 119ms/step - accuracy: 0.5438 - f1_score: 0.4500 - loss: 0.6885 - val_accuracy: 0.5250 - val_f1_score: 0.4062 - val_loss: 0.6935 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 119ms/step - accuracy: 0.5304 - f1_score: 0.5411 - loss: 0.6882 - val_accuracy: 0.5625 - val_f1_score: 0.1860 - val_loss: 0.6867 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 119ms/step - accuracy: 0.5417 - f1_score: 0.4047 - loss: 0.6861 - val_accuracy: 0.4625 - val_f1_score: 0.3385 - val_loss: 0.7056 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step\nmodel4 → Fold 3 Val F1 = 0.6071\n\n>>> Training model5 on Fold 3\nEpoch 1/200\n36/36 - 7s - 196ms/step - accuracy: 0.5139 - f1_score: 0.5425 - loss: 1.6535 - val_accuracy: 0.4250 - val_f1_score: 0.3429 - val_loss: 1.2755 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 34ms/step - accuracy: 0.5347 - f1_score: 0.5355 - loss: 0.8089 - val_accuracy: 0.4875 - val_f1_score: 0.5287 - val_loss: 0.7303 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 34ms/step - accuracy: 0.5312 - f1_score: 0.5345 - loss: 0.7690 - val_accuracy: 0.5125 - val_f1_score: 0.5063 - val_loss: 0.7790 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 30ms/step - accuracy: 0.5538 - f1_score: 0.5871 - loss: 0.7267 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 0.7324 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 30ms/step - accuracy: 0.6020 - f1_score: 0.6237 - loss: 0.6750 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 0.7380 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 33ms/step - accuracy: 0.6628 - f1_score: 0.6873 - loss: 0.6173 - val_accuracy: 0.5750 - val_f1_score: 0.5952 - val_loss: 0.8232 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 32ms/step - accuracy: 0.7661 - f1_score: 0.7736 - loss: 0.4634 - val_accuracy: 0.5625 - val_f1_score: 0.5679 - val_loss: 1.1249 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 31ms/step - accuracy: 0.8416 - f1_score: 0.8496 - loss: 0.3636 - val_accuracy: 0.4625 - val_f1_score: 0.3944 - val_loss: 1.5379 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 32ms/step - accuracy: 0.8602 - f1_score: 0.8613 - loss: 0.3250 - val_accuracy: 0.5500 - val_f1_score: 0.5714 - val_loss: 1.3196 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 31ms/step - accuracy: 0.9167 - f1_score: 0.9151 - loss: 0.2096 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 1.7600 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 32ms/step - accuracy: 0.9180 - f1_score: 0.9166 - loss: 0.2071 - val_accuracy: 0.5250 - val_f1_score: 0.5000 - val_loss: 2.2216 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 31ms/step - accuracy: 0.9249 - f1_score: 0.9272 - loss: 0.2000 - val_accuracy: 0.4625 - val_f1_score: 0.4416 - val_loss: 2.7190 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 32ms/step - accuracy: 0.9501 - f1_score: 0.9504 - loss: 0.1464 - val_accuracy: 0.5125 - val_f1_score: 0.4800 - val_loss: 2.8297 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 31ms/step - accuracy: 0.9622 - f1_score: 0.9618 - loss: 0.1075 - val_accuracy: 0.5000 - val_f1_score: 0.4595 - val_loss: 2.2815 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 33ms/step - accuracy: 0.9887 - f1_score: 0.9883 - loss: 0.0403 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 3.3879 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 70ms/step - accuracy: 0.9839 - f1_score: 0.9840 - loss: 0.0498 - val_accuracy: 0.5750 - val_f1_score: 0.5405 - val_loss: 2.8386 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 33ms/step - accuracy: 0.9766 - f1_score: 0.9773 - loss: 0.0711 - val_accuracy: 0.5750 - val_f1_score: 0.5278 - val_loss: 3.5194 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 32ms/step - accuracy: 0.9891 - f1_score: 0.9891 - loss: 0.0380 - val_accuracy: 0.5125 - val_f1_score: 0.4507 - val_loss: 3.8241 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 31ms/step - accuracy: 0.9800 - f1_score: 0.9802 - loss: 0.0509 - val_accuracy: 0.4875 - val_f1_score: 0.4533 - val_loss: 3.9251 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 31ms/step - accuracy: 0.9735 - f1_score: 0.9738 - loss: 0.0805 - val_accuracy: 0.5875 - val_f1_score: 0.5600 - val_loss: 3.0072 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 32ms/step - accuracy: 0.9809 - f1_score: 0.9814 - loss: 0.0649 - val_accuracy: 0.5625 - val_f1_score: 0.4776 - val_loss: 3.6126 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 32ms/step - accuracy: 0.9887 - f1_score: 0.9888 - loss: 0.0332 - val_accuracy: 0.5625 - val_f1_score: 0.4928 - val_loss: 3.9446 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 34ms/step - accuracy: 0.9900 - f1_score: 0.9903 - loss: 0.0304 - val_accuracy: 0.6375 - val_f1_score: 0.6027 - val_loss: 4.0112 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 34ms/step - accuracy: 0.9926 - f1_score: 0.9927 - loss: 0.0242 - val_accuracy: 0.5625 - val_f1_score: 0.5333 - val_loss: 4.5443 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 32ms/step - accuracy: 0.9900 - f1_score: 0.9903 - loss: 0.0291 - val_accuracy: 0.5625 - val_f1_score: 0.5679 - val_loss: 4.6096 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 32ms/step - accuracy: 0.9878 - f1_score: 0.9879 - loss: 0.0354 - val_accuracy: 0.5750 - val_f1_score: 0.5143 - val_loss: 4.4596 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 32ms/step - accuracy: 0.9961 - f1_score: 0.9961 - loss: 0.0144 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 3.6135 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 31ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0035 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 3.5234 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 32ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - val_accuracy: 0.5875 - val_f1_score: 0.5479 - val_loss: 3.7909 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 33ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0024 - val_accuracy: 0.5875 - val_f1_score: 0.5479 - val_loss: 3.8082 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 32ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6531e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 3.8783 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 31ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6367e-04 - val_accuracy: 0.5875 - val_f1_score: 0.5352 - val_loss: 3.9050 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 31ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3748e-04 - val_accuracy: 0.5875 - val_f1_score: 0.5352 - val_loss: 3.9224 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 31ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 9.0512e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 3.9573 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 32ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8642e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 3.9748 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 31ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5850e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 3.9999 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 30ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2622e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0066 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 31ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7472e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0225 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 33ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3733e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0368 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 1s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8460e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0470 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 1s - 32ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3590e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0559 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 1s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8858e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0519 - learning_rate: 2.2643e-04\nEpoch 43/200\n36/36 - 1s - 32ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0165e-04 - val_accuracy: 0.6000 - val_f1_score: 0.5556 - val_loss: 4.0520 - learning_rate: 2.0267e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step\nmodel5 → Fold 3 Val F1 = 0.6027\n\n>>> Training model6 on Fold 3\nEpoch 1/200\n36/36 - 7s - 197ms/step - accuracy: 0.4861 - f1_score: 0.4970 - loss: 2.6268 - val_accuracy: 0.6000 - val_f1_score: 0.6000 - val_loss: 0.8763 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 40ms/step - accuracy: 0.5130 - f1_score: 0.5197 - loss: 1.0633 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 0.7267 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 39ms/step - accuracy: 0.5035 - f1_score: 0.5257 - loss: 0.8053 - val_accuracy: 0.4750 - val_f1_score: 0.4878 - val_loss: 0.7251 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 39ms/step - accuracy: 0.5095 - f1_score: 0.5403 - loss: 0.7530 - val_accuracy: 0.5125 - val_f1_score: 0.4348 - val_loss: 0.6974 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 40ms/step - accuracy: 0.4839 - f1_score: 0.4778 - loss: 0.7597 - val_accuracy: 0.4125 - val_f1_score: 0.5437 - val_loss: 0.7411 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 40ms/step - accuracy: 0.5156 - f1_score: 0.5701 - loss: 0.7182 - val_accuracy: 0.5625 - val_f1_score: 0.5455 - val_loss: 0.7054 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 39ms/step - accuracy: 0.4935 - f1_score: 0.5447 - loss: 0.7264 - val_accuracy: 0.4375 - val_f1_score: 0.4304 - val_loss: 0.6972 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 40ms/step - accuracy: 0.5247 - f1_score: 0.5697 - loss: 0.7142 - val_accuracy: 0.5750 - val_f1_score: 0.3200 - val_loss: 0.6980 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 40ms/step - accuracy: 0.5052 - f1_score: 0.5540 - loss: 0.7226 - val_accuracy: 0.5625 - val_f1_score: 0.5333 - val_loss: 0.6857 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 40ms/step - accuracy: 0.4918 - f1_score: 0.4807 - loss: 0.7031 - val_accuracy: 0.5000 - val_f1_score: 0.1304 - val_loss: 0.6890 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 40ms/step - accuracy: 0.5213 - f1_score: 0.5034 - loss: 0.7049 - val_accuracy: 0.4875 - val_f1_score: 0.5393 - val_loss: 0.6929 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 39ms/step - accuracy: 0.4931 - f1_score: 0.5256 - loss: 0.7024 - val_accuracy: 0.4500 - val_f1_score: 0.6207 - val_loss: 0.7093 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 39ms/step - accuracy: 0.5061 - f1_score: 0.5455 - loss: 0.7104 - val_accuracy: 0.5500 - val_f1_score: 0.6400 - val_loss: 0.6943 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 40ms/step - accuracy: 0.4970 - f1_score: 0.5244 - loss: 0.7057 - val_accuracy: 0.5875 - val_f1_score: 0.5217 - val_loss: 0.6760 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 40ms/step - accuracy: 0.5109 - f1_score: 0.5085 - loss: 0.7041 - val_accuracy: 0.4875 - val_f1_score: 0.6019 - val_loss: 0.7002 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 39ms/step - accuracy: 0.5004 - f1_score: 0.4727 - loss: 0.7056 - val_accuracy: 0.4875 - val_f1_score: 0.3492 - val_loss: 0.6930 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 39ms/step - accuracy: 0.5265 - f1_score: 0.5860 - loss: 0.6999 - val_accuracy: 0.4375 - val_f1_score: 0.5631 - val_loss: 0.6967 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 40ms/step - accuracy: 0.5091 - f1_score: 0.4013 - loss: 0.6939 - val_accuracy: 0.5250 - val_f1_score: 0.1364 - val_loss: 0.6915 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 39ms/step - accuracy: 0.5026 - f1_score: 0.5261 - loss: 0.6964 - val_accuracy: 0.5125 - val_f1_score: 0.2041 - val_loss: 0.6908 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 39ms/step - accuracy: 0.5204 - f1_score: 0.5251 - loss: 0.6982 - val_accuracy: 0.5125 - val_f1_score: 0.2353 - val_loss: 0.6917 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 39ms/step - accuracy: 0.4852 - f1_score: 0.5179 - loss: 0.6984 - val_accuracy: 0.4750 - val_f1_score: 0.5882 - val_loss: 0.6964 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 39ms/step - accuracy: 0.5074 - f1_score: 0.5312 - loss: 0.6971 - val_accuracy: 0.4875 - val_f1_score: 0.1961 - val_loss: 0.6986 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 39ms/step - accuracy: 0.5048 - f1_score: 0.5747 - loss: 0.6954 - val_accuracy: 0.5125 - val_f1_score: 0.4935 - val_loss: 0.6928 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 39ms/step - accuracy: 0.4944 - f1_score: 0.5465 - loss: 0.6936 - val_accuracy: 0.5625 - val_f1_score: 0.5070 - val_loss: 0.6944 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 39ms/step - accuracy: 0.5043 - f1_score: 0.6442 - loss: 0.6936 - val_accuracy: 0.4500 - val_f1_score: 0.5510 - val_loss: 0.6945 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 39ms/step - accuracy: 0.5030 - f1_score: 0.6039 - loss: 0.6920 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 0.6931 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 39ms/step - accuracy: 0.4944 - f1_score: 0.5835 - loss: 0.6925 - val_accuracy: 0.4625 - val_f1_score: 0.5275 - val_loss: 0.6937 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 39ms/step - accuracy: 0.5061 - f1_score: 0.5351 - loss: 0.6916 - val_accuracy: 0.4500 - val_f1_score: 0.6000 - val_loss: 0.6957 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 39ms/step - accuracy: 0.5009 - f1_score: 0.6379 - loss: 0.6905 - val_accuracy: 0.4375 - val_f1_score: 0.5946 - val_loss: 0.6948 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 39ms/step - accuracy: 0.5035 - f1_score: 0.4526 - loss: 0.6920 - val_accuracy: 0.5500 - val_f1_score: 0.2500 - val_loss: 0.6921 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 39ms/step - accuracy: 0.5195 - f1_score: 0.2132 - loss: 0.6905 - val_accuracy: 0.5625 - val_f1_score: 0.4444 - val_loss: 0.6918 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 39ms/step - accuracy: 0.5143 - f1_score: 0.5382 - loss: 0.6923 - val_accuracy: 0.5000 - val_f1_score: 0.5833 - val_loss: 0.6910 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 39ms/step - accuracy: 0.5213 - f1_score: 0.6597 - loss: 0.6895 - val_accuracy: 0.4875 - val_f1_score: 0.5393 - val_loss: 0.6945 - learning_rate: 4.9148e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step\nmodel6 → Fold 3 Val F1 = 0.6400\n\n==================================================\nFold 4/30 - Subject: S12\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 4\nEpoch 1/200\n36/36 - 8s - 209ms/step - accuracy: 0.5317 - f1_score: 0.5025 - loss: 0.8624 - val_accuracy: 0.5625 - val_f1_score: 0.7107 - val_loss: 0.6946 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 28ms/step - accuracy: 0.5113 - f1_score: 0.4987 - loss: 0.7768 - val_accuracy: 0.5250 - val_f1_score: 0.6885 - val_loss: 0.6994 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 28ms/step - accuracy: 0.5022 - f1_score: 0.4945 - loss: 0.7503 - val_accuracy: 0.4375 - val_f1_score: 0.0426 - val_loss: 0.7081 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 28ms/step - accuracy: 0.5043 - f1_score: 0.4911 - loss: 0.7289 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6971 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.5061 - f1_score: 0.5174 - loss: 0.7248 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6988 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 28ms/step - accuracy: 0.5152 - f1_score: 0.5301 - loss: 0.7122 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6976 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.4961 - f1_score: 0.5066 - loss: 0.7145 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7051 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5226 - f1_score: 0.5124 - loss: 0.7021 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6999 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5074 - f1_score: 0.5312 - loss: 0.7035 - val_accuracy: 0.4875 - val_f1_score: 0.3881 - val_loss: 0.7025 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.5204 - f1_score: 0.5034 - loss: 0.7030 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7080 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 29ms/step - accuracy: 0.5304 - f1_score: 0.5195 - loss: 0.6976 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7193 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5165 - f1_score: 0.4750 - loss: 0.7064 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7022 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5221 - f1_score: 0.4824 - loss: 0.7018 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7076 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5221 - f1_score: 0.4966 - loss: 0.6985 - val_accuracy: 0.5875 - val_f1_score: 0.6857 - val_loss: 0.7003 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 28ms/step - accuracy: 0.5247 - f1_score: 0.4738 - loss: 0.6948 - val_accuracy: 0.5125 - val_f1_score: 0.6139 - val_loss: 0.6998 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5056 - f1_score: 0.4908 - loss: 0.7023 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7081 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.5204 - f1_score: 0.5488 - loss: 0.6970 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7090 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.5191 - f1_score: 0.5682 - loss: 0.7003 - val_accuracy: 0.3750 - val_f1_score: 0.3243 - val_loss: 0.7020 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5174 - f1_score: 0.5656 - loss: 0.7005 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7125 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 28ms/step - accuracy: 0.5195 - f1_score: 0.5650 - loss: 0.6981 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.7021 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 28ms/step - accuracy: 0.5269 - f1_score: 0.5612 - loss: 0.7004 - val_accuracy: 0.5500 - val_f1_score: 0.6538 - val_loss: 0.6998 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step\noldA → Fold 4 Val F1 = 0.7107\n\n>>> Training oldB on Fold 4\nEpoch 1/200\n36/36 - 12s - 346ms/step - accuracy: 0.5056 - f1_score: 0.5002 - loss: 2.5843 - val_accuracy: 0.4875 - val_f1_score: 0.1633 - val_loss: 0.7493 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 36ms/step - accuracy: 0.5208 - f1_score: 0.5137 - loss: 1.7672 - val_accuracy: 0.4625 - val_f1_score: 0.5657 - val_loss: 0.7475 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 36ms/step - accuracy: 0.5152 - f1_score: 0.4980 - loss: 1.3225 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7416 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.5078 - f1_score: 0.4956 - loss: 1.0658 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7446 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 35ms/step - accuracy: 0.4974 - f1_score: 0.5191 - loss: 0.9480 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7446 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 35ms/step - accuracy: 0.4874 - f1_score: 0.4813 - loss: 0.8690 - val_accuracy: 0.5625 - val_f1_score: 0.7009 - val_loss: 0.7457 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 36ms/step - accuracy: 0.4905 - f1_score: 0.5116 - loss: 0.8263 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7454 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 36ms/step - accuracy: 0.5156 - f1_score: 0.5165 - loss: 0.8014 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7461 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 35ms/step - accuracy: 0.5061 - f1_score: 0.5194 - loss: 0.8109 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7459 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 35ms/step - accuracy: 0.4883 - f1_score: 0.5233 - loss: 0.7963 - val_accuracy: 0.4750 - val_f1_score: 0.4474 - val_loss: 0.7474 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 36ms/step - accuracy: 0.5091 - f1_score: 0.4708 - loss: 0.7788 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7499 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 36ms/step - accuracy: 0.5039 - f1_score: 0.4539 - loss: 0.7790 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7479 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 36ms/step - accuracy: 0.5043 - f1_score: 0.5009 - loss: 0.7676 - val_accuracy: 0.4375 - val_f1_score: 0.0816 - val_loss: 0.7480 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 36ms/step - accuracy: 0.5030 - f1_score: 0.4373 - loss: 0.7755 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7512 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 36ms/step - accuracy: 0.5104 - f1_score: 0.3105 - loss: 0.7649 - val_accuracy: 0.5375 - val_f1_score: 0.4932 - val_loss: 0.7482 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 36ms/step - accuracy: 0.4965 - f1_score: 0.4008 - loss: 0.7564 - val_accuracy: 0.4000 - val_f1_score: 0.0769 - val_loss: 0.7496 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 36ms/step - accuracy: 0.4974 - f1_score: 0.4712 - loss: 0.7575 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7477 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 36ms/step - accuracy: 0.4918 - f1_score: 0.5246 - loss: 0.7589 - val_accuracy: 0.5000 - val_f1_score: 0.6429 - val_loss: 0.7476 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 36ms/step - accuracy: 0.5139 - f1_score: 0.5570 - loss: 0.7568 - val_accuracy: 0.5000 - val_f1_score: 0.1667 - val_loss: 0.7474 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 36ms/step - accuracy: 0.5122 - f1_score: 0.5755 - loss: 0.7582 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7448 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.5078 - f1_score: 0.6004 - loss: 0.7568 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7465 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 36ms/step - accuracy: 0.5122 - f1_score: 0.5933 - loss: 0.7514 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7453 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 35ms/step - accuracy: 0.4952 - f1_score: 0.5662 - loss: 0.7551 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7458 - learning_rate: 7.9071e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step\noldB → Fold 4 Val F1 = 0.7097\n\n>>> Training model1 on Fold 4\nEpoch 1/200\n36/36 - 27s - 746ms/step - accuracy: 0.4974 - f1_score: 0.5835 - loss: 0.6937 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6951 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 41ms/step - accuracy: 0.4965 - f1_score: 0.1533 - loss: 0.6935 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6926 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 37ms/step - accuracy: 0.5043 - f1_score: 0.5457 - loss: 0.6932 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6943 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.4996 - f1_score: 0.0000e+00 - loss: 0.6935 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6939 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 33ms/step - accuracy: 0.5035 - f1_score: 0.1214 - loss: 0.6933 - val_accuracy: 0.5375 - val_f1_score: 0.6942 - val_loss: 0.6930 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 31ms/step - accuracy: 0.4865 - f1_score: 0.5409 - loss: 0.6933 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6924 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 29ms/step - accuracy: 0.4961 - f1_score: 0.6632 - loss: 0.6935 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6924 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 29ms/step - accuracy: 0.4952 - f1_score: 0.3015 - loss: 0.6932 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6936 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 30ms/step - accuracy: 0.5039 - f1_score: 0.4438 - loss: 0.6925 - val_accuracy: 0.5000 - val_f1_score: 0.4118 - val_loss: 0.6933 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 30ms/step - accuracy: 0.5056 - f1_score: 0.1582 - loss: 0.6934 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6941 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 30ms/step - accuracy: 0.5048 - f1_score: 0.2449 - loss: 0.6936 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6958 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 30ms/step - accuracy: 0.4974 - f1_score: 0.0882 - loss: 0.6931 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6957 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 30ms/step - accuracy: 0.5069 - f1_score: 0.0241 - loss: 0.6933 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6953 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5174 - f1_score: 0.0974 - loss: 0.6930 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6960 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 30ms/step - accuracy: 0.5104 - f1_score: 0.0000e+00 - loss: 0.6931 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6953 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 29ms/step - accuracy: 0.4996 - f1_score: 0.0694 - loss: 0.6933 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6929 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 29ms/step - accuracy: 0.4961 - f1_score: 0.5962 - loss: 0.6939 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6938 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 30ms/step - accuracy: 0.4922 - f1_score: 0.5988 - loss: 0.6933 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6915 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 34ms/step - accuracy: 0.4991 - f1_score: 0.6659 - loss: 0.6933 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6930 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 30ms/step - accuracy: 0.5252 - f1_score: 0.6887 - loss: 0.6923 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6902 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 30ms/step - accuracy: 0.5078 - f1_score: 0.6736 - loss: 0.6936 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6919 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 30ms/step - accuracy: 0.4939 - f1_score: 0.6608 - loss: 0.6934 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.6925 - learning_rate: 8.1479e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\nmodel1 → Fold 4 Val F1 = 0.7097\n\n>>> Training model2 on Fold 4\nEpoch 1/200\n36/36 - 4s - 122ms/step - accuracy: 0.4974 - f1_score: 0.5227 - loss: 3.4526 - val_accuracy: 0.6125 - val_f1_score: 0.6265 - val_loss: 0.6718 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 22ms/step - accuracy: 0.4957 - f1_score: 0.5269 - loss: 1.4858 - val_accuracy: 0.5625 - val_f1_score: 0.7059 - val_loss: 0.7235 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 21ms/step - accuracy: 0.5143 - f1_score: 0.5162 - loss: 1.0466 - val_accuracy: 0.5375 - val_f1_score: 0.6838 - val_loss: 0.6846 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 21ms/step - accuracy: 0.5204 - f1_score: 0.5147 - loss: 0.9056 - val_accuracy: 0.5750 - val_f1_score: 0.7213 - val_loss: 0.7115 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 20ms/step - accuracy: 0.5234 - f1_score: 0.5275 - loss: 0.8345 - val_accuracy: 0.5750 - val_f1_score: 0.7167 - val_loss: 0.7029 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 21ms/step - accuracy: 0.5365 - f1_score: 0.5655 - loss: 0.8416 - val_accuracy: 0.6375 - val_f1_score: 0.6667 - val_loss: 0.6615 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 22ms/step - accuracy: 0.5213 - f1_score: 0.5489 - loss: 0.8668 - val_accuracy: 0.5750 - val_f1_score: 0.6852 - val_loss: 0.6832 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 21ms/step - accuracy: 0.5339 - f1_score: 0.4977 - loss: 0.7521 - val_accuracy: 0.6000 - val_f1_score: 0.5000 - val_loss: 0.6871 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 21ms/step - accuracy: 0.5347 - f1_score: 0.5244 - loss: 0.7417 - val_accuracy: 0.5375 - val_f1_score: 0.4308 - val_loss: 0.6888 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 22ms/step - accuracy: 0.5404 - f1_score: 0.5537 - loss: 0.7274 - val_accuracy: 0.4750 - val_f1_score: 0.2500 - val_loss: 0.7135 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 21ms/step - accuracy: 0.5430 - f1_score: 0.4969 - loss: 0.7117 - val_accuracy: 0.4500 - val_f1_score: 0.2143 - val_loss: 0.6881 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 21ms/step - accuracy: 0.5634 - f1_score: 0.5112 - loss: 0.6996 - val_accuracy: 0.5375 - val_f1_score: 0.4478 - val_loss: 0.6887 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 21ms/step - accuracy: 0.5638 - f1_score: 0.5409 - loss: 0.7070 - val_accuracy: 0.5000 - val_f1_score: 0.3548 - val_loss: 0.7006 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 24ms/step - accuracy: 0.5425 - f1_score: 0.5231 - loss: 0.7091 - val_accuracy: 0.4625 - val_f1_score: 0.2456 - val_loss: 0.6957 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 21ms/step - accuracy: 0.5391 - f1_score: 0.5155 - loss: 0.7425 - val_accuracy: 0.6000 - val_f1_score: 0.5897 - val_loss: 0.6869 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5642 - f1_score: 0.5596 - loss: 0.7002 - val_accuracy: 0.5750 - val_f1_score: 0.6458 - val_loss: 0.6790 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 21ms/step - accuracy: 0.5530 - f1_score: 0.5621 - loss: 0.7032 - val_accuracy: 0.5625 - val_f1_score: 0.4928 - val_loss: 0.6903 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 21ms/step - accuracy: 0.5525 - f1_score: 0.5776 - loss: 0.6875 - val_accuracy: 0.5625 - val_f1_score: 0.7059 - val_loss: 0.6845 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 22ms/step - accuracy: 0.5590 - f1_score: 0.5516 - loss: 0.6996 - val_accuracy: 0.3500 - val_f1_score: 0.3158 - val_loss: 0.7220 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 21ms/step - accuracy: 0.5525 - f1_score: 0.5807 - loss: 0.7613 - val_accuracy: 0.5000 - val_f1_score: 0.3548 - val_loss: 0.7020 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 21ms/step - accuracy: 0.5438 - f1_score: 0.5314 - loss: 0.7392 - val_accuracy: 0.5750 - val_f1_score: 0.7213 - val_loss: 0.6721 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 21ms/step - accuracy: 0.5469 - f1_score: 0.5557 - loss: 0.7041 - val_accuracy: 0.5125 - val_f1_score: 0.4348 - val_loss: 0.6929 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 21ms/step - accuracy: 0.5438 - f1_score: 0.5177 - loss: 0.6912 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 0.6888 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 21ms/step - accuracy: 0.5621 - f1_score: 0.5815 - loss: 0.7475 - val_accuracy: 0.4375 - val_f1_score: 0.2373 - val_loss: 0.7029 - learning_rate: 7.6518e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step\nmodel2 → Fold 4 Val F1 = 0.7213\n\n>>> Training model3 on Fold 4\nEpoch 1/200\n36/36 - 9s - 240ms/step - accuracy: 0.5243 - f1_score: 0.4991 - loss: 0.7829 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6967 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 3s - 82ms/step - accuracy: 0.5299 - f1_score: 0.4415 - loss: 0.6898 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6952 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 3s - 89ms/step - accuracy: 0.5430 - f1_score: 0.4153 - loss: 0.6822 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6970 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 3s - 89ms/step - accuracy: 0.5994 - f1_score: 0.4759 - loss: 0.6600 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6961 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 98ms/step - accuracy: 0.6788 - f1_score: 0.6397 - loss: 0.5768 - val_accuracy: 0.5250 - val_f1_score: 0.6885 - val_loss: 0.6915 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 3s - 88ms/step - accuracy: 0.7431 - f1_score: 0.7525 - loss: 0.4983 - val_accuracy: 0.5125 - val_f1_score: 0.4000 - val_loss: 0.6939 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 107ms/step - accuracy: 0.8242 - f1_score: 0.8186 - loss: 0.3872 - val_accuracy: 0.4500 - val_f1_score: 0.1200 - val_loss: 0.7598 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 88ms/step - accuracy: 0.8941 - f1_score: 0.8910 - loss: 0.2538 - val_accuracy: 0.6250 - val_f1_score: 0.6739 - val_loss: 0.6881 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 3s - 91ms/step - accuracy: 0.9345 - f1_score: 0.9332 - loss: 0.1942 - val_accuracy: 0.5375 - val_f1_score: 0.5934 - val_loss: 0.7967 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 97ms/step - accuracy: 0.9588 - f1_score: 0.9595 - loss: 0.1079 - val_accuracy: 0.5125 - val_f1_score: 0.5063 - val_loss: 0.7642 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 104ms/step - accuracy: 0.9757 - f1_score: 0.9750 - loss: 0.0750 - val_accuracy: 0.4500 - val_f1_score: 0.3889 - val_loss: 1.6059 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 107ms/step - accuracy: 0.9848 - f1_score: 0.9845 - loss: 0.0597 - val_accuracy: 0.5125 - val_f1_score: 0.5301 - val_loss: 1.2256 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 3s - 96ms/step - accuracy: 0.9926 - f1_score: 0.9925 - loss: 0.0424 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 1.4244 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 100ms/step - accuracy: 0.9961 - f1_score: 0.9960 - loss: 0.0194 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 2.1369 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 95ms/step - accuracy: 0.9944 - f1_score: 0.9942 - loss: 0.0241 - val_accuracy: 0.5125 - val_f1_score: 0.4348 - val_loss: 1.5913 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 91ms/step - accuracy: 0.9961 - f1_score: 0.9961 - loss: 0.0181 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 2.2634 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 3s - 94ms/step - accuracy: 0.9931 - f1_score: 0.9930 - loss: 0.0267 - val_accuracy: 0.4625 - val_f1_score: 0.4267 - val_loss: 1.8027 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 87ms/step - accuracy: 0.9948 - f1_score: 0.9949 - loss: 0.0181 - val_accuracy: 0.4625 - val_f1_score: 0.4557 - val_loss: 1.8525 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 3s - 86ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0056 - val_accuracy: 0.4750 - val_f1_score: 0.4474 - val_loss: 3.4841 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 85ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0013 - val_accuracy: 0.4625 - val_f1_score: 0.4110 - val_loss: 3.9024 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 3s - 94ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0100 - val_accuracy: 0.4250 - val_f1_score: 0.4103 - val_loss: 3.0276 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 3s - 94ms/step - accuracy: 0.9970 - f1_score: 0.9969 - loss: 0.0129 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 2.0052 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 3s - 88ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0062 - val_accuracy: 0.4625 - val_f1_score: 0.4691 - val_loss: 2.6912 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 3s - 97ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5214e-04 - val_accuracy: 0.4500 - val_f1_score: 0.4211 - val_loss: 3.0885 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 3s - 96ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8287e-04 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 3.5111 - learning_rate: 7.3832e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step\nmodel3 → Fold 4 Val F1 = 0.6885\n\n>>> Training model4 on Fold 4\nEpoch 1/200\n36/36 - 9s - 243ms/step - accuracy: 0.5117 - f1_score: 0.5698 - loss: 0.6915 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6958 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 119ms/step - accuracy: 0.5152 - f1_score: 0.3742 - loss: 0.6931 - val_accuracy: 0.5000 - val_f1_score: 0.4595 - val_loss: 0.6899 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 119ms/step - accuracy: 0.5143 - f1_score: 0.3528 - loss: 0.6928 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6976 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 119ms/step - accuracy: 0.5200 - f1_score: 0.3409 - loss: 0.6914 - val_accuracy: 0.5000 - val_f1_score: 0.4737 - val_loss: 0.6878 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 119ms/step - accuracy: 0.5009 - f1_score: 0.2821 - loss: 0.6934 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6937 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 118ms/step - accuracy: 0.5217 - f1_score: 0.5435 - loss: 0.6912 - val_accuracy: 0.5375 - val_f1_score: 0.4789 - val_loss: 0.6851 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 118ms/step - accuracy: 0.5373 - f1_score: 0.4516 - loss: 0.6898 - val_accuracy: 0.5750 - val_f1_score: 0.4687 - val_loss: 0.6899 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 119ms/step - accuracy: 0.5204 - f1_score: 0.3331 - loss: 0.6920 - val_accuracy: 0.4875 - val_f1_score: 0.2264 - val_loss: 0.6941 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 118ms/step - accuracy: 0.5486 - f1_score: 0.4409 - loss: 0.6868 - val_accuracy: 0.5250 - val_f1_score: 0.5250 - val_loss: 0.6916 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 119ms/step - accuracy: 0.5278 - f1_score: 0.3818 - loss: 0.6909 - val_accuracy: 0.5500 - val_f1_score: 0.4857 - val_loss: 0.6916 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 119ms/step - accuracy: 0.5360 - f1_score: 0.4174 - loss: 0.6913 - val_accuracy: 0.5625 - val_f1_score: 0.4615 - val_loss: 0.6934 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 118ms/step - accuracy: 0.5586 - f1_score: 0.4845 - loss: 0.6887 - val_accuracy: 0.5250 - val_f1_score: 0.3214 - val_loss: 0.6955 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 118ms/step - accuracy: 0.5556 - f1_score: 0.4459 - loss: 0.6880 - val_accuracy: 0.5625 - val_f1_score: 0.4928 - val_loss: 0.6896 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 118ms/step - accuracy: 0.5534 - f1_score: 0.4368 - loss: 0.6872 - val_accuracy: 0.5125 - val_f1_score: 0.4800 - val_loss: 0.6917 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 118ms/step - accuracy: 0.5443 - f1_score: 0.4088 - loss: 0.6895 - val_accuracy: 0.5375 - val_f1_score: 0.4789 - val_loss: 0.6886 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 119ms/step - accuracy: 0.5530 - f1_score: 0.4941 - loss: 0.6878 - val_accuracy: 0.5250 - val_f1_score: 0.5366 - val_loss: 0.6840 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 120ms/step - accuracy: 0.5499 - f1_score: 0.4828 - loss: 0.6887 - val_accuracy: 0.5375 - val_f1_score: 0.4789 - val_loss: 0.6873 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 119ms/step - accuracy: 0.5543 - f1_score: 0.5239 - loss: 0.6865 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 0.6836 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 118ms/step - accuracy: 0.5486 - f1_score: 0.4634 - loss: 0.6858 - val_accuracy: 0.5625 - val_f1_score: 0.4928 - val_loss: 0.6909 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 119ms/step - accuracy: 0.5317 - f1_score: 0.5084 - loss: 0.6863 - val_accuracy: 0.5375 - val_f1_score: 0.5432 - val_loss: 0.6816 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 119ms/step - accuracy: 0.5482 - f1_score: 0.4609 - loss: 0.6860 - val_accuracy: 0.5375 - val_f1_score: 0.5542 - val_loss: 0.6843 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 4s - 118ms/step - accuracy: 0.5586 - f1_score: 0.4892 - loss: 0.6814 - val_accuracy: 0.5500 - val_f1_score: 0.5500 - val_loss: 0.6855 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 4s - 119ms/step - accuracy: 0.5525 - f1_score: 0.4780 - loss: 0.6861 - val_accuracy: 0.5500 - val_f1_score: 0.5500 - val_loss: 0.6887 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 4s - 119ms/step - accuracy: 0.5477 - f1_score: 0.5573 - loss: 0.6831 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 0.6805 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 4s - 119ms/step - accuracy: 0.5660 - f1_score: 0.5000 - loss: 0.6828 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 0.6867 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 4s - 119ms/step - accuracy: 0.5560 - f1_score: 0.5331 - loss: 0.6828 - val_accuracy: 0.5500 - val_f1_score: 0.5263 - val_loss: 0.6925 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 4s - 118ms/step - accuracy: 0.5638 - f1_score: 0.5138 - loss: 0.6812 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 0.6825 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 4s - 119ms/step - accuracy: 0.5634 - f1_score: 0.5857 - loss: 0.6787 - val_accuracy: 0.6125 - val_f1_score: 0.7257 - val_loss: 0.6815 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 4s - 119ms/step - accuracy: 0.5543 - f1_score: 0.5334 - loss: 0.6885 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.6952 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 4s - 119ms/step - accuracy: 0.5651 - f1_score: 0.5482 - loss: 0.6784 - val_accuracy: 0.4875 - val_f1_score: 0.5495 - val_loss: 0.6890 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 4s - 119ms/step - accuracy: 0.5690 - f1_score: 0.5488 - loss: 0.6788 - val_accuracy: 0.5375 - val_f1_score: 0.5316 - val_loss: 0.6918 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 4s - 118ms/step - accuracy: 0.5751 - f1_score: 0.5651 - loss: 0.6791 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 0.6885 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 4s - 119ms/step - accuracy: 0.5560 - f1_score: 0.5415 - loss: 0.6819 - val_accuracy: 0.4875 - val_f1_score: 0.5773 - val_loss: 0.6866 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 4s - 118ms/step - accuracy: 0.5825 - f1_score: 0.6170 - loss: 0.6759 - val_accuracy: 0.5500 - val_f1_score: 0.5000 - val_loss: 0.6887 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 4s - 119ms/step - accuracy: 0.5677 - f1_score: 0.4877 - loss: 0.6749 - val_accuracy: 0.5750 - val_f1_score: 0.5405 - val_loss: 0.6859 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 4s - 119ms/step - accuracy: 0.5829 - f1_score: 0.5578 - loss: 0.6683 - val_accuracy: 0.5500 - val_f1_score: 0.5385 - val_loss: 0.6954 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 4s - 119ms/step - accuracy: 0.6011 - f1_score: 0.6057 - loss: 0.6635 - val_accuracy: 0.5125 - val_f1_score: 0.5806 - val_loss: 0.6908 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 4s - 118ms/step - accuracy: 0.5716 - f1_score: 0.5875 - loss: 0.6752 - val_accuracy: 0.5375 - val_f1_score: 0.5647 - val_loss: 0.6923 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 4s - 119ms/step - accuracy: 0.5825 - f1_score: 0.6167 - loss: 0.6680 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 0.6913 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 4s - 119ms/step - accuracy: 0.5881 - f1_score: 0.6001 - loss: 0.6669 - val_accuracy: 0.5125 - val_f1_score: 0.5714 - val_loss: 0.6886 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 4s - 118ms/step - accuracy: 0.5868 - f1_score: 0.6410 - loss: 0.6666 - val_accuracy: 0.4875 - val_f1_score: 0.5773 - val_loss: 0.6952 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 4s - 119ms/step - accuracy: 0.5911 - f1_score: 0.6265 - loss: 0.6608 - val_accuracy: 0.5500 - val_f1_score: 0.5714 - val_loss: 0.6935 - learning_rate: 2.2643e-04\nEpoch 43/200\n36/36 - 4s - 119ms/step - accuracy: 0.5911 - f1_score: 0.6297 - loss: 0.6631 - val_accuracy: 0.5250 - val_f1_score: 0.5870 - val_loss: 0.6920 - learning_rate: 2.0267e-04\nEpoch 44/200\n36/36 - 4s - 119ms/step - accuracy: 0.6011 - f1_score: 0.6191 - loss: 0.6611 - val_accuracy: 0.5375 - val_f1_score: 0.5747 - val_loss: 0.6870 - learning_rate: 1.8042e-04\nEpoch 45/200\n36/36 - 4s - 119ms/step - accuracy: 0.5959 - f1_score: 0.6260 - loss: 0.6593 - val_accuracy: 0.5125 - val_f1_score: 0.6214 - val_loss: 0.6776 - learning_rate: 1.5972e-04\nEpoch 46/200\n36/36 - 4s - 119ms/step - accuracy: 0.6003 - f1_score: 0.6381 - loss: 0.6553 - val_accuracy: 0.5375 - val_f1_score: 0.6337 - val_loss: 0.6815 - learning_rate: 1.4058e-04\nEpoch 47/200\n36/36 - 4s - 118ms/step - accuracy: 0.6016 - f1_score: 0.6467 - loss: 0.6557 - val_accuracy: 0.5500 - val_f1_score: 0.6471 - val_loss: 0.6929 - learning_rate: 1.2302e-04\nEpoch 48/200\n36/36 - 4s - 118ms/step - accuracy: 0.5964 - f1_score: 0.6395 - loss: 0.6606 - val_accuracy: 0.5375 - val_f1_score: 0.6186 - val_loss: 0.6855 - learning_rate: 1.0700e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step\nmodel4 → Fold 4 Val F1 = 0.7257\n\n>>> Training model5 on Fold 4\nEpoch 1/200\n36/36 - 7s - 202ms/step - accuracy: 0.5065 - f1_score: 0.4976 - loss: 1.2430 - val_accuracy: 0.5000 - val_f1_score: 0.6078 - val_loss: 0.7192 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 34ms/step - accuracy: 0.5122 - f1_score: 0.5355 - loss: 0.8740 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.7067 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 33ms/step - accuracy: 0.5391 - f1_score: 0.5088 - loss: 0.7392 - val_accuracy: 0.4375 - val_f1_score: 0.4828 - val_loss: 0.7035 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 33ms/step - accuracy: 0.5352 - f1_score: 0.5425 - loss: 0.7566 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.7254 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 33ms/step - accuracy: 0.6029 - f1_score: 0.5770 - loss: 0.6690 - val_accuracy: 0.5000 - val_f1_score: 0.6226 - val_loss: 0.6912 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 38ms/step - accuracy: 0.6801 - f1_score: 0.6923 - loss: 0.5783 - val_accuracy: 0.5375 - val_f1_score: 0.6476 - val_loss: 0.7169 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 32ms/step - accuracy: 0.7218 - f1_score: 0.7180 - loss: 0.5406 - val_accuracy: 0.4875 - val_f1_score: 0.3051 - val_loss: 0.8435 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 33ms/step - accuracy: 0.7938 - f1_score: 0.7914 - loss: 0.4261 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 0.8130 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 2s - 42ms/step - accuracy: 0.8650 - f1_score: 0.8647 - loss: 0.3174 - val_accuracy: 0.5250 - val_f1_score: 0.4865 - val_loss: 0.9167 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 34ms/step - accuracy: 0.8932 - f1_score: 0.8948 - loss: 0.2543 - val_accuracy: 0.4750 - val_f1_score: 0.5435 - val_loss: 1.1233 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 32ms/step - accuracy: 0.9119 - f1_score: 0.9088 - loss: 0.2091 - val_accuracy: 0.5125 - val_f1_score: 0.5806 - val_loss: 1.2998 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 32ms/step - accuracy: 0.9457 - f1_score: 0.9444 - loss: 0.1478 - val_accuracy: 0.5625 - val_f1_score: 0.5679 - val_loss: 1.3380 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 33ms/step - accuracy: 0.9644 - f1_score: 0.9638 - loss: 0.0953 - val_accuracy: 0.5250 - val_f1_score: 0.5957 - val_loss: 1.5406 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 33ms/step - accuracy: 0.9753 - f1_score: 0.9747 - loss: 0.0734 - val_accuracy: 0.5000 - val_f1_score: 0.6000 - val_loss: 1.7543 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 33ms/step - accuracy: 0.9653 - f1_score: 0.9646 - loss: 0.1102 - val_accuracy: 0.5000 - val_f1_score: 0.5238 - val_loss: 2.0586 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 2s - 42ms/step - accuracy: 0.9818 - f1_score: 0.9819 - loss: 0.0497 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 2.1699 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 32ms/step - accuracy: 0.9826 - f1_score: 0.9826 - loss: 0.0437 - val_accuracy: 0.6000 - val_f1_score: 0.6190 - val_loss: 2.2987 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 2s - 44ms/step - accuracy: 0.9822 - f1_score: 0.9828 - loss: 0.0615 - val_accuracy: 0.4875 - val_f1_score: 0.5495 - val_loss: 2.3872 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 34ms/step - accuracy: 0.9848 - f1_score: 0.9848 - loss: 0.0423 - val_accuracy: 0.5250 - val_f1_score: 0.5250 - val_loss: 2.3405 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 2s - 42ms/step - accuracy: 0.9874 - f1_score: 0.9880 - loss: 0.0450 - val_accuracy: 0.5375 - val_f1_score: 0.5432 - val_loss: 2.3098 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 33ms/step - accuracy: 0.9844 - f1_score: 0.9846 - loss: 0.0546 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 2.4109 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 33ms/step - accuracy: 0.9874 - f1_score: 0.9873 - loss: 0.0341 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 2.3702 - learning_rate: 8.1479e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step\nmodel5 → Fold 4 Val F1 = 0.6992\n\n>>> Training model6 on Fold 4\nEpoch 1/200\n36/36 - 7s - 196ms/step - accuracy: 0.4835 - f1_score: 0.4725 - loss: 3.2517 - val_accuracy: 0.5500 - val_f1_score: 0.6000 - val_loss: 0.6800 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 39ms/step - accuracy: 0.5139 - f1_score: 0.5294 - loss: 0.9360 - val_accuracy: 0.4125 - val_f1_score: 0.4598 - val_loss: 0.7374 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 39ms/step - accuracy: 0.4991 - f1_score: 0.4862 - loss: 0.8994 - val_accuracy: 0.3875 - val_f1_score: 0.0000e+00 - val_loss: 0.7282 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 39ms/step - accuracy: 0.5035 - f1_score: 0.4320 - loss: 0.7982 - val_accuracy: 0.3875 - val_f1_score: 0.4948 - val_loss: 0.7014 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 39ms/step - accuracy: 0.5061 - f1_score: 0.5099 - loss: 0.7509 - val_accuracy: 0.4250 - val_f1_score: 0.3030 - val_loss: 0.7006 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 39ms/step - accuracy: 0.5065 - f1_score: 0.5080 - loss: 0.7486 - val_accuracy: 0.5250 - val_f1_score: 0.6724 - val_loss: 0.6919 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 39ms/step - accuracy: 0.5043 - f1_score: 0.5009 - loss: 0.7722 - val_accuracy: 0.3625 - val_f1_score: 0.3855 - val_loss: 0.7049 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 39ms/step - accuracy: 0.4848 - f1_score: 0.4855 - loss: 0.7541 - val_accuracy: 0.6000 - val_f1_score: 0.6735 - val_loss: 0.6892 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 39ms/step - accuracy: 0.5256 - f1_score: 0.4979 - loss: 0.7013 - val_accuracy: 0.4375 - val_f1_score: 0.2623 - val_loss: 0.6952 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 39ms/step - accuracy: 0.4944 - f1_score: 0.3760 - loss: 0.6978 - val_accuracy: 0.4250 - val_f1_score: 0.4773 - val_loss: 0.6987 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 39ms/step - accuracy: 0.5091 - f1_score: 0.3810 - loss: 0.6997 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6966 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 40ms/step - accuracy: 0.5074 - f1_score: 0.3327 - loss: 0.6935 - val_accuracy: 0.4625 - val_f1_score: 0.2456 - val_loss: 0.6959 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.3928 - loss: 0.6914 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6981 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 39ms/step - accuracy: 0.5013 - f1_score: 0.2723 - loss: 0.6927 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6990 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 39ms/step - accuracy: 0.5135 - f1_score: 0.0894 - loss: 0.6917 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6973 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.2490 - loss: 0.6923 - val_accuracy: 0.4500 - val_f1_score: 0.1538 - val_loss: 0.6968 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 39ms/step - accuracy: 0.5109 - f1_score: 0.2925 - loss: 0.6917 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6955 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 39ms/step - accuracy: 0.5069 - f1_score: 0.5654 - loss: 0.6939 - val_accuracy: 0.5000 - val_f1_score: 0.6491 - val_loss: 0.6938 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 39ms/step - accuracy: 0.5178 - f1_score: 0.5994 - loss: 0.6924 - val_accuracy: 0.4750 - val_f1_score: 0.1923 - val_loss: 0.6961 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 39ms/step - accuracy: 0.5243 - f1_score: 0.5598 - loss: 0.6908 - val_accuracy: 0.4750 - val_f1_score: 0.5227 - val_loss: 0.6951 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 39ms/step - accuracy: 0.5182 - f1_score: 0.5458 - loss: 0.6927 - val_accuracy: 0.5125 - val_f1_score: 0.2909 - val_loss: 0.6946 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 39ms/step - accuracy: 0.5087 - f1_score: 0.4946 - loss: 0.6918 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6952 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 39ms/step - accuracy: 0.5178 - f1_score: 0.2024 - loss: 0.6915 - val_accuracy: 0.4500 - val_f1_score: 0.0435 - val_loss: 0.6942 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 39ms/step - accuracy: 0.5069 - f1_score: 0.4667 - loss: 0.6912 - val_accuracy: 0.4375 - val_f1_score: 0.4444 - val_loss: 0.6948 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 39ms/step - accuracy: 0.5443 - f1_score: 0.5093 - loss: 0.6895 - val_accuracy: 0.4125 - val_f1_score: 0.2985 - val_loss: 0.6946 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 39ms/step - accuracy: 0.5291 - f1_score: 0.5268 - loss: 0.6900 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 0.6979 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 39ms/step - accuracy: 0.5074 - f1_score: 0.3940 - loss: 0.6894 - val_accuracy: 0.4125 - val_f1_score: 0.0408 - val_loss: 0.6980 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 39ms/step - accuracy: 0.5330 - f1_score: 0.5490 - loss: 0.6844 - val_accuracy: 0.4375 - val_f1_score: 0.1176 - val_loss: 0.6968 - learning_rate: 6.5084e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step\nmodel6 → Fold 4 Val F1 = 0.6735\n\n==================================================\nFold 5/30 - Subject: S13\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 5\nEpoch 1/200\n36/36 - 8s - 214ms/step - accuracy: 0.5260 - f1_score: 0.5333 - loss: 0.8184 - val_accuracy: 0.4875 - val_f1_score: 0.2807 - val_loss: 0.7035 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 28ms/step - accuracy: 0.5122 - f1_score: 0.5442 - loss: 0.7656 - val_accuracy: 0.3500 - val_f1_score: 0.4694 - val_loss: 0.7105 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 28ms/step - accuracy: 0.5178 - f1_score: 0.5452 - loss: 0.7308 - val_accuracy: 0.3375 - val_f1_score: 0.0702 - val_loss: 0.7102 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 29ms/step - accuracy: 0.5030 - f1_score: 0.5325 - loss: 0.7266 - val_accuracy: 0.5750 - val_f1_score: 0.7167 - val_loss: 0.7039 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.5347 - f1_score: 0.5351 - loss: 0.7038 - val_accuracy: 0.4375 - val_f1_score: 0.2623 - val_loss: 0.7121 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 29ms/step - accuracy: 0.5195 - f1_score: 0.4892 - loss: 0.7100 - val_accuracy: 0.3375 - val_f1_score: 0.1017 - val_loss: 0.7111 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.5347 - f1_score: 0.5688 - loss: 0.7063 - val_accuracy: 0.4000 - val_f1_score: 0.0000e+00 - val_loss: 0.7251 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5091 - f1_score: 0.5230 - loss: 0.7073 - val_accuracy: 0.3000 - val_f1_score: 0.3333 - val_loss: 0.7113 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5204 - f1_score: 0.5280 - loss: 0.7062 - val_accuracy: 0.2750 - val_f1_score: 0.2162 - val_loss: 0.7169 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.5052 - f1_score: 0.5039 - loss: 0.7052 - val_accuracy: 0.4000 - val_f1_score: 0.0769 - val_loss: 0.7223 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 28ms/step - accuracy: 0.5174 - f1_score: 0.5161 - loss: 0.7009 - val_accuracy: 0.3500 - val_f1_score: 0.4348 - val_loss: 0.7097 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5252 - f1_score: 0.5520 - loss: 0.6987 - val_accuracy: 0.4500 - val_f1_score: 0.1200 - val_loss: 0.7114 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5430 - f1_score: 0.4732 - loss: 0.6969 - val_accuracy: 0.4250 - val_f1_score: 0.0000e+00 - val_loss: 0.7209 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5373 - f1_score: 0.4865 - loss: 0.7007 - val_accuracy: 0.4250 - val_f1_score: 0.0000e+00 - val_loss: 0.7167 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 28ms/step - accuracy: 0.5104 - f1_score: 0.4644 - loss: 0.7008 - val_accuracy: 0.3750 - val_f1_score: 0.3590 - val_loss: 0.7058 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5260 - f1_score: 0.4844 - loss: 0.6955 - val_accuracy: 0.4250 - val_f1_score: 0.0417 - val_loss: 0.7127 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.5195 - f1_score: 0.5287 - loss: 0.6987 - val_accuracy: 0.4625 - val_f1_score: 0.5743 - val_loss: 0.7016 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.5460 - f1_score: 0.5623 - loss: 0.6953 - val_accuracy: 0.4375 - val_f1_score: 0.2373 - val_loss: 0.7114 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5369 - f1_score: 0.5450 - loss: 0.6973 - val_accuracy: 0.4500 - val_f1_score: 0.5849 - val_loss: 0.7027 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 28ms/step - accuracy: 0.5226 - f1_score: 0.5246 - loss: 0.6985 - val_accuracy: 0.4875 - val_f1_score: 0.6435 - val_loss: 0.7059 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 28ms/step - accuracy: 0.5399 - f1_score: 0.5147 - loss: 0.6991 - val_accuracy: 0.4250 - val_f1_score: 0.0000e+00 - val_loss: 0.7256 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 28ms/step - accuracy: 0.5508 - f1_score: 0.4509 - loss: 0.6967 - val_accuracy: 0.4500 - val_f1_score: 0.0435 - val_loss: 0.7178 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 28ms/step - accuracy: 0.5291 - f1_score: 0.4061 - loss: 0.6970 - val_accuracy: 0.4250 - val_f1_score: 0.0000e+00 - val_loss: 0.7203 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 29ms/step - accuracy: 0.5412 - f1_score: 0.5438 - loss: 0.6982 - val_accuracy: 0.4500 - val_f1_score: 0.2667 - val_loss: 0.7195 - learning_rate: 7.6518e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step\noldA → Fold 5 Val F1 = 0.7167\n\n>>> Training oldB on Fold 5\nEpoch 1/200\n36/36 - 13s - 366ms/step - accuracy: 0.5022 - f1_score: 0.5032 - loss: 2.7905 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.7465 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 36ms/step - accuracy: 0.5013 - f1_score: 0.4998 - loss: 2.0241 - val_accuracy: 0.5250 - val_f1_score: 0.6833 - val_loss: 0.7424 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 36ms/step - accuracy: 0.4965 - f1_score: 0.5130 - loss: 1.5689 - val_accuracy: 0.5500 - val_f1_score: 0.7000 - val_loss: 0.7413 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.5178 - f1_score: 0.5282 - loss: 1.2064 - val_accuracy: 0.4625 - val_f1_score: 0.3768 - val_loss: 0.7533 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 36ms/step - accuracy: 0.4900 - f1_score: 0.4907 - loss: 0.9874 - val_accuracy: 0.4500 - val_f1_score: 0.2903 - val_loss: 0.7507 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 36ms/step - accuracy: 0.4913 - f1_score: 0.5076 - loss: 0.9043 - val_accuracy: 0.4875 - val_f1_score: 0.5859 - val_loss: 0.7471 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 36ms/step - accuracy: 0.4891 - f1_score: 0.5221 - loss: 0.9037 - val_accuracy: 0.5250 - val_f1_score: 0.6667 - val_loss: 0.7461 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 36ms/step - accuracy: 0.4883 - f1_score: 0.4942 - loss: 0.8571 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.7470 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 36ms/step - accuracy: 0.5087 - f1_score: 0.5272 - loss: 0.8432 - val_accuracy: 0.5125 - val_f1_score: 0.6609 - val_loss: 0.7490 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 35ms/step - accuracy: 0.4996 - f1_score: 0.5501 - loss: 0.8049 - val_accuracy: 0.5000 - val_f1_score: 0.4286 - val_loss: 0.7473 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 37ms/step - accuracy: 0.4918 - f1_score: 0.4596 - loss: 0.8057 - val_accuracy: 0.5375 - val_f1_score: 0.6838 - val_loss: 0.7466 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 36ms/step - accuracy: 0.5039 - f1_score: 0.5058 - loss: 0.7953 - val_accuracy: 0.5000 - val_f1_score: 0.4118 - val_loss: 0.7478 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 37ms/step - accuracy: 0.5004 - f1_score: 0.4674 - loss: 0.8086 - val_accuracy: 0.5500 - val_f1_score: 0.7049 - val_loss: 0.7475 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 36ms/step - accuracy: 0.4909 - f1_score: 0.5210 - loss: 0.7910 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7489 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 36ms/step - accuracy: 0.4952 - f1_score: 0.5200 - loss: 0.7739 - val_accuracy: 0.5750 - val_f1_score: 0.7258 - val_loss: 0.7472 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 36ms/step - accuracy: 0.5104 - f1_score: 0.5474 - loss: 0.7787 - val_accuracy: 0.5750 - val_f1_score: 0.7213 - val_loss: 0.7480 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 36ms/step - accuracy: 0.4900 - f1_score: 0.5358 - loss: 0.7681 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.7461 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 36ms/step - accuracy: 0.4809 - f1_score: 0.5368 - loss: 0.7694 - val_accuracy: 0.5750 - val_f1_score: 0.7213 - val_loss: 0.7468 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 36ms/step - accuracy: 0.5126 - f1_score: 0.5191 - loss: 0.7497 - val_accuracy: 0.5500 - val_f1_score: 0.6471 - val_loss: 0.7479 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 36ms/step - accuracy: 0.4978 - f1_score: 0.4923 - loss: 0.7734 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.7470 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.4861 - f1_score: 0.5017 - loss: 0.7726 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7493 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 36ms/step - accuracy: 0.4991 - f1_score: 0.4247 - loss: 0.7580 - val_accuracy: 0.4500 - val_f1_score: 0.2143 - val_loss: 0.7479 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 36ms/step - accuracy: 0.4974 - f1_score: 0.4273 - loss: 0.7589 - val_accuracy: 0.4375 - val_f1_score: 0.3284 - val_loss: 0.7491 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 36ms/step - accuracy: 0.5100 - f1_score: 0.5424 - loss: 0.7550 - val_accuracy: 0.5250 - val_f1_score: 0.6885 - val_loss: 0.7484 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 36ms/step - accuracy: 0.4905 - f1_score: 0.5516 - loss: 0.7670 - val_accuracy: 0.5875 - val_f1_score: 0.6452 - val_loss: 0.7473 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 36ms/step - accuracy: 0.5139 - f1_score: 0.6269 - loss: 0.7535 - val_accuracy: 0.5500 - val_f1_score: 0.7097 - val_loss: 0.7473 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 36ms/step - accuracy: 0.4944 - f1_score: 0.4502 - loss: 0.7498 - val_accuracy: 0.5375 - val_f1_score: 0.6022 - val_loss: 0.7475 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 36ms/step - accuracy: 0.5095 - f1_score: 0.5674 - loss: 0.7522 - val_accuracy: 0.5375 - val_f1_score: 0.6942 - val_loss: 0.7480 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 36ms/step - accuracy: 0.5022 - f1_score: 0.5417 - loss: 0.7571 - val_accuracy: 0.5750 - val_f1_score: 0.7258 - val_loss: 0.7456 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 36ms/step - accuracy: 0.4974 - f1_score: 0.5258 - loss: 0.7533 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.7443 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 36ms/step - accuracy: 0.4931 - f1_score: 0.5264 - loss: 0.7562 - val_accuracy: 0.6625 - val_f1_score: 0.7033 - val_loss: 0.7454 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 36ms/step - accuracy: 0.5178 - f1_score: 0.6485 - loss: 0.7493 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.7448 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 36ms/step - accuracy: 0.5039 - f1_score: 0.6478 - loss: 0.7493 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.7447 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 36ms/step - accuracy: 0.4878 - f1_score: 0.6176 - loss: 0.7476 - val_accuracy: 0.5625 - val_f1_score: 0.7154 - val_loss: 0.7458 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 36ms/step - accuracy: 0.5256 - f1_score: 0.6081 - loss: 0.7624 - val_accuracy: 0.5250 - val_f1_score: 0.6833 - val_loss: 0.7466 - learning_rate: 4.2723e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\noldB → Fold 5 Val F1 = 0.7258\n\n>>> Training model1 on Fold 5\nEpoch 1/200\n36/36 - 27s - 748ms/step - accuracy: 0.4935 - f1_score: 0.5983 - loss: 0.6939 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6923 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 41ms/step - accuracy: 0.4931 - f1_score: 0.5000 - loss: 0.6935 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6910 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 39ms/step - accuracy: 0.5161 - f1_score: 0.6786 - loss: 0.6929 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6891 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 35ms/step - accuracy: 0.5004 - f1_score: 0.5923 - loss: 0.6942 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6938 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 30ms/step - accuracy: 0.4800 - f1_score: 0.5843 - loss: 0.6938 - val_accuracy: 0.5875 - val_f1_score: 0.6796 - val_loss: 0.6929 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 30ms/step - accuracy: 0.5043 - f1_score: 0.3202 - loss: 0.6936 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6913 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 29ms/step - accuracy: 0.5078 - f1_score: 0.6325 - loss: 0.6933 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6989 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.4926 - f1_score: 0.5590 - loss: 0.6947 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6921 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 29ms/step - accuracy: 0.5017 - f1_score: 0.6682 - loss: 0.6933 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6919 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 29ms/step - accuracy: 0.4987 - f1_score: 0.6097 - loss: 0.6933 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6939 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 33ms/step - accuracy: 0.4987 - f1_score: 0.0000e+00 - loss: 0.6933 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6932 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 30ms/step - accuracy: 0.4913 - f1_score: 0.6537 - loss: 0.6932 - val_accuracy: 0.5750 - val_f1_score: 0.7018 - val_loss: 0.6928 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 29ms/step - accuracy: 0.5130 - f1_score: 0.2294 - loss: 0.6930 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6948 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 29ms/step - accuracy: 0.5061 - f1_score: 0.0000e+00 - loss: 0.6928 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7041 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 30ms/step - accuracy: 0.4991 - f1_score: 0.5180 - loss: 0.6938 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6909 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 29ms/step - accuracy: 0.5082 - f1_score: 0.6740 - loss: 0.6931 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6921 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 29ms/step - accuracy: 0.5139 - f1_score: 0.6789 - loss: 0.6931 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6899 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.4952 - f1_score: 0.6624 - loss: 0.6934 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6926 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.4983 - f1_score: 0.6636 - loss: 0.6932 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6929 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 29ms/step - accuracy: 0.5017 - f1_score: 0.5585 - loss: 0.6931 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6925 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 31ms/step - accuracy: 0.4900 - f1_score: 0.5365 - loss: 0.6932 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6947 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\nmodel1 → Fold 5 Val F1 = 0.7200\n\n>>> Training model2 on Fold 5\nEpoch 1/200\n36/36 - 4s - 125ms/step - accuracy: 0.5273 - f1_score: 0.5575 - loss: 5.2196 - val_accuracy: 0.4375 - val_f1_score: 0.5545 - val_loss: 1.1215 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 22ms/step - accuracy: 0.5451 - f1_score: 0.5890 - loss: 1.6361 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 1.0792 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 21ms/step - accuracy: 0.5334 - f1_score: 0.5726 - loss: 1.3780 - val_accuracy: 0.4000 - val_f1_score: 0.2941 - val_loss: 0.9405 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 21ms/step - accuracy: 0.5265 - f1_score: 0.5552 - loss: 1.2632 - val_accuracy: 0.4750 - val_f1_score: 0.6038 - val_loss: 0.7487 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 20ms/step - accuracy: 0.5269 - f1_score: 0.5350 - loss: 0.9940 - val_accuracy: 0.3500 - val_f1_score: 0.3953 - val_loss: 0.8360 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 21ms/step - accuracy: 0.5273 - f1_score: 0.4970 - loss: 1.0620 - val_accuracy: 0.4125 - val_f1_score: 0.4719 - val_loss: 0.8350 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 20ms/step - accuracy: 0.5191 - f1_score: 0.5071 - loss: 1.0575 - val_accuracy: 0.4000 - val_f1_score: 0.2258 - val_loss: 0.9591 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 22ms/step - accuracy: 0.5451 - f1_score: 0.5705 - loss: 0.9034 - val_accuracy: 0.4125 - val_f1_score: 0.4471 - val_loss: 0.8486 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 21ms/step - accuracy: 0.5321 - f1_score: 0.5247 - loss: 0.8582 - val_accuracy: 0.4750 - val_f1_score: 0.5227 - val_loss: 0.8137 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 21ms/step - accuracy: 0.5399 - f1_score: 0.5367 - loss: 0.8435 - val_accuracy: 0.3500 - val_f1_score: 0.3333 - val_loss: 0.8079 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 21ms/step - accuracy: 0.5156 - f1_score: 0.5044 - loss: 0.8315 - val_accuracy: 0.4250 - val_f1_score: 0.5106 - val_loss: 0.8200 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 21ms/step - accuracy: 0.5308 - f1_score: 0.5374 - loss: 0.7366 - val_accuracy: 0.3750 - val_f1_score: 0.1935 - val_loss: 0.8005 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 21ms/step - accuracy: 0.5317 - f1_score: 0.5071 - loss: 0.7844 - val_accuracy: 0.4375 - val_f1_score: 0.3662 - val_loss: 0.7391 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 20ms/step - accuracy: 0.5386 - f1_score: 0.5090 - loss: 0.7513 - val_accuracy: 0.4125 - val_f1_score: 0.5053 - val_loss: 0.7680 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 21ms/step - accuracy: 0.5230 - f1_score: 0.5190 - loss: 0.8150 - val_accuracy: 0.4875 - val_f1_score: 0.3492 - val_loss: 0.7656 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5230 - f1_score: 0.5309 - loss: 0.8477 - val_accuracy: 0.4500 - val_f1_score: 0.5686 - val_loss: 0.8070 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 21ms/step - accuracy: 0.5295 - f1_score: 0.5182 - loss: 0.7511 - val_accuracy: 0.4250 - val_f1_score: 0.3235 - val_loss: 0.7425 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 21ms/step - accuracy: 0.5525 - f1_score: 0.5592 - loss: 0.7613 - val_accuracy: 0.5000 - val_f1_score: 0.5833 - val_loss: 0.7478 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 21ms/step - accuracy: 0.5417 - f1_score: 0.4976 - loss: 0.7341 - val_accuracy: 0.4250 - val_f1_score: 0.3947 - val_loss: 0.7638 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 21ms/step - accuracy: 0.5365 - f1_score: 0.5718 - loss: 0.7263 - val_accuracy: 0.5000 - val_f1_score: 0.6078 - val_loss: 0.7138 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 21ms/step - accuracy: 0.5486 - f1_score: 0.4862 - loss: 0.7086 - val_accuracy: 0.4625 - val_f1_score: 0.2951 - val_loss: 0.7443 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 20ms/step - accuracy: 0.5499 - f1_score: 0.5078 - loss: 0.7121 - val_accuracy: 0.3375 - val_f1_score: 0.1311 - val_loss: 0.7728 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 21ms/step - accuracy: 0.5755 - f1_score: 0.4922 - loss: 0.6830 - val_accuracy: 0.4500 - val_f1_score: 0.4359 - val_loss: 0.7470 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 21ms/step - accuracy: 0.5738 - f1_score: 0.5942 - loss: 0.6785 - val_accuracy: 0.4000 - val_f1_score: 0.4286 - val_loss: 0.7492 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 21ms/step - accuracy: 0.5503 - f1_score: 0.5480 - loss: 0.7379 - val_accuracy: 0.3875 - val_f1_score: 0.0392 - val_loss: 0.7976 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 21ms/step - accuracy: 0.5569 - f1_score: 0.5918 - loss: 0.6926 - val_accuracy: 0.4500 - val_f1_score: 0.4211 - val_loss: 0.7805 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 21ms/step - accuracy: 0.5816 - f1_score: 0.5834 - loss: 0.6768 - val_accuracy: 0.4250 - val_f1_score: 0.4103 - val_loss: 0.7630 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 21ms/step - accuracy: 0.5799 - f1_score: 0.5919 - loss: 0.6757 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.7562 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 21ms/step - accuracy: 0.5803 - f1_score: 0.5685 - loss: 0.6948 - val_accuracy: 0.5125 - val_f1_score: 0.5618 - val_loss: 0.7410 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 20ms/step - accuracy: 0.5816 - f1_score: 0.5898 - loss: 0.6818 - val_accuracy: 0.4250 - val_f1_score: 0.3947 - val_loss: 0.7559 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 20ms/step - accuracy: 0.5790 - f1_score: 0.5642 - loss: 0.6693 - val_accuracy: 0.4125 - val_f1_score: 0.3733 - val_loss: 0.7610 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 21ms/step - accuracy: 0.5777 - f1_score: 0.5934 - loss: 0.6660 - val_accuracy: 0.4375 - val_f1_score: 0.5161 - val_loss: 0.7520 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 23ms/step - accuracy: 0.5851 - f1_score: 0.5928 - loss: 0.6575 - val_accuracy: 0.4250 - val_f1_score: 0.4524 - val_loss: 0.7484 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 24ms/step - accuracy: 0.5907 - f1_score: 0.5930 - loss: 0.6553 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 0.7506 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 21ms/step - accuracy: 0.5898 - f1_score: 0.5839 - loss: 0.6555 - val_accuracy: 0.4750 - val_f1_score: 0.4878 - val_loss: 0.7549 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 21ms/step - accuracy: 0.6176 - f1_score: 0.5968 - loss: 0.6464 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 0.7767 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 21ms/step - accuracy: 0.6111 - f1_score: 0.5912 - loss: 0.6513 - val_accuracy: 0.3750 - val_f1_score: 0.1935 - val_loss: 0.7885 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 21ms/step - accuracy: 0.6063 - f1_score: 0.5752 - loss: 0.6459 - val_accuracy: 0.4125 - val_f1_score: 0.4051 - val_loss: 0.7757 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 21ms/step - accuracy: 0.5968 - f1_score: 0.5877 - loss: 0.6600 - val_accuracy: 0.4250 - val_f1_score: 0.3947 - val_loss: 0.7690 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 1s - 21ms/step - accuracy: 0.6150 - f1_score: 0.6159 - loss: 0.6504 - val_accuracy: 0.4250 - val_f1_score: 0.3429 - val_loss: 0.7742 - learning_rate: 2.7820e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step\nmodel2 → Fold 5 Val F1 = 0.6078\n\n>>> Training model3 on Fold 5\nEpoch 1/200\n36/36 - 9s - 257ms/step - accuracy: 0.5260 - f1_score: 0.4699 - loss: 0.7079 - val_accuracy: 0.4125 - val_f1_score: 0.0000e+00 - val_loss: 0.6947 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 98ms/step - accuracy: 0.5473 - f1_score: 0.4860 - loss: 0.6806 - val_accuracy: 0.5000 - val_f1_score: 0.6364 - val_loss: 0.6964 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 3s - 84ms/step - accuracy: 0.5712 - f1_score: 0.6061 - loss: 0.6784 - val_accuracy: 0.5125 - val_f1_score: 0.6286 - val_loss: 0.7056 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 107ms/step - accuracy: 0.5877 - f1_score: 0.6434 - loss: 0.6616 - val_accuracy: 0.4500 - val_f1_score: 0.4054 - val_loss: 0.7029 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 3s - 91ms/step - accuracy: 0.6562 - f1_score: 0.6309 - loss: 0.6029 - val_accuracy: 0.4625 - val_f1_score: 0.3582 - val_loss: 0.8481 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 105ms/step - accuracy: 0.7305 - f1_score: 0.7024 - loss: 0.5195 - val_accuracy: 0.5875 - val_f1_score: 0.6598 - val_loss: 0.7790 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 3s - 88ms/step - accuracy: 0.7904 - f1_score: 0.8073 - loss: 0.4466 - val_accuracy: 0.5625 - val_f1_score: 0.5333 - val_loss: 0.8290 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 91ms/step - accuracy: 0.8641 - f1_score: 0.8661 - loss: 0.3026 - val_accuracy: 0.5125 - val_f1_score: 0.5806 - val_loss: 0.9143 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 3s - 82ms/step - accuracy: 0.9132 - f1_score: 0.9145 - loss: 0.1997 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 1.0694 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 3s - 91ms/step - accuracy: 0.9562 - f1_score: 0.9563 - loss: 0.1101 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 1.8171 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 3s - 92ms/step - accuracy: 0.9701 - f1_score: 0.9703 - loss: 0.1112 - val_accuracy: 0.5875 - val_f1_score: 0.6292 - val_loss: 1.4046 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 3s - 80ms/step - accuracy: 0.9800 - f1_score: 0.9799 - loss: 0.0547 - val_accuracy: 0.5750 - val_f1_score: 0.6136 - val_loss: 1.6134 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 3s - 80ms/step - accuracy: 0.9696 - f1_score: 0.9691 - loss: 0.1177 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 1.3080 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 3s - 95ms/step - accuracy: 0.9800 - f1_score: 0.9798 - loss: 0.0985 - val_accuracy: 0.5125 - val_f1_score: 0.5806 - val_loss: 1.9689 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 94ms/step - accuracy: 0.9891 - f1_score: 0.9892 - loss: 0.0393 - val_accuracy: 0.5500 - val_f1_score: 0.6170 - val_loss: 2.1983 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 81ms/step - accuracy: 0.9961 - f1_score: 0.9962 - loss: 0.0156 - val_accuracy: 0.5625 - val_f1_score: 0.5783 - val_loss: 1.7618 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 124ms/step - accuracy: 0.9978 - f1_score: 0.9979 - loss: 0.0146 - val_accuracy: 0.5500 - val_f1_score: 0.6170 - val_loss: 2.5167 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 93ms/step - accuracy: 0.9978 - f1_score: 0.9978 - loss: 0.0092 - val_accuracy: 0.5750 - val_f1_score: 0.6383 - val_loss: 2.4688 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 3s - 81ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0040 - val_accuracy: 0.5875 - val_f1_score: 0.6452 - val_loss: 1.9682 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 85ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0076 - val_accuracy: 0.5875 - val_f1_score: 0.6374 - val_loss: 2.6183 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 3s - 95ms/step - accuracy: 0.9996 - f1_score: 0.9995 - loss: 0.0019 - val_accuracy: 0.5875 - val_f1_score: 0.6374 - val_loss: 2.9570 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 3s - 83ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0040 - val_accuracy: 0.5250 - val_f1_score: 0.5870 - val_loss: 2.4835 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 3s - 95ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0014 - val_accuracy: 0.5625 - val_f1_score: 0.6067 - val_loss: 3.2293 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 3s - 85ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0051e-04 - val_accuracy: 0.5625 - val_f1_score: 0.6237 - val_loss: 3.5512 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 3s - 81ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9760e-04 - val_accuracy: 0.5750 - val_f1_score: 0.6304 - val_loss: 3.5083 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 3s - 96ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6880e-04 - val_accuracy: 0.5625 - val_f1_score: 0.6237 - val_loss: 3.7647 - learning_rate: 7.1022e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step\nmodel3 → Fold 5 Val F1 = 0.6598\n\n>>> Training model4 on Fold 5\nEpoch 1/200\n36/36 - 9s - 245ms/step - accuracy: 0.5074 - f1_score: 0.5816 - loss: 0.6927 - val_accuracy: 0.4375 - val_f1_score: 0.3662 - val_loss: 0.6942 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 119ms/step - accuracy: 0.4978 - f1_score: 0.4566 - loss: 0.6932 - val_accuracy: 0.5625 - val_f1_score: 0.7107 - val_loss: 0.6898 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 119ms/step - accuracy: 0.5200 - f1_score: 0.5861 - loss: 0.6912 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6780 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 118ms/step - accuracy: 0.5122 - f1_score: 0.6070 - loss: 0.6930 - val_accuracy: 0.4625 - val_f1_score: 0.1569 - val_loss: 0.6931 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 118ms/step - accuracy: 0.5343 - f1_score: 0.5279 - loss: 0.6919 - val_accuracy: 0.5750 - val_f1_score: 0.4848 - val_loss: 0.6892 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 119ms/step - accuracy: 0.5417 - f1_score: 0.4329 - loss: 0.6912 - val_accuracy: 0.4625 - val_f1_score: 0.2951 - val_loss: 0.6956 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 119ms/step - accuracy: 0.5182 - f1_score: 0.5123 - loss: 0.6932 - val_accuracy: 0.4500 - val_f1_score: 0.0435 - val_loss: 0.6957 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 119ms/step - accuracy: 0.5056 - f1_score: 0.3280 - loss: 0.6934 - val_accuracy: 0.4875 - val_f1_score: 0.2545 - val_loss: 0.6933 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 119ms/step - accuracy: 0.5082 - f1_score: 0.4698 - loss: 0.6926 - val_accuracy: 0.5750 - val_f1_score: 0.5405 - val_loss: 0.6858 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 119ms/step - accuracy: 0.5516 - f1_score: 0.5088 - loss: 0.6898 - val_accuracy: 0.6000 - val_f1_score: 0.5429 - val_loss: 0.6898 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 119ms/step - accuracy: 0.5321 - f1_score: 0.4669 - loss: 0.6899 - val_accuracy: 0.5875 - val_f1_score: 0.5352 - val_loss: 0.6831 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 118ms/step - accuracy: 0.5404 - f1_score: 0.4394 - loss: 0.6875 - val_accuracy: 0.5000 - val_f1_score: 0.2000 - val_loss: 0.7006 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 118ms/step - accuracy: 0.5447 - f1_score: 0.4327 - loss: 0.6876 - val_accuracy: 0.5125 - val_f1_score: 0.3390 - val_loss: 0.6978 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 119ms/step - accuracy: 0.5521 - f1_score: 0.4505 - loss: 0.6879 - val_accuracy: 0.5250 - val_f1_score: 0.3667 - val_loss: 0.6935 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 119ms/step - accuracy: 0.5343 - f1_score: 0.4443 - loss: 0.6903 - val_accuracy: 0.6000 - val_f1_score: 0.5676 - val_loss: 0.6781 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 119ms/step - accuracy: 0.5443 - f1_score: 0.5000 - loss: 0.6888 - val_accuracy: 0.6000 - val_f1_score: 0.6279 - val_loss: 0.6677 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 119ms/step - accuracy: 0.5391 - f1_score: 0.5786 - loss: 0.6876 - val_accuracy: 0.5875 - val_f1_score: 0.6526 - val_loss: 0.6783 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 119ms/step - accuracy: 0.5456 - f1_score: 0.4954 - loss: 0.6895 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 0.6894 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 119ms/step - accuracy: 0.5503 - f1_score: 0.4851 - loss: 0.6861 - val_accuracy: 0.5500 - val_f1_score: 0.5500 - val_loss: 0.6745 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 119ms/step - accuracy: 0.5443 - f1_score: 0.4397 - loss: 0.6869 - val_accuracy: 0.6000 - val_f1_score: 0.5676 - val_loss: 0.6669 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 118ms/step - accuracy: 0.5560 - f1_score: 0.4461 - loss: 0.6869 - val_accuracy: 0.6000 - val_f1_score: 0.5429 - val_loss: 0.6829 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 4s - 119ms/step - accuracy: 0.5629 - f1_score: 0.4421 - loss: 0.6860 - val_accuracy: 0.5875 - val_f1_score: 0.5352 - val_loss: 0.6805 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 4s - 119ms/step - accuracy: 0.5799 - f1_score: 0.4829 - loss: 0.6791 - val_accuracy: 0.5500 - val_f1_score: 0.5263 - val_loss: 0.6910 - learning_rate: 7.9071e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step\nmodel4 → Fold 5 Val F1 = 0.7200\n\n>>> Training model5 on Fold 5\nEpoch 1/200\n36/36 - 7s - 204ms/step - accuracy: 0.5243 - f1_score: 0.5387 - loss: 1.1006 - val_accuracy: 0.3875 - val_f1_score: 0.0392 - val_loss: 0.7960 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 39ms/step - accuracy: 0.4909 - f1_score: 0.4867 - loss: 0.7618 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.7035 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 36ms/step - accuracy: 0.5030 - f1_score: 0.5389 - loss: 0.7410 - val_accuracy: 0.5625 - val_f1_score: 0.6957 - val_loss: 0.6836 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 32ms/step - accuracy: 0.5122 - f1_score: 0.5390 - loss: 0.7107 - val_accuracy: 0.5500 - val_f1_score: 0.6538 - val_loss: 0.7039 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 32ms/step - accuracy: 0.5221 - f1_score: 0.5388 - loss: 0.7080 - val_accuracy: 0.4500 - val_f1_score: 0.1538 - val_loss: 0.7016 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 33ms/step - accuracy: 0.5061 - f1_score: 0.4897 - loss: 0.7060 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6863 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 32ms/step - accuracy: 0.4891 - f1_score: 0.4569 - loss: 0.6986 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7087 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 33ms/step - accuracy: 0.4852 - f1_score: 0.4400 - loss: 0.7025 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6893 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 33ms/step - accuracy: 0.5143 - f1_score: 0.5644 - loss: 0.6951 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7183 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 31ms/step - accuracy: 0.4918 - f1_score: 0.4616 - loss: 0.6981 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6922 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 33ms/step - accuracy: 0.4935 - f1_score: 0.4639 - loss: 0.6964 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6856 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 32ms/step - accuracy: 0.4978 - f1_score: 0.4206 - loss: 0.6953 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6979 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 32ms/step - accuracy: 0.4891 - f1_score: 0.2231 - loss: 0.6953 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6927 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 32ms/step - accuracy: 0.4952 - f1_score: 0.4919 - loss: 0.6972 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6857 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 34ms/step - accuracy: 0.5013 - f1_score: 0.5737 - loss: 0.6960 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7170 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 32ms/step - accuracy: 0.4961 - f1_score: 0.5607 - loss: 0.6982 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6974 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 33ms/step - accuracy: 0.4913 - f1_score: 0.5587 - loss: 0.6975 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6940 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 32ms/step - accuracy: 0.5130 - f1_score: 0.4446 - loss: 0.6968 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6980 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 32ms/step - accuracy: 0.5148 - f1_score: 0.4848 - loss: 0.6942 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6979 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 32ms/step - accuracy: 0.4957 - f1_score: 0.6178 - loss: 0.6957 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6854 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 31ms/step - accuracy: 0.5208 - f1_score: 0.1918 - loss: 0.6934 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6943 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 31ms/step - accuracy: 0.5030 - f1_score: 0.4301 - loss: 0.6945 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7029 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 33ms/step - accuracy: 0.5035 - f1_score: 0.2394 - loss: 0.6947 - val_accuracy: 0.5625 - val_f1_score: 0.7200 - val_loss: 0.6926 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 39ms/step - accuracy: 0.5122 - f1_score: 0.6307 - loss: 0.6955 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7019 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 33ms/step - accuracy: 0.5069 - f1_score: 0.5590 - loss: 0.6944 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6982 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 34ms/step - accuracy: 0.5204 - f1_score: 0.5957 - loss: 0.6925 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.6979 - learning_rate: 7.1022e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step\nmodel5 → Fold 5 Val F1 = 0.7200\n\n>>> Training model6 on Fold 5\nEpoch 1/200\n36/36 - 7s - 200ms/step - accuracy: 0.5109 - f1_score: 0.5106 - loss: 2.6405 - val_accuracy: 0.5750 - val_f1_score: 0.6909 - val_loss: 1.0872 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 39ms/step - accuracy: 0.5061 - f1_score: 0.5214 - loss: 1.5736 - val_accuracy: 0.5000 - val_f1_score: 0.6154 - val_loss: 0.7158 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 39ms/step - accuracy: 0.4961 - f1_score: 0.5395 - loss: 0.8104 - val_accuracy: 0.6125 - val_f1_score: 0.7438 - val_loss: 0.6825 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 39ms/step - accuracy: 0.5074 - f1_score: 0.5422 - loss: 0.7511 - val_accuracy: 0.5625 - val_f1_score: 0.5570 - val_loss: 0.6929 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 39ms/step - accuracy: 0.4961 - f1_score: 0.5502 - loss: 0.7128 - val_accuracy: 0.5000 - val_f1_score: 0.6226 - val_loss: 0.6990 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 40ms/step - accuracy: 0.4991 - f1_score: 0.5155 - loss: 0.7741 - val_accuracy: 0.4375 - val_f1_score: 0.2105 - val_loss: 0.7147 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 39ms/step - accuracy: 0.4896 - f1_score: 0.4635 - loss: 1.2867 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.8579 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 39ms/step - accuracy: 0.5113 - f1_score: 0.4566 - loss: 1.0550 - val_accuracy: 0.5500 - val_f1_score: 0.4545 - val_loss: 0.6972 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 39ms/step - accuracy: 0.5100 - f1_score: 0.5214 - loss: 0.7460 - val_accuracy: 0.5250 - val_f1_score: 0.6667 - val_loss: 0.6920 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 39ms/step - accuracy: 0.5000 - f1_score: 0.5992 - loss: 0.6964 - val_accuracy: 0.4875 - val_f1_score: 0.4058 - val_loss: 0.6957 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 40ms/step - accuracy: 0.4931 - f1_score: 0.4374 - loss: 0.7162 - val_accuracy: 0.6125 - val_f1_score: 0.6667 - val_loss: 0.6917 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 39ms/step - accuracy: 0.5013 - f1_score: 0.5646 - loss: 0.6983 - val_accuracy: 0.5375 - val_f1_score: 0.6105 - val_loss: 0.6950 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 40ms/step - accuracy: 0.5252 - f1_score: 0.4658 - loss: 0.6938 - val_accuracy: 0.4750 - val_f1_score: 0.2759 - val_loss: 0.6979 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 39ms/step - accuracy: 0.5278 - f1_score: 0.4784 - loss: 0.6925 - val_accuracy: 0.4875 - val_f1_score: 0.3051 - val_loss: 0.6962 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 39ms/step - accuracy: 0.5161 - f1_score: 0.4845 - loss: 0.6929 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 0.6910 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 40ms/step - accuracy: 0.5343 - f1_score: 0.5897 - loss: 0.6915 - val_accuracy: 0.6125 - val_f1_score: 0.6593 - val_loss: 0.6876 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 40ms/step - accuracy: 0.5321 - f1_score: 0.5825 - loss: 0.6917 - val_accuracy: 0.5625 - val_f1_score: 0.6316 - val_loss: 0.6927 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 39ms/step - accuracy: 0.5152 - f1_score: 0.5435 - loss: 0.6913 - val_accuracy: 0.4250 - val_f1_score: 0.5208 - val_loss: 0.6991 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 39ms/step - accuracy: 0.5161 - f1_score: 0.4354 - loss: 0.6987 - val_accuracy: 0.5750 - val_f1_score: 0.4848 - val_loss: 0.6933 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 39ms/step - accuracy: 0.5330 - f1_score: 0.5285 - loss: 0.6897 - val_accuracy: 0.5000 - val_f1_score: 0.6000 - val_loss: 0.6909 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 39ms/step - accuracy: 0.5074 - f1_score: 0.5462 - loss: 0.6934 - val_accuracy: 0.5500 - val_f1_score: 0.5000 - val_loss: 0.6952 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 39ms/step - accuracy: 0.5191 - f1_score: 0.4709 - loss: 0.6926 - val_accuracy: 0.5250 - val_f1_score: 0.4412 - val_loss: 0.6923 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 39ms/step - accuracy: 0.5312 - f1_score: 0.3822 - loss: 0.6912 - val_accuracy: 0.5375 - val_f1_score: 0.3934 - val_loss: 0.6941 - learning_rate: 7.9071e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step\nmodel6 → Fold 5 Val F1 = 0.7438\n\n==================================================\nFold 6/30 - Subject: S14\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 6\nEpoch 1/200\n36/36 - 8s - 223ms/step - accuracy: 0.5130 - f1_score: 0.5476 - loss: 0.9131 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.7720 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 28ms/step - accuracy: 0.5148 - f1_score: 0.5079 - loss: 0.7912 - val_accuracy: 0.5250 - val_f1_score: 0.5778 - val_loss: 0.6937 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 28ms/step - accuracy: 0.4948 - f1_score: 0.5272 - loss: 0.7534 - val_accuracy: 0.5000 - val_f1_score: 0.5122 - val_loss: 0.6894 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 28ms/step - accuracy: 0.4961 - f1_score: 0.5053 - loss: 0.7292 - val_accuracy: 0.5250 - val_f1_score: 0.4571 - val_loss: 0.6960 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.5182 - f1_score: 0.5301 - loss: 0.7172 - val_accuracy: 0.5250 - val_f1_score: 0.4865 - val_loss: 0.7067 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 28ms/step - accuracy: 0.4766 - f1_score: 0.4364 - loss: 0.7204 - val_accuracy: 0.4500 - val_f1_score: 0.1538 - val_loss: 0.7029 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.5178 - f1_score: 0.5558 - loss: 0.7103 - val_accuracy: 0.5625 - val_f1_score: 0.6667 - val_loss: 0.6952 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 29ms/step - accuracy: 0.5026 - f1_score: 0.5579 - loss: 0.7063 - val_accuracy: 0.5000 - val_f1_score: 0.5918 - val_loss: 0.6881 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 29ms/step - accuracy: 0.5165 - f1_score: 0.5562 - loss: 0.7067 - val_accuracy: 0.4625 - val_f1_score: 0.1224 - val_loss: 0.7023 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.5247 - f1_score: 0.5841 - loss: 0.7028 - val_accuracy: 0.5125 - val_f1_score: 0.4658 - val_loss: 0.6915 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 28ms/step - accuracy: 0.5243 - f1_score: 0.5612 - loss: 0.7024 - val_accuracy: 0.4750 - val_f1_score: 0.2500 - val_loss: 0.7017 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5130 - f1_score: 0.5668 - loss: 0.6991 - val_accuracy: 0.5125 - val_f1_score: 0.4179 - val_loss: 0.7130 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5317 - f1_score: 0.5832 - loss: 0.6960 - val_accuracy: 0.5000 - val_f1_score: 0.5000 - val_loss: 0.7081 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5256 - f1_score: 0.5021 - loss: 0.7018 - val_accuracy: 0.5250 - val_f1_score: 0.5000 - val_loss: 0.6918 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 28ms/step - accuracy: 0.5352 - f1_score: 0.4941 - loss: 0.6987 - val_accuracy: 0.5500 - val_f1_score: 0.5000 - val_loss: 0.6829 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5143 - f1_score: 0.4827 - loss: 0.7041 - val_accuracy: 0.5750 - val_f1_score: 0.5526 - val_loss: 0.6948 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.5347 - f1_score: 0.5383 - loss: 0.6961 - val_accuracy: 0.4875 - val_f1_score: 0.2545 - val_loss: 0.7079 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.5382 - f1_score: 0.5650 - loss: 0.6955 - val_accuracy: 0.4500 - val_f1_score: 0.3529 - val_loss: 0.7077 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5256 - f1_score: 0.5398 - loss: 0.6977 - val_accuracy: 0.4375 - val_f1_score: 0.3662 - val_loss: 0.7070 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 28ms/step - accuracy: 0.5195 - f1_score: 0.5104 - loss: 0.6995 - val_accuracy: 0.5000 - val_f1_score: 0.5000 - val_loss: 0.7046 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 29ms/step - accuracy: 0.5365 - f1_score: 0.5486 - loss: 0.6952 - val_accuracy: 0.4625 - val_f1_score: 0.3944 - val_loss: 0.7198 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step\noldA → Fold 6 Val F1 = 0.6992\n\n>>> Training oldB on Fold 6\nEpoch 1/200\n36/36 - 13s - 363ms/step - accuracy: 0.4913 - f1_score: 0.5096 - loss: 2.9914 - val_accuracy: 0.5125 - val_f1_score: 0.4800 - val_loss: 0.7791 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 37ms/step - accuracy: 0.4918 - f1_score: 0.4742 - loss: 2.0532 - val_accuracy: 0.4375 - val_f1_score: 0.4156 - val_loss: 0.7676 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 36ms/step - accuracy: 0.4983 - f1_score: 0.5155 - loss: 1.5481 - val_accuracy: 0.5000 - val_f1_score: 0.5745 - val_loss: 0.7384 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.5082 - f1_score: 0.5289 - loss: 1.2455 - val_accuracy: 0.3875 - val_f1_score: 0.2222 - val_loss: 0.7510 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 36ms/step - accuracy: 0.5061 - f1_score: 0.4991 - loss: 1.1170 - val_accuracy: 0.5250 - val_f1_score: 0.3214 - val_loss: 0.7503 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 36ms/step - accuracy: 0.5017 - f1_score: 0.4983 - loss: 0.9880 - val_accuracy: 0.5750 - val_f1_score: 0.6136 - val_loss: 0.7385 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 36ms/step - accuracy: 0.5165 - f1_score: 0.5497 - loss: 0.9451 - val_accuracy: 0.5500 - val_f1_score: 0.6786 - val_loss: 0.7407 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 36ms/step - accuracy: 0.4792 - f1_score: 0.5033 - loss: 0.8968 - val_accuracy: 0.5500 - val_f1_score: 0.6471 - val_loss: 0.7467 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 36ms/step - accuracy: 0.5130 - f1_score: 0.5254 - loss: 0.8540 - val_accuracy: 0.5500 - val_f1_score: 0.5135 - val_loss: 0.7461 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 35ms/step - accuracy: 0.5074 - f1_score: 0.5699 - loss: 0.8157 - val_accuracy: 0.5250 - val_f1_score: 0.6780 - val_loss: 0.7465 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 36ms/step - accuracy: 0.4987 - f1_score: 0.5360 - loss: 0.7969 - val_accuracy: 0.5375 - val_f1_score: 0.5843 - val_loss: 0.7475 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 36ms/step - accuracy: 0.5030 - f1_score: 0.5574 - loss: 0.7848 - val_accuracy: 0.5250 - val_f1_score: 0.6607 - val_loss: 0.7480 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 36ms/step - accuracy: 0.5113 - f1_score: 0.5441 - loss: 0.7924 - val_accuracy: 0.5000 - val_f1_score: 0.4286 - val_loss: 0.7482 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 35ms/step - accuracy: 0.5017 - f1_score: 0.4416 - loss: 0.7752 - val_accuracy: 0.4000 - val_f1_score: 0.2258 - val_loss: 0.7488 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 35ms/step - accuracy: 0.5026 - f1_score: 0.4589 - loss: 0.7696 - val_accuracy: 0.4500 - val_f1_score: 0.0435 - val_loss: 0.7487 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 36ms/step - accuracy: 0.5061 - f1_score: 0.4518 - loss: 0.7750 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.7487 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 36ms/step - accuracy: 0.5204 - f1_score: 0.5117 - loss: 0.7757 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7504 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 36ms/step - accuracy: 0.5056 - f1_score: 0.4858 - loss: 0.7736 - val_accuracy: 0.4500 - val_f1_score: 0.0833 - val_loss: 0.7494 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 36ms/step - accuracy: 0.5039 - f1_score: 0.5105 - loss: 0.7617 - val_accuracy: 0.4750 - val_f1_score: 0.0870 - val_loss: 0.7485 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 35ms/step - accuracy: 0.5126 - f1_score: 0.4822 - loss: 0.7689 - val_accuracy: 0.5375 - val_f1_score: 0.2745 - val_loss: 0.7479 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.4952 - f1_score: 0.4976 - loss: 0.7663 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7486 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 36ms/step - accuracy: 0.4831 - f1_score: 0.3877 - loss: 0.7725 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.7482 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 36ms/step - accuracy: 0.5004 - f1_score: 0.4052 - loss: 0.7612 - val_accuracy: 0.5000 - val_f1_score: 0.3333 - val_loss: 0.7476 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 36ms/step - accuracy: 0.5022 - f1_score: 0.4418 - loss: 0.7579 - val_accuracy: 0.4625 - val_f1_score: 0.2182 - val_loss: 0.7476 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 36ms/step - accuracy: 0.4905 - f1_score: 0.3557 - loss: 0.7543 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7479 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 36ms/step - accuracy: 0.4900 - f1_score: 0.3819 - loss: 0.7588 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7474 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 36ms/step - accuracy: 0.5104 - f1_score: 0.4161 - loss: 0.7748 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7484 - learning_rate: 6.8101e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step\noldB → Fold 6 Val F1 = 0.6786\n\n>>> Training model1 on Fold 6\nEpoch 1/200\n36/36 - 26s - 709ms/step - accuracy: 0.5113 - f1_score: 0.6625 - loss: 0.6937 - val_accuracy: 0.5500 - val_f1_score: 0.7000 - val_loss: 0.6930 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 38ms/step - accuracy: 0.5052 - f1_score: 0.0563 - loss: 0.6934 - val_accuracy: 0.4625 - val_f1_score: 0.0851 - val_loss: 0.6933 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 37ms/step - accuracy: 0.5113 - f1_score: 0.6035 - loss: 0.6936 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6923 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 35ms/step - accuracy: 0.4918 - f1_score: 0.5916 - loss: 0.6937 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6918 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 32ms/step - accuracy: 0.4991 - f1_score: 0.6647 - loss: 0.6936 - val_accuracy: 0.4375 - val_f1_score: 0.3077 - val_loss: 0.6932 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 30ms/step - accuracy: 0.4831 - f1_score: 0.4260 - loss: 0.6935 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6931 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 30ms/step - accuracy: 0.5299 - f1_score: 0.6928 - loss: 0.6919 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6905 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 29ms/step - accuracy: 0.5135 - f1_score: 0.6785 - loss: 0.6937 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6906 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 29ms/step - accuracy: 0.5078 - f1_score: 0.6736 - loss: 0.6935 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6913 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 29ms/step - accuracy: 0.5213 - f1_score: 0.6853 - loss: 0.6926 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6911 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 29ms/step - accuracy: 0.4983 - f1_score: 0.6351 - loss: 0.6929 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6920 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 30ms/step - accuracy: 0.5174 - f1_score: 0.6816 - loss: 0.6930 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6919 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 29ms/step - accuracy: 0.5326 - f1_score: 0.6697 - loss: 0.6919 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6905 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 29ms/step - accuracy: 0.5143 - f1_score: 0.6293 - loss: 0.6919 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6923 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 2s - 61ms/step - accuracy: 0.4996 - f1_score: 0.5041 - loss: 0.6924 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6982 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 28ms/step - accuracy: 0.5000 - f1_score: 0.4297 - loss: 0.6909 - val_accuracy: 0.5125 - val_f1_score: 0.6486 - val_loss: 0.7070 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 28ms/step - accuracy: 0.4957 - f1_score: 0.1640 - loss: 0.6952 - val_accuracy: 0.4750 - val_f1_score: 0.4615 - val_loss: 0.6931 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 29ms/step - accuracy: 0.5230 - f1_score: 0.6663 - loss: 0.6920 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6909 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 31ms/step - accuracy: 0.5161 - f1_score: 0.6808 - loss: 0.6924 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6919 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 89ms/step - accuracy: 0.5030 - f1_score: 0.5584 - loss: 0.6890 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7056 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 29ms/step - accuracy: 0.5347 - f1_score: 0.2717 - loss: 0.6851 - val_accuracy: 0.5000 - val_f1_score: 0.5000 - val_loss: 0.6938 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\nmodel1 → Fold 6 Val F1 = 0.7000\n\n>>> Training model2 on Fold 6\nEpoch 1/200\n36/36 - 4s - 121ms/step - accuracy: 0.5126 - f1_score: 0.4870 - loss: 9.5754 - val_accuracy: 0.4875 - val_f1_score: 0.6095 - val_loss: 1.5235 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 22ms/step - accuracy: 0.5165 - f1_score: 0.4740 - loss: 1.7051 - val_accuracy: 0.5125 - val_f1_score: 0.2041 - val_loss: 3.2586 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 21ms/step - accuracy: 0.5182 - f1_score: 0.5110 - loss: 1.7163 - val_accuracy: 0.4500 - val_f1_score: 0.0000e+00 - val_loss: 3.0335 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 21ms/step - accuracy: 0.5234 - f1_score: 0.5316 - loss: 1.5272 - val_accuracy: 0.5125 - val_f1_score: 0.5185 - val_loss: 2.2442 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 21ms/step - accuracy: 0.5117 - f1_score: 0.5051 - loss: 1.4067 - val_accuracy: 0.5375 - val_f1_score: 0.5067 - val_loss: 1.0823 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 20ms/step - accuracy: 0.5373 - f1_score: 0.5258 - loss: 1.1426 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 1.1833 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 20ms/step - accuracy: 0.5148 - f1_score: 0.5463 - loss: 1.3577 - val_accuracy: 0.5625 - val_f1_score: 0.6535 - val_loss: 0.7436 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 21ms/step - accuracy: 0.5360 - f1_score: 0.5548 - loss: 0.9983 - val_accuracy: 0.5125 - val_f1_score: 0.6723 - val_loss: 1.3059 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 21ms/step - accuracy: 0.5456 - f1_score: 0.5704 - loss: 0.9015 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 1.7201 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 20ms/step - accuracy: 0.5360 - f1_score: 0.5628 - loss: 0.9345 - val_accuracy: 0.4625 - val_f1_score: 0.3582 - val_loss: 1.5513 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 20ms/step - accuracy: 0.5334 - f1_score: 0.5416 - loss: 0.8695 - val_accuracy: 0.4250 - val_f1_score: 0.3030 - val_loss: 1.0099 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 20ms/step - accuracy: 0.5486 - f1_score: 0.5670 - loss: 0.8237 - val_accuracy: 0.4875 - val_f1_score: 0.5287 - val_loss: 0.8845 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 21ms/step - accuracy: 0.5720 - f1_score: 0.5850 - loss: 0.7921 - val_accuracy: 0.5750 - val_f1_score: 0.6852 - val_loss: 0.8424 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 21ms/step - accuracy: 0.5599 - f1_score: 0.5424 - loss: 0.7713 - val_accuracy: 0.5125 - val_f1_score: 0.4658 - val_loss: 0.7299 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 21ms/step - accuracy: 0.5786 - f1_score: 0.5456 - loss: 0.7685 - val_accuracy: 0.4875 - val_f1_score: 0.4810 - val_loss: 0.9138 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5621 - f1_score: 0.5449 - loss: 0.7600 - val_accuracy: 0.4250 - val_f1_score: 0.1786 - val_loss: 1.0068 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 21ms/step - accuracy: 0.5859 - f1_score: 0.5808 - loss: 0.7093 - val_accuracy: 0.4875 - val_f1_score: 0.4533 - val_loss: 0.7966 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 21ms/step - accuracy: 0.5712 - f1_score: 0.6045 - loss: 0.7188 - val_accuracy: 0.5375 - val_f1_score: 0.6186 - val_loss: 1.0550 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 20ms/step - accuracy: 0.5447 - f1_score: 0.5724 - loss: 0.7629 - val_accuracy: 0.5375 - val_f1_score: 0.5542 - val_loss: 0.7387 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 21ms/step - accuracy: 0.5651 - f1_score: 0.5420 - loss: 0.7225 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 0.7558 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 21ms/step - accuracy: 0.5660 - f1_score: 0.5629 - loss: 0.7108 - val_accuracy: 0.4375 - val_f1_score: 0.5714 - val_loss: 0.7323 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 21ms/step - accuracy: 0.5777 - f1_score: 0.5615 - loss: 0.7112 - val_accuracy: 0.4375 - val_f1_score: 0.0426 - val_loss: 0.8207 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 21ms/step - accuracy: 0.5916 - f1_score: 0.5845 - loss: 0.7013 - val_accuracy: 0.5125 - val_f1_score: 0.6422 - val_loss: 0.8002 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 23ms/step - accuracy: 0.5729 - f1_score: 0.5627 - loss: 0.7639 - val_accuracy: 0.4625 - val_f1_score: 0.3582 - val_loss: 0.7783 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 21ms/step - accuracy: 0.5508 - f1_score: 0.5711 - loss: 0.7034 - val_accuracy: 0.4375 - val_f1_score: 0.1176 - val_loss: 0.8413 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 21ms/step - accuracy: 0.5738 - f1_score: 0.5528 - loss: 0.6737 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.7798 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 20ms/step - accuracy: 0.5803 - f1_score: 0.5650 - loss: 0.7149 - val_accuracy: 0.5250 - val_f1_score: 0.4571 - val_loss: 0.8129 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 21ms/step - accuracy: 0.5612 - f1_score: 0.5591 - loss: 0.7012 - val_accuracy: 0.4500 - val_f1_score: 0.3125 - val_loss: 0.7759 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 21ms/step - accuracy: 0.5890 - f1_score: 0.5800 - loss: 0.6747 - val_accuracy: 0.4750 - val_f1_score: 0.2500 - val_loss: 0.7812 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 21ms/step - accuracy: 0.5959 - f1_score: 0.6080 - loss: 0.6685 - val_accuracy: 0.4375 - val_f1_score: 0.0426 - val_loss: 0.8140 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 21ms/step - accuracy: 0.6107 - f1_score: 0.6085 - loss: 0.6660 - val_accuracy: 0.4500 - val_f1_score: 0.1852 - val_loss: 0.9017 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 21ms/step - accuracy: 0.6072 - f1_score: 0.6358 - loss: 0.6680 - val_accuracy: 0.5125 - val_f1_score: 0.3607 - val_loss: 0.7265 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 21ms/step - accuracy: 0.6059 - f1_score: 0.5972 - loss: 0.6468 - val_accuracy: 0.4250 - val_f1_score: 0.1154 - val_loss: 0.8170 - learning_rate: 4.9148e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\nmodel2 → Fold 6 Val F1 = 0.6852\n\n>>> Training model3 on Fold 6\nEpoch 1/200\n36/36 - 10s - 274ms/step - accuracy: 0.5035 - f1_score: 0.5975 - loss: 0.7375 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.6932 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 3s - 85ms/step - accuracy: 0.5655 - f1_score: 0.4122 - loss: 0.6868 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.6948 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 100ms/step - accuracy: 0.5877 - f1_score: 0.6289 - loss: 0.6695 - val_accuracy: 0.5625 - val_f1_score: 0.5333 - val_loss: 0.6779 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 3s - 97ms/step - accuracy: 0.6233 - f1_score: 0.6303 - loss: 0.6503 - val_accuracy: 0.5000 - val_f1_score: 0.4444 - val_loss: 0.7168 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 5s - 140ms/step - accuracy: 0.7001 - f1_score: 0.7259 - loss: 0.5460 - val_accuracy: 0.5875 - val_f1_score: 0.6526 - val_loss: 1.3002 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 3s - 97ms/step - accuracy: 0.7999 - f1_score: 0.8116 - loss: 0.4045 - val_accuracy: 0.4625 - val_f1_score: 0.5376 - val_loss: 1.5610 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 105ms/step - accuracy: 0.8694 - f1_score: 0.8787 - loss: 0.3210 - val_accuracy: 0.4125 - val_f1_score: 0.3562 - val_loss: 2.9864 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 94ms/step - accuracy: 0.8997 - f1_score: 0.9051 - loss: 0.2201 - val_accuracy: 0.5125 - val_f1_score: 0.6214 - val_loss: 3.9809 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 3s - 97ms/step - accuracy: 0.9245 - f1_score: 0.9252 - loss: 0.2287 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 2.9076 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 101ms/step - accuracy: 0.9575 - f1_score: 0.9595 - loss: 0.1116 - val_accuracy: 0.5125 - val_f1_score: 0.4935 - val_loss: 3.6425 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 3s - 97ms/step - accuracy: 0.9874 - f1_score: 0.9876 - loss: 0.0478 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 3.8875 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 3s - 87ms/step - accuracy: 0.9865 - f1_score: 0.9870 - loss: 0.0487 - val_accuracy: 0.4500 - val_f1_score: 0.3889 - val_loss: 4.5246 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 97ms/step - accuracy: 0.9905 - f1_score: 0.9908 - loss: 0.0341 - val_accuracy: 0.5000 - val_f1_score: 0.5000 - val_loss: 5.8598 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 3s - 86ms/step - accuracy: 0.9970 - f1_score: 0.9969 - loss: 0.0117 - val_accuracy: 0.4750 - val_f1_score: 0.4878 - val_loss: 4.8460 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 92ms/step - accuracy: 0.9957 - f1_score: 0.9955 - loss: 0.0112 - val_accuracy: 0.4250 - val_f1_score: 0.3429 - val_loss: 5.4586 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 99ms/step - accuracy: 0.9970 - f1_score: 0.9970 - loss: 0.0119 - val_accuracy: 0.4500 - val_f1_score: 0.4634 - val_loss: 9.1930 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 3s - 91ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0048 - val_accuracy: 0.4500 - val_f1_score: 0.3529 - val_loss: 13.2219 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 86ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0063 - val_accuracy: 0.4625 - val_f1_score: 0.5474 - val_loss: 9.4150 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 114ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0042 - val_accuracy: 0.4500 - val_f1_score: 0.4211 - val_loss: 10.2604 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 3s - 95ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0023 - val_accuracy: 0.4500 - val_f1_score: 0.4762 - val_loss: 10.9285 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 104ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.8870e-04 - val_accuracy: 0.4375 - val_f1_score: 0.4444 - val_loss: 12.7043 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 3s - 95ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2276e-04 - val_accuracy: 0.4500 - val_f1_score: 0.4884 - val_loss: 12.0376 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 4s - 106ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1467e-04 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 12.2698 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 4s - 101ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0440e-05 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 12.4624 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 4s - 109ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6263e-05 - val_accuracy: 0.4625 - val_f1_score: 0.4819 - val_loss: 12.5995 - learning_rate: 7.3832e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step\nmodel3 → Fold 6 Val F1 = 0.6526\n\n>>> Training model4 on Fold 6\nEpoch 1/200\n36/36 - 9s - 245ms/step - accuracy: 0.5017 - f1_score: 0.6019 - loss: 0.6927 - val_accuracy: 0.4875 - val_f1_score: 0.0889 - val_loss: 0.6959 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 119ms/step - accuracy: 0.5217 - f1_score: 0.3830 - loss: 0.6932 - val_accuracy: 0.5250 - val_f1_score: 0.6122 - val_loss: 0.6932 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 120ms/step - accuracy: 0.5026 - f1_score: 0.5492 - loss: 0.6930 - val_accuracy: 0.5250 - val_f1_score: 0.6885 - val_loss: 0.6912 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 120ms/step - accuracy: 0.5117 - f1_score: 0.4439 - loss: 0.6921 - val_accuracy: 0.4625 - val_f1_score: 0.3385 - val_loss: 0.6954 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 120ms/step - accuracy: 0.5521 - f1_score: 0.5474 - loss: 0.6899 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7005 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 120ms/step - accuracy: 0.5547 - f1_score: 0.4885 - loss: 0.6862 - val_accuracy: 0.4875 - val_f1_score: 0.4533 - val_loss: 0.7043 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 119ms/step - accuracy: 0.5260 - f1_score: 0.5714 - loss: 0.6921 - val_accuracy: 0.5125 - val_f1_score: 0.6723 - val_loss: 0.6966 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 120ms/step - accuracy: 0.5169 - f1_score: 0.5805 - loss: 0.6916 - val_accuracy: 0.5375 - val_f1_score: 0.6942 - val_loss: 0.6914 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 119ms/step - accuracy: 0.5386 - f1_score: 0.5736 - loss: 0.6868 - val_accuracy: 0.5000 - val_f1_score: 0.5556 - val_loss: 0.6935 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 120ms/step - accuracy: 0.5391 - f1_score: 0.5454 - loss: 0.6888 - val_accuracy: 0.4625 - val_f1_score: 0.4819 - val_loss: 0.7005 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 119ms/step - accuracy: 0.5573 - f1_score: 0.5689 - loss: 0.6863 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 0.7061 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 120ms/step - accuracy: 0.5703 - f1_score: 0.5858 - loss: 0.6788 - val_accuracy: 0.4875 - val_f1_score: 0.1961 - val_loss: 0.6978 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 119ms/step - accuracy: 0.5573 - f1_score: 0.5317 - loss: 0.6866 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 0.7016 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 120ms/step - accuracy: 0.5612 - f1_score: 0.5132 - loss: 0.6858 - val_accuracy: 0.4500 - val_f1_score: 0.5417 - val_loss: 0.6981 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 120ms/step - accuracy: 0.5642 - f1_score: 0.5049 - loss: 0.6850 - val_accuracy: 0.4625 - val_f1_score: 0.2951 - val_loss: 0.7131 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 119ms/step - accuracy: 0.5512 - f1_score: 0.5136 - loss: 0.6857 - val_accuracy: 0.4375 - val_f1_score: 0.3836 - val_loss: 0.7052 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 120ms/step - accuracy: 0.5816 - f1_score: 0.5618 - loss: 0.6772 - val_accuracy: 0.5000 - val_f1_score: 0.6154 - val_loss: 0.7068 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 119ms/step - accuracy: 0.5634 - f1_score: 0.5934 - loss: 0.6825 - val_accuracy: 0.4625 - val_f1_score: 0.5057 - val_loss: 0.7015 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 119ms/step - accuracy: 0.5612 - f1_score: 0.6021 - loss: 0.6825 - val_accuracy: 0.5250 - val_f1_score: 0.6275 - val_loss: 0.6978 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 120ms/step - accuracy: 0.5790 - f1_score: 0.5921 - loss: 0.6784 - val_accuracy: 0.4500 - val_f1_score: 0.5217 - val_loss: 0.6993 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 119ms/step - accuracy: 0.5664 - f1_score: 0.5700 - loss: 0.6778 - val_accuracy: 0.4750 - val_f1_score: 0.5714 - val_loss: 0.6993 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 4s - 119ms/step - accuracy: 0.5755 - f1_score: 0.5959 - loss: 0.6748 - val_accuracy: 0.5000 - val_f1_score: 0.6078 - val_loss: 0.7137 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 4s - 120ms/step - accuracy: 0.5712 - f1_score: 0.5674 - loss: 0.6764 - val_accuracy: 0.4625 - val_f1_score: 0.4557 - val_loss: 0.7197 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 4s - 120ms/step - accuracy: 0.5911 - f1_score: 0.5730 - loss: 0.6726 - val_accuracy: 0.4750 - val_f1_score: 0.4167 - val_loss: 0.7187 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 4s - 119ms/step - accuracy: 0.5590 - f1_score: 0.5724 - loss: 0.6772 - val_accuracy: 0.4875 - val_f1_score: 0.5941 - val_loss: 0.7045 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 4s - 119ms/step - accuracy: 0.5829 - f1_score: 0.5912 - loss: 0.6714 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.7284 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 4s - 120ms/step - accuracy: 0.5894 - f1_score: 0.5762 - loss: 0.6698 - val_accuracy: 0.4625 - val_f1_score: 0.3385 - val_loss: 0.7483 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 4s - 119ms/step - accuracy: 0.5942 - f1_score: 0.5809 - loss: 0.6625 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 0.7360 - learning_rate: 6.5084e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step\nmodel4 → Fold 6 Val F1 = 0.6942\n\n>>> Training model5 on Fold 6\nEpoch 1/200\n36/36 - 7s - 207ms/step - accuracy: 0.4918 - f1_score: 0.4848 - loss: 1.0196 - val_accuracy: 0.5250 - val_f1_score: 0.5000 - val_loss: 0.7465 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 38ms/step - accuracy: 0.4996 - f1_score: 0.4742 - loss: 0.7559 - val_accuracy: 0.5375 - val_f1_score: 0.5195 - val_loss: 0.8587 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 36ms/step - accuracy: 0.5195 - f1_score: 0.5549 - loss: 0.7207 - val_accuracy: 0.5250 - val_f1_score: 0.6200 - val_loss: 0.8362 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.5291 - f1_score: 0.5655 - loss: 0.7296 - val_accuracy: 0.5125 - val_f1_score: 0.5895 - val_loss: 0.6979 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 2s - 54ms/step - accuracy: 0.5334 - f1_score: 0.5515 - loss: 0.7244 - val_accuracy: 0.5250 - val_f1_score: 0.6833 - val_loss: 0.7134 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 36ms/step - accuracy: 0.5278 - f1_score: 0.5186 - loss: 0.7083 - val_accuracy: 0.5000 - val_f1_score: 0.6429 - val_loss: 0.7580 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 2s - 46ms/step - accuracy: 0.5742 - f1_score: 0.6205 - loss: 0.6943 - val_accuracy: 0.4750 - val_f1_score: 0.4750 - val_loss: 0.8948 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 35ms/step - accuracy: 0.6606 - f1_score: 0.6736 - loss: 0.6020 - val_accuracy: 0.5000 - val_f1_score: 0.5122 - val_loss: 0.9469 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 2s - 44ms/step - accuracy: 0.7357 - f1_score: 0.7390 - loss: 0.5209 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 1.1608 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 36ms/step - accuracy: 0.7691 - f1_score: 0.7843 - loss: 0.4634 - val_accuracy: 0.5125 - val_f1_score: 0.5517 - val_loss: 1.2112 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 35ms/step - accuracy: 0.8116 - f1_score: 0.8150 - loss: 0.4233 - val_accuracy: 0.4625 - val_f1_score: 0.4941 - val_loss: 1.3916 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 35ms/step - accuracy: 0.8364 - f1_score: 0.8425 - loss: 0.3586 - val_accuracy: 0.4500 - val_f1_score: 0.4762 - val_loss: 1.6189 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 34ms/step - accuracy: 0.8785 - f1_score: 0.8829 - loss: 0.2785 - val_accuracy: 0.5000 - val_f1_score: 0.5455 - val_loss: 1.9900 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 35ms/step - accuracy: 0.9080 - f1_score: 0.9071 - loss: 0.2342 - val_accuracy: 0.5000 - val_f1_score: 0.4595 - val_loss: 2.3624 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 36ms/step - accuracy: 0.9284 - f1_score: 0.9244 - loss: 0.1841 - val_accuracy: 0.5125 - val_f1_score: 0.5301 - val_loss: 2.8093 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 2s - 44ms/step - accuracy: 0.9436 - f1_score: 0.9436 - loss: 0.1516 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 3.5139 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 35ms/step - accuracy: 0.9553 - f1_score: 0.9560 - loss: 0.1300 - val_accuracy: 0.5750 - val_f1_score: 0.5143 - val_loss: 3.6008 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 2s - 42ms/step - accuracy: 0.9475 - f1_score: 0.9492 - loss: 0.1463 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 3.0610 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 35ms/step - accuracy: 0.9518 - f1_score: 0.9534 - loss: 0.1308 - val_accuracy: 0.5625 - val_f1_score: 0.4928 - val_loss: 3.4621 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 2s - 45ms/step - accuracy: 0.9692 - f1_score: 0.9693 - loss: 0.0954 - val_accuracy: 0.4875 - val_f1_score: 0.5287 - val_loss: 3.3584 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 35ms/step - accuracy: 0.9761 - f1_score: 0.9761 - loss: 0.0596 - val_accuracy: 0.5375 - val_f1_score: 0.5432 - val_loss: 3.6443 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 36ms/step - accuracy: 0.9809 - f1_score: 0.9814 - loss: 0.0526 - val_accuracy: 0.5375 - val_f1_score: 0.5542 - val_loss: 3.6521 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 2s - 44ms/step - accuracy: 0.9896 - f1_score: 0.9896 - loss: 0.0253 - val_accuracy: 0.5250 - val_f1_score: 0.5250 - val_loss: 4.6472 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 35ms/step - accuracy: 0.9935 - f1_score: 0.9933 - loss: 0.0249 - val_accuracy: 0.5375 - val_f1_score: 0.5432 - val_loss: 4.8427 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 2s - 47ms/step - accuracy: 0.9952 - f1_score: 0.9953 - loss: 0.0164 - val_accuracy: 0.5250 - val_f1_score: 0.4865 - val_loss: 5.1342 - learning_rate: 7.3832e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step\nmodel5 → Fold 6 Val F1 = 0.6833\n\n>>> Training model6 on Fold 6\nEpoch 1/200\n36/36 - 7s - 200ms/step - accuracy: 0.5109 - f1_score: 0.5283 - loss: 2.2177 - val_accuracy: 0.5250 - val_f1_score: 0.3667 - val_loss: 0.7647 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 40ms/step - accuracy: 0.5100 - f1_score: 0.4958 - loss: 0.8041 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7156 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 40ms/step - accuracy: 0.5009 - f1_score: 0.4947 - loss: 0.8176 - val_accuracy: 0.5375 - val_f1_score: 0.5647 - val_loss: 0.6818 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 40ms/step - accuracy: 0.5004 - f1_score: 0.4905 - loss: 0.7506 - val_accuracy: 0.4375 - val_f1_score: 0.4304 - val_loss: 0.6973 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 40ms/step - accuracy: 0.5143 - f1_score: 0.4729 - loss: 0.7172 - val_accuracy: 0.5875 - val_f1_score: 0.6667 - val_loss: 0.6823 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 40ms/step - accuracy: 0.5113 - f1_score: 0.4900 - loss: 0.7109 - val_accuracy: 0.5375 - val_f1_score: 0.6408 - val_loss: 0.6905 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 40ms/step - accuracy: 0.5043 - f1_score: 0.5111 - loss: 0.7415 - val_accuracy: 0.4875 - val_f1_score: 0.6095 - val_loss: 0.6925 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 39ms/step - accuracy: 0.5117 - f1_score: 0.5275 - loss: 0.7493 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6937 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 39ms/step - accuracy: 0.4839 - f1_score: 0.5117 - loss: 0.8035 - val_accuracy: 0.4125 - val_f1_score: 0.2985 - val_loss: 0.7007 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 39ms/step - accuracy: 0.4970 - f1_score: 0.5362 - loss: 0.8000 - val_accuracy: 0.4500 - val_f1_score: 0.1538 - val_loss: 0.6926 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.5529 - loss: 0.7503 - val_accuracy: 0.4750 - val_f1_score: 0.5882 - val_loss: 0.6936 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 39ms/step - accuracy: 0.5161 - f1_score: 0.6224 - loss: 0.7023 - val_accuracy: 0.5500 - val_f1_score: 0.6949 - val_loss: 0.6930 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 39ms/step - accuracy: 0.4996 - f1_score: 0.6064 - loss: 0.7040 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6897 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 39ms/step - accuracy: 0.4905 - f1_score: 0.5674 - loss: 0.7043 - val_accuracy: 0.5000 - val_f1_score: 0.5652 - val_loss: 0.6969 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 39ms/step - accuracy: 0.5182 - f1_score: 0.4302 - loss: 0.6975 - val_accuracy: 0.5125 - val_f1_score: 0.5714 - val_loss: 0.6952 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 39ms/step - accuracy: 0.5169 - f1_score: 0.4509 - loss: 0.6974 - val_accuracy: 0.4500 - val_f1_score: 0.2143 - val_loss: 0.6944 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 40ms/step - accuracy: 0.4926 - f1_score: 0.3144 - loss: 0.6965 - val_accuracy: 0.5875 - val_f1_score: 0.6374 - val_loss: 0.6931 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 39ms/step - accuracy: 0.5156 - f1_score: 0.6070 - loss: 0.6963 - val_accuracy: 0.5250 - val_f1_score: 0.6885 - val_loss: 0.6929 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 39ms/step - accuracy: 0.5056 - f1_score: 0.6047 - loss: 0.6967 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6916 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 40ms/step - accuracy: 0.5113 - f1_score: 0.5961 - loss: 0.6941 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6923 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 40ms/step - accuracy: 0.5078 - f1_score: 0.5727 - loss: 0.6945 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6917 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 39ms/step - accuracy: 0.5200 - f1_score: 0.5548 - loss: 0.6927 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.6922 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 39ms/step - accuracy: 0.4948 - f1_score: 0.5280 - loss: 0.6939 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.6938 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 39ms/step - accuracy: 0.5291 - f1_score: 0.4182 - loss: 0.6932 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6955 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 40ms/step - accuracy: 0.5052 - f1_score: 0.4865 - loss: 0.6931 - val_accuracy: 0.5625 - val_f1_score: 0.6903 - val_loss: 0.6916 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 39ms/step - accuracy: 0.5091 - f1_score: 0.6291 - loss: 0.6903 - val_accuracy: 0.5375 - val_f1_score: 0.6942 - val_loss: 0.6927 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 39ms/step - accuracy: 0.5078 - f1_score: 0.5279 - loss: 0.6934 - val_accuracy: 0.5250 - val_f1_score: 0.4062 - val_loss: 0.6920 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 39ms/step - accuracy: 0.5321 - f1_score: 0.4832 - loss: 0.6915 - val_accuracy: 0.5125 - val_f1_score: 0.3390 - val_loss: 0.6925 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 39ms/step - accuracy: 0.5417 - f1_score: 0.4007 - loss: 0.6890 - val_accuracy: 0.5250 - val_f1_score: 0.5581 - val_loss: 0.6929 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 39ms/step - accuracy: 0.5499 - f1_score: 0.5985 - loss: 0.6852 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.6931 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 39ms/step - accuracy: 0.5438 - f1_score: 0.5059 - loss: 0.6885 - val_accuracy: 0.5375 - val_f1_score: 0.5843 - val_loss: 0.6904 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 40ms/step - accuracy: 0.5182 - f1_score: 0.5674 - loss: 0.6906 - val_accuracy: 0.5125 - val_f1_score: 0.6723 - val_loss: 0.6940 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 40ms/step - accuracy: 0.5239 - f1_score: 0.6084 - loss: 0.6865 - val_accuracy: 0.5750 - val_f1_score: 0.6136 - val_loss: 0.6897 - learning_rate: 4.9148e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step\nmodel6 → Fold 6 Val F1 = 0.6992\n\n==================================================\nFold 7/30 - Subject: S15\n==================================================\nComputing CSP for current fold...\nComputing rank from data with rank=None\n    Using tolerance 3.2e+03 (2.2e-16 eps * 4 dim * 3.6e+18  max singular value)\n    Estimated rank (data): 4\n    data: rank 4 computed from 4 data channels with 0 projectors\nReducing data rank from 4 -> 4\nEstimating class=0 covariance using EMPIRICAL\nDone.\nEstimating class=1 covariance using EMPIRICAL\nDone.\n\n>>> Training oldA on Fold 7\nEpoch 1/200\n36/36 - 8s - 211ms/step - accuracy: 0.5078 - f1_score: 0.5435 - loss: 0.8736 - val_accuracy: 0.4375 - val_f1_score: 0.1509 - val_loss: 0.7050 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 28ms/step - accuracy: 0.5174 - f1_score: 0.4995 - loss: 0.7616 - val_accuracy: 0.4500 - val_f1_score: 0.0435 - val_loss: 0.7147 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 29ms/step - accuracy: 0.4974 - f1_score: 0.4862 - loss: 0.7501 - val_accuracy: 0.4500 - val_f1_score: 0.3333 - val_loss: 0.7044 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 28ms/step - accuracy: 0.4957 - f1_score: 0.5178 - loss: 0.7315 - val_accuracy: 0.5000 - val_f1_score: 0.2000 - val_loss: 0.7027 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 28ms/step - accuracy: 0.5230 - f1_score: 0.5244 - loss: 0.7103 - val_accuracy: 0.4375 - val_f1_score: 0.0816 - val_loss: 0.7054 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 28ms/step - accuracy: 0.5152 - f1_score: 0.4478 - loss: 0.7189 - val_accuracy: 0.4375 - val_f1_score: 0.1818 - val_loss: 0.7037 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 28ms/step - accuracy: 0.5217 - f1_score: 0.5311 - loss: 0.7080 - val_accuracy: 0.5000 - val_f1_score: 0.1667 - val_loss: 0.7036 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 28ms/step - accuracy: 0.5004 - f1_score: 0.4604 - loss: 0.7088 - val_accuracy: 0.5125 - val_f1_score: 0.4658 - val_loss: 0.7002 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.5312 - f1_score: 0.4669 - loss: 0.6957 - val_accuracy: 0.4750 - val_f1_score: 0.4167 - val_loss: 0.6989 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 28ms/step - accuracy: 0.5004 - f1_score: 0.3990 - loss: 0.7078 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7043 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 28ms/step - accuracy: 0.5286 - f1_score: 0.4302 - loss: 0.7031 - val_accuracy: 0.4625 - val_f1_score: 0.4691 - val_loss: 0.7045 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 28ms/step - accuracy: 0.5226 - f1_score: 0.4382 - loss: 0.7026 - val_accuracy: 0.5125 - val_f1_score: 0.3810 - val_loss: 0.6992 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 28ms/step - accuracy: 0.5395 - f1_score: 0.4430 - loss: 0.7016 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7056 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 28ms/step - accuracy: 0.5178 - f1_score: 0.4094 - loss: 0.7005 - val_accuracy: 0.4750 - val_f1_score: 0.3636 - val_loss: 0.7012 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 29ms/step - accuracy: 0.5208 - f1_score: 0.4315 - loss: 0.7014 - val_accuracy: 0.5250 - val_f1_score: 0.4062 - val_loss: 0.7012 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 29ms/step - accuracy: 0.5122 - f1_score: 0.5044 - loss: 0.7013 - val_accuracy: 0.4875 - val_f1_score: 0.3692 - val_loss: 0.7006 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 29ms/step - accuracy: 0.5347 - f1_score: 0.5051 - loss: 0.6969 - val_accuracy: 0.5375 - val_f1_score: 0.4932 - val_loss: 0.6963 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 28ms/step - accuracy: 0.5230 - f1_score: 0.5396 - loss: 0.7009 - val_accuracy: 0.4875 - val_f1_score: 0.5393 - val_loss: 0.6971 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 28ms/step - accuracy: 0.5152 - f1_score: 0.5394 - loss: 0.7012 - val_accuracy: 0.4750 - val_f1_score: 0.3824 - val_loss: 0.7004 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 28ms/step - accuracy: 0.5221 - f1_score: 0.5194 - loss: 0.6989 - val_accuracy: 0.5250 - val_f1_score: 0.4571 - val_loss: 0.6978 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 28ms/step - accuracy: 0.5035 - f1_score: 0.4856 - loss: 0.7036 - val_accuracy: 0.4500 - val_f1_score: 0.1852 - val_loss: 0.7032 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 28ms/step - accuracy: 0.5265 - f1_score: 0.5387 - loss: 0.6968 - val_accuracy: 0.5000 - val_f1_score: 0.5833 - val_loss: 0.7022 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 28ms/step - accuracy: 0.5200 - f1_score: 0.5663 - loss: 0.6942 - val_accuracy: 0.4875 - val_f1_score: 0.6306 - val_loss: 0.6987 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 29ms/step - accuracy: 0.5269 - f1_score: 0.5877 - loss: 0.6985 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.6997 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 29ms/step - accuracy: 0.5295 - f1_score: 0.5220 - loss: 0.6984 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.7036 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 28ms/step - accuracy: 0.5195 - f1_score: 0.5172 - loss: 0.7010 - val_accuracy: 0.4625 - val_f1_score: 0.2712 - val_loss: 0.7009 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 28ms/step - accuracy: 0.5148 - f1_score: 0.4867 - loss: 0.6985 - val_accuracy: 0.5125 - val_f1_score: 0.4658 - val_loss: 0.6987 - learning_rate: 6.8101e-04\nEpoch 28/200\n36/36 - 1s - 28ms/step - accuracy: 0.5174 - f1_score: 0.5280 - loss: 0.6976 - val_accuracy: 0.5250 - val_f1_score: 0.5366 - val_loss: 0.6948 - learning_rate: 6.5084e-04\nEpoch 29/200\n36/36 - 1s - 28ms/step - accuracy: 0.5269 - f1_score: 0.4991 - loss: 0.6997 - val_accuracy: 0.4875 - val_f1_score: 0.3051 - val_loss: 0.6989 - learning_rate: 6.1987e-04\nEpoch 30/200\n36/36 - 1s - 28ms/step - accuracy: 0.5187 - f1_score: 0.4952 - loss: 0.6980 - val_accuracy: 0.4875 - val_f1_score: 0.4810 - val_loss: 0.6995 - learning_rate: 5.8827e-04\nEpoch 31/200\n36/36 - 1s - 28ms/step - accuracy: 0.5365 - f1_score: 0.4929 - loss: 0.6978 - val_accuracy: 0.4875 - val_f1_score: 0.3279 - val_loss: 0.6988 - learning_rate: 5.5621e-04\nEpoch 32/200\n36/36 - 1s - 28ms/step - accuracy: 0.5503 - f1_score: 0.5400 - loss: 0.6942 - val_accuracy: 0.5875 - val_f1_score: 0.6374 - val_loss: 0.6974 - learning_rate: 5.2388e-04\nEpoch 33/200\n36/36 - 1s - 28ms/step - accuracy: 0.5213 - f1_score: 0.5260 - loss: 0.6940 - val_accuracy: 0.4750 - val_f1_score: 0.5000 - val_loss: 0.6951 - learning_rate: 4.9148e-04\nEpoch 34/200\n36/36 - 1s - 28ms/step - accuracy: 0.5373 - f1_score: 0.5224 - loss: 0.6938 - val_accuracy: 0.4875 - val_f1_score: 0.4058 - val_loss: 0.6967 - learning_rate: 4.5920e-04\nEpoch 35/200\n36/36 - 1s - 29ms/step - accuracy: 0.5408 - f1_score: 0.4673 - loss: 0.6950 - val_accuracy: 0.5000 - val_f1_score: 0.2308 - val_loss: 0.6999 - learning_rate: 4.2723e-04\nEpoch 36/200\n36/36 - 1s - 28ms/step - accuracy: 0.5334 - f1_score: 0.5443 - loss: 0.6929 - val_accuracy: 0.5250 - val_f1_score: 0.5250 - val_loss: 0.6990 - learning_rate: 3.9575e-04\nEpoch 37/200\n36/36 - 1s - 28ms/step - accuracy: 0.5195 - f1_score: 0.5151 - loss: 0.6939 - val_accuracy: 0.4750 - val_f1_score: 0.1923 - val_loss: 0.7014 - learning_rate: 3.6494e-04\nEpoch 38/200\n36/36 - 1s - 28ms/step - accuracy: 0.5308 - f1_score: 0.5441 - loss: 0.6920 - val_accuracy: 0.4625 - val_f1_score: 0.4110 - val_loss: 0.6982 - learning_rate: 3.3498e-04\nEpoch 39/200\n36/36 - 1s - 28ms/step - accuracy: 0.5408 - f1_score: 0.5314 - loss: 0.6881 - val_accuracy: 0.5125 - val_f1_score: 0.4179 - val_loss: 0.6982 - learning_rate: 3.0602e-04\nEpoch 40/200\n36/36 - 1s - 28ms/step - accuracy: 0.5299 - f1_score: 0.4720 - loss: 0.6929 - val_accuracy: 0.5000 - val_f1_score: 0.4118 - val_loss: 0.6970 - learning_rate: 2.7820e-04\nEpoch 41/200\n36/36 - 1s - 28ms/step - accuracy: 0.5595 - f1_score: 0.5137 - loss: 0.6877 - val_accuracy: 0.4875 - val_f1_score: 0.4533 - val_loss: 0.6961 - learning_rate: 2.5163e-04\nEpoch 42/200\n36/36 - 1s - 28ms/step - accuracy: 0.5490 - f1_score: 0.5421 - loss: 0.6930 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 0.6971 - learning_rate: 2.2643e-04\nEpoch 43/200\n36/36 - 1s - 28ms/step - accuracy: 0.5477 - f1_score: 0.5607 - loss: 0.6895 - val_accuracy: 0.5125 - val_f1_score: 0.5412 - val_loss: 0.6966 - learning_rate: 2.0267e-04\nEpoch 44/200\n36/36 - 1s - 28ms/step - accuracy: 0.5460 - f1_score: 0.5511 - loss: 0.6891 - val_accuracy: 0.5250 - val_f1_score: 0.5000 - val_loss: 0.6943 - learning_rate: 1.8042e-04\nEpoch 45/200\n36/36 - 1s - 29ms/step - accuracy: 0.5451 - f1_score: 0.5292 - loss: 0.6909 - val_accuracy: 0.4875 - val_f1_score: 0.4675 - val_loss: 0.6951 - learning_rate: 1.5972e-04\nEpoch 46/200\n36/36 - 1s - 28ms/step - accuracy: 0.5421 - f1_score: 0.5167 - loss: 0.6937 - val_accuracy: 0.4750 - val_f1_score: 0.4474 - val_loss: 0.6955 - learning_rate: 1.4058e-04\nEpoch 47/200\n36/36 - 1s - 28ms/step - accuracy: 0.5464 - f1_score: 0.5358 - loss: 0.6894 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.6954 - learning_rate: 1.2302e-04\nEpoch 48/200\n36/36 - 1s - 28ms/step - accuracy: 0.5473 - f1_score: 0.5411 - loss: 0.6884 - val_accuracy: 0.4750 - val_f1_score: 0.4750 - val_loss: 0.6958 - learning_rate: 1.0700e-04\nEpoch 49/200\n36/36 - 1s - 28ms/step - accuracy: 0.5503 - f1_score: 0.5412 - loss: 0.6869 - val_accuracy: 0.5250 - val_f1_score: 0.5476 - val_loss: 0.6953 - learning_rate: 9.2503e-05\nEpoch 50/200\n36/36 - 1s - 28ms/step - accuracy: 0.5369 - f1_score: 0.5178 - loss: 0.6923 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.6960 - learning_rate: 7.9466e-05\nEpoch 51/200\n36/36 - 1s - 28ms/step - accuracy: 0.5460 - f1_score: 0.5245 - loss: 0.6879 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 0.6964 - learning_rate: 6.7829e-05\nEpoch 52/200\n36/36 - 1s - 28ms/step - accuracy: 0.5386 - f1_score: 0.5348 - loss: 0.6908 - val_accuracy: 0.4875 - val_f1_score: 0.4675 - val_loss: 0.6964 - learning_rate: 5.7516e-05\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step\noldA → Fold 7 Val F1 = 0.6374\n\n>>> Training oldB on Fold 7\nEpoch 1/200\n36/36 - 13s - 366ms/step - accuracy: 0.4935 - f1_score: 0.5095 - loss: 2.9297 - val_accuracy: 0.6000 - val_f1_score: 0.6863 - val_loss: 0.7271 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 36ms/step - accuracy: 0.4983 - f1_score: 0.4939 - loss: 2.0095 - val_accuracy: 0.5125 - val_f1_score: 0.5714 - val_loss: 0.7421 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 35ms/step - accuracy: 0.5152 - f1_score: 0.5154 - loss: 1.4916 - val_accuracy: 0.4500 - val_f1_score: 0.0435 - val_loss: 0.7504 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.5000 - f1_score: 0.5119 - loss: 1.1899 - val_accuracy: 0.5000 - val_f1_score: 0.2308 - val_loss: 0.7463 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 35ms/step - accuracy: 0.4987 - f1_score: 0.5015 - loss: 1.0180 - val_accuracy: 0.4500 - val_f1_score: 0.1538 - val_loss: 0.7481 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 36ms/step - accuracy: 0.5117 - f1_score: 0.4804 - loss: 0.9051 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7511 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 36ms/step - accuracy: 0.4891 - f1_score: 0.4691 - loss: 0.8616 - val_accuracy: 0.4625 - val_f1_score: 0.0444 - val_loss: 0.7516 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 36ms/step - accuracy: 0.5087 - f1_score: 0.4715 - loss: 0.8575 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7507 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 36ms/step - accuracy: 0.4857 - f1_score: 0.3882 - loss: 0.8224 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7490 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 35ms/step - accuracy: 0.5104 - f1_score: 0.4498 - loss: 0.7981 - val_accuracy: 0.4625 - val_f1_score: 0.0851 - val_loss: 0.7500 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 36ms/step - accuracy: 0.5187 - f1_score: 0.4385 - loss: 0.7995 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7517 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 36ms/step - accuracy: 0.5122 - f1_score: 0.4078 - loss: 0.7946 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7502 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 35ms/step - accuracy: 0.5065 - f1_score: 0.4899 - loss: 0.7774 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7488 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 36ms/step - accuracy: 0.5174 - f1_score: 0.4490 - loss: 0.7696 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7497 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 35ms/step - accuracy: 0.4792 - f1_score: 0.3933 - loss: 0.7820 - val_accuracy: 0.4500 - val_f1_score: 0.1200 - val_loss: 0.7485 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 36ms/step - accuracy: 0.5069 - f1_score: 0.4198 - loss: 0.7699 - val_accuracy: 0.4875 - val_f1_score: 0.0889 - val_loss: 0.7485 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 36ms/step - accuracy: 0.5022 - f1_score: 0.5262 - loss: 0.7684 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7494 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 35ms/step - accuracy: 0.4987 - f1_score: 0.4302 - loss: 0.7633 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.7476 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 36ms/step - accuracy: 0.5143 - f1_score: 0.4993 - loss: 0.7535 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7495 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 35ms/step - accuracy: 0.4900 - f1_score: 0.4455 - loss: 0.7668 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7487 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 36ms/step - accuracy: 0.5109 - f1_score: 0.4948 - loss: 0.7613 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7479 - learning_rate: 8.3736e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\noldB → Fold 7 Val F1 = 0.6863\n\n>>> Training model1 on Fold 7\nEpoch 1/200\n36/36 - 25s - 704ms/step - accuracy: 0.4831 - f1_score: 0.5048 - loss: 0.6941 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6938 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 2s - 43ms/step - accuracy: 0.5078 - f1_score: 0.2693 - loss: 0.6931 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6959 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 2s - 42ms/step - accuracy: 0.4935 - f1_score: 0.4595 - loss: 0.6936 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6921 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 36ms/step - accuracy: 0.5135 - f1_score: 0.6594 - loss: 0.6927 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6910 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 34ms/step - accuracy: 0.5117 - f1_score: 0.6026 - loss: 0.6924 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6956 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 30ms/step - accuracy: 0.5087 - f1_score: 0.2898 - loss: 0.6931 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6966 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 30ms/step - accuracy: 0.5156 - f1_score: 0.6009 - loss: 0.6901 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6911 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 29ms/step - accuracy: 0.4831 - f1_score: 0.6117 - loss: 0.6937 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6932 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 28ms/step - accuracy: 0.4957 - f1_score: 0.4041 - loss: 0.6934 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6944 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 30ms/step - accuracy: 0.5022 - f1_score: 0.0000e+00 - loss: 0.6933 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6938 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 30ms/step - accuracy: 0.5078 - f1_score: 0.0000e+00 - loss: 0.6931 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6939 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 29ms/step - accuracy: 0.5095 - f1_score: 0.0000e+00 - loss: 0.6931 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6942 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 29ms/step - accuracy: 0.5135 - f1_score: 0.0476 - loss: 0.6930 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6942 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 30ms/step - accuracy: 0.4996 - f1_score: 0.0384 - loss: 0.6934 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6942 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 29ms/step - accuracy: 0.4835 - f1_score: 0.2212 - loss: 0.6929 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6930 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 29ms/step - accuracy: 0.5095 - f1_score: 0.6732 - loss: 0.6925 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6925 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 30ms/step - accuracy: 0.5143 - f1_score: 0.6774 - loss: 0.6935 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6923 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 29ms/step - accuracy: 0.5139 - f1_score: 0.6785 - loss: 0.6925 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6916 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 30ms/step - accuracy: 0.5035 - f1_score: 0.5640 - loss: 0.6942 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6963 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 34ms/step - accuracy: 0.5095 - f1_score: 0.6060 - loss: 0.6935 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6910 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 34ms/step - accuracy: 0.4852 - f1_score: 0.5392 - loss: 0.6934 - val_accuracy: 0.5500 - val_f1_score: 0.6604 - val_loss: 0.6929 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 29ms/step - accuracy: 0.5265 - f1_score: 0.6502 - loss: 0.6920 - val_accuracy: 0.5625 - val_f1_score: 0.6789 - val_loss: 0.6910 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 30ms/step - accuracy: 0.5386 - f1_score: 0.6393 - loss: 0.6907 - val_accuracy: 0.5125 - val_f1_score: 0.6061 - val_loss: 0.6909 - learning_rate: 7.9071e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step\nmodel1 → Fold 7 Val F1 = 0.6992\n\n>>> Training model2 on Fold 7\nEpoch 1/200\n36/36 - 4s - 122ms/step - accuracy: 0.5017 - f1_score: 0.5233 - loss: 5.1609 - val_accuracy: 0.4750 - val_f1_score: 0.5116 - val_loss: 1.5202 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 22ms/step - accuracy: 0.5195 - f1_score: 0.5291 - loss: 1.6186 - val_accuracy: 0.4750 - val_f1_score: 0.5000 - val_loss: 1.0097 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 22ms/step - accuracy: 0.5130 - f1_score: 0.5439 - loss: 1.4281 - val_accuracy: 0.4750 - val_f1_score: 0.5882 - val_loss: 0.8951 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 21ms/step - accuracy: 0.5195 - f1_score: 0.5446 - loss: 1.6194 - val_accuracy: 0.4750 - val_f1_score: 0.5962 - val_loss: 0.7616 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 20ms/step - accuracy: 0.5299 - f1_score: 0.5231 - loss: 1.2292 - val_accuracy: 0.5125 - val_f1_score: 0.6486 - val_loss: 0.8003 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 21ms/step - accuracy: 0.5148 - f1_score: 0.4666 - loss: 1.0397 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.9250 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 20ms/step - accuracy: 0.5599 - f1_score: 0.5789 - loss: 0.8680 - val_accuracy: 0.5500 - val_f1_score: 0.7000 - val_loss: 0.8944 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 20ms/step - accuracy: 0.5473 - f1_score: 0.5541 - loss: 0.9909 - val_accuracy: 0.4125 - val_f1_score: 0.4471 - val_loss: 0.7679 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 23ms/step - accuracy: 0.5456 - f1_score: 0.5040 - loss: 0.9028 - val_accuracy: 0.5250 - val_f1_score: 0.6346 - val_loss: 0.7199 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 22ms/step - accuracy: 0.5412 - f1_score: 0.5232 - loss: 0.8515 - val_accuracy: 0.4625 - val_f1_score: 0.4819 - val_loss: 0.7543 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 21ms/step - accuracy: 0.5451 - f1_score: 0.5309 - loss: 0.8319 - val_accuracy: 0.4875 - val_f1_score: 0.5060 - val_loss: 0.7149 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 21ms/step - accuracy: 0.5412 - f1_score: 0.4930 - loss: 0.9061 - val_accuracy: 0.4875 - val_f1_score: 0.5773 - val_loss: 0.7385 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 21ms/step - accuracy: 0.5330 - f1_score: 0.5362 - loss: 0.8156 - val_accuracy: 0.4625 - val_f1_score: 0.0444 - val_loss: 0.8220 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 21ms/step - accuracy: 0.5534 - f1_score: 0.5408 - loss: 0.8061 - val_accuracy: 0.4625 - val_f1_score: 0.1569 - val_loss: 0.7988 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 21ms/step - accuracy: 0.5543 - f1_score: 0.5605 - loss: 0.8312 - val_accuracy: 0.5125 - val_f1_score: 0.4800 - val_loss: 0.7357 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 21ms/step - accuracy: 0.5508 - f1_score: 0.5746 - loss: 0.7566 - val_accuracy: 0.4000 - val_f1_score: 0.1724 - val_loss: 0.7523 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 21ms/step - accuracy: 0.5495 - f1_score: 0.5564 - loss: 0.7394 - val_accuracy: 0.4875 - val_f1_score: 0.4938 - val_loss: 0.7349 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 20ms/step - accuracy: 0.5694 - f1_score: 0.5964 - loss: 0.7306 - val_accuracy: 0.6000 - val_f1_score: 0.6800 - val_loss: 0.7104 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 20ms/step - accuracy: 0.5668 - f1_score: 0.5328 - loss: 0.7116 - val_accuracy: 0.4125 - val_f1_score: 0.2985 - val_loss: 0.7483 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 1s - 20ms/step - accuracy: 0.5812 - f1_score: 0.6004 - loss: 0.6906 - val_accuracy: 0.4500 - val_f1_score: 0.3125 - val_loss: 0.7815 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 20ms/step - accuracy: 0.5846 - f1_score: 0.5855 - loss: 0.7093 - val_accuracy: 0.5000 - val_f1_score: 0.5745 - val_loss: 0.7240 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 20ms/step - accuracy: 0.5556 - f1_score: 0.5748 - loss: 0.7187 - val_accuracy: 0.4875 - val_f1_score: 0.4384 - val_loss: 0.7529 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 20ms/step - accuracy: 0.5642 - f1_score: 0.5792 - loss: 0.7158 - val_accuracy: 0.5250 - val_f1_score: 0.6122 - val_loss: 0.7205 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 1s - 20ms/step - accuracy: 0.5807 - f1_score: 0.5951 - loss: 0.6767 - val_accuracy: 0.4625 - val_f1_score: 0.4267 - val_loss: 0.7710 - learning_rate: 7.6518e-04\nEpoch 25/200\n36/36 - 1s - 20ms/step - accuracy: 0.5907 - f1_score: 0.5884 - loss: 0.6836 - val_accuracy: 0.4250 - val_f1_score: 0.3235 - val_loss: 0.7477 - learning_rate: 7.3832e-04\nEpoch 26/200\n36/36 - 1s - 21ms/step - accuracy: 0.5712 - f1_score: 0.5763 - loss: 0.7033 - val_accuracy: 0.3500 - val_f1_score: 0.1875 - val_loss: 0.7565 - learning_rate: 7.1022e-04\nEpoch 27/200\n36/36 - 1s - 20ms/step - accuracy: 0.5816 - f1_score: 0.5922 - loss: 0.6791 - val_accuracy: 0.5375 - val_f1_score: 0.5316 - val_loss: 0.7452 - learning_rate: 6.8101e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\nmodel2 → Fold 7 Val F1 = 0.7000\n\n>>> Training model3 on Fold 7\nEpoch 1/200\n36/36 - 9s - 239ms/step - accuracy: 0.5022 - f1_score: 0.6065 - loss: 0.7880 - val_accuracy: 0.4875 - val_f1_score: 0.5591 - val_loss: 0.6942 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 3s - 81ms/step - accuracy: 0.5369 - f1_score: 0.5618 - loss: 0.6884 - val_accuracy: 0.5625 - val_f1_score: 0.5455 - val_loss: 0.6923 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 3s - 93ms/step - accuracy: 0.5434 - f1_score: 0.5587 - loss: 0.6875 - val_accuracy: 0.5375 - val_f1_score: 0.6992 - val_loss: 0.6910 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 99ms/step - accuracy: 0.5820 - f1_score: 0.6831 - loss: 0.6750 - val_accuracy: 0.5500 - val_f1_score: 0.6842 - val_loss: 0.6914 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 105ms/step - accuracy: 0.6437 - f1_score: 0.6794 - loss: 0.6135 - val_accuracy: 0.4250 - val_f1_score: 0.3030 - val_loss: 0.7831 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 3s - 88ms/step - accuracy: 0.7266 - f1_score: 0.6850 - loss: 0.5324 - val_accuracy: 0.5250 - val_f1_score: 0.5128 - val_loss: 0.7447 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 3s - 91ms/step - accuracy: 0.8060 - f1_score: 0.7975 - loss: 0.4143 - val_accuracy: 0.5250 - val_f1_score: 0.5957 - val_loss: 0.9059 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 3s - 86ms/step - accuracy: 0.8733 - f1_score: 0.8738 - loss: 0.3132 - val_accuracy: 0.5250 - val_f1_score: 0.5957 - val_loss: 1.5293 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 99ms/step - accuracy: 0.9110 - f1_score: 0.9078 - loss: 0.2206 - val_accuracy: 0.5250 - val_f1_score: 0.5870 - val_loss: 1.5114 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 111ms/step - accuracy: 0.9462 - f1_score: 0.9460 - loss: 0.1682 - val_accuracy: 0.4125 - val_f1_score: 0.4198 - val_loss: 2.1647 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 3s - 91ms/step - accuracy: 0.9714 - f1_score: 0.9708 - loss: 0.1167 - val_accuracy: 0.4250 - val_f1_score: 0.4889 - val_loss: 2.6210 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 98ms/step - accuracy: 0.9727 - f1_score: 0.9723 - loss: 0.0976 - val_accuracy: 0.4375 - val_f1_score: 0.4706 - val_loss: 2.5469 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 99ms/step - accuracy: 0.9922 - f1_score: 0.9920 - loss: 0.0370 - val_accuracy: 0.4500 - val_f1_score: 0.4634 - val_loss: 2.4496 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 3s - 86ms/step - accuracy: 0.9931 - f1_score: 0.9930 - loss: 0.0238 - val_accuracy: 0.4375 - val_f1_score: 0.4156 - val_loss: 2.9299 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 3s - 82ms/step - accuracy: 0.9983 - f1_score: 0.9983 - loss: 0.0088 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 3.5871 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 3s - 95ms/step - accuracy: 0.9991 - f1_score: 0.9991 - loss: 0.0060 - val_accuracy: 0.4500 - val_f1_score: 0.4500 - val_loss: 4.6172 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 104ms/step - accuracy: 0.9991 - f1_score: 0.9992 - loss: 0.0028 - val_accuracy: 0.4250 - val_f1_score: 0.4390 - val_loss: 6.0013 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 3s - 81ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0609e-04 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 7.1202 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 3s - 93ms/step - accuracy: 0.9974 - f1_score: 0.9973 - loss: 0.0177 - val_accuracy: 0.4000 - val_f1_score: 0.3143 - val_loss: 3.7849 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 109ms/step - accuracy: 0.9952 - f1_score: 0.9953 - loss: 0.0217 - val_accuracy: 0.4125 - val_f1_score: 0.3733 - val_loss: 3.3737 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 107ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0017 - val_accuracy: 0.4500 - val_f1_score: 0.4359 - val_loss: 5.9785 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 4s - 98ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3259e-04 - val_accuracy: 0.4875 - val_f1_score: 0.5060 - val_loss: 5.8538 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 3s - 97ms/step - accuracy: 0.9996 - f1_score: 0.9996 - loss: 9.3685e-04 - val_accuracy: 0.4375 - val_f1_score: 0.4304 - val_loss: 6.3996 - learning_rate: 7.9071e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step\nmodel3 → Fold 7 Val F1 = 0.6992\n\n>>> Training model4 on Fold 7\nEpoch 1/200\n36/36 - 9s - 245ms/step - accuracy: 0.5017 - f1_score: 0.5720 - loss: 0.6936 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6959 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 4s - 118ms/step - accuracy: 0.5247 - f1_score: 0.2505 - loss: 0.6926 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6972 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 4s - 119ms/step - accuracy: 0.4857 - f1_score: 0.3361 - loss: 0.6935 - val_accuracy: 0.4125 - val_f1_score: 0.4946 - val_loss: 0.6938 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 4s - 118ms/step - accuracy: 0.5117 - f1_score: 0.5905 - loss: 0.6914 - val_accuracy: 0.5125 - val_f1_score: 0.6667 - val_loss: 0.6935 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 4s - 119ms/step - accuracy: 0.5291 - f1_score: 0.5167 - loss: 0.6914 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7002 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 4s - 119ms/step - accuracy: 0.5234 - f1_score: 0.3624 - loss: 0.6928 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6958 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 4s - 119ms/step - accuracy: 0.5382 - f1_score: 0.5065 - loss: 0.6901 - val_accuracy: 0.4500 - val_f1_score: 0.3889 - val_loss: 0.6994 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 4s - 119ms/step - accuracy: 0.5161 - f1_score: 0.4595 - loss: 0.6927 - val_accuracy: 0.5375 - val_f1_score: 0.4478 - val_loss: 0.6936 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 4s - 119ms/step - accuracy: 0.5391 - f1_score: 0.5115 - loss: 0.6908 - val_accuracy: 0.4750 - val_f1_score: 0.5227 - val_loss: 0.7091 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 4s - 119ms/step - accuracy: 0.5365 - f1_score: 0.4846 - loss: 0.6907 - val_accuracy: 0.4000 - val_f1_score: 0.5102 - val_loss: 0.6996 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 4s - 119ms/step - accuracy: 0.5334 - f1_score: 0.5076 - loss: 0.6909 - val_accuracy: 0.3750 - val_f1_score: 0.0385 - val_loss: 0.7028 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 4s - 119ms/step - accuracy: 0.5664 - f1_score: 0.4916 - loss: 0.6855 - val_accuracy: 0.4375 - val_f1_score: 0.0000e+00 - val_loss: 0.7132 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 4s - 119ms/step - accuracy: 0.5647 - f1_score: 0.4795 - loss: 0.6858 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.7103 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 4s - 118ms/step - accuracy: 0.5516 - f1_score: 0.4187 - loss: 0.6889 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7050 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 4s - 119ms/step - accuracy: 0.5382 - f1_score: 0.5224 - loss: 0.6901 - val_accuracy: 0.4250 - val_f1_score: 0.1786 - val_loss: 0.6998 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 4s - 119ms/step - accuracy: 0.5668 - f1_score: 0.5146 - loss: 0.6833 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7084 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 4s - 119ms/step - accuracy: 0.5634 - f1_score: 0.5250 - loss: 0.6851 - val_accuracy: 0.4000 - val_f1_score: 0.1724 - val_loss: 0.7144 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 4s - 119ms/step - accuracy: 0.5443 - f1_score: 0.4966 - loss: 0.6869 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.6946 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 4s - 119ms/step - accuracy: 0.5543 - f1_score: 0.4659 - loss: 0.6863 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7086 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 4s - 119ms/step - accuracy: 0.5473 - f1_score: 0.5415 - loss: 0.6825 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.7036 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 4s - 119ms/step - accuracy: 0.5556 - f1_score: 0.5067 - loss: 0.6833 - val_accuracy: 0.3875 - val_f1_score: 0.4368 - val_loss: 0.7021 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 4s - 119ms/step - accuracy: 0.5469 - f1_score: 0.4887 - loss: 0.6851 - val_accuracy: 0.4750 - val_f1_score: 0.0455 - val_loss: 0.7054 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 4s - 119ms/step - accuracy: 0.5525 - f1_score: 0.4178 - loss: 0.6824 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 0.6994 - learning_rate: 7.9071e-04\nEpoch 24/200\n36/36 - 4s - 118ms/step - accuracy: 0.5664 - f1_score: 0.5172 - loss: 0.6811 - val_accuracy: 0.4125 - val_f1_score: 0.0784 - val_loss: 0.7117 - learning_rate: 7.6518e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step\nmodel4 → Fold 7 Val F1 = 0.6667\n\n>>> Training model5 on Fold 7\nEpoch 1/200\n36/36 - 7s - 201ms/step - accuracy: 0.5082 - f1_score: 0.5097 - loss: 1.1517 - val_accuracy: 0.5250 - val_f1_score: 0.6545 - val_loss: 0.7564 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 33ms/step - accuracy: 0.5234 - f1_score: 0.4907 - loss: 0.7826 - val_accuracy: 0.5375 - val_f1_score: 0.5747 - val_loss: 0.7011 - learning_rate: 9.9994e-04\nEpoch 3/200\n36/36 - 1s - 33ms/step - accuracy: 0.5182 - f1_score: 0.5539 - loss: 0.7262 - val_accuracy: 0.5500 - val_f1_score: 0.7000 - val_loss: 0.6882 - learning_rate: 9.9969e-04\nEpoch 4/200\n36/36 - 1s - 34ms/step - accuracy: 0.5195 - f1_score: 0.5581 - loss: 0.7101 - val_accuracy: 0.5250 - val_f1_score: 0.6885 - val_loss: 0.7011 - learning_rate: 9.9914e-04\nEpoch 5/200\n36/36 - 1s - 33ms/step - accuracy: 0.4970 - f1_score: 0.4901 - loss: 0.7455 - val_accuracy: 0.4750 - val_f1_score: 0.2759 - val_loss: 0.7798 - learning_rate: 9.9815e-04\nEpoch 6/200\n36/36 - 1s - 33ms/step - accuracy: 0.5269 - f1_score: 0.4704 - loss: 0.7301 - val_accuracy: 0.5125 - val_f1_score: 0.6355 - val_loss: 0.7032 - learning_rate: 9.9661e-04\nEpoch 7/200\n36/36 - 1s - 33ms/step - accuracy: 0.5460 - f1_score: 0.5638 - loss: 0.7406 - val_accuracy: 0.5125 - val_f1_score: 0.6061 - val_loss: 0.7654 - learning_rate: 9.9440e-04\nEpoch 8/200\n36/36 - 1s - 32ms/step - accuracy: 0.6107 - f1_score: 0.6033 - loss: 0.6651 - val_accuracy: 0.4500 - val_f1_score: 0.2143 - val_loss: 0.7704 - learning_rate: 9.9140e-04\nEpoch 9/200\n36/36 - 1s - 32ms/step - accuracy: 0.6532 - f1_score: 0.6347 - loss: 0.6076 - val_accuracy: 0.4375 - val_f1_score: 0.3836 - val_loss: 0.9218 - learning_rate: 9.8749e-04\nEpoch 10/200\n36/36 - 1s - 34ms/step - accuracy: 0.7361 - f1_score: 0.7261 - loss: 0.5300 - val_accuracy: 0.4875 - val_f1_score: 0.4675 - val_loss: 0.9374 - learning_rate: 9.8256e-04\nEpoch 11/200\n36/36 - 1s - 38ms/step - accuracy: 0.7891 - f1_score: 0.7789 - loss: 0.4340 - val_accuracy: 0.4375 - val_f1_score: 0.4944 - val_loss: 1.1817 - learning_rate: 9.7652e-04\nEpoch 12/200\n36/36 - 1s - 32ms/step - accuracy: 0.8507 - f1_score: 0.8443 - loss: 0.3571 - val_accuracy: 0.4750 - val_f1_score: 0.4878 - val_loss: 1.3987 - learning_rate: 9.6924e-04\nEpoch 13/200\n36/36 - 1s - 33ms/step - accuracy: 0.8737 - f1_score: 0.8678 - loss: 0.2849 - val_accuracy: 0.4250 - val_f1_score: 0.3429 - val_loss: 1.6800 - learning_rate: 9.6066e-04\nEpoch 14/200\n36/36 - 1s - 32ms/step - accuracy: 0.9106 - f1_score: 0.9096 - loss: 0.2243 - val_accuracy: 0.5500 - val_f1_score: 0.5135 - val_loss: 1.7578 - learning_rate: 9.5068e-04\nEpoch 15/200\n36/36 - 1s - 32ms/step - accuracy: 0.9336 - f1_score: 0.9347 - loss: 0.1709 - val_accuracy: 0.4875 - val_f1_score: 0.4384 - val_loss: 1.6326 - learning_rate: 9.3923e-04\nEpoch 16/200\n36/36 - 1s - 32ms/step - accuracy: 0.9557 - f1_score: 0.9563 - loss: 0.1178 - val_accuracy: 0.5500 - val_f1_score: 0.5610 - val_loss: 2.0855 - learning_rate: 9.2626e-04\nEpoch 17/200\n36/36 - 1s - 32ms/step - accuracy: 0.9753 - f1_score: 0.9758 - loss: 0.0810 - val_accuracy: 0.4625 - val_f1_score: 0.5057 - val_loss: 2.7483 - learning_rate: 9.1171e-04\nEpoch 18/200\n36/36 - 1s - 33ms/step - accuracy: 0.9783 - f1_score: 0.9789 - loss: 0.0793 - val_accuracy: 0.5250 - val_f1_score: 0.5366 - val_loss: 2.5896 - learning_rate: 8.9555e-04\nEpoch 19/200\n36/36 - 1s - 42ms/step - accuracy: 0.9727 - f1_score: 0.9721 - loss: 0.0749 - val_accuracy: 0.5000 - val_f1_score: 0.4872 - val_loss: 3.0502 - learning_rate: 8.7777e-04\nEpoch 20/200\n36/36 - 2s - 42ms/step - accuracy: 0.9809 - f1_score: 0.9813 - loss: 0.0564 - val_accuracy: 0.5250 - val_f1_score: 0.5366 - val_loss: 2.8489 - learning_rate: 8.5837e-04\nEpoch 21/200\n36/36 - 1s - 33ms/step - accuracy: 0.9800 - f1_score: 0.9803 - loss: 0.0684 - val_accuracy: 0.5500 - val_f1_score: 0.5714 - val_loss: 2.6706 - learning_rate: 8.3736e-04\nEpoch 22/200\n36/36 - 1s - 34ms/step - accuracy: 0.9844 - f1_score: 0.9845 - loss: 0.0616 - val_accuracy: 0.4875 - val_f1_score: 0.4810 - val_loss: 2.8238 - learning_rate: 8.1479e-04\nEpoch 23/200\n36/36 - 1s - 33ms/step - accuracy: 0.9757 - f1_score: 0.9762 - loss: 0.0776 - val_accuracy: 0.5500 - val_f1_score: 0.5500 - val_loss: 2.6753 - learning_rate: 7.9071e-04\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step\nmodel5 → Fold 7 Val F1 = 0.7000\n\n>>> Training model6 on Fold 7\nEpoch 1/200\n36/36 - 7s - 198ms/step - accuracy: 0.4974 - f1_score: 0.5254 - loss: 3.0424 - val_accuracy: 0.4625 - val_f1_score: 0.0000e+00 - val_loss: 1.0063 - learning_rate: 0.0010\nEpoch 2/200\n36/36 - 1s - 39ms/step - accuracy: 0.5091 - f1_score: 0.4814 - loss: 1.1587 - val_accuracy: 0.5875 - val_f1_score: 0.4590 - val_loss: 0.7171 - learning_rate: 9.9994e-04\nEpoch 3/200\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}