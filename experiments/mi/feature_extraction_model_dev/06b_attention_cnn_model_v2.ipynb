{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"},{"sourceId":12255931,"sourceType":"datasetVersion","datasetId":7722631}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import (\n    Conv1D, MaxPooling1D, Dense, Activation, Flatten, Input, \n    GlobalAveragePooling1D, Multiply, Add, Concatenate, BatchNormalization,\n    Reshape, Dropout\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport numpy as np\nimport pandas as pd\nfrom scipy.signal import butter, filtfilt, iirnotch\nfrom sklearn.preprocessing import LabelEncoder\n\n# Configuration\nBASE_PATH = '/kaggle/input/mtcaic3'\nEEG_CHANNELS = ['C3', 'CZ', 'C4']  # Matching BCI Competition 2008 channels\nFS = 250  # Sampling frequency\nNOTCH_FREQ = 50.0  # Notch frequency (Hz)\nLOWCUT = 4.0       # Bandpass low cutoff (Hz)\nHIGHCUT = 40.0     # Bandpass high cutoff (Hz)\nTRIAL_LENGTH = 1000  # Use first 4 seconds (1000 samples)\n\n# Preprocessing functions\ndef butter_bandpass(lowcut, highcut, fs, order=4):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\ndef butter_notch(f0, fs, Q=30):\n    w0 = f0 / (fs / 2)\n    b, a = iirnotch(w0, Q)\n    return b, a\n\ndef apply_filters(data, fs=FS):\n    \"\"\"Apply notch and bandpass filters to EEG data\"\"\"\n    # Notch filter\n    b_notch, a_notch = butter_notch(NOTCH_FREQ, fs)\n    data = filtfilt(b_notch, a_notch, data, axis=0)\n    \n    # Bandpass filter\n    b_band, a_band = butter_bandpass(LOWCUT, HIGHCUT, fs)\n    data = filtfilt(b_band, a_band, data, axis=0)\n    \n    return data\n\ndef normalize(data):\n    \"\"\"Z-score normalization per channel\"\"\"\n    return (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n\n# Load dataset index\ntrain_df = pd.read_csv(f'{BASE_PATH}/train.csv')\nval_df = pd.read_csv(f'{BASE_PATH}/validation.csv')\n\n# Filter MI tasks only\ntrain_mi = train_df[train_df['task'] == 'MI'].copy()\nval_mi = val_df[val_df['task'] == 'MI'].copy()\n\n# Encode labels\nle = LabelEncoder()\ntrain_mi['label_encoded'] = le.fit_transform(train_mi['label'])\nval_mi['label_encoded'] = le.transform(val_mi['label'])\n\n# Function to load and preprocess trial data\ndef load_and_preprocess_trial(row):\n    # Determine dataset split\n    id_num = row['id']\n    split = 'train' if id_num <= 4800 else 'validation'\n    \n    # Build EEG file path\n    eeg_path = f\"{BASE_PATH}/{row['task']}/{split}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n    eeg_data = pd.read_csv(eeg_path)\n    \n    # Extract trial (MI: 2250 samples)\n    start_idx = (row['trial'] - 1) * 2250\n    end_idx = start_idx + 2250\n    trial_data = eeg_data.iloc[start_idx:end_idx]\n    \n    # Select relevant channels\n    trial_eeg = trial_data[EEG_CHANNELS].values\n    \n    # Apply preprocessing\n    trial_eeg = apply_filters(trial_eeg)\n    trial_eeg = normalize(trial_eeg)\n    \n    # Use first 4 seconds (1000 samples)\n    return trial_eeg[:TRIAL_LENGTH]\n\n# Preprocess all trials\ndef preprocess_dataset(df):\n    X = []\n    y = []\n    for _, row in df.iterrows():\n        try:\n            trial = load_and_preprocess_trial(row)\n            X.append(trial)\n            y.append(row['label_encoded'])\n        except Exception as e:\n            print(f\"Error processing {row}: {str(e)}\")\n    return np.array(X), np.array(y)\n\n# Preprocess training and validation data\nprint(\"Preprocessing training data...\")\nX_train, y_train = preprocess_dataset(train_mi)\nprint(\"Preprocessing validation data...\")\nX_val, y_val = preprocess_dataset(val_mi)\n\n# Convert to categorical for sigmoid output\ny_train_cat = tf.keras.utils.to_categorical(y_train)\ny_val_cat = tf.keras.utils.to_categorical(y_val)\n\n# Define model components (exact match to original)\ndef inception_block(x, ince_filter, ince_length, stride, activation):\n    k1, k2, k3, k4 = ince_filter\n    l1, l2, l3, l4 = ince_length\n    inception = []\n\n    # Branch 1\n    x1 = Conv1D(k1, l1, strides=stride, padding='same', \n               kernel_regularizer=regularizers.l2(0.01))(x)\n    x1 = BatchNormalization()(x1)\n    x1 = Activation(activation)(x1)\n    inception.append(x1)\n\n    # Branch 2\n    x2 = Conv1D(k2, l2, strides=stride, padding='same', \n               kernel_regularizer=regularizers.l2(0.01))(x)\n    x2 = BatchNormalization()(x2)\n    x2 = Activation(activation)(x2)\n    inception.append(x2)\n\n    # Branch 3\n    x3 = Conv1D(k3, l3, strides=stride, padding='same', \n               kernel_regularizer=regularizers.l2(0.01))(x)\n    x3 = BatchNormalization()(x3)\n    x3 = Activation(activation)(x3)\n    inception.append(x3)\n\n    # Branch 4\n    x4 = MaxPooling1D(pool_size=l4, strides=stride, padding='same')(x)\n    x4 = Conv1D(k4, 1, strides=1, padding='same')(x4)\n    x4 = BatchNormalization()(x4)\n    x4 = Activation(activation)(x4)\n    inception.append(x4)\n    \n    return Concatenate(axis=-1)(inception)\n\ndef conv_block(x, nb_filter, length, activation):\n    k1, k2, k3 = nb_filter\n\n    # Main path\n    out = Conv1D(k1, length, strides=1, padding='same', \n                kernel_regularizer=regularizers.l2(0.002))(x)\n    out = BatchNormalization()(out)\n    out = Activation(activation)(out)\n\n    out = Conv1D(k2, length, strides=1, padding='same', \n                kernel_regularizer=regularizers.l2(0.002))(out)\n    out = BatchNormalization()(out)\n    out = Activation(activation)(out)\n\n    out = Conv1D(k3, length, strides=1, padding='same', \n                kernel_regularizer=regularizers.l2(0.002))(out)\n    out = BatchNormalization()(out)\n\n    # Shortcut path\n    x = Conv1D(k3, 1, strides=1, padding='same')(x)\n    x = BatchNormalization()(x)\n\n    # Combine paths\n    out = Add()([out, x])\n    out = Activation(activation)(out)\n    out = Dropout(0.8)(out)  # Fixed dropout from original\n    return out\n\ndef squeeze_excitation_layer(x, out_dim, activation, ratio=8):\n    squeeze = GlobalAveragePooling1D()(x)\n    excitation = Dense(units=out_dim//ratio)(squeeze)\n    excitation = Activation(activation)(excitation)\n    excitation = Dense(units=out_dim, activation='sigmoid')(excitation)\n    excitation = Reshape((1, out_dim))(excitation)\n    return Multiply()([x, excitation])\n\n# Rebuild model architecture with original hyperparameters\ndef build_adapted_model():\n    input_tensor = Input(shape=(TRIAL_LENGTH, len(EEG_CHANNELS)))\n    output_conns = []\n    \n    # Hyperparameters from original model\n    inception_filters = [16, 16, 16, 16]\n    inception_kernel_length = [\n        [5, 10, 15, 10],\n        [40, 45, 50, 100],\n        [60, 65, 70, 100],\n        [80, 85, 90, 100],\n        [160, 180, 200, 180]\n    ]\n    inception_stride = [2, 4, 4, 4, 16]\n    res_block_filters = [16, 16, 16]\n    res_block_kernel_stride = [8, 7, 7, 7, 6]\n    second_maxpooling_size = [4, 3, 3, 3, 2]\n    second_maxpooling_stride = [4, 3, 3, 3, 2]\n    activation = 'elu'\n    dropout = 0.8\n\n    # Branch 1 (EIN-a)\n    x = inception_block(input_tensor, inception_filters, inception_kernel_length[0], inception_stride[0], activation)\n    x = MaxPooling1D(pool_size=4, strides=4, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(dropout)(x)\n    x = conv_block(x, res_block_filters, res_block_kernel_stride[0], activation)\n    x = squeeze_excitation_layer(x, 16, activation, ratio=8)  # out_dim = 16 (k3 from conv_block)\n    x = MaxPooling1D(pool_size=second_maxpooling_size[0], strides=second_maxpooling_stride[0], padding='same')(x)\n    x = Flatten()(x)\n    output_conns.append(x)\n\n    # Branch 2 (EIN-b)\n    y1 = inception_block(input_tensor, inception_filters, inception_kernel_length[1], inception_stride[1], activation)\n    y1 = MaxPooling1D(pool_size=4, strides=4, padding='same')(y1)\n    y1 = BatchNormalization()(y1)\n    y1 = Dropout(dropout)(y1)\n    y1 = conv_block(y1, res_block_filters, res_block_kernel_stride[1], activation)\n    y1 = squeeze_excitation_layer(y1, 16, activation, ratio=8)\n    y1 = MaxPooling1D(pool_size=second_maxpooling_size[1], strides=second_maxpooling_stride[1], padding='same')(y1)\n    y1 = Flatten()(y1)\n    output_conns.append(y1)\n\n    # Branch 3 (EIN-c)\n    y2 = inception_block(input_tensor, inception_filters, inception_kernel_length[2], inception_stride[2], activation)\n    y2 = MaxPooling1D(pool_size=4, strides=4, padding='same')(y2)\n    y2 = BatchNormalization()(y2)\n    y2 = Dropout(dropout)(y2)\n    y2 = conv_block(y2, res_block_filters, res_block_kernel_stride[2], activation)\n    y2 = squeeze_excitation_layer(y2, 16, activation, ratio=8)\n    y2 = MaxPooling1D(pool_size=second_maxpooling_size[2], strides=second_maxpooling_stride[2], padding='same')(y2)\n    y2 = Flatten()(y2)\n    output_conns.append(y2)\n\n    # Branch 4 (EIN-d)\n    y3 = inception_block(input_tensor, inception_filters, inception_kernel_length[3], inception_stride[3], activation)\n    y3 = MaxPooling1D(pool_size=4, strides=4, padding='same')(y3)\n    y3 = BatchNormalization()(y3)\n    y3 = Dropout(dropout)(y3)\n    y3 = conv_block(y3, res_block_filters, res_block_kernel_stride[3], activation)\n    y3 = squeeze_excitation_layer(y3, 16, activation, ratio=8)\n    y3 = MaxPooling1D(pool_size=second_maxpooling_size[3], strides=second_maxpooling_stride[3], padding='same')(y3)\n    y3 = Flatten()(y3)\n    output_conns.append(y3)\n\n    # Branch 5 (EIN-e)\n    z = inception_block(input_tensor, inception_filters, inception_kernel_length[4], inception_stride[4], activation)\n    z = MaxPooling1D(pool_size=4, strides=4, padding='same')(z)\n    z = BatchNormalization()(z)\n    z = Dropout(dropout)(z)\n    z = conv_block(z, res_block_filters, res_block_kernel_stride[4], activation)\n    z = squeeze_excitation_layer(z, 16, activation, ratio=8)\n    z = MaxPooling1D(pool_size=second_maxpooling_size[4], strides=second_maxpooling_stride[4], padding='same')(z)\n    z = Flatten()(z)\n    output_conns.append(z)\n\n    # Concatenate all branches\n    concat = Concatenate(axis=-1)(output_conns)\n    concat = Dropout(dropout)(concat)\n    output_tensor = Dense(2, activation='sigmoid')(concat)\n    \n    return Model(input_tensor, output_tensor)\n\n# Build and load pre-trained model\nprint(\"Building model...\")\nmodel = build_adapted_model()\nmodel.load_weights('/kaggle/input/trained-bcic-iv-bs2b/final_model_fold_1_2a.h5')\n\n# Compile with original settings\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['mae', 'binary_accuracy']\n)\n\n# Train with early stopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True\n)\n\nprint(\"Starting fine-tuning...\")\nhistory = model.fit(\n    X_train, y_train_cat,\n    validation_data=(X_val, y_val_cat),\n    epochs=100,\n    batch_size=32,\n    callbacks=[early_stopping]\n)\n\n# Evaluate on validation set\nval_loss, val_mae, val_acc = model.evaluate(X_val, y_val_cat)\nprint(f'\\nValidation Accuracy: {val_acc:.4f}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T11:02:56.558792Z","iopub.execute_input":"2025-06-23T11:02:56.559151Z","iopub.status.idle":"2025-06-23T11:12:01.168194Z","shell.execute_reply.started":"2025-06-23T11:02:56.559124Z","shell.execute_reply":"2025-06-23T11:12:01.167305Z"}},"outputs":[{"name":"stdout","text":"Preprocessing training data...\nPreprocessing validation data...\nBuilding model...\n","output_type":"stream"},{"name":"stderr","text":"2025-06-23 11:06:18.000300: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Starting fine-tuning...\nEpoch 1/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 171ms/step - binary_accuracy: 0.5110 - loss: 1.5482 - mae: 0.4923 - val_binary_accuracy: 0.5200 - val_loss: 0.8799 - val_mae: 0.5086\nEpoch 2/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5339 - loss: 1.0350 - mae: 0.4845 - val_binary_accuracy: 0.5000 - val_loss: 0.9155 - val_mae: 0.5072\nEpoch 3/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - binary_accuracy: 0.5295 - loss: 0.9273 - mae: 0.4758 - val_binary_accuracy: 0.5200 - val_loss: 0.8003 - val_mae: 0.4992\nEpoch 4/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - binary_accuracy: 0.5261 - loss: 0.9105 - mae: 0.4849 - val_binary_accuracy: 0.5000 - val_loss: 0.7537 - val_mae: 0.4904\nEpoch 5/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - binary_accuracy: 0.5316 - loss: 0.8669 - mae: 0.4845 - val_binary_accuracy: 0.5000 - val_loss: 0.7600 - val_mae: 0.4938\nEpoch 6/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - binary_accuracy: 0.5138 - loss: 0.8649 - mae: 0.4919 - val_binary_accuracy: 0.5200 - val_loss: 0.7597 - val_mae: 0.4943\nEpoch 7/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - binary_accuracy: 0.4892 - loss: 0.8621 - mae: 0.4999 - val_binary_accuracy: 0.4800 - val_loss: 0.7567 - val_mae: 0.4939\nEpoch 8/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - binary_accuracy: 0.5256 - loss: 0.8166 - mae: 0.4833 - val_binary_accuracy: 0.4800 - val_loss: 0.7684 - val_mae: 0.4975\nEpoch 9/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - binary_accuracy: 0.5321 - loss: 0.8049 - mae: 0.4857 - val_binary_accuracy: 0.5400 - val_loss: 0.7483 - val_mae: 0.4927\nEpoch 10/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5592 - loss: 0.7757 - mae: 0.4727 - val_binary_accuracy: 0.4600 - val_loss: 0.7562 - val_mae: 0.4962\nEpoch 11/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5425 - loss: 0.7975 - mae: 0.4852 - val_binary_accuracy: 0.4800 - val_loss: 0.7520 - val_mae: 0.4945\nEpoch 12/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - binary_accuracy: 0.5582 - loss: 0.7788 - mae: 0.4806 - val_binary_accuracy: 0.4800 - val_loss: 0.7535 - val_mae: 0.4954\nEpoch 13/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - binary_accuracy: 0.5138 - loss: 0.7899 - mae: 0.4897 - val_binary_accuracy: 0.5800 - val_loss: 0.7447 - val_mae: 0.4920\nEpoch 14/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - binary_accuracy: 0.5203 - loss: 0.7800 - mae: 0.4868 - val_binary_accuracy: 0.6000 - val_loss: 0.7454 - val_mae: 0.4921\nEpoch 15/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - binary_accuracy: 0.5245 - loss: 0.7831 - mae: 0.4895 - val_binary_accuracy: 0.5400 - val_loss: 0.7512 - val_mae: 0.4953\nEpoch 16/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - binary_accuracy: 0.5471 - loss: 0.7703 - mae: 0.4845 - val_binary_accuracy: 0.5600 - val_loss: 0.7514 - val_mae: 0.4950\nEpoch 17/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5561 - loss: 0.7585 - mae: 0.4810 - val_binary_accuracy: 0.5400 - val_loss: 0.7396 - val_mae: 0.4898\nEpoch 18/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - binary_accuracy: 0.5425 - loss: 0.7551 - mae: 0.4793 - val_binary_accuracy: 0.5600 - val_loss: 0.7464 - val_mae: 0.4928\nEpoch 19/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - binary_accuracy: 0.5650 - loss: 0.7468 - mae: 0.4755 - val_binary_accuracy: 0.5000 - val_loss: 0.7481 - val_mae: 0.4911\nEpoch 20/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - binary_accuracy: 0.5619 - loss: 0.7446 - mae: 0.4753 - val_binary_accuracy: 0.5800 - val_loss: 0.7463 - val_mae: 0.4935\nEpoch 21/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5253 - loss: 0.7628 - mae: 0.4856 - val_binary_accuracy: 0.5800 - val_loss: 0.7438 - val_mae: 0.4931\nEpoch 22/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - binary_accuracy: 0.5640 - loss: 0.7423 - mae: 0.4776 - val_binary_accuracy: 0.5300 - val_loss: 0.7375 - val_mae: 0.4900\nEpoch 23/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - binary_accuracy: 0.5573 - loss: 0.7438 - mae: 0.4795 - val_binary_accuracy: 0.6200 - val_loss: 0.7235 - val_mae: 0.4836\nEpoch 24/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - binary_accuracy: 0.5520 - loss: 0.7575 - mae: 0.4847 - val_binary_accuracy: 0.5600 - val_loss: 0.7392 - val_mae: 0.4914\nEpoch 25/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - binary_accuracy: 0.5552 - loss: 0.7473 - mae: 0.4822 - val_binary_accuracy: 0.5600 - val_loss: 0.7344 - val_mae: 0.4893\nEpoch 26/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - binary_accuracy: 0.5608 - loss: 0.7429 - mae: 0.4808 - val_binary_accuracy: 0.5800 - val_loss: 0.7311 - val_mae: 0.4880\nEpoch 27/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - binary_accuracy: 0.5723 - loss: 0.7354 - mae: 0.4753 - val_binary_accuracy: 0.6000 - val_loss: 0.7341 - val_mae: 0.4884\nEpoch 28/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5567 - loss: 0.7443 - mae: 0.4803 - val_binary_accuracy: 0.5200 - val_loss: 0.7428 - val_mae: 0.4940\nEpoch 29/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5805 - loss: 0.7225 - mae: 0.4703 - val_binary_accuracy: 0.5600 - val_loss: 0.7298 - val_mae: 0.4874\nEpoch 30/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5726 - loss: 0.7258 - mae: 0.4685 - val_binary_accuracy: 0.5800 - val_loss: 0.7374 - val_mae: 0.4884\nEpoch 31/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - binary_accuracy: 0.5983 - loss: 0.7141 - mae: 0.4617 - val_binary_accuracy: 0.5800 - val_loss: 0.7296 - val_mae: 0.4857\nEpoch 32/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5646 - loss: 0.7419 - mae: 0.4771 - val_binary_accuracy: 0.5000 - val_loss: 0.7367 - val_mae: 0.4914\nEpoch 33/100\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - binary_accuracy: 0.5580 - loss: 0.7392 - mae: 0.4775 - val_binary_accuracy: 0.5600 - val_loss: 0.7511 - val_mae: 0.4971\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.6321 - loss: 0.7271 - mae: 0.4856\n\nValidation Accuracy: 0.6200\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}