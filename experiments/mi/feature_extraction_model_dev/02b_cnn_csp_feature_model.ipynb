{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"},{"sourceId":12241045,"sourceType":"datasetVersion","datasetId":7712933},{"sourceId":12241055,"sourceType":"datasetVersion","datasetId":7712942}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load preprocessed training metadata\ntrain_df = pd.read_csv('/kaggle/input/preprocessed-with-25-artifact-threshold/quality_controlled_preprocessed/train.csv')\n\n# Filter for MI tasks only\nmi_train_df = train_df[train_df['task'] == 'MI'].copy()\n\n# Remove rejected trials (where preprocessing failed)\nvalid_mi_train_df = mi_train_df[mi_train_df['processed_path'].notnull()]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:17:40.076013Z","iopub.execute_input":"2025-06-21T21:17:40.076313Z","iopub.status.idle":"2025-06-21T21:17:43.574243Z","shell.execute_reply.started":"2025-06-21T21:17:40.076283Z","shell.execute_reply":"2025-06-21T21:17:43.573659Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Count class distribution\nclass_counts = valid_mi_train_df['label'].value_counts()\n\n# Calculate percentages\nclass_percentages = class_counts / len(valid_mi_train_df) * 100\n\n# Display distribution\nprint(\"Motor Imagery Class Distribution:\")\nprint(f\"Total Trials: {len(valid_mi_train_df)}\")\nprint(class_counts)\nprint(\"\\nClass Balance:\")\nprint(class_percentages)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:17:43.575353Z","iopub.execute_input":"2025-06-21T21:17:43.575650Z","iopub.status.idle":"2025-06-21T21:17:43.585337Z","shell.execute_reply.started":"2025-06-21T21:17:43.575609Z","shell.execute_reply":"2025-06-21T21:17:43.584575Z"}},"outputs":[{"name":"stdout","text":"Motor Imagery Class Distribution:\nTotal Trials: 2355\nlabel\nRight    1190\nLeft     1165\nName: count, dtype: int64\n\nClass Balance:\nlabel\nRight    50.530786\nLeft     49.469214\nName: count, dtype: float64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (LSTM, Dense, Input, Dropout, \n                                     Bidirectional, LayerNormalization,\n                                     Attention, Permute, Multiply)\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, CSVLogger, \n                                       EarlyStopping, ReduceLROnPlateau)\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom scipy import signal\n\n# Configuration\nBATCH_SIZE = 32\nEPOCHS = 100  # Increased to allow early stopping\nCLASS_WEIGHTS = {0: 1.01, 1: 0.99}  # Slight adjustment for 50.5/49.5 split\nBASE_PREPROCESSED_PATH = '/kaggle/input/preprocessed-with-25-artifact-threshold'\n\n# Define channel selections\nALL_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\nMI_CHANNELS = ['C3', 'CZ', 'C4', 'FZ', 'PZ']  # Optimal MI channels\nCHANNEL_INDICES = [ALL_CHANNELS.index(ch) for ch in MI_CHANNELS]\n\n# Load and filter data with proper NaN handling\ntrain_df = pd.read_csv(os.path.join(BASE_PREPROCESSED_PATH, 'quality_controlled_preprocessed/train.csv'))\n\n# Clean path strings and convert to absolute paths\ntrain_df['processed_path'] = train_df['processed_path'].astype(str).str.replace('^\\./', '', regex=True)\ntrain_df['abs_path'] = train_df['processed_path'].apply(\n    lambda x: os.path.join(BASE_PREPROCESSED_PATH, x) if x != 'nan' else np.nan\n)\n\n# Filter out invalid entries\ntrain_df = train_df[train_df['abs_path'].notna()]\ntrain_df['file_exists'] = train_df['abs_path'].apply(lambda x: os.path.exists(x) if isinstance(x, str) else False)\nprint(f\"Training files missing: {len(train_df) - train_df['file_exists'].sum()}\")\nmi_train_df = train_df[(train_df['task'] == 'MI') & (train_df['file_exists'])]\n\n# Data generator with fixed-length augmentation and channel selection\nclass EEGDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size, seq_length=2250, augment=True):\n        self.df = df\n        self.batch_size = batch_size\n        self.seq_length = seq_length\n        self.augment = augment\n        self.indices = np.arange(len(df))\n        \n    def __len__(self):\n        return int(np.ceil(len(self.df) / self.batch_size))\n    \n    def __getitem__(self, idx):\n        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n        X_batch = np.zeros((len(batch_indices), self.seq_length, len(MI_CHANNELS)))\n        y_batch = []\n        \n        for j, i in enumerate(batch_indices):\n            row = self.df.iloc[i]\n            data = np.load(row['abs_path'])['data']\n            # Select only MI-relevant channels\n            data = data[:, CHANNEL_INDICES]\n            label = 0 if row['label'] == 'Left' else 1\n            \n            # Augmentation techniques\n            if self.augment:\n                # Gaussian noise\n                if np.random.rand() > 0.7:\n                    data += np.random.normal(0, 0.5, data.shape)\n                \n                # Time warping with fixed length\n                if np.random.rand() > 0.7:\n                    warp_factor = np.random.uniform(0.9, 1.1)\n                    new_length = int(data.shape[0] * warp_factor)\n                    \n                    # Resize to new length\n                    warped = tf.image.resize(data[..., np.newaxis], \n                                           [new_length, data.shape[1]]).numpy()[:, :, 0]\n                    \n                    # Resize back to original length\n                    data = tf.image.resize(warped[..., np.newaxis], \n                                         [self.seq_length, warped.shape[1]]).numpy()[:, :, 0]\n            \n            # Ensure correct length\n            if len(data) != self.seq_length:\n                data = tf.image.resize(data[..., np.newaxis], \n                                      [self.seq_length, data.shape[1]]).numpy()[:, :, 0]\n            \n            X_batch[j] = data\n            y_batch.append(label)\n        \n        y_batch = tf.keras.utils.to_categorical(y_batch, num_classes=2)\n        return X_batch, y_batch\n\n# Create datasets\ntrain_gen = EEGDataGenerator(mi_train_df, BATCH_SIZE, seq_length=2250, augment=True)\n\n# Prepare validation data\nval_df = pd.read_csv(os.path.join(BASE_PREPROCESSED_PATH, 'quality_controlled_preprocessed/validation.csv'))\nval_df['processed_path'] = val_df['processed_path'].astype(str).str.replace('^\\./', '', regex=True)\nval_df['abs_path'] = val_df['processed_path'].apply(\n    lambda x: os.path.join(BASE_PREPROCESSED_PATH, x) if x != 'nan' else np.nan\n)\nval_df = val_df[val_df['abs_path'].notna()]\nval_df['file_exists'] = val_df['abs_path'].apply(lambda x: os.path.exists(x))\nprint(f\"Validation files missing: {len(val_df) - val_df['file_exists'].sum()}\")\nmi_val_df = val_df[(val_df['task'] == 'MI') & (val_df['file_exists'])]\nval_gen = EEGDataGenerator(mi_val_df, BATCH_SIZE, seq_length=2250, augment=False)\n\n# Attention LSTM Model with reduced input channels\ndef create_attention_lstm(input_shape):\n    inputs = Input(shape=input_shape)\n    \n    # Encoder\n    x = Bidirectional(LSTM(128, return_sequences=True))(inputs)\n    x = LayerNormalization()(x)\n    x = Dropout(0.3)(x)\n    \n    # Attention mechanism\n    attention = Dense(1, activation='tanh')(x)\n    attention = Permute((2, 1))(attention)\n    attention = tf.keras.layers.Softmax()(attention)\n    attention = Permute((2, 1))(attention)\n    context = Multiply()([x, attention])\n    \n    # Decoder\n    context = LSTM(64)(context)\n    context = Dropout(0.3)(context)\n    outputs = Dense(2, activation='softmax')(context)\n    \n    model = Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-3),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', \n                 tf.keras.metrics.Precision(name='precision'),\n                 tf.keras.metrics.Recall(name='recall'),\n                 tf.keras.metrics.AUC(name='auc')]\n    )\n    return model\n\n# Create model\nmodel_lstm = create_attention_lstm((2250, len(MI_CHANNELS)))\n\n# Callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=15,\n    restore_best_weights=True,\n    verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    min_lr=1e-6,\n    verbose=1\n)\n\ncheckpoint = ModelCheckpoint('lstm_best_model.h5', save_best_only=True, verbose=1)\ncsv_logger = CSVLogger('lstm_training_log.csv')\n\nhistory = model_lstm.fit(\n    train_gen,\n    epochs=EPOCHS,\n    validation_data=val_gen,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[checkpoint, csv_logger, early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Evaluation\ny_true, y_pred = [], []\nfor i in range(len(val_gen)):\n    X, y = val_gen[i]\n    preds = model_lstm.predict(X, verbose=0)\n    y_true.extend(np.argmax(y, axis=1))\n    y_pred.extend(np.argmax(preds, axis=1))\n\n# Classification report\nprint(\"LSTM Model Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=['Left', 'Right']))\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Left', 'Right'], \n            yticklabels=['Left', 'Right'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('LSTM Confusion Matrix')\nplt.savefig('lstm_confusion_matrix.png', dpi=300)\nplt.close()\n\n# Calculate F1\nprecision = cm[1][1] / (cm[1][1] + cm[0][1]) if (cm[1][1] + cm[0][1]) > 0 else 0\nrecall = cm[1][1] / (cm[1][1] + cm[1][0]) if (cm[1][1] + cm[1][0]) > 0 else 0\nf1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\nprint(f\"\\nValidation F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:38:05.521178Z","iopub.execute_input":"2025-06-21T21:38:05.521508Z"}},"outputs":[{"name":"stdout","text":"Training files missing: 0\nValidation files missing: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.4825 - auc: 0.4825 - loss: 0.6941 - precision: 0.4825 - recall: 0.4825\nEpoch 1: val_loss improved from inf to 0.69355, saving model to lstm_best_model.h5\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 308ms/step - accuracy: 0.4825 - auc: 0.4826 - loss: 0.6941 - precision: 0.4825 - recall: 0.4825 - val_accuracy: 0.4490 - val_auc: 0.4798 - val_loss: 0.6935 - val_precision: 0.4490 - val_recall: 0.4490 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5173 - auc: 0.5047 - loss: 0.6928 - precision: 0.5173 - recall: 0.5173\nEpoch 2: val_loss improved from 0.69355 to 0.69251, saving model to lstm_best_model.h5\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 292ms/step - accuracy: 0.5171 - auc: 0.5046 - loss: 0.6928 - precision: 0.5171 - recall: 0.5171 - val_accuracy: 0.5510 - val_auc: 0.5600 - val_loss: 0.6925 - val_precision: 0.5510 - val_recall: 0.5510 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5114 - auc: 0.5031 - loss: 0.6931 - precision: 0.5114 - recall: 0.5114\nEpoch 3: val_loss did not improve from 0.69251\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.5113 - auc: 0.5030 - loss: 0.6931 - precision: 0.5113 - recall: 0.5113 - val_accuracy: 0.4490 - val_auc: 0.4677 - val_loss: 0.6940 - val_precision: 0.4490 - val_recall: 0.4490 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5152 - auc: 0.5198 - loss: 0.6928 - precision: 0.5152 - recall: 0.5152\nEpoch 4: val_loss did not improve from 0.69251\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.5151 - auc: 0.5195 - loss: 0.6928 - precision: 0.5151 - recall: 0.5151 - val_accuracy: 0.5306 - val_auc: 0.5327 - val_loss: 0.6930 - val_precision: 0.5306 - val_recall: 0.5306 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.5285 - auc: 0.5384 - loss: 0.6924 - precision: 0.5285 - recall: 0.5285\nEpoch 5: val_loss did not improve from 0.69251\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.5283 - auc: 0.5380 - loss: 0.6924 - precision: 0.5283 - recall: 0.5283 - val_accuracy: 0.4490 - val_auc: 0.4552 - val_loss: 0.6957 - val_precision: 0.4490 - val_recall: 0.4490 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.4814 - auc: 0.4928 - loss: 0.6939 - precision: 0.4814 - recall: 0.4814\nEpoch 6: val_loss did not improve from 0.69251\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 293ms/step - accuracy: 0.4816 - auc: 0.4930 - loss: 0.6939 - precision: 0.4816 - recall: 0.4816 - val_accuracy: 0.4898 - val_auc: 0.5040 - val_loss: 0.6940 - val_precision: 0.4898 - val_recall: 0.4898 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.5072 - auc: 0.5041 - loss: 0.6932 - precision: 0.5072 - recall: 0.5072\nEpoch 7: val_loss did not improve from 0.69251\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 290ms/step - accuracy: 0.5073 - auc: 0.5043 - loss: 0.6931 - precision: 0.5073 - recall: 0.5073 - val_accuracy: 0.4490 - val_auc: 0.4431 - val_loss: 0.6963 - val_precision: 0.4490 - val_recall: 0.4490 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5122 - auc: 0.5194 - loss: 0.6924 - precision: 0.5122 - recall: 0.5122\nEpoch 8: val_loss did not improve from 0.69251\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.5121 - auc: 0.5193 - loss: 0.6924 - precision: 0.5121 - recall: 0.5121 - val_accuracy: 0.5510 - val_auc: 0.5512 - val_loss: 0.6932 - val_precision: 0.5510 - val_recall: 0.5510 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5060 - auc: 0.5103 - loss: 0.6927 - precision: 0.5060 - recall: 0.5060\nEpoch 9: val_loss improved from 0.69251 to 0.69149, saving model to lstm_best_model.h5\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 292ms/step - accuracy: 0.5060 - auc: 0.5104 - loss: 0.6927 - precision: 0.5060 - recall: 0.5060 - val_accuracy: 0.5510 - val_auc: 0.5273 - val_loss: 0.6915 - val_precision: 0.5510 - val_recall: 0.5510 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5240 - auc: 0.5212 - loss: 0.6925 - precision: 0.5240 - recall: 0.5240\nEpoch 10: val_loss did not improve from 0.69149\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.5240 - auc: 0.5211 - loss: 0.6925 - precision: 0.5240 - recall: 0.5240 - val_accuracy: 0.5306 - val_auc: 0.5352 - val_loss: 0.6980 - val_precision: 0.5306 - val_recall: 0.5306 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.4994 - auc: 0.5080 - loss: 0.6934 - precision: 0.4994 - recall: 0.4994\nEpoch 11: val_loss did not improve from 0.69149\n\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.4994 - auc: 0.5080 - loss: 0.6934 - precision: 0.4994 - recall: 0.4994 - val_accuracy: 0.4490 - val_auc: 0.4642 - val_loss: 0.7005 - val_precision: 0.4490 - val_recall: 0.4490 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m30/74\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 287ms/step - accuracy: 0.5131 - auc: 0.5192 - loss: 0.6924 - precision: 0.5131 - recall: 0.5131","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# STFT Transformation with channel selection\ndef compute_stft(eeg_data, fs=250):\n    stft_features = []\n    # Compute STFT only for MI-relevant channels\n    for channel_idx in CHANNEL_INDICES:\n        f, t, Zxx = signal.stft(eeg_data[:, channel_idx], \n                                fs=fs, \n                                nperseg=128, \n                                noverlap=96)\n        # Select frequency range (0-40 Hz)\n        freq_mask = (f >= 0) & (f <= 40)\n        mag = np.abs(Zxx[freq_mask])\n        stft_features.append(mag.T)  # Time x Freq\n    \n    return np.stack(stft_features, axis=-1)  # Time x Freq x Channels\n\n# Create STFT dataset with path fixes\ndef create_stft_dataset(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        # Use absolute path\n        abs_path = os.path.join(BASE_PREPROCESSED_PATH, row['processed_path'].lstrip('./'))\n        if not os.path.exists(abs_path):\n            print(f\"File not found: {abs_path}\")\n            continue\n            \n        data = np.load(abs_path)['data']\n        stft_data = compute_stft(data)\n        label = 0 if row['label'] == 'Left' else 1\n        X.append(stft_data)\n        y.append(label)\n    return np.array(X), tf.keras.utils.to_categorical(y, 2)\n\n# Create STFT datasets\nX_train, y_train = create_stft_dataset(mi_train_df)\nX_val, y_val = create_stft_dataset(mi_val_df)\n\n# CNN Model Architecture with reduced input channels\ndef create_cnn_model(input_shape):\n    model = tf.keras.Sequential([\n        # Conv Block 1\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n                               input_shape=input_shape),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        \n        # Conv Block 2\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        \n        # Conv Block 3\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        \n        # Conv Block 4\n        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        \n        # Conv Block 5\n        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        \n        # FC Layers\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(2, activation='softmax')\n    ])\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-4),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', \n                 tf.keras.metrics.Precision(name='precision'),\n                 tf.keras.metrics.Recall(name='recall'),\n                 tf.keras.metrics.AUC(name='auc')]\n    )\n    return model\n\n# Data augmentation\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    fill_mode='nearest'\n)\n\n# Create model\nmodel_cnn = create_cnn_model(X_train.shape[1:])\n\n# Callbacks\nearly_stopping_cnn = EarlyStopping(\n    monitor='val_loss',\n    patience=15,\n    restore_best_weights=True,\n    verbose=1\n)\n\nreduce_lr_cnn = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    min_lr=1e-6,\n    verbose=1\n)\n\ncheckpoint_cnn = ModelCheckpoint('cnn_best_model.h5', save_best_only=True, verbose=1)\ncsv_logger_cnn = CSVLogger('cnn_training_log.csv')\n\nhistory_cnn = model_cnn.fit(\n    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n    epochs=EPOCHS,\n    validation_data=(X_val, y_val),\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[checkpoint_cnn, csv_logger_cnn, early_stopping_cnn, reduce_lr_cnn],\n    verbose=1\n)\n\n# Evaluation\ny_pred_cnn = model_cnn.predict(X_val, verbose=0)\ny_true_cnn = np.argmax(y_val, axis=1)\ny_pred_cnn = np.argmax(y_pred_cnn, axis=1)\n\n# Classification report\nprint(\"\\nCNN Model Classification Report:\")\nprint(classification_report(y_true_cnn, y_pred_cnn, target_names=['Left', 'Right']))\n\n# Confusion matrix\ncm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Left', 'Right'], \n            yticklabels=['Left', 'Right'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('CNN Confusion Matrix')\nplt.savefig('cnn_confusion_matrix.png', dpi=300)\nplt.close()\n\n# Calculate F1\nprecision_cnn = cm_cnn[1][1] / (cm_cnn[1][1] + cm_cnn[0][1]) if (cm_cnn[1][1] + cm_cnn[0][1]) > 0 else 0\nrecall_cnn = cm_cnn[1][1] / (cm_cnn[1][1] + cm_cnn[1][0]) if (cm_cnn[1][1] + cm_cnn[1][0]) > 0 else 0\nf1_cnn = 2 * (precision_cnn * recall_cnn) / (precision_cnn + recall_cnn) if (precision_cnn + recall_cnn) > 0 else 0\nprint(f\"\\nValidation F1 Score: {f1_cnn:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}