{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FBCCA(Weighted) + SVM pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T06:59:08.279356Z",
     "iopub.status.busy": "2025-06-25T06:59:08.279085Z",
     "iopub.status.idle": "2025-06-25T07:05:10.175712Z",
     "shell.execute_reply": "2025-06-25T07:05:10.174960Z",
     "shell.execute_reply.started": "2025-06-25T06:59:08.279336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FBCCA features from training data...\n",
      "  Processed training trial 4800/2400\n",
      "Extracting FBCCA features from validation data...\n",
      "  Processed validation trial 100/50\n",
      "\n",
      "Feature extraction complete. Training features shape: (2400, 4)\n",
      "Training Support Vector Machine (SVM) classifier...\n",
      "Training complete.\n",
      "\n",
      "Evaluating pipeline on validation data...\n",
      "\n",
      "--- FBCCA + SVM Pipeline Results ---\n",
      "Validation Accuracy: 46.00%\n",
      "Validation F1-Score (Weighted): 0.4594\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Forward       0.62      0.36      0.45        14\n",
      "    Backward       0.47      0.58      0.52        12\n",
      "        Left       0.37      0.50      0.42        14\n",
      "       Right       0.50      0.40      0.44        10\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.49      0.46      0.46        50\n",
      "weighted avg       0.49      0.46      0.46        50\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration ---\n",
    "COMPETITION_BASE_PATH = '/kaggle/input/mtcaic3/'\n",
    "FS = 250\n",
    "SSVEP_SAMPLES = 1750\n",
    "TARGET_FREQS = {\n",
    "    'Forward': 7.0, 'Backward': 8.0, 'Left': 10.0, 'Right': 13.0\n",
    "}\n",
    "LABELS = list(TARGET_FREQS.keys())\n",
    "N_HARMONICS = 3\n",
    "RELEVANT_CHANNELS = ['PZ', 'PO7', 'OZ', 'PO8']\n",
    "FILTER_BANK = [\n",
    "    (6, 14), (14, 22), (22, 30), (30, 38), (38, 46)\n",
    "]\n",
    "FILTER_WEIGHTS = [1.0, 1.0, 0.5, 0.5, 0.25]\n",
    "\n",
    "# --- Core Functions ---\n",
    "def load_trial_data(row, base_path, dataset_split):\n",
    "    eeg_path = os.path.join(base_path, row['task'], dataset_split, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "    if not os.path.exists(eeg_path): return None\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "    trial_num = int(row['trial'])\n",
    "    start_idx = (trial_num - 1) * SSVEP_SAMPLES\n",
    "    end_idx = start_idx + SSVEP_SAMPLES\n",
    "    return eeg_data.iloc[start_idx:end_idx]\n",
    "\n",
    "def preprocess_data(trial_df):\n",
    "    return trial_df[RELEVANT_CHANNELS].values.T\n",
    "\n",
    "def generate_reference_signals(freq, n_samples, n_harmonics):\n",
    "    t = np.arange(n_samples) / FS\n",
    "    references = []\n",
    "    for h in range(1, n_harmonics + 1):\n",
    "        harmonic_freq = freq * h\n",
    "        references.append(np.sin(2 * np.pi * harmonic_freq * t))\n",
    "        references.append(np.cos(2 * np.pi * harmonic_freq * t))\n",
    "    return np.array(references).T\n",
    "\n",
    "def extract_fbcca_features(eeg_signal):\n",
    "    \"\"\"\n",
    "    MODIFIED: Instead of returning the predicted label, this now returns the\n",
    "    vector of final correlation scores, which will be our features.\n",
    "    \"\"\"\n",
    "    n_samples = eeg_signal.shape[1]\n",
    "    feature_vector = np.zeros(len(TARGET_FREQS))\n",
    "    cca = CCA(n_components=1)\n",
    "    \n",
    "    for i, (low, high) in enumerate(FILTER_BANK):\n",
    "        b, a = butter(5, [low, high], btype='band', fs=FS)\n",
    "        filtered_eeg = lfilter(b, a, eeg_signal, axis=1)\n",
    "        correlations_for_this_band = []\n",
    "        for freq in TARGET_FREQS.values():\n",
    "            ref_signals = generate_reference_signals(freq, n_samples, N_HARMONICS)\n",
    "            cca.fit(filtered_eeg.T, ref_signals)\n",
    "            eeg_c, ref_c = cca.transform(filtered_eeg.T, ref_signals)\n",
    "            corr = np.corrcoef(eeg_c[:, 0], ref_c[:, 0])[0, 1]\n",
    "            correlations_for_this_band.append(corr)\n",
    "        weight = FILTER_WEIGHTS[i]\n",
    "        feature_vector += (weight * np.square(correlations_for_this_band))\n",
    "        \n",
    "    return feature_vector\n",
    "\n",
    "# --- Main Pipeline Logic ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. Load data index files\n",
    "    train_df = pd.read_csv(os.path.join(COMPETITION_BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(COMPETITION_BASE_PATH, 'validation.csv'))\n",
    "\n",
    "    ssvep_train_df = train_df[train_df['task'] == 'SSVEP']\n",
    "    ssvep_validation_df = validation_df[validation_df['task'] == 'SSVEP']\n",
    "\n",
    "    # 2. Extract FBCCA features for the training set\n",
    "    print(\"Extracting FBCCA features from training data...\")\n",
    "    X_train_features = []\n",
    "    y_train_labels = []\n",
    "    for idx, row in ssvep_train_df.iterrows():\n",
    "        trial_data = load_trial_data(row, COMPETITION_BASE_PATH, 'train')\n",
    "        if trial_data is not None:\n",
    "            preprocessed_eeg = preprocess_data(trial_data)\n",
    "            features = extract_fbcca_features(preprocessed_eeg)\n",
    "            X_train_features.append(features)\n",
    "            y_train_labels.append(row['label'])\n",
    "        print(f\"  Processed training trial {idx + 1}/{len(ssvep_train_df)}\", end='\\r')\n",
    "    \n",
    "    X_train = np.array(X_train_features)\n",
    "    y_train = np.array(y_train_labels)\n",
    "\n",
    "    # 3. Extract FBCCA features for the validation set\n",
    "    print(\"\\nExtracting FBCCA features from validation data...\")\n",
    "    X_val_features = []\n",
    "    y_val_labels = []\n",
    "    for idx, row in ssvep_validation_df.iterrows():\n",
    "        trial_data = load_trial_data(row, COMPETITION_BASE_PATH, 'validation')\n",
    "        if trial_data is not None:\n",
    "            preprocessed_eeg = preprocess_data(trial_data)\n",
    "            features = extract_fbcca_features(preprocessed_eeg)\n",
    "            X_val_features.append(features)\n",
    "            y_val_labels.append(row['label'])\n",
    "        print(f\"  Processed validation trial {idx + 1}/{len(ssvep_validation_df)}\", end='\\r')\n",
    "\n",
    "    X_val = np.array(X_val_features)\n",
    "    y_val = np.array(y_val_labels)\n",
    "    \n",
    "    print(f\"\\n\\nFeature extraction complete. Training features shape: {X_train.shape}\")\n",
    "\n",
    "    # 4. Train the SVM Classifier\n",
    "    print(\"Training Support Vector Machine (SVM) classifier...\")\n",
    "    # We create a pipeline that first scales the data then trains the SVM.\n",
    "    # An RBF kernel is excellent for capturing non-linear relationships.\n",
    "    # C=10 is a good starting point for the regularization parameter.\n",
    "    svm_pipeline = make_pipeline(\n",
    "        StandardScaler(), \n",
    "        SVC(kernel='rbf', C=10, probability=True, random_state=42)\n",
    "    )\n",
    "    \n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # 5. Evaluate the pipeline on the validation set\n",
    "    print(\"\\nEvaluating pipeline on validation data...\")\n",
    "    y_pred = svm_pipeline.predict(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\n--- FBCCA + SVM Pipeline Results ---\")\n",
    "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Validation F1-Score (Weighted): {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=LABELS))\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=LABELS)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS, yticklabels=LABELS)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('FBCCA + SVM Pipeline Performance')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 50% accuracy better approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import cheby1, filtfilt\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "# Use the Kaggle directory structure\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES = [7, 8, 10, 13] # Hz\n",
    "CLASS_LABELS = ['Forward', 'Backward', 'Left', 'Right']\n",
    "SAMPLES_PER_SSVEP_TRIAL = 1750 # 7 seconds * 250 Hz\n",
    "NUM_HARMONICS = 3 # Increased to capture more harmonic information\n",
    "\n",
    "# --- 1. Data Loading Function ---\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"\n",
    "    Loads raw EEG data for a single trial.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', dataset_type, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        \n",
    "        trial_num = int(row['trial'])\n",
    "        start_idx = (trial_num - 1) * SAMPLES_PER_SSVEP_TRIAL\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        \n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        return trial_eeg_data.values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {eeg_path}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Reference Signal Generation ---\n",
    "def get_reference_signals(duration_samples, frequencies, sampling_rate, num_harmonics):\n",
    "    \"\"\"\n",
    "    Generates sine and cosine reference signals for each target frequency.\n",
    "    \"\"\"\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / sampling_rate\n",
    "    \n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, num_harmonics + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.append(np.sin(2 * np.pi * harmonic_freq * t))\n",
    "            refs.append(np.cos(2 * np.pi * harmonic_freq * t))\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "# --- 3. Enhanced Filter Bank and Feature Extraction ---\n",
    "\n",
    "# **IMPROVEMENT 1: More Precise Filter Bank**\n",
    "# This new filter bank uses narrower, overlapping bands to improve frequency resolution.\n",
    "# This helps to better isolate the target SSVEP frequencies from noise.\n",
    "def get_enhanced_filterbank(sampling_rate):\n",
    "    \"\"\"\n",
    "    Creates a more precise bank of 5 Chebyshev Type I bandpass filters.\n",
    "    \"\"\"\n",
    "    # Bands are defined as [start_freq, end_freq]\n",
    "    # Each band has a width of 8Hz, starting from 6Hz and incrementing by 8Hz\n",
    "    # This creates overlapping filters that cover the full spectrum of interest.\n",
    "    filter_bands = [[(i*8 + 6), (i*8 + 14)] for i in range(5)] # e.g., [6,14], [14,22], ... [38, 46]\n",
    "    \n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        # Using a slightly higher order filter for sharper cutoff\n",
    "        b, a = cheby1(5, 0.1, [low/nyquist, high/nyquist], btype='band')\n",
    "        filters.append((b, a))\n",
    "    return filters\n",
    "\n",
    "# **IMPROVEMENT 2: Richer, Concatenated Feature Vector**\n",
    "# Instead of summing the correlations, we now concatenate them to provide more\n",
    "# detailed information to the classifier.\n",
    "def get_fbcca_features(eeg_data, reference_signals, filters):\n",
    "    \"\"\"\n",
    "    Extracts features for a single trial using the enhanced FBCCA method.\n",
    "    The output is a concatenated vector of correlations from all filter banks.\n",
    "    Args:\n",
    "        eeg_data (np.ndarray): The raw EEG data for the trial [samples, channels].\n",
    "        reference_signals (dict): The generated sine/cosine reference signals.\n",
    "        filters (list): The list of filter coefficients from get_enhanced_filterbank.\n",
    "    Returns:\n",
    "        np.ndarray: A rich feature vector of concatenated CCA correlations (length = 20).\n",
    "    \"\"\"\n",
    "    cca = CCA(n_components=1)\n",
    "    # The final feature vector will contain the correlations for each frequency against each filter bank.\n",
    "    # Total length = len(SSVEP_FREQUENCIES) * len(filters) = 4 * 5 = 20\n",
    "    trial_feature_vector = []\n",
    "\n",
    "    for freq in SSVEP_FREQUENCIES:\n",
    "        ref_sig = reference_signals[freq]\n",
    "        \n",
    "        # Apply each filter in the bank and get the CCA correlation\n",
    "        for b, a in filters:\n",
    "            filtered_eeg = filtfilt(b, a, eeg_data, axis=0)\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            corr = np.corrcoef(X_c.ravel(), Y_c.ravel())[0, 1]\n",
    "            trial_feature_vector.append(corr)\n",
    "            \n",
    "    return np.array(trial_feature_vector)\n",
    "\n",
    "\n",
    "# --- 4. Main Execution Logic ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting SSVEP Classification Pipeline with ENHANCED features...\")\n",
    "\n",
    "    # Load index files\n",
    "    try:\n",
    "        train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "        validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Competition CSV files not found in {BASE_PATH}. Please check the path.\")\n",
    "        exit()\n",
    "\n",
    "    # Filter for SSVEP task only\n",
    "    train_ssvep_df = train_df[train_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    validation_ssvep_df = validation_df[validation_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "\n",
    "    # --- Pre-computation ---\n",
    "    print(\"Pre-computing reference signals and enhanced filter bank...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES, SAMPLING_RATE, NUM_HARMONICS)\n",
    "    filters = get_enhanced_filterbank(SAMPLING_RATE)\n",
    "    # The fb_weights are no longer needed as we are concatenating features.\n",
    "\n",
    "    # --- Feature Extraction and Normalization for TRAINING data ---\n",
    "    print(\"Extracting features from training data...\")\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    subjects_train = []\n",
    "    \n",
    "    for idx, row in train_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'train')\n",
    "        if eeg_trial is not None:\n",
    "            # Use the new feature extraction function\n",
    "            features = get_fbcca_features(eeg_trial, reference_signals, filters)\n",
    "            X_train.append(features)\n",
    "            y_train.append(row['label'])\n",
    "            subjects_train.append(row['subject_id'])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    subjects_train = np.array(subjects_train)\n",
    "\n",
    "    # **CRITICAL STEP: Per-Subject Normalization for Training Data**\n",
    "    print(\"Applying per-subject normalization to training features...\")\n",
    "    X_train_normalized = np.zeros_like(X_train)\n",
    "    subject_scalers = {}\n",
    "\n",
    "    for subject_id in np.unique(subjects_train):\n",
    "        subject_indices = np.where(subjects_train == subject_id)[0]\n",
    "        subject_features = X_train[subject_indices]\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(subject_features)\n",
    "        X_train_normalized[subject_indices] = scaled_features\n",
    "        subject_scalers[subject_id] = scaler\n",
    "\n",
    "    # --- Feature Extraction and Normalization for VALIDATION data ---\n",
    "    print(\"Extracting features from validation data...\")\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    subjects_val = []\n",
    "\n",
    "    for idx, row in validation_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'validation')\n",
    "        if eeg_trial is not None:\n",
    "            features = get_fbcca_features(eeg_trial, reference_signals, filters)\n",
    "            X_val.append(features)\n",
    "            y_val.append(row['label'])\n",
    "            subjects_val.append(row['subject_id'])\n",
    "            \n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    subjects_val = np.array(subjects_val)\n",
    "\n",
    "    # **CRITICAL STEP: Per-Subject Normalization for Validation Data**\n",
    "    print(\"Applying per-subject normalization to validation features...\")\n",
    "    X_val_normalized = np.zeros_like(X_val)\n",
    "\n",
    "    for subject_id in np.unique(subjects_val):\n",
    "        subject_indices = np.where(subjects_val == subject_id)[0]\n",
    "        subject_features = X_val[subject_indices]\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(subject_features)\n",
    "        X_val_normalized[subject_indices] = scaled_features\n",
    "\n",
    "\n",
    "    # --- 5. Model Training and Evaluation ---\n",
    "    print(\"\\n--- Model Training and Evaluation ---\")\n",
    "    lda_model = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    \n",
    "    print(\"Training LDA model...\")\n",
    "    lda_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    print(\"\\n--- Results on Validation Set ---\")\n",
    "    predictions = lda_model.predict(X_val_normalized)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, predictions, target_names=CLASS_LABELS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tier 1 leave one subject out cross validation + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Tier 1 Imports: Add classifiers and LabelEncoder ---\n",
    "from scipy.signal import cheby1, filtfilt\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import the classifiers we will test\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use the Kaggle directory structure\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "\n",
    "# --- Tier 1 Mod: Classifier Selection ---\n",
    "# Change this variable to 'XGBoost', 'LGBM', 'SVC', or 'LDA' to test different models.\n",
    "CLASSIFIER_TO_USE = 'XGBoost'\n",
    "\n",
    "# --- Tier 1 Mod: Easily Tunable Time Window ---\n",
    "# Experiment with these values to find the optimal signal segment.\n",
    "# The original paper on TRCA found that shorter windows (e.g., 0.5s) can be effective.\n",
    "TRIAL_TOTAL_DURATION = 7.0  # seconds in the original file\n",
    "SKIP_DURATION = 1.0         # Seconds to skip from the beginning of each trial (removes onset artifacts)\n",
    "DATA_DURATION = 5.0         # Seconds of data to actually use for analysis (the \"sweet spot\")\n",
    "\n",
    "# --- Core EEG & SSVEP Constants ---\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 3\n",
    "\n",
    "# Calculated sample counts based on the time window\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"\n",
    "    Loads raw EEG data for a single trial, applying the specified time window to skip initial artifacts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path_segment = dataset_type\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', path_segment, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        \n",
    "        trial_num = int(row['trial'])\n",
    "        \n",
    "        # Calculate start/end indices based on the refined time window\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        \n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        return trial_eeg_data.values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: EEGdata.csv not found at {eeg_path}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Feature Engineering Functions ---\n",
    "\n",
    "# --- Tier 1 Mod: Refined Filter Bank ---\n",
    "def get_refined_filterbank():\n",
    "    \"\"\"\n",
    "    Creates a bank of 5 narrow, systematic Chebyshev Type I bandpass filters.\n",
    "    This refined bank provides better frequency resolution to isolate SSVEP signals.\n",
    "    \"\"\"\n",
    "    filter_bands = []\n",
    "    # Create 5 bands of 8Hz width, starting from 6Hz and incrementing by 8Hz.\n",
    "    # This systematically covers the spectrum from 6Hz to 46Hz.\n",
    "    # Example: [6-14Hz], [14-22Hz], [22-30Hz], [30-38Hz], [38-46Hz]\n",
    "    for i in range(5):\n",
    "        low_freq = 6 + i * 8\n",
    "        high_freq = low_freq + 8\n",
    "        filter_bands.append([low_freq, high_freq])\n",
    "        \n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        nyquist = 0.5 * SAMPLING_RATE\n",
    "        # A filter order of 5 provides a good balance of sharpness and stability.\n",
    "        b, a = cheby1(5, 0.1, [low/nyquist, high/nyquist], btype='band')\n",
    "        filters.append((b, a))\n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    \"\"\"Applies each filter in the bank to the EEG data.\"\"\"\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    \"\"\"\n",
    "    Generates sine and cosine reference signals for each target frequency and its harmonics.\n",
    "    \"\"\"\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    \n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.append(np.sin(2 * np.pi * harmonic_freq * t))\n",
    "            refs.append(np.cos(2 * np.pi * harmonic_freq * t))\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "def get_fbcca_features(filtered_eeg_bank, reference_signals):\n",
    "    \"\"\"\n",
    "    Extracts features using the Filter-Bank CCA (FBCCA) method.\n",
    "    \"\"\"\n",
    "    cca = CCA(n_components=1)\n",
    "    fb_feature_vector = []\n",
    "\n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            # Handle potential NaN values in correlation\n",
    "            corr = np.corrcoef(X_c.ravel(), Y_c.ravel())[0, 1]\n",
    "            rho_k.append(corr if np.isfinite(corr) else 0)\n",
    "        fb_feature_vector.extend(rho_k)\n",
    "            \n",
    "    return np.array(fb_feature_vector)\n",
    "\n",
    "def get_trca_spatial_filters(X_train, y_train, labels):\n",
    "    \"\"\"\n",
    "    Computes Task-Related Component Analysis (TRCA) spatial filters.\n",
    "    These filters maximize the reproducibility (consistency) of the signal for each class.\n",
    "    \"\"\"\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "\n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2]) # Return zero vector if class not in fold\n",
    "            continue\n",
    "\n",
    "        class_trials = X_train[y_train == label]\n",
    "        \n",
    "        if class_trials.shape[0] < 2: # Need at least 2 trials to compute covariance\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "\n",
    "        class_trials_centered = class_trials - np.mean(class_trials, axis=1, keepdims=True)\n",
    "        \n",
    "        S = np.zeros((X_train.shape[2], X_train.shape[2]))\n",
    "        for i in range(class_trials_centered.shape[0]):\n",
    "            S += np.cov(class_trials_centered[i,:,:].T)\n",
    "\n",
    "        sum_of_trials = np.sum(class_trials_centered, axis=0)\n",
    "        Q = np.cov(sum_of_trials.T)\n",
    "        \n",
    "        try:\n",
    "            # Solve the generalized eigenvalue problem: Qw = Sw\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1] # Eigenvector for the largest eigenvalue\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Fallback for singular matrix S\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            \n",
    "    return spatial_filters\n",
    "\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    \"\"\"\n",
    "    Extracts features for a single trial using the learned TRCA spatial filters.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    # Create class template signals by applying the learned filters\n",
    "    templates = {label: eeg_trial @ w for label, w in spatial_filters.items()}\n",
    "    \n",
    "    for label, w in spatial_filters.items():\n",
    "        projected_eeg = eeg_trial @ w\n",
    "        # Correlate the projected signal with each class template\n",
    "        corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "        features.append(corr if np.isfinite(corr) else 0)\n",
    "        \n",
    "    return np.array(features)\n",
    "\n",
    "# --- 3. Main Execution Logic ---\n",
    "if __name__ == '__main__':\n",
    "    print(f\"--- Starting SSVEP Hybrid Pipeline ---\")\n",
    "    print(f\"Classifier selected: {CLASSIFIER_TO_USE}\")\n",
    "    print(f\"Time window: Skip {SKIP_DURATION}s, Use {DATA_DURATION}s\")\n",
    "\n",
    "    # Load competition index files\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    # Combine train and validation sets for robust cross-validation\n",
    "    full_train_df = pd.concat([\n",
    "        train_df[train_df['task'] == 'SSVEP'],\n",
    "        validation_df[validation_df['task'] == 'SSVEP']\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    # --- Pre-computation ---\n",
    "    print(\"\\nPre-computing reference signals and refined filter bank...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank() # Using the new refined filter bank\n",
    "    \n",
    "    # --- Load All Training Data ---\n",
    "    print(\"Loading all training & validation data...\")\n",
    "    X_all = [load_trial_data(row, BASE_PATH, 'train' if row['id'] <= 4800 else 'validation') for _, row in full_train_df.iterrows()]\n",
    "    X_all = np.array([x for x in X_all if x is not None and x.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS))])\n",
    "    \n",
    "    y_all = full_train_df['label'].values\n",
    "    subjects_all = full_train_df['subject_id'].values\n",
    "\n",
    "    # --- Tier 1 Mod: Label Encoding for XGBoost/LGBM ---\n",
    "    # Classifiers like XGBoost require integer labels instead of strings\n",
    "    le = LabelEncoder()\n",
    "    y_all_encoded = le.fit_transform(y_all)\n",
    "    \n",
    "    print(\"\\nPre-computing all features... (This may take a moment)\")\n",
    "    all_fbcca_features = np.array([get_fbcca_features(apply_filterbank(trial, filters), reference_signals) for trial in X_all])\n",
    "    all_trca_filters_for_features = get_trca_spatial_filters(X_all, y_all, CLASS_LABELS)\n",
    "    all_trca_features = np.array([extract_trca_features(trial, all_trca_filters_for_features) for trial in X_all])\n",
    "    all_hybrid_features = np.concatenate([all_trca_features, all_fbcca_features], axis=1)\n",
    "    print(\"Feature pre-computation complete.\")\n",
    "\n",
    "    # --- Leave-One-Subject-Out Cross-Validation ---\n",
    "    print(\"\\n--- Starting Leave-One-Subject-Out Cross-Validation ---\")\n",
    "    logo = LeaveOneGroupOut()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    # --- Tier 1 Mod: Define models and hyperparameter grids in one place ---\n",
    "    models = {\n",
    "        'XGBoost': (xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'), {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5],\n",
    "            'learning_rate': [0.05, 0.1]\n",
    "        }),\n",
    "        'LGBM': (lgb.LGBMClassifier(random_state=42), {\n",
    "            'n_estimators': [100, 200],\n",
    "            'num_leaves': [20, 31],\n",
    "            'learning_rate': [0.05, 0.1]\n",
    "        }),\n",
    "        'SVC': (SVC(probability=True, random_state=42), {\n",
    "            'C': [10, 50, 100],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['rbf'] \n",
    "        }),\n",
    "        'LDA': (LinearDiscriminantAnalysis(), {\n",
    "            'solver': ['lsqr'],\n",
    "            'shrinkage': ['auto', 0.1, 0.5, 0.9]\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    model_to_run, param_grid = models[CLASSIFIER_TO_USE]\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(logo.split(all_hybrid_features, y_all_encoded, groups=subjects_all)):\n",
    "        val_subject = subjects_all[val_idx][0]\n",
    "        print(f\"Fold {fold_idx+1}/{len(np.unique(subjects_all))}: Validating on subject {val_subject}\")\n",
    "\n",
    "        # Split features and labels for this fold\n",
    "        X_train_fold, X_val_fold = all_hybrid_features[train_idx], all_hybrid_features[val_idx]\n",
    "        y_train_fold, y_val_fold = y_all_encoded[train_idx], y_all_encoded[val_idx] # Use encoded labels\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Hyperparameter tuning for the selected model\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model_to_run,\n",
    "            param_grid=param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, # 3-fold CV within the training set of each LOSO fold\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        grid_search.fit(X_train_scaled, y_train_fold)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Store predictions\n",
    "        predictions_encoded = best_model.predict(X_val_scaled)\n",
    "        all_predictions.extend(predictions_encoded)\n",
    "        all_true_labels.extend(y_val_fold)\n",
    "\n",
    "    # --- Overall Cross-Validation Results ---\n",
    "    print(\"\\n--- Overall LOSO Cross-Validation Results ---\")\n",
    "    # Decode labels back to strings for the report\n",
    "    all_true_str = le.inverse_transform(all_true_labels)\n",
    "    all_predictions_str = le.inverse_transform(all_predictions)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(all_true_str, all_predictions_str)\n",
    "    print(f\"Overall LOSO CV Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_true_str, all_predictions_str, target_names=CLASS_LABELS))\n",
    "    \n",
    "    # --- Final Model Training and Submission File Generation ---\n",
    "    print(\"\\n--- Training Final Model on All Data for Submission ---\")\n",
    "    \n",
    "    # Scale all features\n",
    "    final_scaler = StandardScaler()\n",
    "    X_all_scaled = final_scaler.fit_transform(all_hybrid_features)\n",
    "    \n",
    "    # Re-run grid search on all data to find the absolute best parameters\n",
    "    print(\"Finding best hyperparameters for the final model...\")\n",
    "    final_grid_search = GridSearchCV(estimator=model_to_run, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "    final_grid_search.fit(X_all_scaled, y_all_encoded)\n",
    "    final_model = final_grid_search.best_estimator_\n",
    "    print(f\"Final model trained with best parameters: {final_grid_search.best_params_}\")\n",
    "    \n",
    "    print(\"\\nGenerating predictions for the test set...\")\n",
    "    test_ssvep_df = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    test_predictions_list = []\n",
    "\n",
    "    for idx, row in test_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'test')\n",
    "        if eeg_trial is not None and eeg_trial.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            # Extract features for the test trial\n",
    "            fbcca_feat = get_fbcca_features(apply_filterbank(eeg_trial, filters), reference_signals).reshape(1, -1)\n",
    "            trca_feat = extract_trca_features(eeg_trial, all_trca_filters_for_features).reshape(1, -1)\n",
    "            X_test_hybrid = np.concatenate([trca_feat, fbcca_feat], axis=1)\n",
    "            \n",
    "            # Scale and predict\n",
    "            X_test_scaled = final_scaler.transform(X_test_hybrid)\n",
    "            prediction_encoded = final_model.predict(X_test_scaled)[0]\n",
    "            test_predictions_list.append(prediction_encoded)\n",
    "        else:\n",
    "            # Fallback: predict the most frequent class if data is missing/corrupt\n",
    "            most_frequent_class_encoded = le.transform([pd.Series(y_all).mode()[0]])[0]\n",
    "            test_predictions_list.append(most_frequent_class_encoded)\n",
    "\n",
    "    # Decode predictions and create submission file\n",
    "    final_predictions_str = le.inverse_transform(test_predictions_list)\n",
    "    submission_df = pd.DataFrame({'id': test_ssvep_df['id'], 'label': final_predictions_str})\n",
    "    submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nSubmission file 'submission.csv' has been created successfully!\")\n",
    "    print(submission_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New feature type + Voting ensemble (67% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Feature Type - Power Spectral Density (PSD): I've added a new function, get_psd_features, which calculates the signal power at the precise target frequencies and their harmonics for each EEG channel. This provides a completely new source of information for the model, complementing the correlation-based features. The final feature set now combines TRCA + FBCCA + PSD.\n",
    "Ensemble Classifier (VotingClassifier): Instead of relying on a single model, this script now uses a VotingClassifier. This powerful technique combines the predictions from three different models (XGBoost, SVC, and LDA). By averaging their \"votes\" (specifically, their predicted probabilities), the ensemble can produce a more robust and accurate final decision, smoothing out the errors of any single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T21:50:52.138761Z",
     "iopub.status.busy": "2025-06-27T21:50:52.138438Z",
     "iopub.status.idle": "2025-06-27T21:59:31.807365Z",
     "shell.execute_reply": "2025-06-27T21:59:31.806395Z",
     "shell.execute_reply.started": "2025-06-27T21:50:52.138730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting SSVEP Pipeline: Tier 2 (Ensemble + PSD Features) ---\n",
      "\n",
      "Pre-computing references and filters...\n",
      "Loading all training & validation data...\n",
      "\n",
      "Pre-computing all features (TRCA, FBCCA, PSD)...\n",
      "Feature engineering complete. Total feature dimension: 120\n",
      "\n",
      "Defining Ensemble Classifier...\n",
      "\n",
      "--- Starting LOSO Cross-Validation with Ensemble Model ---\n",
      "Fold 1/35: Validating on subject S1\n",
      "Fold 2/35: Validating on subject S10\n",
      "Fold 3/35: Validating on subject S11\n",
      "Fold 4/35: Validating on subject S12\n",
      "Fold 5/35: Validating on subject S13\n",
      "Fold 6/35: Validating on subject S14\n",
      "Fold 7/35: Validating on subject S15\n",
      "Fold 8/35: Validating on subject S16\n",
      "Fold 9/35: Validating on subject S17\n",
      "Fold 10/35: Validating on subject S18\n",
      "Fold 11/35: Validating on subject S19\n",
      "Fold 12/35: Validating on subject S2\n",
      "Fold 13/35: Validating on subject S20\n",
      "Fold 14/35: Validating on subject S21\n",
      "Fold 15/35: Validating on subject S22\n",
      "Fold 16/35: Validating on subject S23\n",
      "Fold 17/35: Validating on subject S24\n",
      "Fold 18/35: Validating on subject S25\n",
      "Fold 19/35: Validating on subject S26\n",
      "Fold 20/35: Validating on subject S27\n",
      "Fold 21/35: Validating on subject S28\n",
      "Fold 22/35: Validating on subject S29\n",
      "Fold 23/35: Validating on subject S3\n",
      "Fold 24/35: Validating on subject S30\n",
      "Fold 25/35: Validating on subject S31\n",
      "Fold 26/35: Validating on subject S32\n",
      "Fold 27/35: Validating on subject S33\n",
      "Fold 28/35: Validating on subject S34\n",
      "Fold 29/35: Validating on subject S35\n",
      "Fold 30/35: Validating on subject S4\n",
      "Fold 31/35: Validating on subject S5\n",
      "Fold 32/35: Validating on subject S6\n",
      "Fold 33/35: Validating on subject S7\n",
      "Fold 34/35: Validating on subject S8\n",
      "Fold 35/35: Validating on subject S9\n",
      "\n",
      "--- Overall LOSO CV Results for Ensemble Model ---\n",
      "Overall LOSO CV Accuracy: 0.6731\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Forward       0.73      0.69      0.71       650\n",
      "    Backward       0.69      0.67      0.68       592\n",
      "        Left       0.62      0.65      0.63       599\n",
      "       Right       0.66      0.69      0.67       609\n",
      "\n",
      "    accuracy                           0.67      2450\n",
      "   macro avg       0.67      0.67      0.67      2450\n",
      "weighted avg       0.67      0.67      0.67      2450\n",
      "\n",
      "\n",
      "--- Training Final Ensemble Model on All Data for Submission ---\n",
      "Final ensemble model training complete.\n",
      "\n",
      "Generating predictions for the test set...\n",
      "\n",
      "Submission file 'submission.csv' has been created successfully!\n",
      "     id     label\n",
      "0  4951  Backward\n",
      "1  4952  Backward\n",
      "2  4953   Forward\n",
      "3  4954  Backward\n",
      "4  4955  Backward\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Tier 2 Imports: Welch for PSD, VotingClassifier for Ensembling ---\n",
    "from scipy.signal import cheby1, filtfilt, welch\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import the classifiers for the ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "\n",
    "# Time window configuration\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 1.0\n",
    "DATA_DURATION = 5.0\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 3\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "\n",
    "# --- 1. Data Loading Function (Unchanged) ---\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"\n",
    "    Loads raw EEG data for a single trial, applying the specified time window.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path_segment = dataset_type\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', path_segment, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        return trial_eeg_data.values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: EEGdata.csv not found at {eeg_path}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Feature Engineering Functions ---\n",
    "\n",
    "# --- Tier 2 New Feature: Power Spectral Density (PSD) ---\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Calculates Power Spectral Density (PSD) features for a trial.\n",
    "    This captures the power of the signal at key frequencies.\n",
    "    \"\"\"\n",
    "    psd_features = []\n",
    "    \n",
    "    # Define a narrow band for extracting power around the target frequencies\n",
    "    freq_band_width = 0.5 # Hz\n",
    "    \n",
    "    for channel_data in eeg_trial.T: # Iterate through each of the 8 channels\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=SAMPLES_PER_SSVEP_TRIAL)\n",
    "        \n",
    "        # For each target frequency, calculate the average power in a narrow band around it and its harmonics\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                band_mask = (freqs >= harmonic_freq - freq_band_width) & (freqs <= harmonic_freq + freq_band_width)\n",
    "                \n",
    "                if np.any(band_mask):\n",
    "                    avg_power = np.mean(psd[band_mask])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0) # Append 0 if the frequency is not found\n",
    "                    \n",
    "    return np.array(psd_features)\n",
    "\n",
    "\n",
    "# --- FBCCA and TRCA Functions (Unchanged from Tier 1) ---\n",
    "def get_refined_filterbank():\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        filters.append((b, a))\n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "def get_fbcca_features(filtered_eeg_bank, reference_signals):\n",
    "    cca = CCA(n_components=1)\n",
    "    fb_feature_vector = []\n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            corr = np.corrcoef(X_c.ravel(), Y_c.ravel())[0, 1]\n",
    "            rho_k.append(corr if np.isfinite(corr) else 0)\n",
    "        fb_feature_vector.extend(rho_k)\n",
    "    return np.array(fb_feature_vector)\n",
    "\n",
    "def get_trca_spatial_filters(X_train, y_train, labels):\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        class_trials_centered = class_trials - np.mean(class_trials, axis=1, keepdims=True)\n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    return spatial_filters\n",
    "\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    features = []\n",
    "    templates = {label: eeg_trial @ w for label, w in spatial_filters.items()}\n",
    "    for label, w in spatial_filters.items():\n",
    "        projected_eeg = eeg_trial @ w\n",
    "        corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "        features.append(corr if np.isfinite(corr) else 0)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# --- 3. Main Execution Logic ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting SSVEP Pipeline: Tier 2 (Ensemble + PSD Features) ---\")\n",
    "\n",
    "    # Load competition index files\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    full_train_df = pd.concat([\n",
    "        train_df[train_df['task'] == 'SSVEP'],\n",
    "        validation_df[validation_df['task'] == 'SSVEP']\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    print(\"Loading all training & validation data...\")\n",
    "    X_all_raw = [load_trial_data(row, BASE_PATH, 'train' if row['id'] <= 4800 else 'validation') for _, row in full_train_df.iterrows()]\n",
    "    \n",
    "    # Filter out None values and create final arrays\n",
    "    valid_indices = [i for i, x in enumerate(X_all_raw) if x is not None and x.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS))]\n",
    "    X_all = np.array([X_all_raw[i] for i in valid_indices])\n",
    "    y_all = full_train_df.loc[valid_indices, 'label'].values\n",
    "    subjects_all = full_train_df.loc[valid_indices, 'subject_id'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_all_encoded = le.fit_transform(y_all)\n",
    "    \n",
    "    print(\"\\nPre-computing all features (TRCA, FBCCA, PSD)...\")\n",
    "    # FBCCA features\n",
    "    all_fbcca_features = np.array([get_fbcca_features(apply_filterbank(trial, filters), reference_signals) for trial in X_all])\n",
    "    # TRCA features\n",
    "    all_trca_filters_for_features = get_trca_spatial_filters(X_all, y_all, CLASS_LABELS)\n",
    "    all_trca_features = np.array([extract_trca_features(trial, all_trca_filters_for_features) for trial in X_all])\n",
    "    # PSD features\n",
    "    all_psd_features = np.array([get_psd_features(trial) for trial in X_all])\n",
    "    \n",
    "    # --- Tier 2 Feature Concatenation ---\n",
    "    all_features_combined = np.concatenate([all_trca_features, all_fbcca_features, all_psd_features], axis=1)\n",
    "    print(f\"Feature engineering complete. Total feature dimension: {all_features_combined.shape[1]}\")\n",
    "\n",
    "    # --- Tier 2 Ensemble Model Definition ---\n",
    "    print(\"\\nDefining Ensemble Classifier...\")\n",
    "    # Base models for the ensemble. Parameters are set to reasonable defaults or values found from Tier 1.\n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=50, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    # Create the Voting Classifier\n",
    "    # 'soft' voting uses predicted probabilities, which is often better than 'hard' (majority rule).\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.4, 0.4, 0.2] # Give more weight to the more powerful models\n",
    "    )\n",
    "    \n",
    "    # --- Leave-One-Subject-Out Cross-Validation with the Ensemble ---\n",
    "    print(\"\\n--- Starting LOSO Cross-Validation with Ensemble Model ---\")\n",
    "    logo = LeaveOneGroupOut()\n",
    "    all_predictions_encoded = []\n",
    "    all_true_labels_encoded = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(logo.split(all_features_combined, y_all_encoded, groups=subjects_all)):\n",
    "        val_subject = subjects_all[val_idx][0]\n",
    "        print(f\"Fold {fold_idx+1}/{len(np.unique(subjects_all))}: Validating on subject {val_subject}\")\n",
    "\n",
    "        X_train_fold, X_val_fold = all_features_combined[train_idx], all_features_combined[val_idx]\n",
    "        y_train_fold = y_all_encoded[train_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Fit the entire ensemble model\n",
    "        ensemble_model.fit(X_train_scaled, y_train_fold)\n",
    "        \n",
    "        predictions_encoded = ensemble_model.predict(X_val_scaled)\n",
    "        all_predictions_encoded.extend(predictions_encoded)\n",
    "        all_true_labels_encoded.extend(y_all_encoded[val_idx])\n",
    "\n",
    "    # --- Overall Cross-Validation Results ---\n",
    "    print(\"\\n--- Overall LOSO CV Results for Ensemble Model ---\")\n",
    "    all_true_str = le.inverse_transform(all_true_labels_encoded)\n",
    "    all_predictions_str = le.inverse_transform(all_predictions_encoded)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(all_true_str, all_predictions_str)\n",
    "    print(f\"Overall LOSO CV Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_true_str, all_predictions_str, target_names=CLASS_LABELS))\n",
    "    \n",
    "    # --- Final Model Training and Submission ---\n",
    "    print(\"\\n--- Training Final Ensemble Model on All Data for Submission ---\")\n",
    "    \n",
    "    final_scaler = StandardScaler()\n",
    "    X_all_scaled = final_scaler.fit_transform(all_features_combined)\n",
    "    \n",
    "    ensemble_model.fit(X_all_scaled, y_all_encoded)\n",
    "    print(\"Final ensemble model training complete.\")\n",
    "    \n",
    "    print(\"\\nGenerating predictions for the test set...\")\n",
    "    test_ssvep_df = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    test_predictions_list = []\n",
    "\n",
    "    for idx, row in test_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'test')\n",
    "        if eeg_trial is not None and eeg_trial.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            fbcca_feat = get_fbcca_features(apply_filterbank(eeg_trial, filters), reference_signals).reshape(1, -1)\n",
    "            trca_feat = extract_trca_features(eeg_trial, all_trca_filters_for_features).reshape(1, -1)\n",
    "            psd_feat = get_psd_features(eeg_trial).reshape(1, -1)\n",
    "            \n",
    "            X_test_combined = np.concatenate([trca_feat, fbcca_feat, psd_feat], axis=1)\n",
    "            \n",
    "            X_test_scaled = final_scaler.transform(X_test_combined)\n",
    "            prediction_encoded = ensemble_model.predict(X_test_scaled)[0]\n",
    "            test_predictions_list.append(prediction_encoded)\n",
    "        else:\n",
    "            most_frequent_class_encoded = le.transform([pd.Series(y_all).mode()[0]])[0]\n",
    "            test_predictions_list.append(most_frequent_class_encoded)\n",
    "\n",
    "    final_predictions_str = le.inverse_transform(test_predictions_list)\n",
    "    submission_df = pd.DataFrame({'id': test_ssvep_df['id'], 'label': final_predictions_str})\n",
    "    submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nSubmission file 'submission.csv' has been created successfully!\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code prints the confusion matrix of each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T22:59:23.481458Z",
     "iopub.status.busy": "2025-07-16T22:59:23.480818Z",
     "iopub.status.idle": "2025-07-16T23:08:47.117356Z",
     "shell.execute_reply": "2025-07-16T23:08:47.116393Z",
     "shell.execute_reply.started": "2025-07-16T22:59:23.481416Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting SSVEP Pipeline: Tier 2 (Ensemble + PSD Features) ---\n",
      "\n",
      "Pre-computing references and filters...\n",
      "Loading all training & validation data...\n",
      "\n",
      "Pre-computing all features (TRCA, FBCCA, PSD)...\n",
      "Feature engineering complete. Total feature dimension: 120\n",
      "\n",
      "Defining Ensemble Classifier...\n",
      "\n",
      "--- Starting LOSO Cross-Validation with Ensemble Model ---\n",
      "Fold 1/35: Validating on subject S1\n",
      "  Accuracy: 0.3500\n",
      "  F1-Score (Weighted): 0.3566\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         7       11     6      1\n",
      "Forward          0        7     1      2\n",
      "Left             2        9     8      3\n",
      "Right            3        7     7      6\n",
      "------------------------------------------------------------\n",
      "Fold 2/35: Validating on subject S10\n",
      "  Accuracy: 0.5750\n",
      "  F1-Score (Weighted): 0.5775\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        18        4     4      1\n",
      "Forward          2       10     3      2\n",
      "Left             2        5    10      3\n",
      "Right            3        3     2      8\n",
      "------------------------------------------------------------\n",
      "Fold 3/35: Validating on subject S11\n",
      "  Accuracy: 0.6625\n",
      "  F1-Score (Weighted): 0.6594\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        18        1     2      1\n",
      "Forward          1        9     3      2\n",
      "Left             2        4    13      4\n",
      "Right            6        1     0     13\n",
      "------------------------------------------------------------\n",
      "Fold 4/35: Validating on subject S12\n",
      "  Accuracy: 0.8625\n",
      "  F1-Score (Weighted): 0.8621\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        17        0     0      1\n",
      "Forward          1       12     2      1\n",
      "Left             1        0    19      2\n",
      "Right            1        0     2     21\n",
      "------------------------------------------------------------\n",
      "Fold 5/35: Validating on subject S13\n",
      "  Accuracy: 0.6625\n",
      "  F1-Score (Weighted): 0.6656\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        14        0     4      2\n",
      "Forward          1       16     4      0\n",
      "Left             3        0    15      0\n",
      "Right            3        0    10      8\n",
      "------------------------------------------------------------\n",
      "Fold 6/35: Validating on subject S14\n",
      "  Accuracy: 0.5750\n",
      "  F1-Score (Weighted): 0.5912\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        13        1     8      0\n",
      "Forward          2       12     6      1\n",
      "Left             1        2    11      0\n",
      "Right            3        2     8     10\n",
      "------------------------------------------------------------\n",
      "Fold 7/35: Validating on subject S15\n",
      "  Accuracy: 0.5125\n",
      "  F1-Score (Weighted): 0.5178\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        11        6     8      0\n",
      "Forward          1        8     4      3\n",
      "Left             3        4    10      2\n",
      "Right            4        1     3     12\n",
      "------------------------------------------------------------\n",
      "Fold 8/35: Validating on subject S16\n",
      "  Accuracy: 0.7500\n",
      "  F1-Score (Weighted): 0.7429\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        19        2     0      1\n",
      "Forward          3       12     3      5\n",
      "Left             1        3    15      1\n",
      "Right            1        0     0     14\n",
      "------------------------------------------------------------\n",
      "Fold 9/35: Validating on subject S17\n",
      "  Accuracy: 0.9375\n",
      "  F1-Score (Weighted): 0.9374\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        17        0     2      1\n",
      "Forward          1       21     1      0\n",
      "Left             0        0    16      0\n",
      "Right            0        0     0     21\n",
      "------------------------------------------------------------\n",
      "Fold 10/35: Validating on subject S18\n",
      "  Accuracy: 0.4500\n",
      "  F1-Score (Weighted): 0.4426\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         7        6     2      6\n",
      "Forward          3        9     2      3\n",
      "Left             2        7     7      5\n",
      "Right            2        2     4     13\n",
      "------------------------------------------------------------\n",
      "Fold 11/35: Validating on subject S19\n",
      "  Accuracy: 0.4500\n",
      "  F1-Score (Weighted): 0.4502\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         8        1     7      4\n",
      "Forward          4       10     8      8\n",
      "Left             1        3     9      3\n",
      "Right            3        0     2      9\n",
      "------------------------------------------------------------\n",
      "Fold 12/35: Validating on subject S2\n",
      "  Accuracy: 0.7625\n",
      "  F1-Score (Weighted): 0.7634\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        12        0     5      0\n",
      "Forward          0       12     1      3\n",
      "Left             4        0    17      1\n",
      "Right            2        3     0     20\n",
      "------------------------------------------------------------\n",
      "Fold 13/35: Validating on subject S20\n",
      "  Accuracy: 0.8750\n",
      "  F1-Score (Weighted): 0.8771\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        19        0     4      1\n",
      "Forward          1       20     3      1\n",
      "Left             0        0    15      0\n",
      "Right            0        0     0     16\n",
      "------------------------------------------------------------\n",
      "Fold 14/35: Validating on subject S21\n",
      "  Accuracy: 0.6625\n",
      "  F1-Score (Weighted): 0.6585\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        12        0     2      0\n",
      "Forward          0       11     6      2\n",
      "Left             3        0    18      2\n",
      "Right            1        4     7     12\n",
      "------------------------------------------------------------\n",
      "Fold 15/35: Validating on subject S22\n",
      "  Accuracy: 0.6250\n",
      "  F1-Score (Weighted): 0.6187\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        15        5     6      4\n",
      "Forward          0       15     0      2\n",
      "Left             2        3     7      2\n",
      "Right            3        2     1     13\n",
      "------------------------------------------------------------\n",
      "Fold 16/35: Validating on subject S23\n",
      "  Accuracy: 0.5625\n",
      "  F1-Score (Weighted): 0.5561\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         6        5     6      3\n",
      "Forward          1       10     2      2\n",
      "Left             3        5    14      0\n",
      "Right            3        1     4     15\n",
      "------------------------------------------------------------\n",
      "Fold 17/35: Validating on subject S24\n",
      "  Accuracy: 0.9250\n",
      "  F1-Score (Weighted): 0.9236\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        17        0     0      0\n",
      "Forward          0       18     2      0\n",
      "Left             1        2    19      1\n",
      "Right            0        0     0     20\n",
      "------------------------------------------------------------\n",
      "Fold 18/35: Validating on subject S25\n",
      "  Accuracy: 0.7625\n",
      "  F1-Score (Weighted): 0.7625\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        18        0     2      1\n",
      "Forward          2       17     1      1\n",
      "Left             2        3    15      0\n",
      "Right            6        0     1     11\n",
      "------------------------------------------------------------\n",
      "Fold 19/35: Validating on subject S26\n",
      "  Accuracy: 0.8375\n",
      "  F1-Score (Weighted): 0.8307\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        14        0     2      0\n",
      "Forward          0       12     5      4\n",
      "Left             0        0    23      1\n",
      "Right            1        0     0     18\n",
      "------------------------------------------------------------\n",
      "Fold 20/35: Validating on subject S27\n",
      "  Accuracy: 0.1625\n",
      "  F1-Score (Weighted): 0.0874\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         1        2     3     18\n",
      "Forward          2        0     0     16\n",
      "Left             0        1     0     18\n",
      "Right            5        1     1     12\n",
      "------------------------------------------------------------\n",
      "Fold 21/35: Validating on subject S28\n",
      "  Accuracy: 0.7750\n",
      "  F1-Score (Weighted): 0.7724\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        18        0     0      0\n",
      "Forward          0       17     2      0\n",
      "Left             7        1    14      1\n",
      "Right            4        1     2     13\n",
      "------------------------------------------------------------\n",
      "Fold 22/35: Validating on subject S29\n",
      "  Accuracy: 0.8125\n",
      "  F1-Score (Weighted): 0.8075\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        25        0     1      1\n",
      "Forward          0       17     1      3\n",
      "Left             5        1     8      1\n",
      "Right            1        0     1     15\n",
      "------------------------------------------------------------\n",
      "Fold 23/35: Validating on subject S3\n",
      "  Accuracy: 0.7625\n",
      "  F1-Score (Weighted): 0.7718\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        14        0     4      0\n",
      "Forward          0       12     8      0\n",
      "Left             1        0    19      0\n",
      "Right            2        0     4     16\n",
      "------------------------------------------------------------\n",
      "Fold 24/35: Validating on subject S30\n",
      "  Accuracy: 0.8125\n",
      "  F1-Score (Weighted): 0.7900\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        22        0     0      1\n",
      "Forward          3        7     8      1\n",
      "Left             0        0    21      1\n",
      "Right            0        0     1     15\n",
      "------------------------------------------------------------\n",
      "Fold 25/35: Validating on subject S31\n",
      "  Accuracy: 0.3000\n",
      "  F1-Score (Weighted): 0.3333\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         1        0     1      0\n",
      "Forward          0        2     2      0\n",
      "Left             0        2     0      1\n",
      "Right            0        0     1      0\n",
      "------------------------------------------------------------\n",
      "Fold 26/35: Validating on subject S32\n",
      "  Accuracy: 0.4000\n",
      "  F1-Score (Weighted): 0.3619\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         1        0     0      1\n",
      "Forward          1        1     0      0\n",
      "Left             2        0     0      1\n",
      "Right            1        0     0      2\n",
      "------------------------------------------------------------\n",
      "Fold 27/35: Validating on subject S33\n",
      "  Accuracy: 0.8000\n",
      "  F1-Score (Weighted): 0.7905\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         1        0     0      1\n",
      "Forward          0        3     0      0\n",
      "Left             0        1     2      0\n",
      "Right            0        0     0      2\n",
      "------------------------------------------------------------\n",
      "Fold 28/35: Validating on subject S34\n",
      "  Accuracy: 0.3000\n",
      "  F1-Score (Weighted): 0.2727\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         3        0     2      0\n",
      "Forward          0        0     1      0\n",
      "Left             1        0     0      0\n",
      "Right            2        0     1      0\n",
      "------------------------------------------------------------\n",
      "Fold 29/35: Validating on subject S35\n",
      "  Accuracy: 0.8000\n",
      "  F1-Score (Weighted): 0.7838\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         3        0     0      0\n",
      "Forward          0        2     0      0\n",
      "Left             1        1     2      0\n",
      "Right            0        0     0      1\n",
      "------------------------------------------------------------\n",
      "Fold 30/35: Validating on subject S4\n",
      "  Accuracy: 0.9250\n",
      "  F1-Score (Weighted): 0.9231\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        27        0     0      0\n",
      "Forward          0        9     0      0\n",
      "Left             0        0    15      6\n",
      "Right            0        0     0     23\n",
      "------------------------------------------------------------\n",
      "Fold 31/35: Validating on subject S5\n",
      "  Accuracy: 0.3750\n",
      "  F1-Score (Weighted): 0.3759\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         4        1     2      5\n",
      "Forward          6        7     3      7\n",
      "Left             3        3     5      7\n",
      "Right            7        4     2     14\n",
      "------------------------------------------------------------\n",
      "Fold 32/35: Validating on subject S6\n",
      "  Accuracy: 0.7500\n",
      "  F1-Score (Weighted): 0.7330\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        19        2     0      0\n",
      "Forward          0       20     0      0\n",
      "Left             1        6     5      2\n",
      "Right            5        3     1     16\n",
      "------------------------------------------------------------\n",
      "Fold 33/35: Validating on subject S7\n",
      "  Accuracy: 0.7125\n",
      "  F1-Score (Weighted): 0.7217\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        15        2     0      5\n",
      "Forward          0       16     1      6\n",
      "Left             1        2    13      2\n",
      "Right            1        2     1     13\n",
      "------------------------------------------------------------\n",
      "Fold 34/35: Validating on subject S8\n",
      "  Accuracy: 0.8625\n",
      "  F1-Score (Weighted): 0.8574\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        22        0     0      0\n",
      "Forward          0       22     0      0\n",
      "Left             3        0    15      2\n",
      "Right            1        0     5     10\n",
      "------------------------------------------------------------\n",
      "Fold 35/35: Validating on subject S9\n",
      "  Accuracy: 0.5375\n",
      "  F1-Score (Weighted): 0.5378\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         8       10     0      3\n",
      "Forward          1       19     1      2\n",
      "Left             0        8     9      4\n",
      "Right            0        8     0      7\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Overall LOSO CV Results for Ensemble Model ---\n",
      "Overall LOSO CV Accuracy: 0.6731\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Forward       0.73      0.69      0.71       650\n",
      "    Backward       0.69      0.67      0.68       592\n",
      "        Left       0.62      0.65      0.63       599\n",
      "       Right       0.66      0.69      0.67       609\n",
      "\n",
      "    accuracy                           0.67      2450\n",
      "   macro avg       0.67      0.67      0.67      2450\n",
      "weighted avg       0.67      0.67      0.67      2450\n",
      "\n",
      "\n",
      "--- Training Final Ensemble Model on All Data for Submission ---\n",
      "Final ensemble model training complete.\n",
      "\n",
      "Generating predictions for the test set...\n",
      "\n",
      "Submission file 'submission.csv' has been created successfully!\n",
      "     id     label\n",
      "0  4951  Backward\n",
      "1  4952  Backward\n",
      "2  4953   Forward\n",
      "3  4954  Backward\n",
      "4  4955  Backward\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Tier 2 Imports: Welch for PSD, VotingClassifier for Ensembling ---\n",
    "from scipy.signal import cheby1, filtfilt, welch\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "# MODIFICATION START: Import additional metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "# MODIFICATION END\n",
    "\n",
    "# Import the classifiers for the ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "\n",
    "# Time window configuration\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 1.0\n",
    "DATA_DURATION = 5.0\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 3\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "\n",
    "# --- 1. Data Loading Function (Unchanged) ---\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"\n",
    "    Loads raw EEG data for a single trial, applying the specified time window.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path_segment = dataset_type\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', path_segment, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        return trial_eeg_data.values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: EEGdata.csv not found at {eeg_path}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Feature Engineering Functions ---\n",
    "\n",
    "# --- Tier 2 New Feature: Power Spectral Density (PSD) ---\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Calculates Power Spectral Density (PSD) features for a trial.\n",
    "    This captures the power of the signal at key frequencies.\n",
    "    \"\"\"\n",
    "    psd_features = []\n",
    "    \n",
    "    # Define a narrow band for extracting power around the target frequencies\n",
    "    freq_band_width = 0.5 # Hz\n",
    "    \n",
    "    for channel_data in eeg_trial.T: # Iterate through each of the 8 channels\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=SAMPLES_PER_SSVEP_TRIAL)\n",
    "        \n",
    "        # For each target frequency, calculate the average power in a narrow band around it and its harmonics\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                band_mask = (freqs >= harmonic_freq - freq_band_width) & (freqs <= harmonic_freq + freq_band_width)\n",
    "                \n",
    "                if np.any(band_mask):\n",
    "                    avg_power = np.mean(psd[band_mask])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0) # Append 0 if the frequency is not found\n",
    "                    \n",
    "    return np.array(psd_features)\n",
    "\n",
    "\n",
    "# --- FBCCA and TRCA Functions (Unchanged from Tier 1) ---\n",
    "def get_refined_filterbank():\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        filters.append((b, a))\n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "def get_fbcca_features(filtered_eeg_bank, reference_signals):\n",
    "    cca = CCA(n_components=1)\n",
    "    fb_feature_vector = []\n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            corr = np.corrcoef(X_c.ravel(), Y_c.ravel())[0, 1]\n",
    "            rho_k.append(corr if np.isfinite(corr) else 0)\n",
    "        fb_feature_vector.extend(rho_k)\n",
    "    return np.array(fb_feature_vector)\n",
    "\n",
    "def get_trca_spatial_filters(X_train, y_train, labels):\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        class_trials_centered = class_trials - np.mean(class_trials, axis=1, keepdims=True)\n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    return spatial_filters\n",
    "\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    features = []\n",
    "    templates = {label: eeg_trial @ w for label, w in spatial_filters.items()}\n",
    "    for label, w in spatial_filters.items():\n",
    "        projected_eeg = eeg_trial @ w\n",
    "        corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "        features.append(corr if np.isfinite(corr) else 0)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# --- 3. Main Execution Logic ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting SSVEP Pipeline: Tier 2 (Ensemble + PSD Features) ---\")\n",
    "\n",
    "    # Load competition index files\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    full_train_df = pd.concat([\n",
    "        train_df[train_df['task'] == 'SSVEP'],\n",
    "        validation_df[validation_df['task'] == 'SSVEP']\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    print(\"Loading all training & validation data...\")\n",
    "    X_all_raw = [load_trial_data(row, BASE_PATH, 'train' if row['id'] <= 4800 else 'validation') for _, row in full_train_df.iterrows()]\n",
    "    \n",
    "    # Filter out None values and create final arrays\n",
    "    valid_indices = [i for i, x in enumerate(X_all_raw) if x is not None and x.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS))]\n",
    "    X_all = np.array([X_all_raw[i] for i in valid_indices])\n",
    "    y_all = full_train_df.loc[valid_indices, 'label'].values\n",
    "    subjects_all = full_train_df.loc[valid_indices, 'subject_id'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_all_encoded = le.fit_transform(y_all)\n",
    "    \n",
    "    print(\"\\nPre-computing all features (TRCA, FBCCA, PSD)...\")\n",
    "    # FBCCA features\n",
    "    all_fbcca_features = np.array([get_fbcca_features(apply_filterbank(trial, filters), reference_signals) for trial in X_all])\n",
    "    # TRCA features\n",
    "    all_trca_filters_for_features = get_trca_spatial_filters(X_all, y_all, CLASS_LABELS)\n",
    "    all_trca_features = np.array([extract_trca_features(trial, all_trca_filters_for_features) for trial in X_all])\n",
    "    # PSD features\n",
    "    all_psd_features = np.array([get_psd_features(trial) for trial in X_all])\n",
    "    \n",
    "    # --- Tier 2 Feature Concatenation ---\n",
    "    all_features_combined = np.concatenate([all_trca_features, all_fbcca_features, all_psd_features], axis=1)\n",
    "    print(f\"Feature engineering complete. Total feature dimension: {all_features_combined.shape[1]}\")\n",
    "\n",
    "    # --- Tier 2 Ensemble Model Definition ---\n",
    "    print(\"\\nDefining Ensemble Classifier...\")\n",
    "    # Base models for the ensemble. Parameters are set to reasonable defaults or values found from Tier 1.\n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=50, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    # Create the Voting Classifier\n",
    "    # 'soft' voting uses predicted probabilities, which is often better than 'hard' (majority rule).\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.4, 0.4, 0.2] # Give more weight to the more powerful models\n",
    "    )\n",
    "    \n",
    "    # --- Leave-One-Subject-Out Cross-Validation with the Ensemble ---\n",
    "    print(\"\\n--- Starting LOSO Cross-Validation with Ensemble Model ---\")\n",
    "    logo = LeaveOneGroupOut()\n",
    "    all_predictions_encoded = []\n",
    "    all_true_labels_encoded = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(logo.split(all_features_combined, y_all_encoded, groups=subjects_all)):\n",
    "        val_subject = subjects_all[val_idx][0]\n",
    "        print(f\"Fold {fold_idx+1}/{len(np.unique(subjects_all))}: Validating on subject {val_subject}\")\n",
    "\n",
    "        X_train_fold, X_val_fold = all_features_combined[train_idx], all_features_combined[val_idx]\n",
    "        y_train_fold, y_val_fold = y_all_encoded[train_idx], y_all_encoded[val_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Fit the entire ensemble model\n",
    "        ensemble_model.fit(X_train_scaled, y_train_fold)\n",
    "        \n",
    "        predictions_encoded = ensemble_model.predict(X_val_scaled)\n",
    "        \n",
    "        # MODIFICATION START: Calculate and print metrics for the current fold\n",
    "        fold_accuracy = accuracy_score(y_val_fold, predictions_encoded)\n",
    "        fold_f1 = f1_score(y_val_fold, predictions_encoded, average='weighted')\n",
    "        fold_cm = confusion_matrix(y_val_fold, predictions_encoded, labels=range(len(CLASS_LABELS)))\n",
    "\n",
    "        print(f\"  Accuracy: {fold_accuracy:.4f}\")\n",
    "        print(f\"  F1-Score (Weighted): {fold_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix (Rows: True, Cols: Predicted):\")\n",
    "        # Use a DataFrame for a nicely formatted confusion matrix with labels\n",
    "        cm_df = pd.DataFrame(fold_cm, index=le.classes_, columns=le.classes_)\n",
    "        print(cm_df)\n",
    "        print(\"-\" * 60) # Separator for readability\n",
    "        # MODIFICATION END\n",
    "\n",
    "        all_predictions_encoded.extend(predictions_encoded)\n",
    "        all_true_labels_encoded.extend(y_val_fold)\n",
    "\n",
    "    # --- Overall Cross-Validation Results ---\n",
    "    print(\"\\n--- Overall LOSO CV Results for Ensemble Model ---\")\n",
    "    all_true_str = le.inverse_transform(all_true_labels_encoded)\n",
    "    all_predictions_str = le.inverse_transform(all_predictions_encoded)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(all_true_str, all_predictions_str)\n",
    "    print(f\"Overall LOSO CV Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"\\nOverall Classification Report:\")\n",
    "    print(classification_report(all_true_str, all_predictions_str, target_names=CLASS_LABELS))\n",
    "    \n",
    "    # --- Final Model Training and Submission ---\n",
    "    print(\"\\n--- Training Final Ensemble Model on All Data for Submission ---\")\n",
    "    \n",
    "    final_scaler = StandardScaler()\n",
    "    X_all_scaled = final_scaler.fit_transform(all_features_combined)\n",
    "    \n",
    "    ensemble_model.fit(X_all_scaled, y_all_encoded)\n",
    "    print(\"Final ensemble model training complete.\")\n",
    "    \n",
    "    print(\"\\nGenerating predictions for the test set...\")\n",
    "    test_ssvep_df = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    test_predictions_list = []\n",
    "\n",
    "    for idx, row in test_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'test')\n",
    "        if eeg_trial is not None and eeg_trial.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            fbcca_feat = get_fbcca_features(apply_filterbank(eeg_trial, filters), reference_signals).reshape(1, -1)\n",
    "            trca_feat = extract_trca_features(eeg_trial, all_trca_filters_for_features).reshape(1, -1)\n",
    "            psd_feat = get_psd_features(eeg_trial).reshape(1, -1)\n",
    "            \n",
    "            X_test_combined = np.concatenate([trca_feat, fbcca_feat, psd_feat], axis=1)\n",
    "            \n",
    "            X_test_scaled = final_scaler.transform(X_test_combined)\n",
    "            prediction_encoded = ensemble_model.predict(X_test_scaled)[0]\n",
    "            test_predictions_list.append(prediction_encoded)\n",
    "        else:\n",
    "            most_frequent_class_encoded = le.transform([pd.Series(y_all).mode()[0]])[0]\n",
    "            test_predictions_list.append(most_frequent_class_encoded)\n",
    "\n",
    "    final_predictions_str = le.inverse_transform(test_predictions_list)\n",
    "    submission_df = pd.DataFrame({'id': test_ssvep_df['id'], 'label': final_predictions_str})\n",
    "    submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nSubmission file 'submission.csv' has been created successfully!\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW BEST! only used 4 seconds and skipped the first 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T17:01:11.342642Z",
     "iopub.status.busy": "2025-07-18T17:01:11.342317Z",
     "iopub.status.idle": "2025-07-18T17:09:46.457739Z",
     "shell.execute_reply": "2025-07-18T17:09:46.456960Z",
     "shell.execute_reply.started": "2025-07-18T17:01:11.342618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting SSVEP Pipeline: Tier 2 (Ensemble + PSD Features) ---\n",
      "\n",
      "Pre-computing references and filters...\n",
      "Loading all training & validation data...\n",
      "\n",
      "Pre-computing all features (TRCA, FBCCA, PSD)...\n",
      "Feature engineering complete. Total feature dimension: 120\n",
      "\n",
      "Defining Ensemble Classifier...\n",
      "\n",
      "--- Starting LOSO Cross-Validation with Ensemble Model ---\n",
      "Fold 1/35: Validating on subject S1\n",
      "  Accuracy: 0.3250\n",
      "  F1-Score (Weighted): 0.3466\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         7       13     5      0\n",
      "Forward          0        6     2      2\n",
      "Left             2       10     7      3\n",
      "Right            3       10     4      6\n",
      "------------------------------------------------------------\n",
      "Fold 2/35: Validating on subject S10\n",
      "  Accuracy: 0.6125\n",
      "  F1-Score (Weighted): 0.6078\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        22        1     4      0\n",
      "Forward          3        6     7      1\n",
      "Left             0        4    13      3\n",
      "Right            3        3     2      8\n",
      "------------------------------------------------------------\n",
      "Fold 3/35: Validating on subject S11\n",
      "  Accuracy: 0.6375\n",
      "  F1-Score (Weighted): 0.6382\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        16        1     4      1\n",
      "Forward          1        8     5      1\n",
      "Left             2        4    12      5\n",
      "Right            1        3     1     15\n",
      "------------------------------------------------------------\n",
      "Fold 4/35: Validating on subject S12\n",
      "  Accuracy: 0.9125\n",
      "  F1-Score (Weighted): 0.9129\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        17        0     0      1\n",
      "Forward          0       15     0      1\n",
      "Left             1        0    18      3\n",
      "Right            0        0     1     23\n",
      "------------------------------------------------------------\n",
      "Fold 5/35: Validating on subject S13\n",
      "  Accuracy: 0.7000\n",
      "  F1-Score (Weighted): 0.6798\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        15        2     1      2\n",
      "Forward          0       19     2      0\n",
      "Left             2        0    16      0\n",
      "Right            2        1    12      6\n",
      "------------------------------------------------------------\n",
      "Fold 6/35: Validating on subject S14\n",
      "  Accuracy: 0.5875\n",
      "  F1-Score (Weighted): 0.5935\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        14        3     5      0\n",
      "Forward          1       11     8      1\n",
      "Left             1        1    12      0\n",
      "Right            6        1     6     10\n",
      "------------------------------------------------------------\n",
      "Fold 7/35: Validating on subject S15\n",
      "  Accuracy: 0.5875\n",
      "  F1-Score (Weighted): 0.5819\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        13        5     6      1\n",
      "Forward          1       12     2      1\n",
      "Left             4        5     7      3\n",
      "Right            3        2     0     15\n",
      "------------------------------------------------------------\n",
      "Fold 8/35: Validating on subject S16\n",
      "  Accuracy: 0.8000\n",
      "  F1-Score (Weighted): 0.7916\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        20        1     0      1\n",
      "Forward          5       13     3      2\n",
      "Left             1        3    16      0\n",
      "Right            0        0     0     15\n",
      "------------------------------------------------------------\n",
      "Fold 9/35: Validating on subject S17\n",
      "  Accuracy: 0.9750\n",
      "  F1-Score (Weighted): 0.9754\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        19        0     1      0\n",
      "Forward          0       22     1      0\n",
      "Left             0        0    16      0\n",
      "Right            0        0     0     21\n",
      "------------------------------------------------------------\n",
      "Fold 10/35: Validating on subject S18\n",
      "  Accuracy: 0.5250\n",
      "  F1-Score (Weighted): 0.5254\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         9        4     4      4\n",
      "Forward          3       10     3      1\n",
      "Left             1        6    10      4\n",
      "Right            1        4     3     13\n",
      "------------------------------------------------------------\n",
      "Fold 11/35: Validating on subject S19\n",
      "  Accuracy: 0.5500\n",
      "  F1-Score (Weighted): 0.5442\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        11        2     7      0\n",
      "Forward          4       11     9      6\n",
      "Left             1        1    13      1\n",
      "Right            3        0     2      9\n",
      "------------------------------------------------------------\n",
      "Fold 12/35: Validating on subject S2\n",
      "  Accuracy: 0.8625\n",
      "  F1-Score (Weighted): 0.8607\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        12        0     4      1\n",
      "Forward          0       15     0      1\n",
      "Left             2        0    20      0\n",
      "Right            0        3     0     22\n",
      "------------------------------------------------------------\n",
      "Fold 13/35: Validating on subject S20\n",
      "  Accuracy: 0.9250\n",
      "  F1-Score (Weighted): 0.9249\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        22        0     1      1\n",
      "Forward          1       21     2      1\n",
      "Left             0        0    15      0\n",
      "Right            0        0     0     16\n",
      "------------------------------------------------------------\n",
      "Fold 14/35: Validating on subject S21\n",
      "  Accuracy: 0.8125\n",
      "  F1-Score (Weighted): 0.8133\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        14        0     0      0\n",
      "Forward          0       14     5      0\n",
      "Left             1        0    21      1\n",
      "Right            2        0     6     16\n",
      "------------------------------------------------------------\n",
      "Fold 15/35: Validating on subject S22\n",
      "  Accuracy: 0.6125\n",
      "  F1-Score (Weighted): 0.6030\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        16        5     4      5\n",
      "Forward          1       15     1      0\n",
      "Left             3        5     5      1\n",
      "Right            4        1     1     13\n",
      "------------------------------------------------------------\n",
      "Fold 16/35: Validating on subject S23\n",
      "  Accuracy: 0.5625\n",
      "  F1-Score (Weighted): 0.5623\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         8        6     3      3\n",
      "Forward          1       12     2      0\n",
      "Left             3        6    13      0\n",
      "Right            4        3     4     12\n",
      "------------------------------------------------------------\n",
      "Fold 17/35: Validating on subject S24\n",
      "  Accuracy: 0.9500\n",
      "  F1-Score (Weighted): 0.9495\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        17        0     0      0\n",
      "Forward          0       19     1      0\n",
      "Left             0        2    20      1\n",
      "Right            0        0     0     20\n",
      "------------------------------------------------------------\n",
      "Fold 18/35: Validating on subject S25\n",
      "  Accuracy: 0.8375\n",
      "  F1-Score (Weighted): 0.8380\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        19        0     1      1\n",
      "Forward          2       17     1      1\n",
      "Left             2        2    16      0\n",
      "Right            2        0     1     15\n",
      "------------------------------------------------------------\n",
      "Fold 19/35: Validating on subject S26\n",
      "  Accuracy: 0.8125\n",
      "  F1-Score (Weighted): 0.8072\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        14        0     1      1\n",
      "Forward          1       12     4      4\n",
      "Left             0        0    22      2\n",
      "Right            2        0     0     17\n",
      "------------------------------------------------------------\n",
      "Fold 20/35: Validating on subject S27\n",
      "  Accuracy: 0.1375\n",
      "  F1-Score (Weighted): 0.0770\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         0        1     7     16\n",
      "Forward          1        0     6     11\n",
      "Left             0        0     1     18\n",
      "Right            3        2     4     10\n",
      "------------------------------------------------------------\n",
      "Fold 21/35: Validating on subject S28\n",
      "  Accuracy: 0.8250\n",
      "  F1-Score (Weighted): 0.8195\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        18        0     0      0\n",
      "Forward          1       18     0      0\n",
      "Left             6        3    13      1\n",
      "Right            2        0     1     17\n",
      "------------------------------------------------------------\n",
      "Fold 22/35: Validating on subject S29\n",
      "  Accuracy: 0.8625\n",
      "  F1-Score (Weighted): 0.8620\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        23        0     3      1\n",
      "Forward          0       20     1      0\n",
      "Left             4        0    10      1\n",
      "Right            1        0     0     16\n",
      "------------------------------------------------------------\n",
      "Fold 23/35: Validating on subject S3\n",
      "  Accuracy: 0.7875\n",
      "  F1-Score (Weighted): 0.7869\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        13        1     4      0\n",
      "Forward          0       16     4      0\n",
      "Left             0        0    20      0\n",
      "Right            5        1     2     14\n",
      "------------------------------------------------------------\n",
      "Fold 24/35: Validating on subject S30\n",
      "  Accuracy: 0.8750\n",
      "  F1-Score (Weighted): 0.8672\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        23        0     0      0\n",
      "Forward          1       11     5      2\n",
      "Left             1        0    21      0\n",
      "Right            0        0     1     15\n",
      "------------------------------------------------------------\n",
      "Fold 25/35: Validating on subject S31\n",
      "  Accuracy: 0.3000\n",
      "  F1-Score (Weighted): 0.2635\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         0        1     0      1\n",
      "Forward          0        2     2      0\n",
      "Left             0        2     1      0\n",
      "Right            0        0     1      0\n",
      "------------------------------------------------------------\n",
      "Fold 26/35: Validating on subject S32\n",
      "  Accuracy: 0.1000\n",
      "  F1-Score (Weighted): 0.0500\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         1        0     0      1\n",
      "Forward          1        0     1      0\n",
      "Left             1        0     0      2\n",
      "Right            3        0     0      0\n",
      "------------------------------------------------------------\n",
      "Fold 27/35: Validating on subject S33\n",
      "  Accuracy: 0.7000\n",
      "  F1-Score (Weighted): 0.6976\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         1        0     0      1\n",
      "Forward          0        1     0      2\n",
      "Left             0        0     3      0\n",
      "Right            0        0     0      2\n",
      "------------------------------------------------------------\n",
      "Fold 28/35: Validating on subject S34\n",
      "  Accuracy: 0.4000\n",
      "  F1-Score (Weighted): 0.4000\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         3        0     2      0\n",
      "Forward          0        1     0      0\n",
      "Left             1        0     0      0\n",
      "Right            1        0     2      0\n",
      "------------------------------------------------------------\n",
      "Fold 29/35: Validating on subject S35\n",
      "  Accuracy: 0.8000\n",
      "  F1-Score (Weighted): 0.7838\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         3        0     0      0\n",
      "Forward          0        2     0      0\n",
      "Left             1        1     2      0\n",
      "Right            0        0     0      1\n",
      "------------------------------------------------------------\n",
      "Fold 30/35: Validating on subject S4\n",
      "  Accuracy: 0.9375\n",
      "  F1-Score (Weighted): 0.9354\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        27        0     0      0\n",
      "Forward          0        9     0      0\n",
      "Left             1        0    16      4\n",
      "Right            0        0     0     23\n",
      "------------------------------------------------------------\n",
      "Fold 31/35: Validating on subject S5\n",
      "  Accuracy: 0.3750\n",
      "  F1-Score (Weighted): 0.3594\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward         4        2     1      5\n",
      "Forward          3        6     2     12\n",
      "Left             1        4     4      9\n",
      "Right            2        5     4     16\n",
      "------------------------------------------------------------\n",
      "Fold 32/35: Validating on subject S6\n",
      "  Accuracy: 0.7375\n",
      "  F1-Score (Weighted): 0.7209\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        20        1     0      0\n",
      "Forward          0       20     0      0\n",
      "Left             2        8     4      0\n",
      "Right            2        3     5     15\n",
      "------------------------------------------------------------\n",
      "Fold 33/35: Validating on subject S7\n",
      "  Accuracy: 0.7750\n",
      "  F1-Score (Weighted): 0.7768\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        16        1     2      3\n",
      "Forward          0       18     1      4\n",
      "Left             2        1    15      0\n",
      "Right            0        3     1     13\n",
      "------------------------------------------------------------\n",
      "Fold 34/35: Validating on subject S8\n",
      "  Accuracy: 0.9625\n",
      "  F1-Score (Weighted): 0.9623\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        22        0     0      0\n",
      "Forward          0       22     0      0\n",
      "Left             1        0    19      0\n",
      "Right            0        0     2     14\n",
      "------------------------------------------------------------\n",
      "Fold 35/35: Validating on subject S9\n",
      "  Accuracy: 0.5500\n",
      "  F1-Score (Weighted): 0.5553\n",
      "  Confusion Matrix (Rows: True, Cols: Predicted):\n",
      "          Backward  Forward  Left  Right\n",
      "Backward        13        5     3      0\n",
      "Forward          1       16     4      2\n",
      "Left             1       10     9      1\n",
      "Right            0        7     2      6\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Overall LOSO CV Results for Ensemble Model ---\n",
      "Overall LOSO CV Accuracy: 0.7086\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Forward       0.78      0.73      0.75       650\n",
      "    Backward       0.69      0.71      0.70       592\n",
      "        Left       0.65      0.68      0.66       599\n",
      "       Right       0.72      0.71      0.72       609\n",
      "\n",
      "    accuracy                           0.71      2450\n",
      "   macro avg       0.71      0.71      0.71      2450\n",
      "weighted avg       0.71      0.71      0.71      2450\n",
      "\n",
      "\n",
      "--- Training Final Ensemble Model on All Data for Submission ---\n",
      "Final ensemble model training complete.\n",
      "\n",
      "Generating predictions for the test set...\n",
      "\n",
      "Submission file 'submission.csv' has been created successfully!\n",
      "     id     label\n",
      "0  4951  Backward\n",
      "1  4952  Backward\n",
      "2  4953   Forward\n",
      "3  4954  Backward\n",
      "4  4955  Backward\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Tier 2 Imports: Welch for PSD, VotingClassifier for Ensembling ---\n",
    "from scipy.signal import cheby1, filtfilt, welch\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "# MODIFICATION START: Import additional metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "# MODIFICATION END\n",
    "\n",
    "# Import the classifiers for the ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "\n",
    "# Time window configuration based on new info\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 2.0  # Skip the 2-second marker/preparation period\n",
    "DATA_DURATION = 4.0  # Analyze the 4-second stimulation period\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 3\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "\n",
    "# --- 1. Data Loading Function (Unchanged) ---\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"\n",
    "    Loads raw EEG data for a single trial, applying the specified time window.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path_segment = dataset_type\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', path_segment, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        return trial_eeg_data.values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: EEGdata.csv not found at {eeg_path}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Feature Engineering Functions ---\n",
    "\n",
    "# --- Tier 2 New Feature: Power Spectral Density (PSD) ---\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Calculates Power Spectral Density (PSD) features for a trial.\n",
    "    This captures the power of the signal at key frequencies.\n",
    "    \"\"\"\n",
    "    psd_features = []\n",
    "    \n",
    "    # Define a narrow band for extracting power around the target frequencies\n",
    "    freq_band_width = 0.5 # Hz\n",
    "    \n",
    "    for channel_data in eeg_trial.T: # Iterate through each of the 8 channels\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=SAMPLES_PER_SSVEP_TRIAL)\n",
    "        \n",
    "        # For each target frequency, calculate the average power in a narrow band around it and its harmonics\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                band_mask = (freqs >= harmonic_freq - freq_band_width) & (freqs <= harmonic_freq + freq_band_width)\n",
    "                \n",
    "                if np.any(band_mask):\n",
    "                    avg_power = np.mean(psd[band_mask])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0) # Append 0 if the frequency is not found\n",
    "                    \n",
    "    return np.array(psd_features)\n",
    "\n",
    "\n",
    "# --- FBCCA and TRCA Functions (Unchanged from Tier 1) ---\n",
    "def get_refined_filterbank():\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        filters.append((b, a))\n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "def get_fbcca_features(filtered_eeg_bank, reference_signals):\n",
    "    cca = CCA(n_components=1)\n",
    "    fb_feature_vector = []\n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            corr = np.corrcoef(X_c.ravel(), Y_c.ravel())[0, 1]\n",
    "            rho_k.append(corr if np.isfinite(corr) else 0)\n",
    "        fb_feature_vector.extend(rho_k)\n",
    "    return np.array(fb_feature_vector)\n",
    "\n",
    "def get_trca_spatial_filters(X_train, y_train, labels):\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        class_trials_centered = class_trials - np.mean(class_trials, axis=1, keepdims=True)\n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    return spatial_filters\n",
    "\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    features = []\n",
    "    templates = {label: eeg_trial @ w for label, w in spatial_filters.items()}\n",
    "    for label, w in spatial_filters.items():\n",
    "        projected_eeg = eeg_trial @ w\n",
    "        corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "        features.append(corr if np.isfinite(corr) else 0)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# --- 3. Main Execution Logic ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting SSVEP Pipeline: Tier 2 (Ensemble + PSD Features) ---\")\n",
    "\n",
    "    # Load competition index files\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    full_train_df = pd.concat([\n",
    "        train_df[train_df['task'] == 'SSVEP'],\n",
    "        validation_df[validation_df['task'] == 'SSVEP']\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    print(\"Loading all training & validation data...\")\n",
    "    X_all_raw = [load_trial_data(row, BASE_PATH, 'train' if row['id'] <= 4800 else 'validation') for _, row in full_train_df.iterrows()]\n",
    "    \n",
    "    # Filter out None values and create final arrays\n",
    "    valid_indices = [i for i, x in enumerate(X_all_raw) if x is not None and x.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS))]\n",
    "    X_all = np.array([X_all_raw[i] for i in valid_indices])\n",
    "    y_all = full_train_df.loc[valid_indices, 'label'].values\n",
    "    subjects_all = full_train_df.loc[valid_indices, 'subject_id'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_all_encoded = le.fit_transform(y_all)\n",
    "    \n",
    "    print(\"\\nPre-computing all features (TRCA, FBCCA, PSD)...\")\n",
    "    # FBCCA features\n",
    "    all_fbcca_features = np.array([get_fbcca_features(apply_filterbank(trial, filters), reference_signals) for trial in X_all])\n",
    "    # TRCA features\n",
    "    all_trca_filters_for_features = get_trca_spatial_filters(X_all, y_all, CLASS_LABELS)\n",
    "    all_trca_features = np.array([extract_trca_features(trial, all_trca_filters_for_features) for trial in X_all])\n",
    "    # PSD features\n",
    "    all_psd_features = np.array([get_psd_features(trial) for trial in X_all])\n",
    "    \n",
    "    # --- Tier 2 Feature Concatenation ---\n",
    "    all_features_combined = np.concatenate([all_trca_features, all_fbcca_features, all_psd_features], axis=1)\n",
    "    print(f\"Feature engineering complete. Total feature dimension: {all_features_combined.shape[1]}\")\n",
    "\n",
    "    # --- Tier 2 Ensemble Model Definition ---\n",
    "    print(\"\\nDefining Ensemble Classifier...\")\n",
    "    # Base models for the ensemble. Parameters are set to reasonable defaults or values found from Tier 1.\n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=50, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    # Create the Voting Classifier\n",
    "    # 'soft' voting uses predicted probabilities, which is often better than 'hard' (majority rule).\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.4, 0.4, 0.2] # Give more weight to the more powerful models\n",
    "    )\n",
    "    \n",
    "    # --- Leave-One-Subject-Out Cross-Validation with the Ensemble ---\n",
    "    print(\"\\n--- Starting LOSO Cross-Validation with Ensemble Model ---\")\n",
    "    logo = LeaveOneGroupOut()\n",
    "    all_predictions_encoded = []\n",
    "    all_true_labels_encoded = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(logo.split(all_features_combined, y_all_encoded, groups=subjects_all)):\n",
    "        val_subject = subjects_all[val_idx][0]\n",
    "        print(f\"Fold {fold_idx+1}/{len(np.unique(subjects_all))}: Validating on subject {val_subject}\")\n",
    "\n",
    "        X_train_fold, X_val_fold = all_features_combined[train_idx], all_features_combined[val_idx]\n",
    "        y_train_fold, y_val_fold = y_all_encoded[train_idx], y_all_encoded[val_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Fit the entire ensemble model\n",
    "        ensemble_model.fit(X_train_scaled, y_train_fold)\n",
    "        \n",
    "        predictions_encoded = ensemble_model.predict(X_val_scaled)\n",
    "        \n",
    "        # MODIFICATION START: Calculate and print metrics for the current fold\n",
    "        fold_accuracy = accuracy_score(y_val_fold, predictions_encoded)\n",
    "        fold_f1 = f1_score(y_val_fold, predictions_encoded, average='weighted')\n",
    "        fold_cm = confusion_matrix(y_val_fold, predictions_encoded, labels=range(len(CLASS_LABELS)))\n",
    "\n",
    "        print(f\"  Accuracy: {fold_accuracy:.4f}\")\n",
    "        print(f\"  F1-Score (Weighted): {fold_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix (Rows: True, Cols: Predicted):\")\n",
    "        # Use a DataFrame for a nicely formatted confusion matrix with labels\n",
    "        cm_df = pd.DataFrame(fold_cm, index=le.classes_, columns=le.classes_)\n",
    "        print(cm_df)\n",
    "        print(\"-\" * 60) # Separator for readability\n",
    "        # MODIFICATION END\n",
    "\n",
    "        all_predictions_encoded.extend(predictions_encoded)\n",
    "        all_true_labels_encoded.extend(y_val_fold)\n",
    "\n",
    "    # --- Overall Cross-Validation Results ---\n",
    "    print(\"\\n--- Overall LOSO CV Results for Ensemble Model ---\")\n",
    "    all_true_str = le.inverse_transform(all_true_labels_encoded)\n",
    "    all_predictions_str = le.inverse_transform(all_predictions_encoded)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(all_true_str, all_predictions_str)\n",
    "    print(f\"Overall LOSO CV Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"\\nOverall Classification Report:\")\n",
    "    print(classification_report(all_true_str, all_predictions_str, target_names=CLASS_LABELS))\n",
    "    \n",
    "    # --- Final Model Training and Submission ---\n",
    "    print(\"\\n--- Training Final Ensemble Model on All Data for Submission ---\")\n",
    "    \n",
    "    final_scaler = StandardScaler()\n",
    "    X_all_scaled = final_scaler.fit_transform(all_features_combined)\n",
    "    \n",
    "    ensemble_model.fit(X_all_scaled, y_all_encoded)\n",
    "    print(\"Final ensemble model training complete.\")\n",
    "    \n",
    "    print(\"\\nGenerating predictions for the test set...\")\n",
    "    test_ssvep_df = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    test_predictions_list = []\n",
    "\n",
    "    for idx, row in test_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'test')\n",
    "        if eeg_trial is not None and eeg_trial.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            fbcca_feat = get_fbcca_features(apply_filterbank(eeg_trial, filters), reference_signals).reshape(1, -1)\n",
    "            trca_feat = extract_trca_features(eeg_trial, all_trca_filters_for_features).reshape(1, -1)\n",
    "            psd_feat = get_psd_features(eeg_trial).reshape(1, -1)\n",
    "            \n",
    "            X_test_combined = np.concatenate([trca_feat, fbcca_feat, psd_feat], axis=1)\n",
    "            \n",
    "            X_test_scaled = final_scaler.transform(X_test_combined)\n",
    "            prediction_encoded = ensemble_model.predict(X_test_scaled)[0]\n",
    "            test_predictions_list.append(prediction_encoded)\n",
    "        else:\n",
    "            most_frequent_class_encoded = le.transform([pd.Series(y_all).mode()[0]])[0]\n",
    "            test_predictions_list.append(most_frequent_class_encoded)\n",
    "\n",
    "    final_predictions_str = le.inverse_transform(test_predictions_list)\n",
    "    submission_df = pd.DataFrame({'id': test_ssvep_df['id'], 'label': final_predictions_str})\n",
    "    submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nSubmission file 'submission.csv' has been created successfully!\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our New best: The 0.715 LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy.signal import cheby1, filtfilt, welch, hilbert, butter\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# --- Enhanced Configuration ---\n",
    "warnings.filterwarnings('ignore')\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "\n",
    "# Time window configuration\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 2.0\n",
    "DATA_DURATION = 4.0\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 5  # Increased from 3 to 5\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 1: Common Average Reference (CAR) Preprocessing ---\n",
    "def apply_car_preprocessing(eeg_data):\n",
    "    \"\"\"\n",
    "    Apply Common Average Reference (CAR) - typically improves SSVEP accuracy by 2-3%\n",
    "    \"\"\"\n",
    "    # Subtract the average across all channels for each time point\n",
    "    car_data = eeg_data - np.mean(eeg_data, axis=1, keepdims=True)\n",
    "    return car_data\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 2: Multi-Window Temporal Averaging ---\n",
    "def extract_multiwindow_features(eeg_trial, window_size=2.0, step_size=0.5):\n",
    "    \"\"\"\n",
    "    Extract features from overlapping time windows - improves robustness by 1-2%\n",
    "    \"\"\"\n",
    "    window_samples = int(window_size * SAMPLING_RATE)\n",
    "    step_samples = int(step_size * SAMPLING_RATE)\n",
    "    \n",
    "    windows = []\n",
    "    for start in range(0, eeg_trial.shape[0] - window_samples + 1, step_samples):\n",
    "        end = start + window_samples\n",
    "        windows.append(eeg_trial[start:end])\n",
    "    \n",
    "    return windows\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 3: Phase Locking Value (PLV) Features ---\n",
    "def get_plv_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Calculate Phase Locking Value between channels - highly effective for SSVEP\n",
    "    Expected improvement: 2-4%\n",
    "    \"\"\"\n",
    "    plv_features = []\n",
    "    \n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        # Narrow bandpass filter around target frequency\n",
    "        low_freq = max(1, target_freq - 1)\n",
    "        high_freq = min(125, target_freq + 1)\n",
    "        \n",
    "        # Create filter\n",
    "        b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        \n",
    "        # Filter all channels\n",
    "        filtered_channels = []\n",
    "        for ch in range(eeg_trial.shape[1]):\n",
    "            filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "            analytic_signal = hilbert(filtered_sig)\n",
    "            phase = np.angle(analytic_signal)\n",
    "            filtered_channels.append(phase)\n",
    "        \n",
    "        # Calculate PLV between all channel pairs\n",
    "        for i in range(len(filtered_channels)):\n",
    "            for j in range(i+1, len(filtered_channels)):\n",
    "                phase_diff = filtered_channels[i] - filtered_channels[j]\n",
    "                plv = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "                plv_features.append(plv)\n",
    "    \n",
    "    return np.array(plv_features)\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 4: Enhanced Harmonic Features ---\n",
    "def get_enhanced_harmonic_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Extract power and phase features for all harmonics\n",
    "    Expected improvement: 1-3%\n",
    "    \"\"\"\n",
    "    harmonic_features = []\n",
    "    \n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = target_freq * h\n",
    "            if harmonic_freq > 60:  # Skip if too high (line noise)\n",
    "                continue\n",
    "                \n",
    "            # Narrow band around harmonic\n",
    "            low_freq = max(1, harmonic_freq - 0.5)\n",
    "            high_freq = min(125, harmonic_freq + 0.5)\n",
    "            \n",
    "            b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            \n",
    "            channel_powers = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "                # Power at harmonic\n",
    "                power = np.mean(filtered_sig**2)\n",
    "                channel_powers.append(power)\n",
    "            \n",
    "            # Features: max power, mean power, power ratio\n",
    "            harmonic_features.extend([\n",
    "                np.max(channel_powers),\n",
    "                np.mean(channel_powers),\n",
    "                np.max(channel_powers) / (np.mean(channel_powers) + 1e-10)\n",
    "            ])\n",
    "    \n",
    "    return np.array(harmonic_features)\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 5: Improved CCA with Multiple Components ---\n",
    "def get_enhanced_cca_features(filtered_eeg_bank, reference_signals):\n",
    "    \"\"\"\n",
    "    Enhanced CCA with multiple components and better correlation measures\n",
    "    Expected improvement: 1-2%\n",
    "    \"\"\"\n",
    "    enhanced_features = []\n",
    "    \n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            \n",
    "            # Use multiple CCA components\n",
    "            cca = CCA(n_components=min(3, filtered_eeg.shape[1], ref_sig.shape[1]))\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            \n",
    "            # Calculate correlation for each component\n",
    "            component_corrs = []\n",
    "            for comp in range(X_c.shape[1]):\n",
    "                corr = np.corrcoef(X_c[:, comp], Y_c[:, comp])[0, 1]\n",
    "                component_corrs.append(corr if np.isfinite(corr) else 0)\n",
    "            \n",
    "            # Features: max correlation, mean correlation, weighted sum\n",
    "            rho_k.extend([\n",
    "                np.max(component_corrs),\n",
    "                np.mean(component_corrs),\n",
    "                np.sum([w * c for w, c in zip([0.5, 0.3, 0.2], component_corrs)])\n",
    "            ])\n",
    "        \n",
    "        enhanced_features.extend(rho_k)\n",
    "    \n",
    "    return np.array(enhanced_features)\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 6: Spatial Filtering Enhancement ---\n",
    "def get_optimized_spatial_filters(X_train, y_train, labels):\n",
    "    \"\"\"\n",
    "    Improved spatial filtering with regularization\n",
    "    Expected improvement: 1-2%\n",
    "    \"\"\"\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    \n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "            \n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        \n",
    "        # Apply CAR to each trial\n",
    "        class_trials_car = np.array([apply_car_preprocessing(trial) for trial in class_trials])\n",
    "        class_trials_centered = class_trials_car - np.mean(class_trials_car, axis=1, keepdims=True)\n",
    "        \n",
    "        # Covariance matrices with regularization\n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        \n",
    "        # Add regularization to avoid numerical issues\n",
    "        reg_param = 0.01 * np.trace(S) / S.shape[0]\n",
    "        S += reg_param * np.eye(S.shape[0])\n",
    "        Q += reg_param * np.eye(Q.shape[0])\n",
    "        \n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            # Take the eigenvector with largest eigenvalue\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    \n",
    "    return spatial_filters\n",
    "\n",
    "# --- HIGH-IMPACT FEATURE 7: Frequency Domain SNR Features ---\n",
    "def get_snr_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Calculate SNR at target frequencies vs. neighboring frequencies\n",
    "    Expected improvement: 1-2%\n",
    "    \"\"\"\n",
    "    snr_features = []\n",
    "    \n",
    "    for ch in range(eeg_trial.shape[1]):\n",
    "        # Compute power spectral density\n",
    "        freqs, psd = welch(eeg_trial[:, ch], fs=SAMPLING_RATE, nperseg=min(512, eeg_trial.shape[0]))\n",
    "        \n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            # Find closest frequency bin\n",
    "            freq_idx = np.argmin(np.abs(freqs - target_freq))\n",
    "            \n",
    "            if freq_idx > 2 and freq_idx < len(psd) - 2:\n",
    "                # Signal power at target frequency\n",
    "                signal_power = psd[freq_idx]\n",
    "                \n",
    "                # Noise power from neighboring frequencies (excluding target)\n",
    "                noise_indices = [freq_idx-2, freq_idx-1, freq_idx+1, freq_idx+2]\n",
    "                noise_indices = [i for i in noise_indices if 0 <= i < len(psd)]\n",
    "                noise_power = np.mean(psd[noise_indices])\n",
    "                \n",
    "                # SNR calculation\n",
    "                snr = signal_power / (noise_power + 1e-10)\n",
    "                snr_features.append(snr)\n",
    "            else:\n",
    "                snr_features.append(0)\n",
    "    \n",
    "    return np.array(snr_features)\n",
    "\n",
    "# --- Original functions (updated to use CAR preprocessing) ---\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"\n",
    "    Enhanced data loading with CAR preprocessing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path_segment = dataset_type\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', path_segment, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        \n",
    "        # Apply CAR preprocessing\n",
    "        eeg_array = trial_eeg_data.values\n",
    "        eeg_array = apply_car_preprocessing(eeg_array)\n",
    "        \n",
    "        return eeg_array\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: EEGdata.csv not found at {eeg_path}\")\n",
    "        return None\n",
    "\n",
    "def get_refined_filterbank():\n",
    "    \"\"\"Enhanced filterbank with more bands\"\"\"\n",
    "    # Original bands\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    \n",
    "    # Add narrow bands around target frequencies\n",
    "    for freq in SSVEP_FREQUENCIES_LIST:\n",
    "        filter_bands.append([freq - 1, freq + 1])\n",
    "    \n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        if high <= 125:  # Nyquist frequency\n",
    "            b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            filters.append((b, a))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    \"\"\"Enhanced TRCA features\"\"\"\n",
    "    features = []\n",
    "    templates = {}\n",
    "    \n",
    "    # Create templates for each class\n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            templates[label] = projected_eeg\n",
    "        else:\n",
    "            templates[label] = np.zeros(eeg_trial.shape[0])\n",
    "    \n",
    "    # Calculate correlations\n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            \n",
    "            # Multiple correlation measures\n",
    "            corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "            features.append(corr if np.isfinite(corr) else 0)\n",
    "            \n",
    "            # Power correlation\n",
    "            power_corr = np.corrcoef(projected_eeg**2, templates[label]**2)[0, 1]\n",
    "            features.append(power_corr if np.isfinite(power_corr) else 0)\n",
    "        else:\n",
    "            features.extend([0, 0])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# --- Enhanced PSD features ---\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"\n",
    "    Enhanced PSD features with better frequency resolution\n",
    "    \"\"\"\n",
    "    psd_features = []\n",
    "    \n",
    "    for channel_data in eeg_trial.T:\n",
    "        # Use longer window for better frequency resolution\n",
    "        nperseg = min(1000, eeg_trial.shape[0])\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=nperseg, noverlap=nperseg//2)\n",
    "        \n",
    "        # Extract power at target frequencies and harmonics\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                if harmonic_freq <= freqs[-1]:\n",
    "                    # Find frequency bin\n",
    "                    freq_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
    "                    \n",
    "                    # Average power in narrow band\n",
    "                    band_indices = [i for i in range(max(0, freq_idx-1), min(len(psd), freq_idx+2))]\n",
    "                    avg_power = np.mean(psd[band_indices])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0)\n",
    "    \n",
    "    return np.array(psd_features)\n",
    "\n",
    "# --- Main execution starts here ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Enhanced SSVEP Pipeline with High-Impact Features ---\")\n",
    "    print(\"Expected improvements:\")\n",
    "    print(\"- CAR preprocessing: +2-3%\")\n",
    "    print(\"- PLV features: +2-4%\") \n",
    "    print(\"- Enhanced harmonics: +1-3%\")\n",
    "    print(\"- Improved CCA: +1-2%\")\n",
    "    print(\"- SNR features: +1-2%\")\n",
    "    print(\"- Total expected improvement: +7-15%\")\n",
    "    \n",
    "    # Load data (same as before)\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    full_train_df = pd.concat([\n",
    "        train_df[train_df['task'] == 'SSVEP'],\n",
    "        validation_df[validation_df['task'] == 'SSVEP']\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    print(\"Loading all training & validation data with CAR preprocessing...\")\n",
    "    X_all_raw = [load_trial_data(row, BASE_PATH, 'train' if row['id'] <= 4800 else 'validation') \n",
    "                 for _, row in full_train_df.iterrows()]\n",
    "    \n",
    "    # Filter out None values\n",
    "    valid_indices = [i for i, x in enumerate(X_all_raw) if x is not None and x.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS))]\n",
    "    X_all = np.array([X_all_raw[i] for i in valid_indices])\n",
    "    y_all = full_train_df.loc[valid_indices, 'label'].values\n",
    "    subjects_all = full_train_df.loc[valid_indices, 'subject_id'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_all_encoded = le.fit_transform(y_all)\n",
    "    \n",
    "    print(\"\\nExtracting enhanced features...\")\n",
    "    \n",
    "    # Extract all enhanced features\n",
    "    all_features_list = []\n",
    "    \n",
    "    for i, trial in enumerate(X_all):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing trial {i}/{len(X_all)}\")\n",
    "        \n",
    "        # Original features\n",
    "        fbcca_feat = get_enhanced_cca_features(apply_filterbank(trial, filters), reference_signals)\n",
    "        \n",
    "        # Enhanced features\n",
    "        plv_feat = get_plv_features(trial)\n",
    "        harmonic_feat = get_enhanced_harmonic_features(trial)\n",
    "        snr_feat = get_snr_features(trial)\n",
    "        psd_feat = get_psd_features(trial)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined_features = np.concatenate([fbcca_feat, plv_feat, harmonic_feat, snr_feat, psd_feat])\n",
    "        all_features_list.append(combined_features)\n",
    "    \n",
    "    # Get enhanced TRCA features\n",
    "    print(\"Computing enhanced TRCA features...\")\n",
    "    enhanced_trca_filters = get_optimized_spatial_filters(X_all, y_all, CLASS_LABELS)\n",
    "    all_trca_features = np.array([extract_trca_features(trial, enhanced_trca_filters) for trial in X_all])\n",
    "    \n",
    "    # Final feature combination\n",
    "    other_features = np.array(all_features_list)\n",
    "    all_features_combined = np.concatenate([all_trca_features, other_features], axis=1)\n",
    "    \n",
    "    print(f\"\\nEnhanced feature extraction complete!\")\n",
    "    print(f\"Total feature dimension: {all_features_combined.shape[1]}\")\n",
    "    print(f\"Feature breakdown:\")\n",
    "    print(f\"- TRCA features: {all_trca_features.shape[1]}\")\n",
    "    print(f\"- FBCCA features: {fbcca_feat.shape[0]}\")\n",
    "    print(f\"- PLV features: {plv_feat.shape[0]}\")\n",
    "    print(f\"- Harmonic features: {harmonic_feat.shape[0]}\")\n",
    "    print(f\"- SNR features: {snr_feat.shape[0]}\")\n",
    "    print(f\"- PSD features: {psd_feat.shape[0]}\")\n",
    "    \n",
    "    print(\"\\nDefining Enhanced Ensemble Classifier...\")\n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', \n",
    "                             learning_rate=0.1, max_depth=4, n_estimators=150)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=100, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.5, 0.3, 0.2]\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Starting Enhanced LOSO Cross-Validation ---\")\n",
    "    # --- [START] CV AND EVALUATION LOGIC FROM CODE #2 ---\n",
    "    logo = LeaveOneGroupOut()\n",
    "    all_predictions_encoded = []\n",
    "    all_true_labels_encoded = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(logo.split(all_features_combined, y_all_encoded, groups=subjects_all)):\n",
    "        val_subject = subjects_all[val_idx][0]\n",
    "        print(f\"Fold {fold_idx+1}/{len(np.unique(subjects_all))}: Validating on subject {val_subject}\")\n",
    "\n",
    "        X_train_fold, X_val_fold = all_features_combined[train_idx], all_features_combined[val_idx]\n",
    "        y_train_fold, y_val_fold = y_all_encoded[train_idx], y_all_encoded[val_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Fit the entire ensemble model\n",
    "        ensemble_model.fit(X_train_scaled, y_train_fold)\n",
    "        \n",
    "        predictions_encoded = ensemble_model.predict(X_val_scaled)\n",
    "        \n",
    "        # Calculate and print metrics for the current fold\n",
    "        fold_accuracy = accuracy_score(y_val_fold, predictions_encoded)\n",
    "        fold_f1 = f1_score(y_val_fold, predictions_encoded, average='weighted')\n",
    "        fold_cm = confusion_matrix(y_val_fold, predictions_encoded, labels=range(len(CLASS_LABELS)))\n",
    "\n",
    "        print(f\"  Accuracy: {fold_accuracy:.4f}\")\n",
    "        print(f\"  F1-Score (Weighted): {fold_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix (Rows: True, Cols: Predicted):\")\n",
    "        cm_df = pd.DataFrame(fold_cm, index=le.classes_, columns=le.classes_)\n",
    "        print(cm_df)\n",
    "        print(\"-\" * 60) # Separator for readability\n",
    "\n",
    "        all_predictions_encoded.extend(predictions_encoded)\n",
    "        all_true_labels_encoded.extend(y_val_fold)\n",
    "\n",
    "    # --- Overall Cross-Validation Results ---\n",
    "    print(\"\\n--- Overall LOSO CV Results for Ensemble Model ---\")\n",
    "    all_true_str = le.inverse_transform(all_true_labels_encoded)\n",
    "    all_predictions_str = le.inverse_transform(all_predictions_encoded)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(all_true_str, all_predictions_str)\n",
    "    print(f\"Overall LOSO CV Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"\\nOverall Classification Report:\")\n",
    "    print(classification_report(all_true_str, all_predictions_str, target_names=CLASS_LABELS))\n",
    "    \n",
    "    # --- Final Model Training and Submission ---\n",
    "    print(\"\\n--- Training Final Ensemble Model on All Data for Submission ---\")\n",
    "    \n",
    "    final_scaler = StandardScaler()\n",
    "    X_all_scaled = final_scaler.fit_transform(all_features_combined)\n",
    "    \n",
    "    ensemble_model.fit(X_all_scaled, y_all_encoded)\n",
    "    print(\"Final ensemble model training complete.\")\n",
    "    \n",
    "    print(\"\\nGenerating predictions for the test set...\")\n",
    "    test_ssvep_df = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    test_predictions_list = []\n",
    "\n",
    "    for idx, row in test_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'test')\n",
    "        if eeg_trial is not None and eeg_trial.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            # Extract all enhanced features for the test trial\n",
    "            trca_feat = extract_trca_features(eeg_trial, enhanced_trca_filters)\n",
    "            fbcca_feat = get_enhanced_cca_features(apply_filterbank(eeg_trial, filters), reference_signals)\n",
    "            plv_feat = get_plv_features(eeg_trial)\n",
    "            harmonic_feat = get_enhanced_harmonic_features(eeg_trial)\n",
    "            snr_feat = get_snr_features(eeg_trial)\n",
    "            psd_feat = get_psd_features(eeg_trial)\n",
    "\n",
    "            # Combine features in the same order as training\n",
    "            X_test_combined = np.concatenate([trca_feat, fbcca_feat, plv_feat, harmonic_feat, snr_feat, psd_feat]).reshape(1, -1)\n",
    "            \n",
    "            X_test_scaled = final_scaler.transform(X_test_combined)\n",
    "            prediction_encoded = ensemble_model.predict(X_test_scaled)[0]\n",
    "            test_predictions_list.append(prediction_encoded)\n",
    "        else:\n",
    "            # Fallback for corrupted/missing data: predict the most frequent class\n",
    "            most_frequent_class_encoded = le.transform([pd.Series(y_all).mode()[0]])[0]\n",
    "            test_predictions_list.append(most_frequent_class_encoded)\n",
    "\n",
    "    final_predictions_str = le.inverse_transform(test_predictions_list)\n",
    "    submission_df = pd.DataFrame({'id': test_ssvep_df['id'], 'label': final_predictions_str})\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nSubmission file 'submission.csv' has been created successfully!\")\n",
    "    print(submission_df.head())\n",
    "    # --- [END] CV AND EVALUATION LOGIC ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 0.737 competition submission code (Based on the 0.715 LOSO CV CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy.signal import cheby1, filtfilt, welch, hilbert, butter\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# --- Configuration ---\n",
    "warnings.filterwarnings('ignore')\n",
    "# NOTE: Adjust this path to your dataset location.\n",
    "# It's set for a typical Kaggle environment.\n",
    "BASE_PATH = '/kaggle/input/mtcaic3-phase-ii'\n",
    "\n",
    "# Time window configuration\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 2.0\n",
    "DATA_DURATION = 4.0\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 5\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "# --- Feature Engineering Functions ---\n",
    "\n",
    "def apply_car_preprocessing(eeg_data):\n",
    "    \"\"\"Apply Common Average Reference (CAR).\"\"\"\n",
    "    car_data = eeg_data - np.mean(eeg_data, axis=1, keepdims=True)\n",
    "    return car_data\n",
    "\n",
    "def get_plv_features(eeg_trial):\n",
    "    \"\"\"Calculate Phase Locking Value (PLV) between channel pairs for each target frequency.\"\"\"\n",
    "    plv_features = []\n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        low_freq, high_freq = max(1, target_freq - 1), min(125, target_freq + 1)\n",
    "        b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        \n",
    "        filtered_phases = []\n",
    "        for ch in range(eeg_trial.shape[1]):\n",
    "            filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "            analytic_signal = hilbert(filtered_sig)\n",
    "            phase = np.angle(analytic_signal)\n",
    "            filtered_phases.append(phase)\n",
    "        \n",
    "        for i in range(len(filtered_phases)):\n",
    "            for j in range(i + 1, len(filtered_phases)):\n",
    "                phase_diff = filtered_phases[i] - filtered_phases[j]\n",
    "                plv = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "                plv_features.append(plv)\n",
    "    return np.array(plv_features)\n",
    "\n",
    "def get_enhanced_harmonic_features(eeg_trial):\n",
    "    \"\"\"Extract power features for harmonics of target frequencies.\"\"\"\n",
    "    harmonic_features = []\n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = target_freq * h\n",
    "            if harmonic_freq > 60: continue\n",
    "            \n",
    "            low_freq, high_freq = max(1, harmonic_freq - 0.5), min(125, harmonic_freq + 0.5)\n",
    "            b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            \n",
    "            channel_powers = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "                power = np.mean(filtered_sig**2)\n",
    "                channel_powers.append(power)\n",
    "            \n",
    "            harmonic_features.extend([\n",
    "                np.max(channel_powers),\n",
    "                np.mean(channel_powers),\n",
    "                np.max(channel_powers) / (np.mean(channel_powers) + 1e-10)\n",
    "            ])\n",
    "    return np.array(harmonic_features)\n",
    "\n",
    "def get_enhanced_cca_features(filtered_eeg_bank, reference_signals):\n",
    "    \"\"\"Enhanced CCA with multiple components.\"\"\"\n",
    "    enhanced_features = []\n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            cca = CCA(n_components=min(3, filtered_eeg.shape[1], ref_sig.shape[1]))\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            \n",
    "            component_corrs = [np.corrcoef(X_c[:, comp], Y_c[:, comp])[0, 1] for comp in range(X_c.shape[1])]\n",
    "            component_corrs = [c if np.isfinite(c) else 0 for c in component_corrs]\n",
    "            \n",
    "            rho_k.extend([\n",
    "                np.max(component_corrs),\n",
    "                np.mean(component_corrs),\n",
    "                np.sum([w * c for w, c in zip([0.5, 0.3, 0.2], component_corrs)])\n",
    "            ])\n",
    "        enhanced_features.extend(rho_k)\n",
    "    return np.array(enhanced_features)\n",
    "\n",
    "def get_optimized_spatial_filters(X_train, y_train, labels):\n",
    "    \"\"\"Improved spatial filtering (TRCA) with regularization.\"\"\"\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    \n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "            \n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        \n",
    "        class_trials_car = np.array([apply_car_preprocessing(trial) for trial in class_trials])\n",
    "        class_trials_centered = class_trials_car - np.mean(class_trials_car, axis=1, keepdims=True)\n",
    "        \n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        \n",
    "        reg_param = 0.01 * np.trace(S) / S.shape[0]\n",
    "        S += reg_param * np.eye(S.shape[0])\n",
    "        Q += reg_param * np.eye(Q.shape[0])\n",
    "        \n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    \n",
    "    return spatial_filters\n",
    "\n",
    "def get_snr_features(eeg_trial):\n",
    "    \"\"\"Calculate SNR at target frequencies vs. neighboring frequencies.\"\"\"\n",
    "    snr_features = []\n",
    "    for ch in range(eeg_trial.shape[1]):\n",
    "        freqs, psd = welch(eeg_trial[:, ch], fs=SAMPLING_RATE, nperseg=min(512, eeg_trial.shape[0]))\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            freq_idx = np.argmin(np.abs(freqs - target_freq))\n",
    "            if freq_idx > 2 and freq_idx < len(psd) - 2:\n",
    "                signal_power = psd[freq_idx]\n",
    "                noise_indices = [freq_idx-2, freq_idx-1, freq_idx+1, freq_idx+2]\n",
    "                noise_indices = [i for i in noise_indices if 0 <= i < len(psd)]\n",
    "                noise_power = np.mean(psd[noise_indices])\n",
    "                snr = signal_power / (noise_power + 1e-10)\n",
    "                snr_features.append(snr)\n",
    "            else:\n",
    "                snr_features.append(0)\n",
    "    return np.array(snr_features)\n",
    "\n",
    "def load_trial_data(row, base_path, dataset_type):\n",
    "    \"\"\"Load and preprocess a single trial's EEG data.\"\"\"\n",
    "    try:\n",
    "        eeg_path = os.path.join(base_path, 'SSVEP', dataset_type, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        \n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        \n",
    "        eeg_array = trial_eeg_data.values\n",
    "        eeg_array = apply_car_preprocessing(eeg_array) # Apply CAR\n",
    "        \n",
    "        return eeg_array\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: EEGdata.csv not found at {eeg_path}. Skipping trial.\")\n",
    "        return None\n",
    "\n",
    "def get_refined_filterbank():\n",
    "    \"\"\"Create a refined filterbank with both broad and narrow bands.\"\"\"\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    for freq in SSVEP_FREQUENCIES_LIST:\n",
    "        filter_bands.append([freq - 1, freq + 1])\n",
    "    \n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        if high <= SAMPLING_RATE / 2:\n",
    "            b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            filters.append((b, a))\n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    \"\"\"Generate sine/cosine reference signals for CCA.\"\"\"\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    \"\"\"Extract TRCA features using pre-computed spatial filters.\"\"\"\n",
    "    features = []\n",
    "    templates = {label: eeg_trial @ w for label, w in spatial_filters.items() if len(w) == eeg_trial.shape[1]}\n",
    "    \n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "            features.append(corr if np.isfinite(corr) else 0)\n",
    "            power_corr = np.corrcoef(projected_eeg**2, templates[label]**2)[0, 1]\n",
    "            features.append(power_corr if np.isfinite(power_corr) else 0)\n",
    "        else:\n",
    "            features.extend([0, 0])\n",
    "    return np.array(features)\n",
    "\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"Enhanced PSD features with better frequency resolution.\"\"\"\n",
    "    psd_features = []\n",
    "    for channel_data in eeg_trial.T:\n",
    "        nperseg = min(1000, eeg_trial.shape[0])\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=nperseg, noverlap=nperseg//2)\n",
    "        \n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                if harmonic_freq <= freqs[-1]:\n",
    "                    freq_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
    "                    band_indices = range(max(0, freq_idx-1), min(len(psd), freq_idx+2))\n",
    "                    avg_power = np.mean(psd[band_indices])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0)\n",
    "    return np.array(psd_features)\n",
    "\n",
    "def extract_all_features_for_trial(eeg_trial, filters, reference_signals, trca_filters):\n",
    "    \"\"\"Helper function to extract all features for a single trial.\"\"\"\n",
    "    # FBCCA features\n",
    "    fbcca_feat = get_enhanced_cca_features(apply_filterbank(eeg_trial, filters), reference_signals)\n",
    "    # TRCA features\n",
    "    trca_feat = extract_trca_features(eeg_trial, trca_filters)\n",
    "    # Other features\n",
    "    plv_feat = get_plv_features(eeg_trial)\n",
    "    harmonic_feat = get_enhanced_harmonic_features(eeg_trial)\n",
    "    snr_feat = get_snr_features(eeg_trial)\n",
    "    psd_feat = get_psd_features(eeg_trial)\n",
    "    # Combine all features in a consistent order\n",
    "    return np.concatenate([trca_feat, fbcca_feat, plv_feat, harmonic_feat, snr_feat, psd_feat])\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- SSVEP Final Model Training and Prediction ---\")\n",
    "    \n",
    "    # 1. Load Data Indexes\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    # 2. Combine Training and Validation Data, then Filter\n",
    "    full_train_df = pd.concat([\n",
    "        train_df[train_df['task'] == 'SSVEP'],\n",
    "        validation_df[validation_df['task'] == 'SSVEP']\n",
    "    ]).reset_index(drop=True)\n",
    "    \n",
    "    # **Exclude subject S27 as requested**\n",
    "    print(f\"Original number of training trials: {len(full_train_df)}\")\n",
    "    full_train_df = full_train_df[full_train_df['subject_id'] != 'S27'].reset_index(drop=True)\n",
    "    print(f\"Number of training trials after excluding S27: {len(full_train_df)}\")\n",
    "    \n",
    "    # 3. Pre-compute References and Filters\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    # 4. Load Raw EEG Data for Training\n",
    "    print(\"Loading all training & validation data...\")\n",
    "    X_all_raw = [load_trial_data(row, BASE_PATH, 'train' if row['id'] <= 4800 else 'validation') \n",
    "                 for _, row in full_train_df.iterrows()]\n",
    "    \n",
    "    valid_indices = [i for i, x in enumerate(X_all_raw) if x is not None and x.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS))]\n",
    "    X_train = np.array([X_all_raw[i] for i in valid_indices])\n",
    "    y_train = full_train_df.loc[valid_indices, 'label'].values\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "    # 5. Extract Features for the Entire Training Set\n",
    "    print(\"\\nExtracting features for the training set...\")\n",
    "    \n",
    "    # First, compute TRCA filters based on all training data\n",
    "    print(\"Computing optimized TRCA spatial filters...\")\n",
    "    trca_filters = get_optimized_spatial_filters(X_train, y_train, CLASS_LABELS)\n",
    "    \n",
    "    # Now extract all features for each training trial\n",
    "    all_train_features_list = []\n",
    "    for i, trial in enumerate(X_train):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processing training trial {i+1}/{len(X_train)}\")\n",
    "        trial_features = extract_all_features_for_trial(trial, filters, reference_signals, trca_filters)\n",
    "        all_train_features_list.append(trial_features)\n",
    "    \n",
    "    X_train_features = np.array(all_train_features_list)\n",
    "    print(f\"Feature extraction complete. Feature matrix shape: {X_train_features.shape}\")\n",
    "\n",
    "    # 6. Define and Train the Final Model\n",
    "    print(\"\\nDefining and training the final ensemble model...\")\n",
    "    \n",
    "    # Define classifiers\n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', \n",
    "                             learning_rate=0.1, max_depth=4, n_estimators=150)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=100, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    # Create ensemble\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.5, 0.3, 0.2]\n",
    "    )\n",
    "    \n",
    "    # Create and fit the scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "    \n",
    "    # Train the model\n",
    "    ensemble_model.fit(X_train_scaled, y_train_encoded)\n",
    "    print(\"Final model training complete.\")\n",
    "    \n",
    "    # 7. Generate Predictions for the Test Set\n",
    "    print(\"\\nGenerating predictions for the test set...\")\n",
    "    test_ssvep_df = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "    test_predictions_list = []\n",
    "\n",
    "    for idx, row in test_ssvep_df.iterrows():\n",
    "        eeg_trial = load_trial_data(row, BASE_PATH, 'test')\n",
    "        if eeg_trial is not None and eeg_trial.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            # Extract features for the test trial\n",
    "            X_test_features = extract_all_features_for_trial(eeg_trial, filters, reference_signals, trca_filters).reshape(1, -1)\n",
    "            \n",
    "            # Scale features using the scaler fitted on training data\n",
    "            X_test_scaled = scaler.transform(X_test_features)\n",
    "            \n",
    "            # Predict\n",
    "            prediction_encoded = ensemble_model.predict(X_test_scaled)[0]\n",
    "            test_predictions_list.append(prediction_encoded)\n",
    "        else:\n",
    "            # Fallback for corrupted/missing data: predict the most frequent class\n",
    "            print(f\"Fallback prediction for test ID {row['id']}\")\n",
    "            most_frequent_class_encoded = le.transform([pd.Series(y_train).mode()[0]])[0]\n",
    "            test_predictions_list.append(most_frequent_class_encoded)\n",
    "\n",
    "    # 8. Create Submission File\n",
    "    final_predictions_str = le.inverse_transform(test_predictions_list)\n",
    "    submission_df = pd.DataFrame({'id': test_ssvep_df['id'], 'label': final_predictions_str})\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nSubmission file 'submission.csv' has been created successfully! \")\n",
    "    print(\"Top 5 predictions:\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.73712 --> 0.73758 ocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy.signal import cheby1, filtfilt, welch, hilbert, butter\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# --- Enhanced Configuration ---\n",
    "warnings.filterwarnings('ignore')\n",
    "BASE_PATH = '/kaggle/input/mtcaic3'\n",
    "\n",
    "# Time window configuration\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 2.0\n",
    "DATA_DURATION = 4.0\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 5\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "# --- Subject-Specific Template Features ---\n",
    "def extract_subject_specific_templates(X_train, y_train, subjects_train):\n",
    "    \"\"\"Create subject-specific SSVEP templates for each class\"\"\"\n",
    "    print(\"Creating subject-specific templates...\")\n",
    "    subject_templates = {}\n",
    "    global_templates = {}\n",
    "    \n",
    "    # First, create global templates as fallback\n",
    "    for class_label in CLASS_LABELS:\n",
    "        class_mask = y_train == class_label\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_trials = X_train[class_mask]\n",
    "            global_templates[class_label] = np.mean(class_trials, axis=0)\n",
    "        else:\n",
    "            global_templates[class_label] = np.zeros((SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)))\n",
    "    \n",
    "    # Create subject-specific templates\n",
    "    for subject in np.unique(subjects_train):\n",
    "        subject_mask = subjects_train == subject\n",
    "        subject_templates[subject] = {}\n",
    "        \n",
    "        for class_label in CLASS_LABELS:\n",
    "            class_mask = y_train == class_label\n",
    "            combined_mask = subject_mask & class_mask\n",
    "            \n",
    "            if np.sum(combined_mask) >= 2:  # Need at least 2 trials for reliable template\n",
    "                class_trials = X_train[combined_mask]\n",
    "                subject_templates[subject][class_label] = np.mean(class_trials, axis=0)\n",
    "            else:\n",
    "                # Fallback to global template\n",
    "                subject_templates[subject][class_label] = global_templates[class_label]\n",
    "    \n",
    "    print(f\"Created templates for {len(subject_templates)} subjects\")\n",
    "    return subject_templates, global_templates\n",
    "\n",
    "def get_template_correlation_features(eeg_trial, subject_templates, global_templates, subject_id):\n",
    "    \"\"\"Extract correlation features with subject-specific templates\"\"\"\n",
    "    correlations = []\n",
    "    \n",
    "    # Use subject-specific templates if available, otherwise global\n",
    "    templates_to_use = subject_templates.get(subject_id, global_templates)\n",
    "    \n",
    "    for class_label in CLASS_LABELS:\n",
    "        if class_label in templates_to_use:\n",
    "            template = templates_to_use[class_label]\n",
    "            \n",
    "            # Multiple correlation measures\n",
    "            corr_measures = []\n",
    "            \n",
    "            # 1. Channel-wise correlation (average across channels)\n",
    "            channel_corrs = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                corr = np.corrcoef(eeg_trial[:, ch], template[:, ch])[0, 1]\n",
    "                channel_corrs.append(corr if np.isfinite(corr) else 0)\n",
    "            corr_measures.append(np.mean(channel_corrs))\n",
    "            \n",
    "            # 2. Global correlation (flatten both signals)\n",
    "            global_corr = np.corrcoef(eeg_trial.flatten(), template.flatten())[0, 1]\n",
    "            corr_measures.append(global_corr if np.isfinite(global_corr) else 0)\n",
    "            \n",
    "            # 3. Power correlation\n",
    "            trial_power = np.mean(eeg_trial**2, axis=0)\n",
    "            template_power = np.mean(template**2, axis=0)\n",
    "            power_corr = np.corrcoef(trial_power, template_power)[0, 1]\n",
    "            corr_measures.append(power_corr if np.isfinite(power_corr) else 0)\n",
    "            \n",
    "            # 4. Phase correlation (using Hilbert transform)\n",
    "            phase_corrs = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                trial_phase = np.angle(hilbert(eeg_trial[:, ch]))\n",
    "                template_phase = np.angle(hilbert(template[:, ch]))\n",
    "                phase_corr = np.abs(np.mean(np.exp(1j * (trial_phase - template_phase))))\n",
    "                phase_corrs.append(phase_corr if np.isfinite(phase_corr) else 0)\n",
    "            corr_measures.append(np.mean(phase_corrs))\n",
    "            \n",
    "            correlations.extend(corr_measures)\n",
    "        else:\n",
    "            correlations.extend([0, 0, 0, 0])  # 4 zeros for missing template\n",
    "    \n",
    "    return np.array(correlations)\n",
    "\n",
    "# --- Common Average Reference (CAR) Preprocessing ---\n",
    "def apply_car_preprocessing(eeg_data):\n",
    "    \"\"\"Apply Common Average Reference (CAR) - improves SSVEP accuracy by 2-3%\"\"\"\n",
    "    car_data = eeg_data - np.mean(eeg_data, axis=1, keepdims=True)\n",
    "    return car_data\n",
    "\n",
    "# --- Phase Locking Value (PLV) Features ---\n",
    "def get_plv_features(eeg_trial):\n",
    "    \"\"\"Calculate Phase Locking Value between channels - highly effective for SSVEP\"\"\"\n",
    "    plv_features = []\n",
    "    \n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        # Narrow bandpass filter around target frequency\n",
    "        low_freq = max(1, target_freq - 1)\n",
    "        high_freq = min(125, target_freq + 1)\n",
    "        \n",
    "        # Create filter\n",
    "        b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        \n",
    "        # Filter all channels\n",
    "        filtered_channels = []\n",
    "        for ch in range(eeg_trial.shape[1]):\n",
    "            filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "            analytic_signal = hilbert(filtered_sig)\n",
    "            phase = np.angle(analytic_signal)\n",
    "            filtered_channels.append(phase)\n",
    "        \n",
    "        # Calculate PLV between all channel pairs\n",
    "        for i in range(len(filtered_channels)):\n",
    "            for j in range(i+1, len(filtered_channels)):\n",
    "                phase_diff = filtered_channels[i] - filtered_channels[j]\n",
    "                plv = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "                plv_features.append(plv)\n",
    "    \n",
    "    return np.array(plv_features)\n",
    "\n",
    "# --- Enhanced Harmonic Features ---\n",
    "def get_enhanced_harmonic_features(eeg_trial):\n",
    "    \"\"\"Extract power and phase features for all harmonics\"\"\"\n",
    "    harmonic_features = []\n",
    "    \n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = target_freq * h\n",
    "            if harmonic_freq > 60:  # Skip if too high (line noise)\n",
    "                continue\n",
    "                \n",
    "            # Narrow band around harmonic\n",
    "            low_freq = max(1, harmonic_freq - 0.5)\n",
    "            high_freq = min(125, harmonic_freq + 0.5)\n",
    "            \n",
    "            b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            \n",
    "            channel_powers = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "                power = np.mean(filtered_sig**2)\n",
    "                channel_powers.append(power)\n",
    "            \n",
    "            # Features: max power, mean power, power ratio\n",
    "            harmonic_features.extend([\n",
    "                np.max(channel_powers),\n",
    "                np.mean(channel_powers),\n",
    "                np.max(channel_powers) / (np.mean(channel_powers) + 1e-10)\n",
    "            ])\n",
    "    \n",
    "    return np.array(harmonic_features)\n",
    "\n",
    "# --- Enhanced CCA Features ---\n",
    "def get_enhanced_cca_features(filtered_eeg_bank, reference_signals):\n",
    "    \"\"\"Enhanced CCA with multiple components and better correlation measures\"\"\"\n",
    "    enhanced_features = []\n",
    "    \n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            \n",
    "            # Use multiple CCA components\n",
    "            cca = CCA(n_components=min(3, filtered_eeg.shape[1], ref_sig.shape[1]))\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            \n",
    "            # Calculate correlation for each component\n",
    "            component_corrs = []\n",
    "            for comp in range(X_c.shape[1]):\n",
    "                corr = np.corrcoef(X_c[:, comp], Y_c[:, comp])[0, 1]\n",
    "                component_corrs.append(corr if np.isfinite(corr) else 0)\n",
    "            \n",
    "            # Features: max correlation, mean correlation, weighted sum\n",
    "            rho_k.extend([\n",
    "                np.max(component_corrs),\n",
    "                np.mean(component_corrs),\n",
    "                np.sum([w * c for w, c in zip([0.5, 0.3, 0.2], component_corrs)])\n",
    "            ])\n",
    "        \n",
    "        enhanced_features.extend(rho_k)\n",
    "    \n",
    "    return np.array(enhanced_features)\n",
    "\n",
    "# --- Optimized Spatial Filters ---\n",
    "def get_optimized_spatial_filters(X_train, y_train, labels):\n",
    "    \"\"\"Improved spatial filtering with regularization\"\"\"\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    \n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "            \n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        \n",
    "        # Apply CAR to each trial\n",
    "        class_trials_car = np.array([apply_car_preprocessing(trial) for trial in class_trials])\n",
    "        class_trials_centered = class_trials_car - np.mean(class_trials_car, axis=1, keepdims=True)\n",
    "        \n",
    "        # Covariance matrices with regularization\n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        \n",
    "        # Add regularization to avoid numerical issues\n",
    "        reg_param = 0.01 * np.trace(S) / S.shape[0]\n",
    "        S += reg_param * np.eye(S.shape[0])\n",
    "        Q += reg_param * np.eye(Q.shape[0])\n",
    "        \n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    \n",
    "    return spatial_filters\n",
    "\n",
    "# --- SNR Features ---\n",
    "def get_snr_features(eeg_trial):\n",
    "    \"\"\"Calculate SNR at target frequencies vs. neighboring frequencies\"\"\"\n",
    "    snr_features = []\n",
    "    \n",
    "    for ch in range(eeg_trial.shape[1]):\n",
    "        freqs, psd = welch(eeg_trial[:, ch], fs=SAMPLING_RATE, nperseg=min(512, eeg_trial.shape[0]))\n",
    "        \n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            freq_idx = np.argmin(np.abs(freqs - target_freq))\n",
    "            \n",
    "            if freq_idx > 2 and freq_idx < len(psd) - 2:\n",
    "                signal_power = psd[freq_idx]\n",
    "                noise_indices = [freq_idx-2, freq_idx-1, freq_idx+1, freq_idx+2]\n",
    "                noise_indices = [i for i in noise_indices if 0 <= i < len(psd)]\n",
    "                noise_power = np.mean(psd[noise_indices])\n",
    "                \n",
    "                snr = signal_power / (noise_power + 1e-10)\n",
    "                snr_features.append(snr)\n",
    "            else:\n",
    "                snr_features.append(0)\n",
    "    \n",
    "    return np.array(snr_features)\n",
    "\n",
    "# --- Data Loading ---\n",
    "def load_trial_data(row, base_path):\n",
    "    \"\"\"Enhanced data loading with CAR preprocessing\"\"\"\n",
    "    try:\n",
    "        id_num = row['id']\n",
    "        if id_num <= 4800:\n",
    "            dataset = 'train'\n",
    "        elif id_num <= 4900:\n",
    "            dataset = 'validation'\n",
    "        else:\n",
    "            dataset = 'test'\n",
    "        \n",
    "        eeg_path = os.path.join(base_path, row['task'], dataset, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        \n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        \n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        \n",
    "        # Apply CAR preprocessing\n",
    "        eeg_array = trial_eeg_data.values\n",
    "        eeg_array = apply_car_preprocessing(eeg_array)\n",
    "        \n",
    "        return eeg_array\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"Error loading trial {row['id']}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Filter Bank and Reference Signals ---\n",
    "def get_refined_filterbank():\n",
    "    \"\"\"Enhanced filterbank with more bands\"\"\"\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    \n",
    "    # Add narrow bands around target frequencies\n",
    "    for freq in SSVEP_FREQUENCIES_LIST:\n",
    "        filter_bands.append([freq - 1, freq + 1])\n",
    "    \n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        if high <= 125:  # Nyquist frequency\n",
    "            b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            filters.append((b, a))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "# --- TRCA Features ---\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    \"\"\"Enhanced TRCA features\"\"\"\n",
    "    features = []\n",
    "    templates = {}\n",
    "    \n",
    "    # Create templates for each class\n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            templates[label] = projected_eeg\n",
    "        else:\n",
    "            templates[label] = np.zeros(eeg_trial.shape[0])\n",
    "    \n",
    "    # Calculate correlations\n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            \n",
    "            # Multiple correlation measures\n",
    "            corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "            features.append(corr if np.isfinite(corr) else 0)\n",
    "            \n",
    "            # Power correlation\n",
    "            power_corr = np.corrcoef(projected_eeg**2, templates[label]**2)[0, 1]\n",
    "            features.append(power_corr if np.isfinite(power_corr) else 0)\n",
    "        else:\n",
    "            features.extend([0, 0])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# --- Enhanced PSD Features ---\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"Enhanced PSD features with better frequency resolution\"\"\"\n",
    "    psd_features = []\n",
    "    \n",
    "    for channel_data in eeg_trial.T:\n",
    "        nperseg = min(1000, eeg_trial.shape[0])\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=nperseg, noverlap=nperseg//2)\n",
    "        \n",
    "        # Extract power at target frequencies and harmonics\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                if harmonic_freq <= freqs[-1]:\n",
    "                    freq_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
    "                    band_indices = [i for i in range(max(0, freq_idx-1), min(len(psd), freq_idx+2))]\n",
    "                    avg_power = np.mean(psd[band_indices])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0)\n",
    "    \n",
    "    return np.array(psd_features)\n",
    "\n",
    "# --- Combined Feature Extraction ---\n",
    "def extract_all_features(eeg_trial, filters, reference_signals, spatial_filters, \n",
    "                         subject_templates, global_templates, subject_id):\n",
    "    \"\"\"Extract all features including subject-specific ones\"\"\"\n",
    "    \n",
    "    # Original features\n",
    "    fbcca_feat = get_enhanced_cca_features(apply_filterbank(eeg_trial, filters), reference_signals)\n",
    "    trca_feat = extract_trca_features(eeg_trial, spatial_filters)\n",
    "    plv_feat = get_plv_features(eeg_trial)\n",
    "    harmonic_feat = get_enhanced_harmonic_features(eeg_trial)\n",
    "    snr_feat = get_snr_features(eeg_trial)\n",
    "    psd_feat = get_psd_features(eeg_trial)\n",
    "    \n",
    "    # Subject-specific template correlation features\n",
    "    template_corr_feat = get_template_correlation_features(eeg_trial, subject_templates, global_templates, subject_id)\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = np.concatenate([\n",
    "        trca_feat, fbcca_feat, plv_feat, harmonic_feat, \n",
    "        snr_feat, psd_feat, template_corr_feat\n",
    "    ])\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Enhanced SSVEP Pipeline for Competition ---\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    # Filter for SSVEP tasks only and exclude subject 27\n",
    "    train_ssvep = train_df[(train_df['task'] == 'SSVEP') & (train_df['subject_id'] != 'S27')].reset_index(drop=True)\n",
    "    validation_ssvep = validation_df[(validation_df['task'] == 'SSVEP') & (validation_df['subject_id'] != 'S27')].reset_index(drop=True)\n",
    "    test_ssvep = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "\n",
    "    # Combine train and validation for training\n",
    "    full_train_df = pd.concat([train_ssvep, validation_ssvep]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Training data: {len(full_train_df)} trials\")\n",
    "    print(f\"Test data: {len(test_ssvep)} trials\")\n",
    "    print(f\"Subjects in training: {sorted(full_train_df['subject_id'].unique())}\")\n",
    "\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    print(\"Loading all training data...\")\n",
    "    X_train_raw = []\n",
    "    y_train = []\n",
    "    subjects_train = []\n",
    "    \n",
    "    for _, row in full_train_df.iterrows():\n",
    "        trial_data = load_trial_data(row, BASE_PATH)\n",
    "        if trial_data is not None and trial_data.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            X_train_raw.append(trial_data)\n",
    "            y_train.append(row['label'])\n",
    "            subjects_train.append(row['subject_id'])\n",
    "    \n",
    "    X_train = np.array(X_train_raw)\n",
    "    y_train = np.array(y_train)\n",
    "    subjects_train = np.array(subjects_train)\n",
    "    \n",
    "    print(f\"Successfully loaded {len(X_train)} training trials\")\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    \n",
    "    print(\"\\nCreating subject-specific templates...\")\n",
    "    subject_templates, global_templates = extract_subject_specific_templates(X_train, y_train, subjects_train)\n",
    "    \n",
    "    print(\"Computing spatial filters...\")\n",
    "    spatial_filters = get_optimized_spatial_filters(X_train, y_train, CLASS_LABELS)\n",
    "    \n",
    "    print(\"Extracting training features...\")\n",
    "    X_train_features = []\n",
    "    \n",
    "    for i, (trial, subject_id) in enumerate(zip(X_train, subjects_train)):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing trial {i}/{len(X_train)}\")\n",
    "        \n",
    "        features = extract_all_features(\n",
    "            trial, filters, reference_signals, spatial_filters,\n",
    "            subject_templates, global_templates, subject_id\n",
    "        )\n",
    "        X_train_features.append(features)\n",
    "    \n",
    "    X_train_features = np.array(X_train_features)\n",
    "    \n",
    "    print(f\"Training feature shape: {X_train_features.shape}\")\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\nTraining ensemble classifier...\")\n",
    "    \n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', \n",
    "                             learning_rate=0.1, max_depth=4, n_estimators=150)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=100, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.5, 0.3, 0.2]\n",
    "    )\n",
    "    \n",
    "    # Scale features and train\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "    ensemble_model.fit(X_train_scaled, y_train_encoded)\n",
    "    \n",
    "    print(\"Model training complete!\")\n",
    "    \n",
    "    # Generate test predictions\n",
    "    print(\"\\nGenerating test predictions...\")\n",
    "    test_predictions = []\n",
    "    \n",
    "    for idx, row in test_ssvep.iterrows():\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Processing test trial {idx}/{len(test_ssvep)}\")\n",
    "            \n",
    "        trial_data = load_trial_data(row, BASE_PATH)\n",
    "        \n",
    "        if trial_data is not None and trial_data.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            # Extract features for this test trial\n",
    "            test_features = extract_all_features(\n",
    "                trial_data, filters, reference_signals, spatial_filters,\n",
    "                subject_templates, global_templates, row['subject_id']\n",
    "            ).reshape(1, -1)\n",
    "            \n",
    "            # Scale and predict\n",
    "            test_features_scaled = scaler.transform(test_features)\n",
    "            prediction_encoded = ensemble_model.predict(test_features_scaled)[0]\n",
    "            prediction = le.inverse_transform([prediction_encoded])[0]\n",
    "            test_predictions.append(prediction)\n",
    "        else:\n",
    "            # Fallback prediction for missing/corrupted data\n",
    "            most_frequent_class = pd.Series(y_train).mode()[0]\n",
    "            test_predictions.append(most_frequent_class)\n",
    "    \n",
    "    # Create submission file\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ssvep['id'], \n",
    "        'label': test_predictions\n",
    "    })\n",
    "    \n",
    "    submission_df.to_csv('submission_SSVEP.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission file 'submission_SSVEP.csv' created successfully!\")\n",
    "    print(f\"Predictions summary:\")\n",
    "    print(submission_df['label'].value_counts())\n",
    "    print(f\"\\nFirst 10 predictions:\")\n",
    "    print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 0.8 f1 SSVEP on Phase 2\n",
    "The code trains on both training and validation data (Excluding subject 27) and tests on the 100 SSVEP test trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy.signal import cheby1, filtfilt, welch, hilbert, butter\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# --- Enhanced Configuration ---\n",
    "warnings.filterwarnings('ignore')\n",
    "# MODIFIED: Updated base path for the expanded Phase II dataset\n",
    "BASE_PATH = '/kaggle/input/mtcaic3-phase-ii'\n",
    "\n",
    "# Time window configuration\n",
    "TRIAL_TOTAL_DURATION = 7.0\n",
    "SKIP_DURATION = 2.0\n",
    "DATA_DURATION = 4.0\n",
    "\n",
    "# Core EEG & SSVEP Constants\n",
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLING_RATE = 250\n",
    "SSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\n",
    "CLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\n",
    "SSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\n",
    "NUM_HARMONICS = 5\n",
    "\n",
    "# Calculated sample counts\n",
    "SAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\n",
    "SAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)\n",
    "\n",
    "# --- Subject-Specific Template Features ---\n",
    "def extract_subject_specific_templates(X_train, y_train, subjects_train):\n",
    "    \"\"\"Create subject-specific SSVEP templates for each class\"\"\"\n",
    "    print(\"Creating subject-specific templates...\")\n",
    "    subject_templates = {}\n",
    "    global_templates = {}\n",
    "    \n",
    "    # First, create global templates as fallback\n",
    "    for class_label in CLASS_LABELS:\n",
    "        class_mask = y_train == class_label\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_trials = X_train[class_mask]\n",
    "            global_templates[class_label] = np.mean(class_trials, axis=0)\n",
    "        else:\n",
    "            global_templates[class_label] = np.zeros((SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)))\n",
    "    \n",
    "    # Create subject-specific templates\n",
    "    for subject in np.unique(subjects_train):\n",
    "        subject_mask = subjects_train == subject\n",
    "        subject_templates[subject] = {}\n",
    "        \n",
    "        for class_label in CLASS_LABELS:\n",
    "            class_mask = y_train == class_label\n",
    "            combined_mask = subject_mask & class_mask\n",
    "            \n",
    "            if np.sum(combined_mask) >= 2:  # Need at least 2 trials for reliable template\n",
    "                class_trials = X_train[combined_mask]\n",
    "                subject_templates[subject][class_label] = np.mean(class_trials, axis=0)\n",
    "            else:\n",
    "                # Fallback to global template\n",
    "                subject_templates[subject][class_label] = global_templates[class_label]\n",
    "    \n",
    "    print(f\"Created templates for {len(subject_templates)} subjects\")\n",
    "    return subject_templates, global_templates\n",
    "\n",
    "def get_template_correlation_features(eeg_trial, subject_templates, global_templates, subject_id):\n",
    "    \"\"\"Extract correlation features with subject-specific templates\"\"\"\n",
    "    correlations = []\n",
    "    \n",
    "    # Use subject-specific templates if available, otherwise global\n",
    "    templates_to_use = subject_templates.get(subject_id, global_templates)\n",
    "    \n",
    "    for class_label in CLASS_LABELS:\n",
    "        if class_label in templates_to_use:\n",
    "            template = templates_to_use[class_label]\n",
    "            \n",
    "            # Multiple correlation measures\n",
    "            corr_measures = []\n",
    "            \n",
    "            # 1. Channel-wise correlation (average across channels)\n",
    "            channel_corrs = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                corr = np.corrcoef(eeg_trial[:, ch], template[:, ch])[0, 1]\n",
    "                channel_corrs.append(corr if np.isfinite(corr) else 0)\n",
    "            corr_measures.append(np.mean(channel_corrs))\n",
    "            \n",
    "            # 2. Global correlation (flatten both signals)\n",
    "            global_corr = np.corrcoef(eeg_trial.flatten(), template.flatten())[0, 1]\n",
    "            corr_measures.append(global_corr if np.isfinite(global_corr) else 0)\n",
    "            \n",
    "            # 3. Power correlation\n",
    "            trial_power = np.mean(eeg_trial**2, axis=0)\n",
    "            template_power = np.mean(template**2, axis=0)\n",
    "            power_corr = np.corrcoef(trial_power, template_power)[0, 1]\n",
    "            corr_measures.append(power_corr if np.isfinite(power_corr) else 0)\n",
    "            \n",
    "            # 4. Phase correlation (using Hilbert transform)\n",
    "            phase_corrs = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                trial_phase = np.angle(hilbert(eeg_trial[:, ch]))\n",
    "                template_phase = np.angle(hilbert(template[:, ch]))\n",
    "                phase_corr = np.abs(np.mean(np.exp(1j * (trial_phase - template_phase))))\n",
    "                phase_corrs.append(phase_corr if np.isfinite(phase_corr) else 0)\n",
    "            corr_measures.append(np.mean(phase_corrs))\n",
    "            \n",
    "            correlations.extend(corr_measures)\n",
    "        else:\n",
    "            correlations.extend([0, 0, 0, 0])  # 4 zeros for missing template\n",
    "    \n",
    "    return np.array(correlations)\n",
    "\n",
    "# --- Common Average Reference (CAR) Preprocessing ---\n",
    "def apply_car_preprocessing(eeg_data):\n",
    "    \"\"\"Apply Common Average Reference (CAR) - improves SSVEP accuracy by 2-3%\"\"\"\n",
    "    car_data = eeg_data - np.mean(eeg_data, axis=1, keepdims=True)\n",
    "    return car_data\n",
    "\n",
    "# --- Phase Locking Value (PLV) Features ---\n",
    "def get_plv_features(eeg_trial):\n",
    "    \"\"\"Calculate Phase Locking Value between channels - highly effective for SSVEP\"\"\"\n",
    "    plv_features = []\n",
    "    \n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        # Narrow bandpass filter around target frequency\n",
    "        low_freq = max(1, target_freq - 1)\n",
    "        high_freq = min(125, target_freq + 1)\n",
    "        \n",
    "        # Create filter\n",
    "        b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "        \n",
    "        # Filter all channels\n",
    "        filtered_channels = []\n",
    "        for ch in range(eeg_trial.shape[1]):\n",
    "            filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "            analytic_signal = hilbert(filtered_sig)\n",
    "            phase = np.angle(analytic_signal)\n",
    "            filtered_channels.append(phase)\n",
    "        \n",
    "        # Calculate PLV between all channel pairs\n",
    "        for i in range(len(filtered_channels)):\n",
    "            for j in range(i+1, len(filtered_channels)):\n",
    "                phase_diff = filtered_channels[i] - filtered_channels[j]\n",
    "                plv = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "                plv_features.append(plv)\n",
    "    \n",
    "    return np.array(plv_features)\n",
    "\n",
    "# --- Enhanced Harmonic Features ---\n",
    "def get_enhanced_harmonic_features(eeg_trial):\n",
    "    \"\"\"Extract power and phase features for all harmonics\"\"\"\n",
    "    harmonic_features = []\n",
    "    \n",
    "    for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = target_freq * h\n",
    "            if harmonic_freq > 60:  # Skip if too high (line noise)\n",
    "                continue\n",
    "                \n",
    "            # Narrow band around harmonic\n",
    "            low_freq = max(1, harmonic_freq - 0.5)\n",
    "            high_freq = min(125, harmonic_freq + 0.5)\n",
    "            \n",
    "            b, a = butter(4, [low_freq/(0.5*SAMPLING_RATE), high_freq/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            \n",
    "            channel_powers = []\n",
    "            for ch in range(eeg_trial.shape[1]):\n",
    "                filtered_sig = filtfilt(b, a, eeg_trial[:, ch])\n",
    "                power = np.mean(filtered_sig**2)\n",
    "                channel_powers.append(power)\n",
    "            \n",
    "            # Features: max power, mean power, power ratio\n",
    "            harmonic_features.extend([\n",
    "                np.max(channel_powers),\n",
    "                np.mean(channel_powers),\n",
    "                np.max(channel_powers) / (np.mean(channel_powers) + 1e-10)\n",
    "            ])\n",
    "    \n",
    "    return np.array(harmonic_features)\n",
    "\n",
    "# --- Enhanced CCA Features ---\n",
    "def get_enhanced_cca_features(filtered_eeg_bank, reference_signals):\n",
    "    \"\"\"Enhanced CCA with multiple components and better correlation measures\"\"\"\n",
    "    enhanced_features = []\n",
    "    \n",
    "    for filtered_eeg in filtered_eeg_bank:\n",
    "        rho_k = []\n",
    "        for freq in SSVEP_FREQUENCIES_LIST:\n",
    "            ref_sig = reference_signals[freq]\n",
    "            \n",
    "            # Use multiple CCA components\n",
    "            cca = CCA(n_components=min(3, filtered_eeg.shape[1], ref_sig.shape[1]))\n",
    "            cca.fit(filtered_eeg, ref_sig)\n",
    "            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n",
    "            \n",
    "            # Calculate correlation for each component\n",
    "            component_corrs = []\n",
    "            for comp in range(X_c.shape[1]):\n",
    "                corr = np.corrcoef(X_c[:, comp], Y_c[:, comp])[0, 1]\n",
    "                component_corrs.append(corr if np.isfinite(corr) else 0)\n",
    "            \n",
    "            # Features: max correlation, mean correlation, weighted sum\n",
    "            rho_k.extend([\n",
    "                np.max(component_corrs),\n",
    "                np.mean(component_corrs),\n",
    "                np.sum([w * c for w, c in zip([0.5, 0.3, 0.2], component_corrs)])\n",
    "            ])\n",
    "        \n",
    "        enhanced_features.extend(rho_k)\n",
    "    \n",
    "    return np.array(enhanced_features)\n",
    "\n",
    "# --- Optimized Spatial Filters ---\n",
    "def get_optimized_spatial_filters(X_train, y_train, labels):\n",
    "    \"\"\"Improved spatial filtering with regularization\"\"\"\n",
    "    spatial_filters = {}\n",
    "    unique_labels = np.unique(y_train)\n",
    "    \n",
    "    for label in labels:\n",
    "        if label not in unique_labels:\n",
    "            spatial_filters[label] = np.zeros(X_train.shape[2])\n",
    "            continue\n",
    "            \n",
    "        class_trials = X_train[y_train == label]\n",
    "        if class_trials.shape[0] < 2:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "            continue\n",
    "        \n",
    "        # Apply CAR to each trial\n",
    "        class_trials_car = np.array([apply_car_preprocessing(trial) for trial in class_trials])\n",
    "        class_trials_centered = class_trials_car - np.mean(class_trials_car, axis=1, keepdims=True)\n",
    "        \n",
    "        # Covariance matrices with regularization\n",
    "        S = np.sum([np.cov(trial.T) for trial in class_trials_centered], axis=0)\n",
    "        Q = np.cov(np.sum(class_trials_centered, axis=0).T)\n",
    "        \n",
    "        # Add regularization to avoid numerical issues\n",
    "        reg_param = 0.01 * np.trace(S) / S.shape[0]\n",
    "        S += reg_param * np.eye(S.shape[0])\n",
    "        Q += reg_param * np.eye(Q.shape[0])\n",
    "        \n",
    "        try:\n",
    "            evals, evecs = eigh(Q, S)\n",
    "            spatial_filters[label] = evecs[:, -1]\n",
    "        except np.linalg.LinAlgError:\n",
    "            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n",
    "    \n",
    "    return spatial_filters\n",
    "\n",
    "# --- SNR Features ---\n",
    "def get_snr_features(eeg_trial):\n",
    "    \"\"\"Calculate SNR at target frequencies vs. neighboring frequencies\"\"\"\n",
    "    snr_features = []\n",
    "    \n",
    "    for ch in range(eeg_trial.shape[1]):\n",
    "        freqs, psd = welch(eeg_trial[:, ch], fs=SAMPLING_RATE, nperseg=min(512, eeg_trial.shape[0]))\n",
    "        \n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            freq_idx = np.argmin(np.abs(freqs - target_freq))\n",
    "            \n",
    "            if freq_idx > 2 and freq_idx < len(psd) - 2:\n",
    "                signal_power = psd[freq_idx]\n",
    "                noise_indices = [freq_idx-2, freq_idx-1, freq_idx+1, freq_idx+2]\n",
    "                noise_indices = [i for i in noise_indices if 0 <= i < len(psd)]\n",
    "                noise_power = np.mean(psd[noise_indices])\n",
    "                \n",
    "                snr = signal_power / (noise_power + 1e-10)\n",
    "                snr_features.append(snr)\n",
    "            else:\n",
    "                snr_features.append(0)\n",
    "    \n",
    "    return np.array(snr_features)\n",
    "\n",
    "# --- Data Loading ---\n",
    "def load_trial_data(row, base_path):\n",
    "    \"\"\"Enhanced data loading with CAR preprocessing\"\"\"\n",
    "    try:\n",
    "        id_num = row['id']\n",
    "        # NOTE: This logic correctly identifies test trials (even new ones) as their IDs will be highest.\n",
    "        if id_num <= 4800:\n",
    "            dataset = 'train'\n",
    "        elif id_num <= 4900:\n",
    "            dataset = 'validation'\n",
    "        else:\n",
    "            dataset = 'test'\n",
    "        \n",
    "        eeg_path = os.path.join(base_path, row['task'], dataset, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
    "        eeg_data = pd.read_csv(eeg_path)\n",
    "        \n",
    "        trial_num = int(row['trial'])\n",
    "        trial_start_in_file = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL\n",
    "        start_idx = trial_start_in_file + SAMPLES_TO_SKIP\n",
    "        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n",
    "        \n",
    "        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS]\n",
    "        \n",
    "        # Apply CAR preprocessing\n",
    "        eeg_array = trial_eeg_data.values\n",
    "        eeg_array = apply_car_preprocessing(eeg_array)\n",
    "        \n",
    "        return eeg_array\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"Error loading trial {row['id']}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Filter Bank and Reference Signals ---\n",
    "def get_refined_filterbank():\n",
    "    \"\"\"Enhanced filterbank with more bands\"\"\"\n",
    "    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n",
    "    \n",
    "    # Add narrow bands around target frequencies\n",
    "    for freq in SSVEP_FREQUENCIES_LIST:\n",
    "        filter_bands.append([freq - 1, freq + 1])\n",
    "    \n",
    "    filters = []\n",
    "    for (low, high) in filter_bands:\n",
    "        if high <= 125:  # Nyquist frequency\n",
    "            b, a = cheby1(5, 0.1, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n",
    "            filters.append((b, a))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def apply_filterbank(eeg_data, filters):\n",
    "    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n",
    "\n",
    "def get_reference_signals(duration_samples, frequencies):\n",
    "    reference_signals = {}\n",
    "    t = np.arange(duration_samples) / SAMPLING_RATE\n",
    "    for freq in frequencies:\n",
    "        refs = []\n",
    "        for h in range(1, NUM_HARMONICS + 1):\n",
    "            harmonic_freq = freq * h\n",
    "            refs.extend([np.sin(2 * np.pi * harmonic_freq * t), np.cos(2 * np.pi * harmonic_freq * t)])\n",
    "        reference_signals[freq] = np.array(refs).T\n",
    "    return reference_signals\n",
    "\n",
    "# --- TRCA Features ---\n",
    "def extract_trca_features(eeg_trial, spatial_filters):\n",
    "    \"\"\"Enhanced TRCA features\"\"\"\n",
    "    features = []\n",
    "    templates = {}\n",
    "    \n",
    "    # Create templates for each class\n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            templates[label] = projected_eeg\n",
    "        else:\n",
    "            templates[label] = np.zeros(eeg_trial.shape[0])\n",
    "    \n",
    "    # Calculate correlations\n",
    "    for label, w in spatial_filters.items():\n",
    "        if len(w) == eeg_trial.shape[1]:\n",
    "            projected_eeg = eeg_trial @ w\n",
    "            \n",
    "            # Multiple correlation measures\n",
    "            corr = np.corrcoef(projected_eeg, templates[label])[0, 1]\n",
    "            features.append(corr if np.isfinite(corr) else 0)\n",
    "            \n",
    "            # Power correlation\n",
    "            power_corr = np.corrcoef(projected_eeg**2, templates[label]**2)[0, 1]\n",
    "            features.append(power_corr if np.isfinite(power_corr) else 0)\n",
    "        else:\n",
    "            features.extend([0, 0])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# --- Enhanced PSD Features ---\n",
    "def get_psd_features(eeg_trial):\n",
    "    \"\"\"Enhanced PSD features with better frequency resolution\"\"\"\n",
    "    psd_features = []\n",
    "    \n",
    "    for channel_data in eeg_trial.T:\n",
    "        nperseg = min(1000, eeg_trial.shape[0])\n",
    "        freqs, psd = welch(channel_data, fs=SAMPLING_RATE, nperseg=nperseg, noverlap=nperseg//2)\n",
    "        \n",
    "        # Extract power at target frequencies and harmonics\n",
    "        for target_freq in SSVEP_FREQUENCIES_LIST:\n",
    "            for h in range(1, NUM_HARMONICS + 1):\n",
    "                harmonic_freq = target_freq * h\n",
    "                if harmonic_freq <= freqs[-1]:\n",
    "                    freq_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
    "                    band_indices = [i for i in range(max(0, freq_idx-1), min(len(psd), freq_idx+2))]\n",
    "                    avg_power = np.mean(psd[band_indices])\n",
    "                    psd_features.append(avg_power)\n",
    "                else:\n",
    "                    psd_features.append(0)\n",
    "    \n",
    "    return np.array(psd_features)\n",
    "\n",
    "# --- Combined Feature Extraction ---\n",
    "def extract_all_features(eeg_trial, filters, reference_signals, spatial_filters, \n",
    "                         subject_templates, global_templates, subject_id):\n",
    "    \"\"\"Extract all features including subject-specific ones\"\"\"\n",
    "    \n",
    "    # Original features\n",
    "    fbcca_feat = get_enhanced_cca_features(apply_filterbank(eeg_trial, filters), reference_signals)\n",
    "    trca_feat = extract_trca_features(eeg_trial, spatial_filters)\n",
    "    plv_feat = get_plv_features(eeg_trial)\n",
    "    harmonic_feat = get_enhanced_harmonic_features(eeg_trial)\n",
    "    snr_feat = get_snr_features(eeg_trial)\n",
    "    psd_feat = get_psd_features(eeg_trial)\n",
    "    \n",
    "    # Subject-specific template correlation features\n",
    "    template_corr_feat = get_template_correlation_features(eeg_trial, subject_templates, global_templates, subject_id)\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = np.concatenate([\n",
    "        trca_feat, fbcca_feat, plv_feat, harmonic_feat, \n",
    "        snr_feat, psd_feat, template_corr_feat\n",
    "    ])\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Enhanced SSVEP Pipeline for Competition ---\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    validation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "    # Filter for SSVEP tasks only and exclude subject 27\n",
    "    train_ssvep = train_df[(train_df['task'] == 'SSVEP') & (train_df['subject_id'] != 'S27')].reset_index(drop=True)\n",
    "    validation_ssvep = validation_df[(validation_df['task'] == 'SSVEP') & (validation_df['subject_id'] != 'S27')].reset_index(drop=True)\n",
    "    test_ssvep = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\n",
    "\n",
    "    # Combine train and validation for training\n",
    "    full_train_df = pd.concat([train_ssvep, validation_ssvep]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Training data: {len(full_train_df)} trials\")\n",
    "    print(f\"Test data: {len(test_ssvep)} trials\")\n",
    "    print(f\"Subjects in training: {sorted(full_train_df['subject_id'].unique())}\")\n",
    "\n",
    "    print(\"\\nPre-computing references and filters...\")\n",
    "    reference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\n",
    "    filters = get_refined_filterbank()\n",
    "    \n",
    "    print(\"Loading all training data...\")\n",
    "    X_train_raw = []\n",
    "    y_train = []\n",
    "    subjects_train = []\n",
    "    \n",
    "    for _, row in full_train_df.iterrows():\n",
    "        trial_data = load_trial_data(row, BASE_PATH)\n",
    "        if trial_data is not None and trial_data.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            X_train_raw.append(trial_data)\n",
    "            y_train.append(row['label'])\n",
    "            subjects_train.append(row['subject_id'])\n",
    "    \n",
    "    X_train = np.array(X_train_raw)\n",
    "    y_train = np.array(y_train)\n",
    "    subjects_train = np.array(subjects_train)\n",
    "    \n",
    "    print(f\"Successfully loaded {len(X_train)} training trials\")\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    \n",
    "    print(\"\\nCreating subject-specific templates...\")\n",
    "    subject_templates, global_templates = extract_subject_specific_templates(X_train, y_train, subjects_train)\n",
    "    \n",
    "    print(\"Computing spatial filters...\")\n",
    "    spatial_filters = get_optimized_spatial_filters(X_train, y_train, CLASS_LABELS)\n",
    "    \n",
    "    print(\"Extracting training features...\")\n",
    "    X_train_features = []\n",
    "    \n",
    "    for i, (trial, subject_id) in enumerate(zip(X_train, subjects_train)):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing trial {i}/{len(X_train)}\")\n",
    "        \n",
    "        features = extract_all_features(\n",
    "            trial, filters, reference_signals, spatial_filters,\n",
    "            subject_templates, global_templates, subject_id\n",
    "        )\n",
    "        X_train_features.append(features)\n",
    "    \n",
    "    X_train_features = np.array(X_train_features)\n",
    "    \n",
    "    print(f\"Training feature shape: {X_train_features.shape}\")\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\nTraining ensemble classifier...\")\n",
    "    \n",
    "    clf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', \n",
    "                             learning_rate=0.1, max_depth=4, n_estimators=150)\n",
    "    clf2 = SVC(probability=True, random_state=42, C=100, kernel='rbf', gamma='scale')\n",
    "    clf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)],\n",
    "        voting='soft',\n",
    "        weights=[0.5, 0.3, 0.2]\n",
    "    )\n",
    "    \n",
    "    # Scale features and train\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "    ensemble_model.fit(X_train_scaled, y_train_encoded)\n",
    "    \n",
    "    print(\"Model training complete!\")\n",
    "    \n",
    "    # Generate test predictions\n",
    "    print(\"\\nGenerating test predictions...\")\n",
    "    test_predictions = []\n",
    "    \n",
    "    for idx, row in test_ssvep.iterrows():\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Processing test trial {idx}/{len(test_ssvep)}\")\n",
    "            \n",
    "        trial_data = load_trial_data(row, BASE_PATH)\n",
    "        \n",
    "        if trial_data is not None and trial_data.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n",
    "            # Extract features for this test trial\n",
    "            test_features = extract_all_features(\n",
    "                trial_data, filters, reference_signals, spatial_filters,\n",
    "                subject_templates, global_templates, row['subject_id']\n",
    "            ).reshape(1, -1)\n",
    "            \n",
    "            # Scale and predict\n",
    "            test_features_scaled = scaler.transform(test_features)\n",
    "            prediction_encoded = ensemble_model.predict(test_features_scaled)[0]\n",
    "            prediction = le.inverse_transform([prediction_encoded])[0]\n",
    "            test_predictions.append(prediction)\n",
    "        else:\n",
    "            # Fallback prediction for missing/corrupted data\n",
    "            most_frequent_class = pd.Series(y_train).mode()[0]\n",
    "            test_predictions.append(most_frequent_class)\n",
    "    \n",
    "    # Create submission file\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ssvep['id'], \n",
    "        'label': test_predictions\n",
    "    })\n",
    "    \n",
    "    # MODIFIED: Changed output filename as requested\n",
    "    submission_df.to_csv('submission_p2.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission file 'submission_p2.csv' created successfully!\")\n",
    "    print(f\"Predictions summary:\")\n",
    "    print(submission_df['label'].value_counts())\n",
    "    print(f\"\\nFirst 10 predictions:\")\n",
    "    print(submission_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12673416,
     "sourceId": 98188,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
