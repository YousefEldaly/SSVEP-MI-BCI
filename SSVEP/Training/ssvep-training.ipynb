{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":106880,"databundleVersionId":13088836,"sourceType":"competition"},{"sourceId":12528315,"sourceType":"datasetVersion","datasetId":7908593},{"sourceId":12550055,"sourceType":"datasetVersion","datasetId":7923861}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and Environment Setup\nThis first cell imports all the necessary libraries for data manipulation, signal processing, and machine learning. It also sets up the environment by suppressing warnings for a cleaner output and defining the base paths for the competition datasets.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport warnings\nimport pickle\n\n# Signal processing libraries\nfrom scipy.signal import cheby1, filtfilt, welch, hilbert, butter\nfrom scipy.linalg import eigh\n\n# Machine learning and preprocessing libraries\nfrom sklearn.cross_decomposition import CCA\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nimport xgboost as xgb\nfrom sklearn.ensemble import VotingClassifier\n\n# --- Configuration ---\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')\n\n# --- Paths ---\n# Define base paths for the competition data, supplementary data, and outlier list\nBASE_PATH = '/kaggle/input/mtcaic3-phase-ii'\nIMITATION_BASE_PATH = '/kaggle/input/imitation/SSVEP'\nOUTLIER_CSV_PATH = '/kaggle/input/outliers-list-for-ssvep/outliers_list.csv'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:35:34.306623Z","iopub.execute_input":"2025-09-11T23:35:34.307129Z","iopub.status.idle":"2025-09-11T23:35:39.858825Z","shell.execute_reply.started":"2025-09-11T23:35:34.307094Z","shell.execute_reply":"2025-09-11T23:35:39.857429Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Global Constants and Parameters\nHere, we define all the critical constants and parameters for the SSVEP paradigm. These values are derived from the competition's dataset description and are crucial for ensuring consistency across all processing steps.\n\n","metadata":{}},{"cell_type":"code","source":"# --- Trial Timing Parameters ---\nTRIAL_TOTAL_DURATION = 7.0  # Total duration of one trial in seconds\nSKIP_DURATION = 2.0         # Initial period to skip (marker/preparation) in seconds\nDATA_DURATION = 4.0         # Duration of the actual SSVEP data to be used, in seconds\nSAMPLING_RATE = 250         # EEG sampling rate in Hz\n\n# --- EEG and SSVEP Configuration ---\nEEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\nSSVEP_FREQUENCIES_MAP = {'Forward': 7, 'Backward': 8, 'Left': 10, 'Right': 13}\nCLASS_LABELS = list(SSVEP_FREQUENCIES_MAP.keys())\nSSVEP_FREQUENCIES_LIST = list(SSVEP_FREQUENCIES_MAP.values())\nNUM_HARMONICS = 5           # Number of harmonics to consider for frequency-based features\n\n# --- Sample Calculation ---\n# Convert time durations to number of samples\nSAMPLES_PER_TRIAL_FULL = int(TRIAL_TOTAL_DURATION * SAMPLING_RATE)\nSAMPLES_TO_SKIP = int(SKIP_DURATION * SAMPLING_RATE)\nSAMPLES_PER_SSVEP_TRIAL = int(DATA_DURATION * SAMPLING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:35:43.426694Z","iopub.execute_input":"2025-09-11T23:35:43.427418Z","iopub.status.idle":"2025-09-11T23:35:43.435812Z","shell.execute_reply.started":"2025-09-11T23:35:43.427387Z","shell.execute_reply":"2025-09-11T23:35:43.434297Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Data Loading and Preprocessing Utilities\nThis section contains the utility functions responsible for loading and preparing the raw EEG data. The load_trial_data function is the cornerstone, capable of locating and extracting the precise 4-second EEG segment for any given trial. It also applies Common Average Referencing (CAR), a standard preprocessing step to reduce noise common to all channels.\n\n","metadata":{}},{"cell_type":"code","source":"def apply_car_preprocessing(eeg_data):\n    \"\"\"Applies Common Average Referencing (CAR) to the EEG data.\"\"\"\n    return eeg_data - np.mean(eeg_data, axis=1, keepdims=True)\n\ndef load_trial_data(row, base_path, imitation_base_path):\n    \"\"\"\n    Loads, extracts, and preprocesses the EEG data for a single trial.\n    Handles data from both the main competition dataset and the supplementary imitation dataset.\n    \"\"\"\n    eeg_path = ''\n    try:\n        # Construct path based on whether the subject is from the imitation dataset\n        if row['subject_id'] == 'IMITATION_S1':\n            eeg_path = os.path.join(imitation_base_path, str(row['trial_session']), 'EEGdata.csv')\n        else:\n            # Determine if the data is from train, validation, or test set\n            id_num = row['id']\n            dataset = 'test' if id_num > 4900 else 'validation' if id_num > 4800 else 'train'\n            eeg_path = os.path.join(base_path, row['task'], dataset, row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n        \n        eeg_data = pd.read_csv(eeg_path)\n        \n        # Calculate the start and end indices for the 4-second SSVEP stimulation period\n        trial_num = int(row['trial'])\n        start_idx = (trial_num - 1) * SAMPLES_PER_TRIAL_FULL + SAMPLES_TO_SKIP\n        end_idx = start_idx + SAMPLES_PER_SSVEP_TRIAL\n        \n        # Extract the relevant data and apply CAR\n        trial_eeg_data = eeg_data.loc[start_idx:end_idx-1, EEG_CHANNELS].values\n        return apply_car_preprocessing(trial_eeg_data)\n        \n    except (FileNotFoundError, KeyError) as e:\n        print(f\"Error loading trial {row.get('id', 'N/A')}: {e} for path {eeg_path}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:35:43.895041Z","iopub.execute_input":"2025-09-11T23:35:43.895400Z","iopub.status.idle":"2025-09-11T23:35:43.904139Z","shell.execute_reply.started":"2025-09-11T23:35:43.895374Z","shell.execute_reply":"2025-09-11T23:35:43.903037Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Signal Processing & Filterbank Utilities\nThese functions build the necessary tools for frequency-domain analysis. We define a refined filterbank for FBCCA and a function to generate the synthetic sine-cosine reference signals required for CCA.","metadata":{}},{"cell_type":"code","source":"def get_refined_filterbank():\n    \"\"\"Creates a set of Chebyshev and narrow-band bandpass filters for FBCCA.\"\"\"\n    # Broad frequency bands\n    filter_bands = [[6 + i * 8, 14 + i * 8] for i in range(5)]\n    # Narrow bands centered around target frequencies\n    for freq in SSVEP_FREQUENCIES_LIST:\n        filter_bands.append([freq - 1, freq + 1])\n    \n    # Create filter coefficients, ensuring the high-pass frequency is below Nyquist\n    return [cheby1(5, 0.1, [l/(0.5*SAMPLING_RATE), h/(0.5*SAMPLING_RATE)], btype='band') \n            for l, h in filter_bands if h <= 125]\n\ndef apply_filterbank(eeg_data, filters):\n    \"\"\"Applies a bank of filters to the EEG data.\"\"\"\n    return np.array([filtfilt(b, a, eeg_data, axis=0) for b, a in filters])\n\ndef get_reference_signals(duration_samples, frequencies):\n    \"\"\"Generates sine and cosine reference signals for each target frequency and its harmonics.\"\"\"\n    t = np.arange(duration_samples) / SAMPLING_RATE\n    return {freq: np.array([m(2 * np.pi * freq * h * t) for h in range(1, NUM_HARMONICS + 1) for m in [np.sin, np.cos]]).T \n            for freq in frequencies}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:35:48.471223Z","iopub.execute_input":"2025-09-11T23:35:48.471588Z","iopub.status.idle":"2025-09-11T23:35:48.480228Z","shell.execute_reply.started":"2025-09-11T23:35:48.471561Z","shell.execute_reply":"2025-09-11T23:35:48.479011Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Feature Engineering Functions\nThis is the core of the feature extraction pipeline. We define a diverse set of functions to capture different aspects of the SSVEP response from the EEG signal. The features range from spatial filtering (TRCA) and frequency correlation (FBCCA) to phase synchronization (PLV) and power analysis (PSD, SNR). A key innovation is the use of subject-specific templates, which capture the unique neural response patterns of each individual.","metadata":{}},{"cell_type":"code","source":"def extract_subject_specific_templates(X_train, y_train, subjects_train):\n    \"\"\"Creates subject-specific and global average SSVEP templates for each class.\"\"\"\n    subject_templates, global_templates = {}, {}\n    \n    # Create global templates as a fallback\n    for class_label in CLASS_LABELS:\n        class_trials = X_train[y_train == class_label]\n        global_templates[class_label] = np.mean(class_trials, axis=0) if len(class_trials) > 0 else np.zeros((SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)))\n    \n    # Create subject-specific templates\n    for subject in np.unique(subjects_train):\n        subject_templates[subject] = {}\n        for class_label in CLASS_LABELS:\n            mask = (subjects_train == subject) & (y_train == class_label)\n            # Use subject-specific average if enough trials exist, otherwise use global template\n            subject_templates[subject][class_label] = np.mean(X_train[mask], axis=0) if np.sum(mask) >= 2 else global_templates[class_label]\n            \n    return subject_templates, global_templates\n\ndef get_template_correlation_features(eeg_trial, subject_templates, global_templates, subject_id):\n    \"\"\"Calculates correlation, power, and phase coherence between a trial and learned templates.\"\"\"\n    templates_to_use = subject_templates.get(subject_id, global_templates)\n    correlations = []\n    for class_label in CLASS_LABELS:\n        template = templates_to_use.get(class_label, global_templates[class_label])\n        # Calculate multiple correlation types\n        channel_corrs = [np.corrcoef(eeg_trial[:, ch], template[:, ch])[0, 1] for ch in range(eeg_trial.shape[1])]\n        trial_power = np.mean(eeg_trial**2, axis=0)\n        template_power = np.mean(template**2, axis=0)\n        power_corr = np.corrcoef(trial_power, template_power)[0, 1]\n        trial_phase = np.angle(hilbert(eeg_trial, axis=0))\n        template_phase = np.angle(hilbert(template, axis=0))\n        phase_coherence = np.mean(np.abs(np.mean(np.exp(1j * (trial_phase - template_phase)), axis=0)))\n        \n        correlations.extend([np.nanmean(channel_corrs), power_corr, phase_coherence])\n    return np.nan_to_num(np.array(correlations))\n\ndef get_plv_features(eeg_trial):\n    \"\"\"Calculates Phase-Locking Value (PLV) between all channel pairs for each target frequency.\"\"\"\n    plv_features = []\n    for target_freq in SSVEP_FREQUENCIES_LIST:\n        low, high = max(1, target_freq - 1), min(125, target_freq + 1)\n        b, a = butter(4, [low/(0.5*SAMPLING_RATE), high/(0.5*SAMPLING_RATE)], btype='band')\n        filtered_phases = [np.angle(hilbert(filtfilt(b, a, eeg_trial[:, ch]))) for ch in range(eeg_trial.shape[1])]\n        for i in range(len(filtered_phases)):\n            for j in range(i + 1, len(filtered_phases)):\n                plv = np.abs(np.mean(np.exp(1j * (filtered_phases[i] - filtered_phases[j]))))\n                plv_features.append(plv)\n    return np.array(plv_features)\n\ndef get_enhanced_cca_features(filtered_eeg_bank, reference_signals):\n    \"\"\"Calculates enhanced CCA correlation features from a filterbank of EEG signals.\"\"\"\n    enhanced_features = []\n    for filtered_eeg in filtered_eeg_bank:\n        for freq in SSVEP_FREQUENCIES_LIST:\n            ref_sig = reference_signals[freq]\n            cca = CCA(n_components=1)\n            cca.fit(filtered_eeg, ref_sig)\n            X_c, Y_c = cca.transform(filtered_eeg, ref_sig)\n            corr = np.corrcoef(X_c.T, Y_c.T)[0, 1]\n            enhanced_features.append(corr)\n    return np.nan_to_num(np.array(enhanced_features))\n\ndef get_optimized_spatial_filters(X_train, y_train, labels):\n    \"\"\"Computes spatial filters that maximize inter-trial covariance for each class (related to TRCA).\"\"\"\n    spatial_filters = {}\n    for label in labels:\n        class_trials = X_train[y_train == label]\n        if len(class_trials) < 2:\n            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n            continue\n        S = np.sum([np.cov(t.T) for t in class_trials], axis=0)\n        Q = np.cov(np.mean(class_trials, axis=0).T)\n        reg = 1e-5 * np.eye(S.shape[0])\n        try:\n            _, evecs = eigh(Q, S + reg)\n            spatial_filters[label] = evecs[:, -1]\n        except np.linalg.LinAlgError:\n            spatial_filters[label] = np.ones(X_train.shape[2]) / X_train.shape[2]\n    return spatial_filters\n\ndef extract_trca_features(eeg_trial, spatial_filters):\n    \"\"\"Applies spatial filters and calculates correlation with the mean template.\"\"\"\n    features = []\n    # Create a single template from the current trial\n    trial_template = np.mean(eeg_trial, axis=0)\n    \n    for label, w in spatial_filters.items():\n        proj_trial = eeg_trial @ w\n        proj_template = trial_template @ w\n        \n        # Create a template signal by repeating the projected template value\n        template_signal = np.full_like(proj_trial, proj_template)\n        \n        # Calculate correlation between projected trial and template signal\n        if np.std(proj_trial) > 1e-10 and np.std(template_signal) > 1e-10:\n            corr = np.corrcoef(proj_trial, template_signal)[0, 1]\n        else:\n            corr = 0.0\n        features.append(corr)\n    return np.nan_to_num(np.array(features))\n\ndef get_psd_features(eeg_trial):\n    \"\"\"Computes Power Spectral Density (PSD) features around target frequencies and their harmonics.\"\"\"\n    psd_features = []\n    freqs, psd = welch(eeg_trial, fs=SAMPLING_RATE, nperseg=eeg_trial.shape[0], axis=0)\n    for target_freq in SSVEP_FREQUENCIES_LIST:\n        for h in range(1, NUM_HARMONICS + 1):\n            harmonic_freq = target_freq * h\n            if harmonic_freq <= freqs[-1]:\n                idx = np.argmin(np.abs(freqs - harmonic_freq))\n                # Average power in a small band around the target frequency, across all channels\n                psd_features.append(np.mean(psd[idx, :]))\n            else:\n                psd_features.append(0)\n    return np.array(psd_features)\n\ndef get_snr_features(eeg_trial):\n    \"\"\"Computes Signal-to-Noise Ratio (SNR) at target frequencies.\"\"\"\n    snr_features = []\n    freqs, psd = welch(eeg_trial, fs=SAMPLING_RATE, nperseg=eeg_trial.shape[0], axis=0)\n    for target_freq in SSVEP_FREQUENCIES_LIST:\n        idx = np.argmin(np.abs(freqs - target_freq))\n        if 2 < idx < len(psd) - 2:\n            signal_power = np.mean(psd[idx, :])\n            # Noise is estimated from neighboring frequency bins\n            noise_power = np.mean(psd[[idx-2, idx-1, idx+1, idx+2], :])\n            snr_features.append(signal_power / (noise_power + 1e-10))\n        else:\n            snr_features.append(0)\n    return np.array(snr_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:35:51.858278Z","iopub.execute_input":"2025-09-11T23:35:51.858612Z","iopub.status.idle":"2025-09-11T23:35:51.884566Z","shell.execute_reply.started":"2025-09-11T23:35:51.858586Z","shell.execute_reply":"2025-09-11T23:35:51.883355Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Master Feature Extraction Pipeline\nThis function acts as an orchestrator. For each EEG trial, it calls all the individual feature engineering functions defined above and concatenates their outputs into a single, comprehensive feature vector. This vector will be the input to our machine learning model.","metadata":{}},{"cell_type":"code","source":"def extract_all_features(eeg_trial, filters, reference_signals, spatial_filters, subject_templates, global_templates, subject_id):\n    \"\"\"\n    Combines all feature extraction methods into a single function to generate a complete feature vector.\n    \"\"\"\n    # Apply filterbank for FBCCA\n    filtered_bank = apply_filterbank(eeg_trial, filters)\n    \n    # Extract features from each domain\n    fbcca_feat = get_enhanced_cca_features(filtered_bank, reference_signals)\n    trca_feat = extract_trca_features(eeg_trial, spatial_filters)\n    plv_feat = get_plv_features(eeg_trial)\n    psd_feat = get_psd_features(eeg_trial)\n    snr_feat = get_snr_features(eeg_trial)\n    template_corr_feat = get_template_correlation_features(eeg_trial, subject_templates, global_templates, subject_id)\n    \n    # Concatenate all features into one vector\n    return np.concatenate([trca_feat, fbcca_feat, plv_feat, psd_feat, snr_feat, template_corr_feat])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:35:55.604752Z","iopub.execute_input":"2025-09-11T23:35:55.605181Z","iopub.status.idle":"2025-09-11T23:35:55.611595Z","shell.execute_reply.started":"2025-09-11T23:35:55.605154Z","shell.execute_reply":"2025-09-11T23:35:55.610426Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Main - Data Loading and Preparation\nThe main execution begins here. This cell handles the initial data loading and preparation steps:\n\n1. Loads the outlier list from the provided CSV.\n\n1. Loads the main `train.csv`, `validation.csv`, and `test.csv` files.\n\n1. Filters out the identified outlier trials from the training and validation sets. (This had its own outlier analysis and generated a file specifying which trails are too extreme and need to be removed)\n\n1. Loads the supplementary imitation dataset to augment our training data.\n\n1. Combines all data sources into a single `full_train_df` for model training.","metadata":{}},{"cell_type":"code","source":"# [STEP 1 & 2] Load outlier list and main competition dataset\nprint(\"[STEP 1 & 2] Loading outliers and main dataset...\")\ntry:\n    outliers_df = pd.read_csv(OUTLIER_CSV_PATH)\n    print(f\"✅ Success: Found {len(outliers_df)} trials marked for exclusion.\")\nexcept FileNotFoundError:\n    print(f\"⚠️ Warning: Outlier file not found. Proceeding without excluding trials.\")\n    outliers_df = pd.DataFrame()\n\ntrain_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\nvalidation_df = pd.read_csv(os.path.join(BASE_PATH, 'validation.csv'))\ntest_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n\n# Filter for SSVEP task only\ntrain_ssvep = train_df[train_df['task'] == 'SSVEP'].copy()\nvalidation_ssvep = validation_df[validation_df['task'] == 'SSVEP'].copy()\ntest_ssvep = test_df[test_df['task'] == 'SSVEP'].reset_index(drop=True)\nprint(\"✅ Success: Main dataset loaded.\")\n\n# [STEP 3] Filter out the specified outliers\nif not outliers_df.empty:\n    print(\"\\n[STEP 3] Filtering outlier trials from the dataset...\")\n    # Create a unique key for merging\n    outliers_df['outlier_key'] = outliers_df['subject_number'].astype(str) + '_' + outliers_df['session_number'].astype(str) + '_' + outliers_df['trial_number'].astype(str)\n    train_ssvep['subject_number'] = train_ssvep['subject_id'].str.replace('S', '').astype(int)\n    train_ssvep['trial_key'] = train_ssvep['subject_number'].astype(str) + '_' + train_ssvep['trial_session'].astype(str) + '_' + train_ssvep['trial'].astype(str)\n    \n    # Keep only rows that are not in the outlier list\n    initial_train_count = len(train_ssvep)\n    train_ssvep = train_ssvep[~train_ssvep['trial_key'].isin(outliers_df['outlier_key'])].drop(columns=['subject_number', 'trial_key'])\n    print(f\"Removed {initial_train_count - len(train_ssvep)} trials from the training set.\")\n    print(\"✅ Success: Filtering complete.\")\n\n# [STEP 4] Load supplementary imitation dataset and combine\nprint(\"\\n[STEP 4] Loading and combining supplementary imitation dataset...\")\nimitation_dfs = []\nfor session in [1, 2]:\n    label_path = os.path.join(IMITATION_BASE_PATH, str(session), 'trial_labels.csv')\n    temp_df = pd.read_csv(label_path)\n    temp_df['subject_id'] = 'IMITATION_S1'\n    temp_df['trial_session'] = session\n    temp_df['task'] = 'SSVEP'\n    temp_df.rename(columns={'direction': 'label'}, inplace=True)\n    temp_df['id'] = 20000 + (session * 100) + temp_df.index # Unique ID\n    imitation_dfs.append(temp_df)\nimitation_df = pd.concat(imitation_dfs, ignore_index=True)\nprint(f\"✅ Success: Loaded {len(imitation_df)} supplementary trials.\")\n\n# Combine all data for training\nfull_train_df = pd.concat([train_ssvep, validation_ssvep, imitation_df]).reset_index(drop=True)\nprint(f\"\\nTotal training data after filtering and augmentation: {len(full_train_df)} trials\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:36:03.478140Z","iopub.execute_input":"2025-09-11T23:36:03.478464Z","iopub.status.idle":"2025-09-11T23:36:03.617447Z","shell.execute_reply.started":"2025-09-11T23:36:03.478438Z","shell.execute_reply":"2025-09-11T23:36:03.616045Z"}},"outputs":[{"name":"stdout","text":"[STEP 1 & 2] Loading outliers and main dataset...\n✅ Success: Found 86 trials marked for exclusion.\n✅ Success: Main dataset loaded.\n\n[STEP 3] Filtering outlier trials from the dataset...\nRemoved 65 trials from the training set.\n✅ Success: Filtering complete.\n\n[STEP 4] Loading and combining supplementary imitation dataset...\n✅ Success: Loaded 20 supplementary trials.\n\nTotal training data after filtering and augmentation: 2405 trials\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Model Training Pipeline\nThis cell executes the core model training process.\n\n1. Loads all raw EEG trials into memory.\n   \n1. Generates the necessary assets for feature extraction (templates, spatial filters, reference signals).\n\n1. Iterates through the training data, applying the `extract_all_features` function to each trial.\n\n1. Defines the ensemble model: a `VotingClassifier` combining XGBoost, SVC, and LDA.\n\n1. Scales the features using `StandardScaler`.\n\n1. Trains the final ensemble model on the complete, scaled feature set.","metadata":{}},{"cell_type":"code","source":"print(\"\\n[STEP 5] Pre-computing features and training model...\")\n\n# Generate assets for feature extraction\nreference_signals = get_reference_signals(SAMPLES_PER_SSVEP_TRIAL, SSVEP_FREQUENCIES_LIST)\nfilters = get_refined_filterbank()\n\n# Load all raw training data into memory\nX_train_raw, y_train, subjects_train = [], [], []\nfor _, row in full_train_df.iterrows():\n    trial_data = load_trial_data(row, BASE_PATH, IMITATION_BASE_PATH)\n    if trial_data is not None and trial_data.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n        X_train_raw.append(trial_data)\n        y_train.append(row['label'])\n        subjects_train.append(row['subject_id'])\n        \nX_train, y_train, subjects_train = np.array(X_train_raw), np.array(y_train), np.array(subjects_train)\n\n# Encode labels\nle = LabelEncoder()\ny_train_encoded = le.fit_transform(y_train)\n\n# Create subject-specific assets from the training data\nsubject_templates, global_templates = extract_subject_specific_templates(X_train, y_train, subjects_train)\nspatial_filters = get_optimized_spatial_filters(X_train, y_train, CLASS_LABELS)\n\n# Extract features for the entire training set\nX_train_features = np.array([extract_all_features(trial, filters, reference_signals, spatial_filters, subject_templates, global_templates, sub_id) \n                             for trial, sub_id in zip(X_train, subjects_train)])\n\n# Define the ensemble model with tuned hyperparameters\nclf1 = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', learning_rate=0.1, max_depth=4, n_estimators=150)\nclf2 = SVC(probability=True, random_state=42, C=100, kernel='rbf', gamma='scale')\nclf3 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\nensemble_model = VotingClassifier(estimators=[('xgb', clf1), ('svc', clf2), ('lda', clf3)], voting='soft', weights=[0.5, 0.3, 0.2])\n\n# Scale features and train the model\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_features)\nensemble_model.fit(X_train_scaled, y_train_encoded)\n\nprint(\"✅ Success: Model training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:36:04.897012Z","iopub.execute_input":"2025-09-11T23:36:04.897361Z","iopub.status.idle":"2025-09-11T23:46:58.812457Z","shell.execute_reply.started":"2025-09-11T23:36:04.897333Z","shell.execute_reply":"2025-09-11T23:46:58.810670Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 5] Pre-computing features and training model...\n✅ Success: Model training complete.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Checkpointing, Prediction, and Submission\n\nIn the final cells, we save our entire trained pipeline and generate the final submission file.\n\n1. **Checkpointing**: All trained components—the model, scaler, label encoder, and feature extraction assets—are saved into a single pickle file. This allows for easy reloading and inference without retraining.\n\n1. **Prediction**: We loop through the test set, load each trial, extract its features using the pre-computed assets, and predict the label with our trained model.\n\n1. **Submission**: The predictions are formatted into the required submission.csv file.","metadata":{}},{"cell_type":"code","source":"# [STEP 6] Save the complete trained pipeline to a checkpoint file\nprint(\"\\n[STEP 6] Saving trained model and assets to checkpoint...\")\n\ncheckpoint = {\n    'model': ensemble_model,\n    'scaler': scaler,\n    'label_encoder': le,\n    'spatial_filters': spatial_filters,\n    'subject_templates': subject_templates,\n    'global_templates': global_templates,\n    'filter_bank': filters,\n    'ref_signals': reference_signals\n}\n\ncheckpoint_filename = 'ssvep_checkpoint.pkl'\nwith open(checkpoint_filename, 'wb') as f:\n    pickle.dump(checkpoint, f)\n    \nprint(f\"✅ Success: Checkpoint saved to '{checkpoint_filename}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:49:03.403600Z","iopub.execute_input":"2025-09-11T23:49:03.403925Z","iopub.status.idle":"2025-09-11T23:49:03.453012Z","shell.execute_reply.started":"2025-09-11T23:49:03.403899Z","shell.execute_reply":"2025-09-11T23:49:03.452035Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 6] Saving trained model and assets to checkpoint...\n✅ Success: Checkpoint saved to 'ssvep_checkpoint.pkl'\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# [STEP 7] Generate submission file for the test set\nprint(\"\\n[STEP 7] Generating submission file for the test set...\")\n\ntest_predictions = []\nfor _, row in test_ssvep.iterrows():\n    trial_data = load_trial_data(row, BASE_PATH, IMITATION_BASE_PATH)\n    if trial_data is not None and trial_data.shape == (SAMPLES_PER_SSVEP_TRIAL, len(EEG_CHANNELS)):\n        # Extract features for the test trial\n        test_features = extract_all_features(trial_data, filters, reference_signals, spatial_filters, subject_templates, global_templates, row['subject_id']).reshape(1, -1)\n        # Scale and predict\n        test_features_scaled = scaler.transform(test_features)\n        prediction_encoded = ensemble_model.predict(test_features_scaled)[0]\n        # Decode the prediction back to the original label\n        test_predictions.append(le.inverse_transform([prediction_encoded])[0])\n    else:\n        # Fallback to the most frequent class if data loading fails\n        test_predictions.append(pd.Series(y_train).mode()[0])\n        \n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({'id': test_ssvep['id'], 'label': test_predictions})\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(f\"\\n✅ All steps complete. Submission file 'submission.csv' created successfully!\")\nprint(\"\\nPredictions summary:\\n\", submission_df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T23:49:09.490041Z","iopub.execute_input":"2025-09-11T23:49:09.490395Z","iopub.status.idle":"2025-09-11T23:49:39.645284Z","shell.execute_reply.started":"2025-09-11T23:49:09.490368Z","shell.execute_reply":"2025-09-11T23:49:39.644122Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 7] Generating submission file for the test set...\n\n✅ All steps complete. Submission file 'submission.csv' created successfully!\n\nPredictions summary:\n label\nLeft        33\nBackward    28\nForward     23\nRight       16\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}